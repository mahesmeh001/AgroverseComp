{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "log=\"\"\"Total agents: 1500\n",
    "Pruned due to zero frame in Tobs+Tpred: 1209\n",
    "Pruned due to zero frame in observed or future window: 2\n",
    "Remaining valid agents: 289\n",
    "Training on 289 valid agent trajectories.\n",
    "Input shape: (289, 50, 6), Delta Output shape: (289, 60, 2)\n",
    "X_train NaNs: 0\n",
    "y_train NaNs: 0\n",
    "Any std == 0? False False\n",
    "ğŸ”§ GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=3\n",
    "\n",
    "--- Phase 1: Training ---\n",
    "ğŸš€ GradientMonitoringCallback: Training started!\n",
    "Epoch 1/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 293ms/step - loss: 0.9189 - mae: 0.2264   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âš ï¸  WARNING: Variable norm 1.73e-06 is too small (layer 20)\n",
    "   âš ï¸  Found 1 norm warnings\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 212ms/step - loss: 0.9447 - mae: 0.2298   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âš ï¸  WARNING: Variable norm 7.49e-06 is too small (layer 20)\n",
    "   âš ï¸  Found 1 norm warnings\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 190ms/step - loss: 0.9633 - mae: 0.2315   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âš ï¸  WARNING: Variable norm 1.20e-05 is too small (layer 20)\n",
    "   âš ï¸  Found 1 norm warnings\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 358ms/step - loss: 0.9731 - mae: 0.2319\n",
    "Epoch 2/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 272ms/step - loss: 0.9546 - mae: 0.2228   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âš ï¸  WARNING: Variable norm 1.45e-05 is too small (layer 20)\n",
    "   âš ï¸  Found 1 norm warnings\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 169ms/step - loss: 0.9671 - mae: 0.2203   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âš ï¸  WARNING: Variable norm 2.62e-05 is too small (layer 20)\n",
    "   âš ï¸  Found 1 norm warnings\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 0.9906 - mae: 0.2211   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âš ï¸  WARNING: Variable norm 3.48e-05 is too small (layer 20)\n",
    "   âš ï¸  Found 1 norm warnings\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 168ms/step - loss: 0.9934 - mae: 0.2209\n",
    "Epoch 3/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âš ï¸  WARNING: Variable norm 4.05e-05 is too small (layer 20)\n",
    "   âš ï¸  Found 1 norm warnings\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 165ms/step - loss: 1.0719 - mae: 0.2328   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âš ï¸  WARNING: Variable norm 4.51e-05 is too small (layer 20)\n",
    "   âš ï¸  Found 1 norm warnings\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 158ms/step - loss: 1.0339 - mae: 0.2271   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âš ï¸  WARNING: Variable norm 5.01e-05 is too small (layer 20)\n",
    "   âš ï¸  Found 1 norm warnings\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 160ms/step - loss: 1.0200 - mae: 0.2239   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âš ï¸  WARNING: Variable norm 5.49e-05 is too small (layer 20)\n",
    "   âš ï¸  Found 1 norm warnings\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 162ms/step - loss: 1.0151 - mae: 0.2226\n",
    "Epoch 4/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 208ms/step - loss: 0.9648 - mae: 0.2086   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âš ï¸  WARNING: Variable norm 5.74e-05 is too small (layer 20)\n",
    "   âš ï¸  Found 1 norm warnings\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 174ms/step - loss: 0.9521 - mae: 0.2112   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âš ï¸  WARNING: Variable norm 6.16e-05 is too small (layer 20)\n",
    "   âš ï¸  Found 1 norm warnings\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 0.9530 - mae: 0.2113   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âš ï¸  WARNING: Variable norm 6.96e-05 is too small (layer 20)\n",
    "   âš ï¸  Found 1 norm warnings\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 168ms/step - loss: 0.9625 - mae: 0.2123\n",
    "Epoch 5/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 199ms/step - loss: 0.8510 - mae: 0.2071   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âš ï¸  WARNING: Variable norm 8.35e-05 is too small (layer 20)\n",
    "   âš ï¸  Found 1 norm warnings\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 229ms/step - loss: 0.9660 - mae: 0.2156   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 220ms/step - loss: 0.9626 - mae: 0.2145   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 202ms/step - loss: 0.9735 - mae: 0.2148\n",
    "Epoch 6/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 159ms/step - loss: 0.9477 - mae: 0.2108   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 158ms/step - loss: 0.9634 - mae: 0.2119   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 159ms/step - loss: 0.9696 - mae: 0.2124   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 162ms/step - loss: 0.9729 - mae: 0.2128\n",
    "Epoch 7/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 159ms/step - loss: 0.9736 - mae: 0.2180   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 159ms/step - loss: 0.9455 - mae: 0.2127   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 158ms/step - loss: 0.9638 - mae: 0.2140   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 164ms/step - loss: 0.9694 - mae: 0.2142\n",
    "Epoch 8/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 193ms/step - loss: 1.0712 - mae: 0.2224   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 176ms/step - loss: 1.0690 - mae: 0.2210   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 175ms/step - loss: 1.0309 - mae: 0.2173   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 173ms/step - loss: 1.0149 - mae: 0.2165\n",
    "Epoch 9/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 159ms/step - loss: 1.0326 - mae: 0.2251   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 158ms/step - loss: 1.0004 - mae: 0.2195   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 160ms/step - loss: 0.9872 - mae: 0.2171   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 163ms/step - loss: 0.9865 - mae: 0.2166\n",
    "Epoch 10/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 170ms/step - loss: 0.9070 - mae: 0.2099   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 0.9536 - mae: 0.2132   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 0.9674 - mae: 0.2139   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 168ms/step - loss: 0.9711 - mae: 0.2139\n",
    "Epoch 11/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 217ms/step - loss: 1.0596 - mae: 0.2179   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 199ms/step - loss: 1.0098 - mae: 0.2141   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 201ms/step - loss: 0.9945 - mae: 0.2132   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 213ms/step - loss: 0.9871 - mae: 0.2135\n",
    "Epoch 12/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 186ms/step - loss: 0.9362 - mae: 0.2109   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 189ms/step - loss: 0.9572 - mae: 0.2127   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 297ms/step - loss: 0.9622 - mae: 0.2132   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 301ms/step - loss: 0.9644 - mae: 0.2136\n",
    "Epoch 13/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 178ms/step - loss: 1.1109 - mae: 0.2350   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 1.0662 - mae: 0.2289   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 1.0372 - mae: 0.2250   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 184ms/step - loss: 1.0191 - mae: 0.2226\n",
    "Epoch 14/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 229ms/step - loss: 1.0268 - mae: 0.2223   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 172ms/step - loss: 0.9972 - mae: 0.2164   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 0.9964 - mae: 0.2179   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 168ms/step - loss: 0.9865 - mae: 0.2179\n",
    "Epoch 15/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 170ms/step - loss: 0.9958 - mae: 0.2208   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 0.9731 - mae: 0.2190   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 0.9693 - mae: 0.2185   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 166ms/step - loss: 0.9670 - mae: 0.2185\n",
    "Epoch 16/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 179ms/step - loss: 1.0588 - mae: 0.2365   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 161ms/step - loss: 1.0248 - mae: 0.2305   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 159ms/step - loss: 1.0076 - mae: 0.2283   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 160ms/step - loss: 0.9910 - mae: 0.2259\n",
    "Epoch 17/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 159ms/step - loss: 0.9675 - mae: 0.2213   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 199ms/step - loss: 0.9805 - mae: 0.2244   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 179ms/step - loss: 0.9766 - mae: 0.2235   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 192ms/step - loss: 0.9621 - mae: 0.2219\n",
    "Epoch 18/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 211ms/step - loss: 0.8852 - mae: 0.2108   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 0.8955 - mae: 0.2126   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 175ms/step - loss: 0.9058 - mae: 0.2146   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.45e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 185ms/step - loss: 0.9089 - mae: 0.2153\n",
    "Epoch 19/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 179ms/step - loss: 0.9564 - mae: 0.2219   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 159ms/step - loss: 0.9136 - mae: 0.2186   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 232ms/step - loss: 0.9070 - mae: 0.2176   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 223ms/step - loss: 0.9080 - mae: 0.2172\n",
    "Epoch 20/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 228ms/step - loss: 0.7966 - mae: 0.2029   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 185ms/step - loss: 0.8089 - mae: 0.2048   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 176ms/step - loss: 0.8272 - mae: 0.2061   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 177ms/step - loss: 0.8495 - mae: 0.2083\n",
    "Epoch 21/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 152ms/step - loss: 0.7977 - mae: 0.2019   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 160ms/step - loss: 0.8044 - mae: 0.2041   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 160ms/step - loss: 0.8290 - mae: 0.2067   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 162ms/step - loss: 0.8382 - mae: 0.2076\n",
    "Epoch 22/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 179ms/step - loss: 0.8986 - mae: 0.2130   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 163ms/step - loss: 0.8737 - mae: 0.2129   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 163ms/step - loss: 0.8720 - mae: 0.2128   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 163ms/step - loss: 0.8701 - mae: 0.2127\n",
    "Epoch 23/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 327ms/step - loss: 1.0480 - mae: 0.2353   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 488ms/step - loss: 0.8946 - mae: 0.2203   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 376ms/step - loss: 0.8754 - mae: 0.2183   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 304ms/step - loss: 0.8657 - mae: 0.2174\n",
    "Epoch 24/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 189ms/step - loss: 0.7910 - mae: 0.2154   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 0.8315 - mae: 0.2203   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.26e+01\n",
    "      Variable 2 norm: 2.26e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 201ms/step - loss: 0.8392 - mae: 0.2219   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 221ms/step - loss: 0.8383 - mae: 0.2222\n",
    "Epoch 25/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 331ms/step - loss: 0.8628 - mae: 0.2236   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 223ms/step - loss: 0.8136 - mae: 0.2215   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 201ms/step - loss: 0.8092 - mae: 0.2218   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 202ms/step - loss: 0.8111 - mae: 0.2223\n",
    "Epoch 26/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m3s\u001B[0m 365ms/step - loss: 0.7142 - mae: 0.2220   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m3s\u001B[0m 561ms/step - loss: 0.7434 - mae: 0.2211   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 555ms/step - loss: 0.7480 - mae: 0.2212   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 822ms/step - loss: 0.7630 - mae: 0.2220\n",
    "Epoch 27/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 386ms/step - loss: 0.7313 - mae: 0.2243   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 444ms/step - loss: 0.7374 - mae: 0.2245   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 455ms/step - loss: 0.7476 - mae: 0.2252   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 463ms/step - loss: 0.7519 - mae: 0.2255\n",
    "Epoch 28/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m3s\u001B[0m 410ms/step - loss: 0.7355 - mae: 0.2249   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 403ms/step - loss: 0.7498 - mae: 0.2249   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 390ms/step - loss: 0.7496 - mae: 0.2233   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 385ms/step - loss: 0.7495 - mae: 0.2229\n",
    "Epoch 29/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m4s\u001B[0m 494ms/step - loss: 0.7634 - mae: 0.2195   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 311ms/step - loss: 0.7617 - mae: 0.2207   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 352ms/step - loss: 0.7481 - mae: 0.2203   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 353ms/step - loss: 0.7419 - mae: 0.2203\n",
    "Epoch 30/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 289ms/step - loss: 0.6636 - mae: 0.2194   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 215ms/step - loss: 0.6867 - mae: 0.2200   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 332ms/step - loss: 0.6920 - mae: 0.2186   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 429ms/step - loss: 0.6957 - mae: 0.2180\n",
    "Epoch 31/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m3s\u001B[0m 379ms/step - loss: 0.7347 - mae: 0.2162   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 256ms/step - loss: 0.7098 - mae: 0.2133   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 407ms/step - loss: 0.7021 - mae: 0.2130   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 426ms/step - loss: 0.7009 - mae: 0.2134\n",
    "Epoch 32/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 247ms/step - loss: 0.7094 - mae: 0.2186   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m3s\u001B[0m 549ms/step - loss: 0.7363 - mae: 0.2193   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 502ms/step - loss: 0.7210 - mae: 0.2183   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 404ms/step - loss: 0.7071 - mae: 0.2168\n",
    "Epoch 33/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 160ms/step - loss: 0.7488 - mae: 0.2179   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 158ms/step - loss: 0.7317 - mae: 0.2155   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 0.7102 - mae: 0.2126   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 164ms/step - loss: 0.7022 - mae: 0.2114\n",
    "Epoch 34/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 182ms/step - loss: 0.5567 - mae: 0.1943   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 0.5927 - mae: 0.1989   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 178ms/step - loss: 0.6035 - mae: 0.2001   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 176ms/step - loss: 0.6165 - mae: 0.2013\n",
    "Epoch 35/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 195ms/step - loss: 0.5702 - mae: 0.1988   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 189ms/step - loss: 0.6105 - mae: 0.2002   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 359ms/step - loss: 0.6091 - mae: 0.2007   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 294ms/step - loss: 0.6183 - mae: 0.2018\n",
    "Epoch 36/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 152ms/step - loss: 0.6802 - mae: 0.2083   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 153ms/step - loss: 0.6538 - mae: 0.2055   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 0.6431 - mae: 0.2053   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 171ms/step - loss: 0.6393 - mae: 0.2053\n",
    "Epoch 37/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m6s\u001B[0m 849ms/step - loss: 0.6258 - mae: 0.1998   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 530ms/step - loss: 0.6501 - mae: 0.2065   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 594ms/step - loss: 0.6460 - mae: 0.2090   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 501ms/step - loss: 0.6365 - mae: 0.2092\n",
    "Epoch 38/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 242ms/step - loss: 0.7093 - mae: 0.2170   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 186ms/step - loss: 0.6455 - mae: 0.2100   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 0.6196 - mae: 0.2053   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 177ms/step - loss: 0.6132 - mae: 0.2026\n",
    "Epoch 39/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 163ms/step - loss: 0.6349 - mae: 0.1994   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 161ms/step - loss: 0.6026 - mae: 0.1987   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 163ms/step - loss: 0.6018 - mae: 0.1989   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 168ms/step - loss: 0.5995 - mae: 0.1988\n",
    "Epoch 40/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 172ms/step - loss: 0.6062 - mae: 0.2112   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 177ms/step - loss: 0.5770 - mae: 0.2023   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - loss: 0.5707 - mae: 0.1992   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 174ms/step - loss: 0.5725 - mae: 0.1980\n",
    "Epoch 41/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 247ms/step - loss: 0.5751 - mae: 0.1866   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 214ms/step - loss: 0.6158 - mae: 0.1904   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 313ms/step - loss: 0.6098 - mae: 0.1916   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 262ms/step - loss: 0.5959 - mae: 0.1923\n",
    "Epoch 42/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 153ms/step - loss: 0.5515 - mae: 0.1848   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 155ms/step - loss: 0.5609 - mae: 0.1870   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 0.5660 - mae: 0.1878   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 182ms/step - loss: 0.5649 - mae: 0.1877\n",
    "Epoch 43/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 159ms/step - loss: 0.5635 - mae: 0.1998   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.46e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 0.5582 - mae: 0.1960   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 0.5574 - mae: 0.1937   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 165ms/step - loss: 0.5563 - mae: 0.1921\n",
    "Epoch 44/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 232ms/step - loss: 0.4606 - mae: 0.1814   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 163ms/step - loss: 0.4645 - mae: 0.1831   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 0.4970 - mae: 0.1845   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 165ms/step - loss: 0.5145 - mae: 0.1852\n",
    "Epoch 45/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 167ms/step - loss: 0.6373 - mae: 0.1903   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 163ms/step - loss: 0.6154 - mae: 0.1886   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 0.5955 - mae: 0.1865   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 182ms/step - loss: 0.5855 - mae: 0.1855\n",
    "Epoch 46/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 153ms/step - loss: 0.5161 - mae: 0.1721   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 406ms/step - loss: 0.5188 - mae: 0.1756   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 397ms/step - loss: 0.5226 - mae: 0.1778   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 358ms/step - loss: 0.5252 - mae: 0.1792\n",
    "Epoch 47/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 263ms/step - loss: 0.5309 - mae: 0.1768   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 0.4978 - mae: 0.1754   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 162ms/step - loss: 0.5008 - mae: 0.1748   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 163ms/step - loss: 0.5090 - mae: 0.1748\n",
    "Epoch 48/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 158ms/step - loss: 0.4572 - mae: 0.1764   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 160ms/step - loss: 0.4718 - mae: 0.1755   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 157ms/step - loss: 0.4877 - mae: 0.1760   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 161ms/step - loss: 0.4929 - mae: 0.1762\n",
    "Epoch 49/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 152ms/step - loss: 0.5057 - mae: 0.1717   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 0.5130 - mae: 0.1725   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 0.5059 - mae: 0.1717   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 169ms/step - loss: 0.5064 - mae: 0.1718\n",
    "Epoch 50/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 194ms/step - loss: 0.5708 - mae: 0.1710   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 196ms/step - loss: 0.5277 - mae: 0.1699   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 191ms/step - loss: 0.5159 - mae: 0.1693   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 182ms/step - loss: 0.5103 - mae: 0.1693\n",
    "Epoch 51/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 176ms/step - loss: 0.5292 - mae: 0.1718   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 0.5021 - mae: 0.1718   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 176ms/step - loss: 0.4966 - mae: 0.1717   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 181ms/step - loss: 0.4959 - mae: 0.1715\n",
    "Epoch 52/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 218ms/step - loss: 0.4983 - mae: 0.1659   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 394ms/step - loss: 0.4945 - mae: 0.1656   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 296ms/step - loss: 0.4891 - mae: 0.1648   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 270ms/step - loss: 0.4878 - mae: 0.1647\n",
    "Epoch 53/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 214ms/step - loss: 0.5203 - mae: 0.1686   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 0.4996 - mae: 0.1672   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 163ms/step - loss: 0.4831 - mae: 0.1655   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 162ms/step - loss: 0.4803 - mae: 0.1644\n",
    "Epoch 54/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 199ms/step - loss: 0.4795 - mae: 0.1632   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 0.5013 - mae: 0.1693   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - loss: 0.4949 - mae: 0.1699   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 176ms/step - loss: 0.4908 - mae: 0.1701\n",
    "Epoch 55/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 153ms/step - loss: 0.4722 - mae: 0.1687   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 158ms/step - loss: 0.4953 - mae: 0.1724   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 162ms/step - loss: 0.4882 - mae: 0.1719   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 164ms/step - loss: 0.4817 - mae: 0.1707\n",
    "Epoch 56/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 172ms/step - loss: 0.5080 - mae: 0.1625   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 162ms/step - loss: 0.5248 - mae: 0.1647   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 0.5055 - mae: 0.1636   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 167ms/step - loss: 0.4884 - mae: 0.1617\n",
    "Epoch 57/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 173ms/step - loss: 0.4440 - mae: 0.1530   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 0.4504 - mae: 0.1546   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.27e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 247ms/step - loss: 0.4511 - mae: 0.1552   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 238ms/step - loss: 0.4509 - mae: 0.1553\n",
    "Epoch 58/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 173ms/step - loss: 0.4680 - mae: 0.1704   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 162ms/step - loss: 0.4471 - mae: 0.1686   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 159ms/step - loss: 0.4416 - mae: 0.1665   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 162ms/step - loss: 0.4425 - mae: 0.1657\n",
    "Epoch 59/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 215ms/step - loss: 0.3545 - mae: 0.1696   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 169ms/step - loss: 0.3976 - mae: 0.1657   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 0.4179 - mae: 0.1624   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 165ms/step - loss: 0.4252 - mae: 0.1607\n",
    "Epoch 60/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 197ms/step - loss: 0.5209 - mae: 0.1667   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 190ms/step - loss: 0.4940 - mae: 0.1630   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 0.4780 - mae: 0.1613   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 180ms/step - loss: 0.4694 - mae: 0.1603\n",
    "Epoch 61/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 184ms/step - loss: 0.3863 - mae: 0.1420   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 0.4305 - mae: 0.1469   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 0.4342 - mae: 0.1475   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 167ms/step - loss: 0.4318 - mae: 0.1473\n",
    "Epoch 62/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 194ms/step - loss: 0.5144 - mae: 0.1698   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 177ms/step - loss: 0.4774 - mae: 0.1681   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 174ms/step - loss: 0.4539 - mae: 0.1676   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 172ms/step - loss: 0.4430 - mae: 0.1673\n",
    "Epoch 63/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 160ms/step - loss: 0.4598 - mae: 0.1618   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 159ms/step - loss: 0.4488 - mae: 0.1612   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 159ms/step - loss: 0.4357 - mae: 0.1585   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 164ms/step - loss: 0.4320 - mae: 0.1574\n",
    "Epoch 64/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m4s\u001B[0m 565ms/step - loss: 0.4533 - mae: 0.1664   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 332ms/step - loss: 0.4427 - mae: 0.1618   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 263ms/step - loss: 0.4271 - mae: 0.1609   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 241ms/step - loss: 0.4220 - mae: 0.1608\n",
    "Epoch 65/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 247ms/step - loss: 0.4439 - mae: 0.1467   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 0.4111 - mae: 0.1451   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 0.4154 - mae: 0.1448   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 168ms/step - loss: 0.4112 - mae: 0.1437\n",
    "Epoch 66/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 192ms/step - loss: 0.3454 - mae: 0.1300   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 192ms/step - loss: 0.3674 - mae: 0.1325   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 190ms/step - loss: 0.3770 - mae: 0.1343   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 192ms/step - loss: 0.3806 - mae: 0.1351\n",
    "Epoch 67/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 170ms/step - loss: 0.4623 - mae: 0.1438   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 0.4255 - mae: 0.1458   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - loss: 0.4157 - mae: 0.1461   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.47e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 174ms/step - loss: 0.4092 - mae: 0.1462\n",
    "Epoch 68/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 201ms/step - loss: 0.5014 - mae: 0.1494   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 170ms/step - loss: 0.4353 - mae: 0.1433   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 0.4182 - mae: 0.1419   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 168ms/step - loss: 0.4083 - mae: 0.1402\n",
    "Epoch 69/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 156ms/step - loss: 0.3693 - mae: 0.1527   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 158ms/step - loss: 0.3651 - mae: 0.1531   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 162ms/step - loss: 0.3686 - mae: 0.1537   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 166ms/step - loss: 0.3715 - mae: 0.1541\n",
    "Epoch 70/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m5s\u001B[0m 707ms/step - loss: 0.4796 - mae: 0.1605   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 560ms/step - loss: 0.4398 - mae: 0.1528   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 414ms/step - loss: 0.4196 - mae: 0.1496   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 388ms/step - loss: 0.4085 - mae: 0.1476\n",
    "Epoch 71/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 261ms/step - loss: 0.4061 - mae: 0.1483   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 177ms/step - loss: 0.3865 - mae: 0.1500   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 175ms/step - loss: 0.3847 - mae: 0.1486   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 185ms/step - loss: 0.3815 - mae: 0.1468\n",
    "Epoch 72/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 184ms/step - loss: 0.3741 - mae: 0.1402   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 178ms/step - loss: 0.3707 - mae: 0.1418   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - loss: 0.3721 - mae: 0.1425   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 173ms/step - loss: 0.3717 - mae: 0.1428\n",
    "Epoch 73/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 161ms/step - loss: 0.3836 - mae: 0.1475   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 163ms/step - loss: 0.3761 - mae: 0.1402   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 233ms/step - loss: 0.3692 - mae: 0.1385   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 233ms/step - loss: 0.3678 - mae: 0.1375\n",
    "Epoch 74/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 196ms/step - loss: 0.3370 - mae: 0.1302   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 169ms/step - loss: 0.3733 - mae: 0.1378   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 0.3728 - mae: 0.1390   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 169ms/step - loss: 0.3686 - mae: 0.1401\n",
    "Epoch 75/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 189ms/step - loss: 0.3866 - mae: 0.1355   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 176ms/step - loss: 0.3700 - mae: 0.1345   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - loss: 0.3650 - mae: 0.1345   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 173ms/step - loss: 0.3632 - mae: 0.1346\n",
    "Epoch 76/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 236ms/step - loss: 0.3827 - mae: 0.1457   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 207ms/step - loss: 0.3820 - mae: 0.1444   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 193ms/step - loss: 0.3707 - mae: 0.1420   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 195ms/step - loss: 0.3655 - mae: 0.1406\n",
    "Epoch 77/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 256ms/step - loss: 0.3536 - mae: 0.1548   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 175ms/step - loss: 0.3567 - mae: 0.1474   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 177ms/step - loss: 0.3456 - mae: 0.1415   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 181ms/step - loss: 0.3465 - mae: 0.1388\n",
    "Epoch 78/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 185ms/step - loss: 0.4321 - mae: 0.1338   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 176ms/step - loss: 0.3965 - mae: 0.1316   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 246ms/step - loss: 0.3802 - mae: 0.1312   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 306ms/step - loss: 0.3735 - mae: 0.1311\n",
    "Epoch 79/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m3s\u001B[0m 470ms/step - loss: 0.3409 - mae: 0.1341   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 264ms/step - loss: 0.3361 - mae: 0.1311   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 248ms/step - loss: 0.3386 - mae: 0.1313   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 237ms/step - loss: 0.3390 - mae: 0.1312\n",
    "Epoch 80/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 225ms/step - loss: 0.3288 - mae: 0.1234   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 199ms/step - loss: 0.3251 - mae: 0.1282   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 188ms/step - loss: 0.3251 - mae: 0.1292   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 192ms/step - loss: 0.3301 - mae: 0.1298\n",
    "Epoch 81/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 275ms/step - loss: 0.3950 - mae: 0.1333   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 220ms/step - loss: 0.3757 - mae: 0.1329   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 297ms/step - loss: 0.3624 - mae: 0.1326   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 284ms/step - loss: 0.3574 - mae: 0.1326\n",
    "Epoch 82/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 168ms/step - loss: 0.2937 - mae: 0.1219   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 0.3033 - mae: 0.1233   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 163ms/step - loss: 0.3148 - mae: 0.1242   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 165ms/step - loss: 0.3196 - mae: 0.1245\n",
    "Epoch 83/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 169ms/step - loss: 0.3241 - mae: 0.1233   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 168ms/step - loss: 0.3171 - mae: 0.1261   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 178ms/step - loss: 0.3210 - mae: 0.1279   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 176ms/step - loss: 0.3244 - mae: 0.1288\n",
    "Epoch 84/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 158ms/step - loss: 0.2796 - mae: 0.1197   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 0.2902 - mae: 0.1204   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 0.3019 - mae: 0.1222   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 168ms/step - loss: 0.3068 - mae: 0.1230\n",
    "Epoch 85/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 182ms/step - loss: 0.3191 - mae: 0.1309   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - loss: 0.3160 - mae: 0.1339   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 0.3190 - mae: 0.1332   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 168ms/step - loss: 0.3212 - mae: 0.1335\n",
    "Epoch 86/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 190ms/step - loss: 0.3197 - mae: 0.1218   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 347ms/step - loss: 0.3400 - mae: 0.1255   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 285ms/step - loss: 0.3399 - mae: 0.1283   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 243ms/step - loss: 0.3339 - mae: 0.1282\n",
    "Epoch 87/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 162ms/step - loss: 0.3065 - mae: 0.1330   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 162ms/step - loss: 0.3114 - mae: 0.1324   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 161ms/step - loss: 0.3138 - mae: 0.1319   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 164ms/step - loss: 0.3145 - mae: 0.1316\n",
    "Epoch 88/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 216ms/step - loss: 0.3284 - mae: 0.1401   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 0.3197 - mae: 0.1423   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 174ms/step - loss: 0.3139 - mae: 0.1411   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 176ms/step - loss: 0.3139 - mae: 0.1399\n",
    "Epoch 89/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 187ms/step - loss: 0.3118 - mae: 0.1410   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 169ms/step - loss: 0.2845 - mae: 0.1288   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 0.2897 - mae: 0.1280   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 167ms/step - loss: 0.2972 - mae: 0.1274\n",
    "Epoch 90/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 163ms/step - loss: 0.3014 - mae: 0.1198   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 162ms/step - loss: 0.3088 - mae: 0.1224   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 0.3092 - mae: 0.1239   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 210ms/step - loss: 0.3087 - mae: 0.1248\n",
    "Epoch 91/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 285ms/step - loss: 0.2872 - mae: 0.1147   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 199ms/step - loss: 0.3049 - mae: 0.1231   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 0.3053 - mae: 0.1257   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 180ms/step - loss: 0.3046 - mae: 0.1268\n",
    "Epoch 92/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 248ms/step - loss: 0.2747 - mae: 0.1172   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 169ms/step - loss: 0.2984 - mae: 0.1246   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 201ms/step - loss: 0.3015 - mae: 0.1246   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 193ms/step - loss: 0.3003 - mae: 0.1242\n",
    "Epoch 93/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 177ms/step - loss: 0.3145 - mae: 0.1320   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 179ms/step - loss: 0.2986 - mae: 0.1306   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 174ms/step - loss: 0.2970 - mae: 0.1297   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 175ms/step - loss: 0.2968 - mae: 0.1293\n",
    "Epoch 94/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 199ms/step - loss: 0.2479 - mae: 0.1169   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 0.2687 - mae: 0.1177   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 0.2746 - mae: 0.1179   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 183ms/step - loss: 0.2792 - mae: 0.1183\n",
    "Epoch 95/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m3s\u001B[0m 442ms/step - loss: 0.3892 - mae: 0.1420   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.48e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 452ms/step - loss: 0.3587 - mae: 0.1383   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 309ms/step - loss: 0.3341 - mae: 0.1333   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 268ms/step - loss: 0.3183 - mae: 0.1308\n",
    "Epoch 96/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m4s\u001B[0m 635ms/step - loss: 0.2808 - mae: 0.1248   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 394ms/step - loss: 0.2876 - mae: 0.1252   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 345ms/step - loss: 0.2892 - mae: 0.1268   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 327ms/step - loss: 0.2890 - mae: 0.1272\n",
    "Epoch 97/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 171ms/step - loss: 0.3047 - mae: 0.1215   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 198ms/step - loss: 0.3019 - mae: 0.1200   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 190ms/step - loss: 0.2988 - mae: 0.1191   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 195ms/step - loss: 0.2947 - mae: 0.1181\n",
    "Epoch 98/100\n",
    "\u001B[1m 1/10\u001B[0m \u001B[32mâ”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m2s\u001B[0m 261ms/step - loss: 0.3216 - mae: 0.1333   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 4/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 191ms/step - loss: 0.3003 - mae: 0.1292   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 7/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 0.2989 - mae: 0.1284   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 234ms/step - loss: 0.2932 - mae: 0.1273\n",
    "Epoch 99/100\n",
    "   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 3/10\u001B[0m \u001B[32mâ”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 176ms/step - loss: 0.2348 - mae: 0.1137   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 6/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 175ms/step - loss: 0.2602 - mae: 0.1170   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 9/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”\u001B[0m \u001B[1m0s\u001B[0m 177ms/step - loss: 0.2672 - mae: 0.1170   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 178ms/step - loss: 0.2695 - mae: 0.1170\n",
    "Epoch 100/100\n",
    "\u001B[1m 2/10\u001B[0m \u001B[32mâ”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 247ms/step - loss: 0.3643 - mae: 0.1281   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 5/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[1m1s\u001B[0m 224ms/step - loss: 0.3215 - mae: 0.1220   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m 8/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”â”â”â”\u001B[0m \u001B[1m0s\u001B[0m 201ms/step - loss: 0.3035 - mae: 0.1198   ğŸ“‹ Optimizer type: Adam\n",
    "   ğŸ“ˆ Number of trainable variables: 21\n",
    "   âŒ Optimizer doesn't have get_gradients, using variable norms\n",
    "      Variable 0 norm: 2.49e+00\n",
    "      Variable 1 norm: 2.28e+01\n",
    "      Variable 2 norm: 2.27e+01\n",
    "   ğŸ”¬ Checking 21 variable norms...\n",
    "   âœ… All variable norms are within acceptable range\n",
    "\u001B[1m10/10\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 195ms/step - loss: 0.2962 - mae: 0.1189\n",
    "ğŸ GradientMonitoringCallback: Training completed!\n",
    "   ğŸ“Š Final stats - Total calls: 1000, Gradient checks: 333, Fallbacks: 0\n",
    "   âœ… Gradient monitoring completed successfully!\n",
    "\n",
    "--- Phase 2: Fine-tuning ---\n",
    "ğŸš€ GradientMonitoringCallback: Training started!\n",
    "Epoch 1/300\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T19:45:18.937755Z",
     "start_time": "2025-05-28T19:45:18.839747Z"
    }
   },
   "id": "d0eae129c1bbd172",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-28T19:45:20.810164Z",
     "start_time": "2025-05-28T19:45:20.122728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x700 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Regex pattern for floating point numbers including scientific notation\n",
    "num_pattern = r\"(-?\\d+(?:\\.\\d+)?(?:e[-+]?\\d+)?)\"\n",
    "\n",
    "loss_values = [float(m.group(1)) for m in re.finditer(rf\"loss: {num_pattern}\", log)]\n",
    "val_loss_values = [float(m.group(1)) for m in re.finditer(rf\"val_loss: {num_pattern}\", log)]\n",
    "mae_values = [float(m.group(1)) for m in re.finditer(rf\"mae: {num_pattern}\", log)]\n",
    "val_mae_values = [float(m.group(1)) for m in re.finditer(rf\"val_mae: {num_pattern}\", log)]\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.plot(epochs, loss_values, marker='o', label='loss')\n",
    "# plt.plot(epochs, val_loss_values, marker='o', label='val_loss')\n",
    "plt.plot(epochs, mae_values, marker='o', label='mae')\n",
    "# plt.plot(epochs, val_mae_values, marker='o', label='val_mae')\n",
    "\n",
    "plt.title('Training and Validation Metrics over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig(\"training_metrics.png\", dpi=300)\n",
    "\n",
    "# Optionally show it\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "44886bbb93d248b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
