{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "69207995c2b68685"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehul/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:31:11.408289Z",
     "start_time": "2025-05-29T20:31:07.814153Z"
    }
   },
   "id": "12ecbb45022667b6",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:31:12.602195Z",
     "start_time": "2025-05-29T20:31:11.408612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape (10000, 50, 110, 6)\n",
      "test_data's shape (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import numpy as np\n",
    "train_file = np.load('data/train.npz')\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape\", train_data.shape)\n",
    "test_file = np.load('data/test_input.npz')\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, RepeatVector, TimeDistributed, Dropout"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:31:12.660923Z",
     "start_time": "2025-05-29T20:31:12.603987Z"
    }
   },
   "id": "14d9241b88b2e2e4",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def standardize_data_dimensions(scenario_data):\n",
    "    \"\"\"\n",
    "    Standardize position data by centering a single scenario at the origin.\n",
    "    \n",
    "    :param scenario_data: numpy array of shape (50, 110, 6)\n",
    "                         where dimensions are [position_x, position_y, velocity_x, velocity_y, heading, object_type]\n",
    "    :returns: tuple of (standardized_data, min_values)\n",
    "             - standardized_data: same shape as input with centered positions\n",
    "             - min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    \"\"\"\n",
    "    # Copy the data to avoid modifying the original\n",
    "    standardized_data = scenario_data.copy()\n",
    "    \n",
    "    # Extract position data (first 2 dimensions)\n",
    "    positions = scenario_data[:, :, :2]  # Shape: (50, 110, 2)\n",
    "    \n",
    "    # Create mask for non-zero positions (to ignore padding)\n",
    "    # We consider a position valid if it's not (0,0) or if the object_type is not 0\n",
    "    object_types = scenario_data[:, :, 5]  # Shape: (50, 110)\n",
    "    valid_mask = (positions[:, :, 0] != 0) | (positions[:, :, 1] != 0) | (object_types != 0)\n",
    "    \n",
    "    # Find min values across all valid positions in this scenario\n",
    "    if np.any(valid_mask):\n",
    "        valid_positions = positions[valid_mask]  # Shape: (num_valid_points, 2)\n",
    "        min_x = np.min(valid_positions[:, 0])\n",
    "        min_y = np.min(valid_positions[:, 1])\n",
    "    else:\n",
    "        # If no valid positions found, use 0 as min values\n",
    "        min_x = 0\n",
    "        min_y = 0\n",
    "    \n",
    "    # Store min values\n",
    "    min_values = np.array([min_x, min_y])\n",
    "    \n",
    "    # Standardize positions by subtracting min values\n",
    "    # Only modify non-zero positions to preserve padding\n",
    "    for agent_idx in range(scenario_data.shape[0]):\n",
    "        for time_idx in range(scenario_data.shape[1]):\n",
    "            if valid_mask[agent_idx, time_idx]:\n",
    "                standardized_data[agent_idx, time_idx, 0] -= min_x  # position_x\n",
    "                standardized_data[agent_idx, time_idx, 1] -= min_y  # position_y\n",
    "    \n",
    "    return standardized_data, min_values\n",
    "\n",
    "\n",
    "def denormalize_predictions(predictions, min_values):\n",
    "    \"\"\"\n",
    "    Helper function to add back the min values to predicted positions.\n",
    "    \n",
    "    :param predictions: predicted data with standardized positions, shape (50, 110, 6) or similar\n",
    "    :param min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    :returns: predictions with original coordinate system restored\n",
    "    \"\"\"\n",
    "    denormalized = predictions.copy()\n",
    "    \n",
    "    # Add back the min values to restore original coordinate system\n",
    "    # Assuming predictions have position_x and position_y as first two dimensions\n",
    "    denormalized[:, :, 0] += min_values[0]  # position_x\n",
    "    denormalized[:, :, 1] += min_values[1]  # position_y\n",
    "    \n",
    "    return denormalized"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:31:12.661641Z",
     "start_time": "2025-05-29T20:31:12.630902Z"
    }
   },
   "id": "9df4b831ee8e017",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "def standardize_single_scene(scene_data):\n",
    "    \"\"\"\n",
    "    Wrapper function to standardize a single scene and return both standardized data and min values.\n",
    "    This function will be called in parallel.\n",
    "    \"\"\"\n",
    "    standardized_scene, min_vals = standardize_data_dimensions(scene_data)\n",
    "    return standardized_scene, min_vals\n",
    "\n",
    "def parallel_standardize_training_data(train_data, n_jobs=-1, verbose=True):\n",
    "    \"\"\"\n",
    "    Parallelize the standardization of training data across all scenes.\n",
    "    \n",
    "    :param train_data: numpy array of shape (10000, 50, 110, 6)\n",
    "    :param n_jobs: number of parallel jobs (-1 uses all available cores)\n",
    "    :param verbose: whether to show progress bar\n",
    "    :returns: tuple of (standardized_data, min_values_array)\n",
    "    \"\"\"\n",
    "    print(f\"Standardizing {train_data.shape[0]} scenes using {multiprocessing.cpu_count() if n_jobs == -1 else n_jobs} cores...\")\n",
    "    \n",
    "    # Use joblib to parallelize the processing\n",
    "    if verbose:\n",
    "        # With progress bar\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(standardize_single_scene)(train_data[i]) \n",
    "            for i in tqdm(range(train_data.shape[0]), desc=\"Processing scenes\")\n",
    "        )\n",
    "    else:\n",
    "        # Without progress bar\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(standardize_single_scene)(train_data[i]) \n",
    "            for i in range(train_data.shape[0])\n",
    "        )\n",
    "    \n",
    "    # Unpack results\n",
    "    standardized_scenes, min_values_list = zip(*results)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    standardized_data = np.array(standardized_scenes)\n",
    "    min_values_array = np.array(min_values_list)\n",
    "    \n",
    "    print(f\"Standardization complete!\")\n",
    "    print(f\"Standardized data shape: {standardized_data.shape}\")\n",
    "    print(f\"Min values shape: {min_values_array.shape}\")\n",
    "    \n",
    "    return standardized_data, min_values_array"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:31:12.662294Z",
     "start_time": "2025-05-29T20:31:12.635822Z"
    }
   },
   "id": "db886a7f7f3d9df5",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing 10000 scenes using 8 cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing scenes: 100%|██████████| 10000/10000 [00:14<00:00, 701.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardization complete!\n",
      "Standardized data shape: (10000, 50, 110, 6)\n",
      "Min values shape: (10000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(10000, 50, 110, 6)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_train_data, min_values = parallel_standardize_training_data(\n",
    "    train_data, \n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=True\n",
    ")\n",
    "standardized_train_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:31:43.984732Z",
     "start_time": "2025-05-29T20:31:12.649083Z"
    }
   },
   "id": "3c81976ba8c9b548",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input, LSTM, Dense, Dropout, RepeatVector, TimeDistributed, \n",
    "    Concatenate, Activation, Dot, Layer, BatchNormalization, \n",
    "    LayerNormalization, Add\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import Orthogonal, GlorotUniform\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class ScaleLayer(Layer):\n",
    "    def __init__(self, scale_factor, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.scale_factor = scale_factor\n",
    "    \n",
    "    def call(self, x):\n",
    "        return x / self.scale_factor\n",
    "\n",
    "class MaxSubtractLayer(Layer):\n",
    "    def call(self, x):\n",
    "        return x - K.max(x, axis=-1, keepdims=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:31:44.059459Z",
     "start_time": "2025-05-29T20:31:43.413293Z"
    }
   },
   "id": "f40b1487275e6996",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def load_model(model_path='lstm2.keras'):\n",
    "    \n",
    "    custom_objects = {\n",
    "        'ScaleLayer':ScaleLayer,\n",
    "        'MaxSubtractLayer':MaxSubtractLayer\n",
    "    }\n",
    "    \n",
    "    model = keras.models.load_model(model_path, custom_objects=custom_objects, safe_mode=False)\n",
    "    print(f\"Keras model loaded from {model_path}\")\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:31:44.061847Z",
     "start_time": "2025-05-29T20:31:43.441321Z"
    }
   },
   "id": "e0a6a9b5057173bc",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed, Dropout, Attention, Concatenate, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_lstm_encoder_decoder_with_attention(input_dim, output_dim, timesteps_in, timesteps_out,\n",
    "                                             lstm_units=512, num_layers=3, loss_fn='mse', lr=0.001):\n",
    "    inputs = Input(shape=(timesteps_in, input_dim))\n",
    "\n",
    "    # Encoder - preserve all timesteps for attention\n",
    "    x = inputs\n",
    "    for i in range(num_layers):\n",
    "        x = LSTM(lstm_units, return_sequences=True, name=f'encoder_lstm_{i}')(x)\n",
    "    encoder_outputs = x  # All encoder hidden states\n",
    "    \n",
    "    # Get context vector from final timestep\n",
    "    context_vector = Lambda(lambda x: x[:, -1, :])(encoder_outputs)\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = RepeatVector(timesteps_out)(context_vector)\n",
    "    \n",
    "    # Decoder LSTM layers\n",
    "    decoder_output = decoder_input\n",
    "    for i in range(num_layers):\n",
    "        decoder_output = LSTM(lstm_units, return_sequences=True, name=f'decoder_lstm_{i}')(decoder_output)\n",
    "    \n",
    "    # Attention mechanism\n",
    "    attention_layer = Attention(name='attention')\n",
    "    attended_context = attention_layer([decoder_output, encoder_outputs])\n",
    "    \n",
    "    # Combine decoder output with attended context\n",
    "    combined = Concatenate(axis=-1)([decoder_output, attended_context])\n",
    "    \n",
    "    # Output layers\n",
    "    x = TimeDistributed(Dense(128, activation='relu'))(combined)\n",
    "    x = TimeDistributed(Dense(64, activation='relu'))(x)\n",
    "    outputs = TimeDistributed(Dense(output_dim))(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr, clipnorm=0.5), loss='mse', metrics=['mae'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:35:31.734388Z",
     "start_time": "2025-05-29T20:35:31.730407Z"
    }
   },
   "id": "d49a92ffcd8f00c",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.src.callbacks import LearningRateScheduler, EarlyStopping, Callback\n",
    "from keras.src.optimizers import Adam\n",
    "from keras import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class DynamicReduceLROnPlateau(Callback):\n",
    "    def __init__(self, factor=0.1, patience=3, min_lr=1e-7, verbose=1):\n",
    "        super().__init__()\n",
    "        self.factor = factor\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.verbose = verbose\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        current_val_loss = logs.get(\"val_loss\")\n",
    "\n",
    "        if current_val_loss is None:\n",
    "            return  # can't do anything if val_loss isn't available\n",
    "\n",
    "        if current_val_loss < self.best_val_loss - 1e-4:  # a small delta\n",
    "            self.best_val_loss = current_val_loss\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                old_lr = float(self.model.optimizer.learning_rate.numpy())\n",
    "                if old_lr > self.min_lr:\n",
    "                    new_lr = max(old_lr * self.factor, self.min_lr)\n",
    "                    self.model.optimizer.learning_rate.assign(new_lr)\n",
    "                    if self.verbose:\n",
    "                        print(f\"\\nEpoch {epoch+1}: val_loss did not improve. Reducing LR from {old_lr:.6f} to {new_lr:.6f}\")\n",
    "                    self.wait = 0  # reset after LR reduction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:35:31.860939Z",
     "start_time": "2025-05-29T20:35:31.859179Z"
    }
   },
   "id": "ee1df27124751b62",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LRThresholdCallback(Callback):\n",
    "    def __init__(self, threshold=9e-5):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "        self.should_stop = False\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = float(self.model.optimizer.learning_rate.numpy())\n",
    "        if lr < self.threshold:\n",
    "            print(f\"\\nLearning rate {lr:.6f} < threshold {self.threshold}, moving to Phase 2.\")\n",
    "            self.model.stop_training = True\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:35:32.032707Z",
     "start_time": "2025-05-29T20:35:32.025961Z"
    }
   },
   "id": "99dd9a0ab8e0e651",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class GradientMonitoringCallback(Callback):\n",
    "    def __init__(self, clip_min=1e-4, clip_max=1e2, monitor_frequency=3):\n",
    "        \"\"\"\n",
    "        Monitor gradient norms during training\n",
    "        \n",
    "        Args:\n",
    "            clip_min: Minimum threshold for gradient norms\n",
    "            clip_max: Maximum threshold for gradient norms  \n",
    "            monitor_frequency: How often to check gradients (every N batches)\n",
    "        \"\"\"\n",
    "        print(f\"🔧 GradientMonitoringCallback initialized with clip_min={clip_min}, clip_max={clip_max}, monitor_freq={monitor_frequency}\")\n",
    "        self.clip_min = clip_min\n",
    "        self.clip_max = clip_max\n",
    "        self.monitor_frequency = monitor_frequency\n",
    "        self.batch_count = 0\n",
    "        self.total_calls = 0\n",
    "        self.gradient_checks = 0\n",
    "        self.fallback_calls = 0\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        print(\"🚀 GradientMonitoringCallback: Training started!\")\n",
    "        self.batch_count = 0\n",
    "        self.total_calls = 0\n",
    "        self.gradient_checks = 0\n",
    "        self.fallback_calls = 0\n",
    "        \n",
    "    # def on_epoch_begin(self, epoch, logs=None):\n",
    "    #     print(f\"📍 GradientMonitoringCallback: Starting epoch {epoch + 1}\")\n",
    "        \n",
    "    # def on_train_batch_begin(self, batch, logs=None):\n",
    "    #     # Just to prove we're being called\n",
    "    #     if batch % 50 == 0:  # Print every 50 batches to avoid spam\n",
    "    #         print(f\"⚡ GradientMonitoringCallback: Batch {batch} starting\")\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.batch_count += 1\n",
    "        self.total_calls += 1\n",
    "        \n",
    "        # Print every time to show we're being called\n",
    "        # if batch % 50 == 0:  # Print every 50 batches\n",
    "            # print(f\"📊 GradientMonitoringCallback: Batch {batch} ended (total calls: {self.total_calls})\")\n",
    "        \n",
    "        # Only monitor every N batches to avoid performance overhead\n",
    "        if self.batch_count % self.monitor_frequency != 0:\n",
    "            return\n",
    "            \n",
    "        # print(f\"🔍 GradientMonitoringCallback: Checking gradients at batch {batch} (check #{self.gradient_checks + 1})\")\n",
    "        \n",
    "        # Get gradients from the optimizer's current state\n",
    "        try:\n",
    "            # Access the model's optimizer to get gradient information\n",
    "            optimizer = self.model.optimizer\n",
    "            print(f\"   📋 Optimizer type: {type(optimizer).__name__}\")\n",
    "            \n",
    "            # Get trainable variables\n",
    "            trainable_vars = self.model.trainable_variables\n",
    "            print(f\"   📈 Number of trainable variables: {len(trainable_vars)}\")\n",
    "            \n",
    "            if hasattr(optimizer, 'get_gradients'):\n",
    "                print(\"   ✅ Optimizer has get_gradients method\")\n",
    "                # For some optimizers, we can access gradients directly\n",
    "                grads = optimizer.get_gradients(self.model.total_loss, trainable_vars)\n",
    "                print(f\"   📊 Retrieved {len([g for g in grads if g is not None])} gradients\")\n",
    "            else:\n",
    "                print(\"   ❌ Optimizer doesn't have get_gradients, using variable norms\")\n",
    "                # Alternative approach: check the current variable states\n",
    "                grad_norms = []\n",
    "                for i, var in enumerate(trainable_vars):\n",
    "                    if var is not None:\n",
    "                        var_norm = tf.norm(var)\n",
    "                        grad_norms.append(var_norm)\n",
    "                        if i < 3:  # Print first 3 for debugging\n",
    "                            print(f\"      Variable {i} norm: {float(var_norm.numpy()):.2e}\")\n",
    "                \n",
    "                self._check_norms(grad_norms, \"Variable\")\n",
    "                self.gradient_checks += 1\n",
    "                return\n",
    "                \n",
    "            # Compute gradient norms\n",
    "            grad_norms = []\n",
    "            for i, grad in enumerate(grads):\n",
    "                if grad is not None:\n",
    "                    grad_norm = tf.norm(grad)\n",
    "                    grad_norms.append(grad_norm)\n",
    "                    if i < 3:  # Print first 3 for debugging\n",
    "                        print(f\"      Gradient {i} norm: {float(grad_norm.numpy()):.2e}\")\n",
    "                    \n",
    "            print(f\"   ✅ Computed {len(grad_norms)} gradient norms\")\n",
    "            self._check_norms(grad_norms, \"Gradient\")\n",
    "            self.gradient_checks += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Exception in gradient monitoring: {str(e)}\")\n",
    "            self.fallback_calls += 1\n",
    "            # Fallback: just monitor the loss for signs of instability\n",
    "            print('   🔄 Fallback: monitoring loss only')\n",
    "            if logs:\n",
    "                loss_value = logs.get('loss', 0)\n",
    "                print(f\"   📉 Current loss: {loss_value:.2e}\")\n",
    "                if np.isnan(loss_value) or np.isinf(loss_value):\n",
    "                    print(f\"   ⚠️  WARNING: Loss became {loss_value} at batch {batch}\")\n",
    "                elif loss_value > 1e6:\n",
    "                    print(f\"   ⚠️  WARNING: Very large loss {loss_value:.2e} at batch {batch}\")\n",
    "    \n",
    "    def _check_norms(self, norms, norm_type=\"Gradient\"):\n",
    "        \"\"\"Check if norms are within acceptable range\"\"\"\n",
    "        print(f\"   🔬 Checking {len(norms)} {norm_type.lower()} norms...\")\n",
    "        warnings = 0\n",
    "        \n",
    "        for idx, norm in enumerate(norms):\n",
    "            try:\n",
    "                norm_value = float(norm.numpy()) if hasattr(norm, 'numpy') else float(norm)\n",
    "                \n",
    "                if norm_value > self.clip_max:\n",
    "                    print(f\"   ⚠️  WARNING: {norm_type} norm {norm_value:.2e} is too large (layer {idx})\")\n",
    "                    warnings += 1\n",
    "                elif norm_value < self.clip_min:\n",
    "                    print(f\"   ⚠️  WARNING: {norm_type} norm {norm_value:.2e} is too small (layer {idx})\")\n",
    "                    warnings += 1\n",
    "                elif np.isnan(norm_value) or np.isinf(norm_value):\n",
    "                    print(f\"   ⚠️  WARNING: {norm_type} norm is {norm_value} (layer {idx})\")\n",
    "                    warnings += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Cannot convert norm to float for layer {idx}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        if warnings == 0:\n",
    "            print(f\"   ✅ All {norm_type.lower()} norms are within acceptable range\")\n",
    "        else:\n",
    "            print(f\"   ⚠️  Found {warnings} norm warnings\")\n",
    "    \n",
    "    # def on_epoch_end(self, epoch, logs=None):\n",
    "    #     \"\"\"Print summary at end of each epoch\"\"\"\n",
    "    #     print(f\"📈 GradientMonitoringCallback: Epoch {epoch + 1} completed\")\n",
    "    #     print(f\"   📊 Total batch calls: {self.total_calls}\")\n",
    "    #     print(f\"   🔍 Gradient checks performed: {self.gradient_checks}\")\n",
    "    #     print(f\"   🔄 Fallback calls: {self.fallback_calls}\")\n",
    "    #     \n",
    "    #     if logs:\n",
    "    #         loss = logs.get('loss', 0)\n",
    "    #         val_loss = logs.get('val_loss', 0)\n",
    "    #         print(f\"   📉 Final epoch loss: {loss:.2e}\")\n",
    "    #         if val_loss:\n",
    "    #             print(f\"   📉 Final epoch val_loss: {val_loss:.2e}\")\n",
    "    #         \n",
    "    #         if np.isnan(loss) or np.isinf(loss):\n",
    "    #             print(f\"   ⚠️  WARNING: Training loss became unstable: {loss}\")\n",
    "    #         if val_loss and (np.isnan(val_loss) or np.isinf(val_loss)):\n",
    "    #             print(f\"   ⚠️  WARNING: Validation loss became unstable: {val_loss}\")\n",
    "        \n",
    "    def on_train_end(self, logs=None):\n",
    "        print(\"🏁 GradientMonitoringCallback: Training completed!\")\n",
    "        print(f\"   📊 Final stats - Total calls: {self.total_calls}, Gradient checks: {self.gradient_checks}, Fallbacks: {self.fallback_calls}\")\n",
    "        \n",
    "        if self.total_calls == 0:\n",
    "            print(\"   ❌ ERROR: Callback was never called! Check if it's properly added to callbacks list.\")\n",
    "        elif self.gradient_checks == 0 and self.fallback_calls == 0:\n",
    "            print(\"   ⚠️  WARNING: No gradient monitoring was performed. Check monitor_frequency setting.\")\n",
    "        else:\n",
    "            print(\"   ✅ Gradient monitoring completed successfully!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:35:32.166332Z",
     "start_time": "2025-05-29T20:35:32.159768Z"
    }
   },
   "id": "48e6074507a81432",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.src.callbacks import LearningRateScheduler, EarlyStopping, Callback\n",
    "from keras.src.optimizers import Adam\n",
    "from keras import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def exponential_decay_schedule(epoch, lr):\n",
    "    decay_rate = 0.9\n",
    "    decay_steps = 5\n",
    "    if epoch % decay_steps == 0 and epoch:\n",
    "        print('Learning rate update:', lr * decay_rate)\n",
    "        return lr * decay_rate\n",
    "    return lr\n",
    "\n",
    "\n",
    "# Custom callback to monitor LR and stop training\n",
    "class LRThresholdCallback(Callback):\n",
    "    def __init__(self, threshold=9e-5):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "        self.should_stop = False\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = float(self.model.optimizer.learning_rate.numpy())\n",
    "        if lr < self.threshold:\n",
    "            print(f\"\\nLearning rate {lr:.6f} < threshold {self.threshold}, moving to next phase.\")\n",
    "            self.model.stop_training = True\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:35:32.305413Z",
     "start_time": "2025-05-29T20:35:32.301588Z"
    }
   },
   "id": "2d3c3926a64b326d",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DynamicReduceLROnPlateau(Callback):\n",
    "    def __init__(self, factor=0.1, patience=3, min_lr=1e-7, verbose=1):\n",
    "        super().__init__()\n",
    "        self.factor = factor\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.verbose = verbose\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        current_val_loss = logs.get(\"val_loss\")\n",
    "\n",
    "        if current_val_loss is None:\n",
    "            return  # can't do anything if val_loss isn't available\n",
    "\n",
    "        if current_val_loss < self.best_val_loss - 1e-4:  # a small delta\n",
    "            self.best_val_loss = current_val_loss\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                old_lr = float(self.model.optimizer.learning_rate.numpy())\n",
    "                if old_lr > self.min_lr:\n",
    "                    new_lr = max(old_lr * self.factor, self.min_lr)\n",
    "                    self.model.optimizer.learning_rate.assign(new_lr)\n",
    "                    if self.verbose:\n",
    "                        print(f\"\\nEpoch {epoch+1}: val_loss did not improve. Reducing LR from {old_lr:.6f} to {new_lr:.6f}\")\n",
    "                    self.wait = 0  # reset after LR reduction\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:35:32.439120Z",
     "start_time": "2025-05-29T20:35:32.435880Z"
    }
   },
   "id": "5af39153df21a474",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "class SaveBestModelCallback(Callback):\n",
    "    def __init__(self, save_path='best_model', monitor='val_loss'):\n",
    "        super().__init__()\n",
    "        self.best = float('inf')\n",
    "        self.monitor = monitor\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is not None and current < self.best:\n",
    "            self.best = current\n",
    "            print(f\"\\nNew best {self.monitor}: {current:.6f}. Saving model...\")\n",
    "            self.model.save(self.save_path+'.keras', overwrite=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:35:32.581507Z",
     "start_time": "2025-05-29T20:35:32.576019Z"
    }
   },
   "id": "f08667de7129e4e0",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(train_data, batch_size=32, validation_split=0.2, Tobs=50, Tpred=60, epochs1=50, epochs2=50, lr1=0.001, lr2=0.000001):\n",
    "    n_scenarios = train_data.shape[0]\n",
    "    n_agents = train_data.shape[1]\n",
    "    X_train_raw = []\n",
    "    y_train_deltas = []\n",
    "\n",
    "    # Counters for pruning reasons\n",
    "    pruned_zero_frame = 0\n",
    "    pruned_observed_or_future_zero = 0\n",
    "    total_agents = n_scenarios * n_agents\n",
    "    \n",
    "    for i in range(n_scenarios):\n",
    "        for agent_id in range(n_agents):\n",
    "            agent_data = train_data[i, agent_id, :, :]  # shape (110, 6)\n",
    "        \n",
    "            observed = agent_data[:Tobs]         # shape (Tobs, 6)\n",
    "            future = agent_data[Tobs:Tobs + Tpred, :2]  # position_x, position_y\n",
    "            last_obs_pos = observed[-1, :2]\n",
    "        \n",
    "            # Skip if more than 20% of observed or future rows are all zeros\n",
    "            observed_zero_ratio = np.mean(np.all(observed == 0, axis=1))\n",
    "            future_zero_ratio = np.mean(np.all(future == 0, axis=1))\n",
    "            \n",
    "            if observed_zero_ratio > 0.2 or future_zero_ratio > 0.2:\n",
    "                pruned_observed_or_future_zero += 1\n",
    "                continue\n",
    "                \n",
    "            # Compute deltas w.r.t. previous future timestep\n",
    "            delta = np.diff(np.vstack([last_obs_pos, future]), axis=0)  # (60, 2)\n",
    "            \n",
    "            # prediction of future steps for agent\n",
    "            X_train_raw.append(observed)\n",
    "            y_train_deltas.append(delta)\n",
    "            \n",
    "    \n",
    "    # Print pruning summary\n",
    "    print(f\"Total agents: {total_agents}\")\n",
    "    print(f\"Pruned due to zero frame in Tobs+Tpred: {pruned_zero_frame}\")\n",
    "    print(f\"Pruned due to zero frame in observed or future window: {pruned_observed_or_future_zero}\")\n",
    "    print(f\"Remaining valid agents: {len(X_train_raw)}\")\n",
    "    \n",
    "    \n",
    "    X_train = np.array(X_train_raw)     # shape (N_valid, Tobs, 6)\n",
    "    y_train = np.array(y_train_deltas)  # shape (N_valid, Tpred, 2)\n",
    "    \n",
    "    # how much of the data is 0?\n",
    "    # For X_train\n",
    "    num_elements_X = X_train.size\n",
    "    num_zeros_X = np.count_nonzero(X_train == 0)\n",
    "    percent_zeros_X = 100 * num_zeros_X / num_elements_X\n",
    "    \n",
    "    # For y_train\n",
    "    num_elements_y = y_train.size\n",
    "    num_zeros_y = np.count_nonzero(y_train == 0)\n",
    "    percent_zeros_y = 100 * num_zeros_y / num_elements_y\n",
    "    \n",
    "    print(f\"X_train: {num_zeros_X} zeros out of {num_elements_X} elements ({percent_zeros_X:.2f}%)\")\n",
    "    print(f\"y_train: {num_zeros_y} zeros out of {num_elements_y} elements ({percent_zeros_y:.2f}%)\")\n",
    "    \n",
    "    # print(f\"ex. y_train {y_train[0]}\")\n",
    "\n",
    "\n",
    "    print(f\"Training on {X_train.shape[0]} valid agent trajectories.\")\n",
    "    print(f\"Input shape: {X_train.shape}, Delta Output shape: {y_train.shape}\")\n",
    "    \n",
    "    # --- Normalize Input and Output ---\n",
    "    X_mean = X_train.mean(axis=(0, 1), keepdims=True)  # shape: (1, 1, 6)\n",
    "    X_std = X_train.std(axis=(0, 1), keepdims=True) + 1e-8\n",
    "\n",
    "    y_mean = y_train.mean(axis=(0, 1), keepdims=True)  # shape: (1, 1, 2)\n",
    "    y_std = y_train.std(axis=(0, 1), keepdims=True) + 1e-8\n",
    "\n",
    "    X_std = np.where(X_std < 1e-6, 1.0, X_std)\n",
    "    y_std = np.where(y_std < 1e-6, 1.0, y_std)\n",
    "    \n",
    "    # take out standardization for testing\n",
    "    # X_train = (X_train - X_mean) / X_std\n",
    "    # y_train = (y_train - y_mean) / y_std \n",
    "    # \n",
    "    print(\"X_train NaNs:\", np.isnan(X_train).sum())\n",
    "    print(\"y_train NaNs:\", np.isnan(y_train).sum())\n",
    "\n",
    "    print(\"Any std == 0?\", np.any(X_std == 0), np.any(y_std == 0))\n",
    "    \n",
    "    X_mean, X_std, y_mean, y_std = None, None, None, None\n",
    "    \n",
    "    \n",
    "    # print(X_train[:2])\n",
    "    # print(y_train[:2])\n",
    "    \n",
    "    model = create_lstm_encoder_decoder_with_attention(\n",
    "        input_dim=X_train.shape[-1],\n",
    "        output_dim=2,\n",
    "        timesteps_in=Tobs,\n",
    "        timesteps_out=Tpred,\n",
    "        loss_fn='mse',\n",
    "        lr=lr1\n",
    "    )\n",
    "    \n",
    "    gradient_monitoring_callback = GradientMonitoringCallback(clip_min=1e-4, clip_max=1e2)\n",
    "    \n",
    "    # Pass normalization parameters to SaveBestModelCallback\n",
    "    save_best_callback = SaveBestModelCallback(\n",
    "        save_path='lstm2', \n",
    "        monitor='val_loss',\n",
    "    )\n",
    "\n",
    "\n",
    "    phase1_callbacks = [\n",
    "        # LearningRateScheduler(exponential_decay_schedule),\n",
    "        DynamicReduceLROnPlateau(factor=0.7, patience=3, min_lr=1e-9),\n",
    "        EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss'),\n",
    "        LRThresholdCallback(threshold=9e-8),\n",
    "        # gradient_monitoring_callback,\n",
    "        save_best_callback\n",
    "    ]\n",
    "\n",
    "    print(\"\\n--- Phase 1: Training ---\")\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs1,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=phase1_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Phase 2: Fine-tuning ---\")\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=lr2,\n",
    "            clipnorm=0.1,      # More aggressive clipping\n",
    "            beta_1=0.9,         # Standard momentum\n",
    "            beta_2=0.999,       # Standard RMSprop decay\n",
    "            epsilon=1e-7        # Smaller epsilon for stability\n",
    "        ),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    phase2_callbacks = [\n",
    "        # LearningRateScheduler(exponential_decay_schedule),\n",
    "        EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss'), \n",
    "        DynamicReduceLROnPlateau(factor=0.5, patience=2, min_lr=1e-9),\n",
    "        LRThresholdCallback(threshold=9e-8),\n",
    "        # gradient_monitoring_callback\n",
    "    ]\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs2,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=phase2_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"X_mean:{X_mean}, X_std:{X_std}, y_mean:{y_mean}, y_std:{y_std}\")\n",
    "\n",
    "    # Return model and normalization parameters\n",
    "    return model, X_mean, X_std, y_mean, y_std"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:35:32.873166Z",
     "start_time": "2025-05-29T20:35:32.860029Z"
    }
   },
   "id": "ea4e240971bc7867",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_mae_by_timestep(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Visualize MAE across timesteps in the prediction horizon.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): shape (N, Tpred, 2)\n",
    "        y_pred (np.ndarray): shape (N, Tpred, 2)\n",
    "    \"\"\"\n",
    "    mae_per_timestep = np.mean(np.abs(y_true - y_pred), axis=(0, 2))  # shape (Tpred,)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(mae_per_timestep, label='MAE per Timestep')\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.ylabel('MAE (meters)')\n",
    "    plt.title('Mean Absolute Error Over Prediction Horizon')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:35:33.290708Z",
     "start_time": "2025-05-29T20:35:33.284273Z"
    }
   },
   "id": "1dae50c6d460015",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reconstruct_absolute_positions(pred_deltas, last_observed_positions):\n",
    "    \"\"\"\n",
    "    Reconstruct absolute predicted positions in an autoregressive way.\n",
    "    \n",
    "    Args:\n",
    "        pred_deltas: np.ndarray of shape (N, Tpred, 2)\n",
    "        last_observed_positions: np.ndarray of shape (N, 2)\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray of shape (N, Tpred, 2)\n",
    "    \"\"\"\n",
    "    N, Tpred, _ = pred_deltas.shape\n",
    "    positions = np.zeros((N, Tpred, 2), dtype=pred_deltas.dtype)\n",
    "    positions[:, 0, :] = last_observed_positions + pred_deltas[:, 0, :]\n",
    "    \n",
    "    for t in range(1, Tpred):\n",
    "        positions[:, t, :] = positions[:, t-1, :] + pred_deltas[:, t, :]\n",
    "    \n",
    "    return positions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:35:33.427413Z",
     "start_time": "2025-05-29T20:35:33.423950Z"
    }
   },
   "id": "f303823d230afdb9",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def forecast_positions(scenario_data, Tobs, Tpred, model, X_mean=None, X_std=None, y_mean=None, y_std=None):\n",
    "    \"\"\"\n",
    "    Use LSTM model to forecast future deltas and reconstruct absolute positions of only the ego\n",
    "    Applies normalization only if statistics are provided.\n",
    "\n",
    "    Args:\n",
    "        scenario_data (numpy.ndarray): Shape (agents, time_steps, dimensions)\n",
    "        Tobs (int): Number of observed time steps\n",
    "        Tpred (int): Number of future time steps to predict\n",
    "        model (Model): Trained LSTM model\n",
    "        X_mean, X_std: Optional normalization stats for input\n",
    "        y_mean, y_std: Optional normalization stats for output\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Predicted absolute positions of shape (Tpred, 2)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Only process ego agent (agent_index=0)\n",
    "    agent_idx = 0\n",
    "    agent_data = scenario_data[agent_idx, :Tobs, :].copy()  # shape (Tobs, 6)\n",
    "    \n",
    "    # Skip if fully padded\n",
    "    if np.all(agent_data == 0):\n",
    "        return np.zeros((Tpred, 2))\n",
    "    \n",
    "    X_pred = np.expand_dims(agent_data, axis=0)  # shape (1, Tobs, 6)\n",
    "\n",
    "    # Normalize if stats are provided\n",
    "    if X_mean is not None and X_std is not None:\n",
    "        X_pred = (X_pred - X_mean) / X_std\n",
    "\n",
    "    # Predict deltas (normalized or raw)\n",
    "    pred_deltas = model.predict(X_pred, verbose=0)  # shape (1, Tpred, 2)\n",
    "    \n",
    "    print(\"pred deltas\")\n",
    "    print(pred_deltas[:,:])\n",
    "\n",
    "    # Denormalize if stats are provided\n",
    "    if y_mean is not None and y_std is not None:\n",
    "        pred_deltas = pred_deltas * y_std + y_mean\n",
    "\n",
    "    # Reconstruct absolute positions\n",
    "    last_pos = agent_data[Tobs - 1, :2]  # shape (2,)\n",
    "    abs_positions = reconstruct_absolute_positions(\n",
    "        pred_deltas=pred_deltas,\n",
    "        last_observed_positions=np.expand_dims(last_pos, axis=0)\n",
    "    )[0]\n",
    "    \n",
    "    return abs_positions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:35:33.769461Z",
     "start_time": "2025-05-29T20:35:33.765198Z"
    }
   },
   "id": "10132f4e6ee1e1df",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def make_gif(data_matrix1, data_matrix2, name='comparison'):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.animation as animation\n",
    "\n",
    "    cmap1 = plt.cm.get_cmap('viridis', 50)\n",
    "    cmap2 = plt.cm.get_cmap('plasma', 50)\n",
    "\n",
    "    assert data_matrix1.shape[1] == data_matrix2.shape[1], \"Both matrices must have same number of timesteps\"\n",
    "    timesteps = data_matrix1.shape[1]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "    ax1, ax2 = axes\n",
    "\n",
    "    def update(frame):\n",
    "        for ax in axes:\n",
    "            ax.clear()\n",
    "\n",
    "        for i in range(data_matrix1.shape[0]):\n",
    "            for (data_matrix, ax, cmap) in [(data_matrix1, ax1, cmap1), (data_matrix2, ax2, cmap2)]:\n",
    "                x = data_matrix[i, frame, 0]\n",
    "                y = data_matrix[i, frame, 1]\n",
    "                if x != 0 and y != 0:\n",
    "                    xs = data_matrix[i, :frame+1, 0]\n",
    "                    ys = data_matrix[i, :frame+1, 1]\n",
    "                    mask = (xs != 0) & (ys != 0)\n",
    "                    xs = xs[mask]\n",
    "                    ys = ys[mask]\n",
    "                    if len(xs) > 0 and len(ys) > 0:\n",
    "                        color = cmap(i)\n",
    "                        ax.plot(xs, ys, alpha=0.9, color=color)\n",
    "                        ax.scatter(x, y, s=80, color=color)\n",
    "\n",
    "        # Plot ego vehicle (index 0) on both\n",
    "        ax1.plot(data_matrix1[0, :frame, 0], data_matrix1[0, :frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "        ax1.scatter(data_matrix1[0, frame, 0], data_matrix1[0, frame, 1], s=80, color='tab:orange')\n",
    "        ax1.set_title('Prediction')\n",
    "\n",
    "        ax2.plot(data_matrix2[0, :frame, 0], data_matrix2[0, :frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "        ax2.scatter(data_matrix2[0, frame, 0], data_matrix2[0, frame, 1], s=80, color='tab:orange')\n",
    "        ax2.set_title('Actual')\n",
    "\n",
    "        for ax, data_matrix in zip(axes, [data_matrix1, data_matrix2]):\n",
    "            ax.set_xlim(data_matrix[:, :, 0][data_matrix[:, :, 0] != 0].min() - 10,\n",
    "                        data_matrix[:, :, 0][data_matrix[:, :, 0] != 0].max() + 10)\n",
    "            ax.set_ylim(data_matrix[:, :, 1][data_matrix[:, :, 1] != 0].min() - 10,\n",
    "                        data_matrix[:, :, 1][data_matrix[:, :, 1] != 0].max() + 10)\n",
    "            ax.legend()\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "\n",
    "        # Compute MSE over non-zero entries up to current frame\n",
    "        mask = (data_matrix2[:, :frame+1, :] != 0) & (data_matrix1[:, :frame+1, :] != 0)\n",
    "        mse = np.mean((data_matrix1[:, :frame+1, :][mask] - data_matrix2[:, :frame+1, :][mask]) ** 2)\n",
    "\n",
    "        fig.suptitle(f\"Timestep {frame} - MSE: {mse:.4f}\", fontsize=16)\n",
    "        return ax1.collections + ax1.lines + ax2.collections + ax2.lines\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, update, frames=list(range(0, timesteps, 3)), interval=100, blit=True)\n",
    "    anim.save(f'trajectory_visualization_{name}.gif', writer='pillow')\n",
    "    plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:35:34.135865Z",
     "start_time": "2025-05-29T20:35:34.109898Z"
    }
   },
   "id": "e475f845b5d73bae",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # figure out stats\n",
    "# def stats():\n",
    "#     Tobs = 50\n",
    "#     Tpred = 60\n",
    "#     n_scenarios = train_data.shape[0]\n",
    "#     X_train_raw = []\n",
    "#     y_train_deltas = []\n",
    "# \n",
    "#     for i in range(n_scenarios):\n",
    "#         ego_data = train_data[i, 0, :, :]\n",
    "#         if np.all(ego_data == 0):\n",
    "#             continue\n",
    "# \n",
    "#         observed = ego_data[:Tobs]            # shape (50, 6)\n",
    "#         future = ego_data[Tobs:Tobs+Tpred, :2]\n",
    "#         last_obs_pos = observed[-1, :2]\n",
    "# \n",
    "#         if np.any(np.all(observed == 0, axis=1)) or np.any(np.all(future == 0, axis=1)):\n",
    "#             continue\n",
    "# \n",
    "#         # Compute deltas w.r.t. previous future timestep\n",
    "#         delta = np.diff(np.vstack([last_obs_pos, future]), axis=0)  # (60, 2)\n",
    "# \n",
    "#         X_train_raw.append(observed)\n",
    "#         y_train_deltas.append(delta)\n",
    "# \n",
    "# \n",
    "#     X_train = np.array(X_train_raw)\n",
    "#     y_train = np.array(y_train_deltas)\n",
    "# \n",
    "#     print(f\"{X_train.shape[0]} valid sequences.\")\n",
    "#     print(f\"Input shape: {X_train.shape}, Delta Output shape: {y_train.shape}\")\n",
    "# \n",
    "#     # --- Normalize Input and Output ---\n",
    "#     X_mean = X_train.mean(axis=(0, 1), keepdims=True)  # shape: (1, 1, 6)\n",
    "#     X_std = X_train.std(axis=(0, 1), keepdims=True) + 1e-8\n",
    "# \n",
    "#     y_mean = y_train.mean(axis=(0, 1), keepdims=True)  # shape: (1, 1, 2)\n",
    "#     y_std = y_train.std(axis=(0, 1), keepdims=True) + 1e-8\n",
    "# \n",
    "#     X_train = (X_train - X_mean) / X_std\n",
    "#     y_train = (y_train - y_mean) / y_std\n",
    "#     return X_mean, X_std, y_mean, y_std\n",
    "# X_mean, X_std, y_mean, y_std = stats()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:35:34.469765Z",
     "start_time": "2025-05-29T20:35:34.464024Z"
    }
   },
   "id": "ac3b5ab02eaf908a",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "K.clear_session()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:35:35.378237Z",
     "start_time": "2025-05-29T20:35:35.373204Z"
    }
   },
   "id": "1dfecba2866a2d9d",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = create_lstm_encoder_decoder_with_attention(10000,2,50,60)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:35:37.227850Z",
     "start_time": "2025-05-29T20:35:35.499244Z"
    }
   },
   "id": "7721496a026fc273",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"functional\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m, \u001B[38;5;34m10000\u001B[0m) │          \u001B[38;5;34m0\u001B[0m │ -                 │\n│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ encoder_lstm_0      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m, \u001B[38;5;34m512\u001B[0m)   │ \u001B[38;5;34m21,530,624\u001B[0m │ input_layer[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n│ (\u001B[38;5;33mLSTM\u001B[0m)              │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ encoder_lstm_1      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m, \u001B[38;5;34m512\u001B[0m)   │  \u001B[38;5;34m2,099,200\u001B[0m │ encoder_lstm_0[\u001B[38;5;34m0\u001B[0m… │\n│ (\u001B[38;5;33mLSTM\u001B[0m)              │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ encoder_lstm_2      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m, \u001B[38;5;34m512\u001B[0m)   │  \u001B[38;5;34m2,099,200\u001B[0m │ encoder_lstm_1[\u001B[38;5;34m0\u001B[0m… │\n│ (\u001B[38;5;33mLSTM\u001B[0m)              │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda (\u001B[38;5;33mLambda\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ encoder_lstm_2[\u001B[38;5;34m0\u001B[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ repeat_vector       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m60\u001B[0m, \u001B[38;5;34m512\u001B[0m)   │          \u001B[38;5;34m0\u001B[0m │ lambda[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n│ (\u001B[38;5;33mRepeatVector\u001B[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_lstm_0      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m60\u001B[0m, \u001B[38;5;34m512\u001B[0m)   │  \u001B[38;5;34m2,099,200\u001B[0m │ repeat_vector[\u001B[38;5;34m0\u001B[0m]… │\n│ (\u001B[38;5;33mLSTM\u001B[0m)              │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_lstm_1      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m60\u001B[0m, \u001B[38;5;34m512\u001B[0m)   │  \u001B[38;5;34m2,099,200\u001B[0m │ decoder_lstm_0[\u001B[38;5;34m0\u001B[0m… │\n│ (\u001B[38;5;33mLSTM\u001B[0m)              │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_lstm_2      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m60\u001B[0m, \u001B[38;5;34m512\u001B[0m)   │  \u001B[38;5;34m2,099,200\u001B[0m │ decoder_lstm_1[\u001B[38;5;34m0\u001B[0m… │\n│ (\u001B[38;5;33mLSTM\u001B[0m)              │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m60\u001B[0m, \u001B[38;5;34m512\u001B[0m)   │          \u001B[38;5;34m0\u001B[0m │ decoder_lstm_2[\u001B[38;5;34m0\u001B[0m… │\n│ (\u001B[38;5;33mAttention\u001B[0m)         │                   │            │ encoder_lstm_2[\u001B[38;5;34m0\u001B[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m60\u001B[0m, \u001B[38;5;34m1024\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ decoder_lstm_2[\u001B[38;5;34m0\u001B[0m… │\n│ (\u001B[38;5;33mConcatenate\u001B[0m)       │                   │            │ attention[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ time_distributed    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m60\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │    \u001B[38;5;34m131,200\u001B[0m │ concatenate[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n│ (\u001B[38;5;33mTimeDistributed\u001B[0m)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ time_distributed_1  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m60\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │      \u001B[38;5;34m8,256\u001B[0m │ time_distributed… │\n│ (\u001B[38;5;33mTimeDistributed\u001B[0m)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ time_distributed_2  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m60\u001B[0m, \u001B[38;5;34m2\u001B[0m)     │        \u001B[38;5;34m130\u001B[0m │ time_distributed… │\n│ (\u001B[38;5;33mTimeDistributed\u001B[0m)   │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ encoder_lstm_0      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">21,530,624</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ encoder_lstm_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ encoder_lstm_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ encoder_lstm_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ encoder_lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ repeat_vector       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_lstm_0      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_lstm_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ decoder_lstm_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_lstm_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ decoder_lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ encoder_lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ time_distributed    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ time_distributed_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ time_distributed… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ time_distributed_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ time_distributed… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m32,166,210\u001B[0m (122.70 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,166,210</span> (122.70 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m32,166,210\u001B[0m (122.70 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,166,210</span> (122.70 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:35:37.763357Z",
     "start_time": "2025-05-29T20:35:37.750070Z"
    }
   },
   "id": "49f18bb60147110c",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# fit\n",
    "model, X_mean, X_std, y_mean, y_std = train_model(standardized_train_data[:],epochs1=50, epochs2=10, validation_split=0.2, lr1=0.001, lr2=0.00001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-29T20:31:45.325892Z"
    }
   },
   "id": "71d257d5cc4ad709",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = load_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-29T20:31:45.326465Z"
    }
   },
   "id": "b7209bcaafda7611",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# visualize regular prediction\n",
    "\n",
    "# model = load_model()\n",
    "\n",
    "# Parameters\n",
    "Tobs = 50\n",
    "Tpred = 60\n",
    "\n",
    "data = standardized_train_data[6325]\n",
    "\n",
    "# Select a test scenario (can use any valid index)\n",
    "test_scenario = data.copy()  # shape (agents, time_steps, features)\n",
    "\n",
    "\n",
    "# Forecast future positions\n",
    "predicted_positions = forecast_positions(test_scenario, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std)\n",
    "\n",
    "# Create combined matrix of past observed + predicted for ego agent (agent 0)\n",
    "ego_past = test_scenario[0, :Tobs, :2]               # shape (Tobs, 2)\n",
    "ego_future = predicted_positions                     # shape (Tpred, 2)\n",
    "\n",
    "print(ego_future[:5])\n",
    "print(test_scenario[0, Tobs:Tobs+5, :2])\n",
    "ego_full = np.concatenate([ego_past, ego_future], axis=0)  # shape (Tobs + Tpred, 2)\n",
    "\n",
    "# Create updated scenario with predicted ego and original others\n",
    "updated_scenario = test_scenario.copy()\n",
    "updated_scenario[0, :Tobs+Tpred, :2] = ego_full  # Replace ego trajectory\n",
    "\n",
    "# Visualize\n",
    "make_gif(updated_scenario, data, name='lstm2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:31:45.327927Z",
     "start_time": "2025-05-29T20:31:45.327309Z"
    }
   },
   "id": "86ac55f8c53f2860",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # visualize prediction\n",
    "# \n",
    "# # model = load_model()\n",
    "# \n",
    "# # Parameters\n",
    "# Tobs = 50\n",
    "# Tpred = 60\n",
    "# \n",
    "# data = train_data[0]\n",
    "# \n",
    "# # Select a test scenario (can use any valid index)\n",
    "# test_scenario = data.copy()  # shape (agents, time_steps, features)\n",
    "# \n",
    "# \n",
    "# # Forecast future positions\n",
    "# predicted_positions = finetune_forecast_positions(test_scenario, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std)\n",
    "# \n",
    "# # Create combined matrix of past observed + predicted for ego agent (agent 0)\n",
    "# ego_past = test_scenario[0, :Tobs, :2]               # shape (Tobs, 2)\n",
    "# ego_future = predicted_positions[0]                  # shape (Tpred, 2)\n",
    "# ego_full = np.concatenate([ego_past, ego_future], axis=0)  # shape (Tobs + Tpred, 2)\n",
    "# \n",
    "# # Create updated scenario with predicted ego and original others\n",
    "# updated_scenario = test_scenario.copy()\n",
    "# updated_scenario[0, :Tobs+Tpred, :2] = ego_full  # Replace ego trajectory\n",
    "# \n",
    "# # Visualize\n",
    "# make_gif(updated_scenario, data, name='lstm2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:31:45.328472Z",
     "start_time": "2025-05-29T20:31:45.328095Z"
    }
   },
   "id": "afd67ae1834bd217",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def evaluate_mse(train_data, model, Tobs=50, Tpred=60):\n",
    "    \"\"\"\n",
    "    Computes LSTM prediction for ego agent and evaluates MSE with progress reporting.\n",
    "    \"\"\"\n",
    "    N = train_data.shape[0]\n",
    "    mse_list = []\n",
    "    valid_scenarios = 0\n",
    "    \n",
    "    print(f\"Evaluating {N} scenarios...\")\n",
    "    \n",
    "    # Progress reporting variables\n",
    "    report_interval = max(1, N // 10)  # Report at 10% intervals\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Progress reporting\n",
    "        if i % report_interval == 0 or i == N-1:\n",
    "            print(f\"Processing scenario {i+1}/{N} ({(i+1)/N*100:.1f}%)\")\n",
    "        \n",
    "        scenario_data = train_data[i]\n",
    "        ego_agent_data = scenario_data[0]\n",
    "        ground_truth = ego_agent_data[Tobs:Tobs+Tpred, :2]\n",
    "        \n",
    "        # Skip if ground truth contains all zeros (padded)\n",
    "        if np.all(ground_truth == 0):\n",
    "            continue\n",
    "            \n",
    "        valid_scenarios += 1\n",
    "        \n",
    "        # Forecast future positions\n",
    "        predicted_positions = forecast_positions(\n",
    "            ego_agent_data[np.newaxis, :, :],\n",
    "            Tobs, Tpred, model, X_mean, X_std, y_mean, y_std\n",
    "        )\n",
    "        \n",
    "        # Compute MSE\n",
    "        mse = mean_squared_error(ground_truth, predicted_positions)\n",
    "        mse_list.append(mse)\n",
    "        \n",
    "        # Occasional MSE reporting\n",
    "        if i % report_interval == 0:\n",
    "            print(f\"  Current scenario MSE: {mse:.4f}\")\n",
    "    \n",
    "    # Final results\n",
    "    if mse_list:\n",
    "        overall_mse = np.mean(mse_list)\n",
    "        print(f\"Evaluation complete: {valid_scenarios} valid scenarios\")\n",
    "        print(f\"Mean Squared Error (MSE): {overall_mse:.4f}\")\n",
    "        print(f\"Min MSE: {np.min(mse_list):.4f}, Max MSE: {np.max(mse_list):.4f}\")\n",
    "        return overall_mse\n",
    "    else:\n",
    "        print(\"No valid scenarios for evaluation.\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-29T20:31:45.333420Z",
     "start_time": "2025-05-29T20:31:45.328675Z"
    }
   },
   "id": "11f6401b403c51b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate on training data\n",
    "evaluate_mse(standardized_train_data, model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-29T20:31:45.329244Z"
    }
   },
   "id": "c75caee9a06e8acb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_submission(data, output_csv, Tobs=50, Tpred=60):\n",
    "    \"\"\"\n",
    "    Applies forecasting and generates a submission CSV with format:\n",
    "    index,x,y where index is auto-generated and matches submission key.\n",
    "    \n",
    "    Args:\n",
    "        data (np.ndarray): Test data of shape (num_scenarios, 50, 50, 6).\n",
    "        output_csv (str): Output CSV file path.\n",
    "        Tobs (int): Observed time steps (default 50).\n",
    "        Tpred (int): Prediction time steps (default 60).\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        scenario_data = data[i]            # Shape: (50, 50, 6)\n",
    "        ego_agent_data = scenario_data[0]  # Shape: (50, 6)\n",
    "\n",
    "        # Predict future positions for the ego agent\n",
    "        predicted_positions = finetune_forecast_positions(\n",
    "            ego_agent_data[np.newaxis, :, :], Tobs, Tpred, model\n",
    "        )  # Shape: (1, 60, 2)\n",
    "\n",
    "        # Append 60 predictions (x, y) for this scenario\n",
    "        predictions.extend(predicted_positions)  # Shape: (60, 2)\n",
    "\n",
    "    # Create DataFrame without explicit ID\n",
    "    submission_df = pd.DataFrame(predictions, columns=[\"x\", \"y\"])\n",
    "    submission_df.index.name = 'index'  # Match Kaggle format\n",
    "\n",
    "    # Save CSV with index\n",
    "    submission_df.to_csv(output_csv)\n",
    "    print(f\"Submission file '{output_csv}' saved with shape {submission_df.shape}\")\n",
    "\n",
    "generate_submission(test_data, 'lstm_submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-29T20:31:45.329765Z"
    }
   },
   "id": "907c41122d6ed7b9",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
