{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9885a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:59:33.423576Z",
     "start_time": "2025-05-30T19:59:32.069696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape (10000, 50, 110, 6)\n",
      "test_data's shape (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import numpy as np\n",
    "train_file = np.load('data/train.npz')\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape\", train_data.shape)\n",
    "test_file = np.load('data/test_input.npz')\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c708e385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:59:34.294156Z",
     "start_time": "2025-05-30T19:59:34.066491Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Optional\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def rotate_trajectory(trajectory: np.ndarray, angle: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Rotate trajectory by given angle around the origin.\n",
    "    Updates position, velocity, and heading.\n",
    "    \n",
    "    Args:\n",
    "        trajectory: Shape (timesteps, 6) where columns are [pos_x, pos_y, vel_x, vel_y, heading, obj_type]\n",
    "        angle: Rotation angle in radians\n",
    "        \n",
    "    Returns:\n",
    "        Rotated trajectory of same shape\n",
    "    \"\"\"\n",
    "    if trajectory.shape[-1] < 6:\n",
    "        raise ValueError(\"Trajectory must have 6 features\")\n",
    "        \n",
    "    cos_a, sin_a = np.cos(angle), np.sin(angle)\n",
    "    rotation_matrix = np.array([[cos_a, -sin_a],\n",
    "                               [sin_a, cos_a]])\n",
    "    \n",
    "    rotated_trajectory = trajectory.copy()\n",
    "    \n",
    "    # Rotate positions (columns 0, 1)\n",
    "    pos_xy = trajectory[:, :2]  # position_x, position_y\n",
    "    rotated_pos = pos_xy @ rotation_matrix.T\n",
    "    rotated_trajectory[:, :2] = rotated_pos\n",
    "    \n",
    "    # Rotate velocities (columns 2, 3)\n",
    "    vel_xy = trajectory[:, 2:4]  # velocity_x, velocity_y\n",
    "    rotated_vel = vel_xy @ rotation_matrix.T\n",
    "    rotated_trajectory[:, 2:4] = rotated_vel\n",
    "    \n",
    "    # Update heading (column 4)\n",
    "    rotated_trajectory[:, 4] = trajectory[:, 4] + angle\n",
    "    \n",
    "    # Keep object_type unchanged (column 5)\n",
    "    \n",
    "    return rotated_trajectory\n",
    "\n",
    "def translate_trajectory(trajectory: np.ndarray, dx: float, dy: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Translate trajectory by given offsets.\n",
    "    Only affects position coordinates.\n",
    "    \n",
    "    Args:\n",
    "        trajectory: Shape (timesteps, 6)\n",
    "        dx: Translation in x direction\n",
    "        dy: Translation in y direction\n",
    "        \n",
    "    Returns:\n",
    "        Translated trajectory of same shape\n",
    "    \"\"\"\n",
    "    if trajectory.shape[-1] < 6:\n",
    "        raise ValueError(\"Trajectory must have 6 features\")\n",
    "        \n",
    "    translated_trajectory = trajectory.copy()\n",
    "    translated_trajectory[:, 0] += dx  # position_x\n",
    "    translated_trajectory[:, 1] += dy  # position_y\n",
    "    \n",
    "    return translated_trajectory\n",
    "\n",
    "def flip_horizontal(trajectory: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Flip trajectory horizontally (mirror across y-axis).\n",
    "    Updates position, velocity, and heading.\n",
    "    \"\"\"\n",
    "    if trajectory.shape[-1] < 6:\n",
    "        raise ValueError(\"Trajectory must have 6 features\")\n",
    "        \n",
    "    flipped = trajectory.copy()\n",
    "    flipped[:, 0] = -flipped[:, 0]  # Negate position_x\n",
    "    flipped[:, 2] = -flipped[:, 2]  # Negate velocity_x\n",
    "    flipped[:, 4] = np.pi - flipped[:, 4]  # Mirror heading across y-axis\n",
    "    \n",
    "    return flipped\n",
    "\n",
    "def flip_vertical(trajectory: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Flip trajectory vertically (mirror across x-axis).\n",
    "    Updates position, velocity, and heading.\n",
    "    \"\"\"\n",
    "    if trajectory.shape[-1] < 6:\n",
    "        raise ValueError(\"Trajectory must have 6 features\")\n",
    "        \n",
    "    flipped = trajectory.copy()\n",
    "    flipped[:, 1] = -flipped[:, 1]  # Negate position_y\n",
    "    flipped[:, 3] = -flipped[:, 3]  # Negate velocity_y\n",
    "    flipped[:, 4] = -flipped[:, 4]  # Mirror heading across x-axis\n",
    "    \n",
    "    return flipped\n",
    "\n",
    "def augment_single_sample(sample: np.ndarray, \n",
    "                         rotation_range: float = np.pi/4,\n",
    "                         translation_range: float = 5.0,\n",
    "                         flip_prob: float = 0.5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply random augmentations to a single sample.\n",
    "    \n",
    "    Args:\n",
    "        sample: Shape (agents, timesteps, 6) for single scene\n",
    "        rotation_range: Maximum rotation angle in radians\n",
    "        translation_range: Maximum translation distance\n",
    "        flip_prob: Probability of applying flips\n",
    "        \n",
    "    Returns:\n",
    "        Augmented sample of same shape\n",
    "    \"\"\"\n",
    "    if len(sample.shape) != 3 or sample.shape[2] != 6:\n",
    "        raise ValueError(f\"Expected shape (agents, timesteps, 6), got {sample.shape}\")\n",
    "    \n",
    "    augmented = sample.copy()\n",
    "    \n",
    "    # Random rotation, translation parameters (same for all agents in scene)\n",
    "    angle = np.random.uniform(-rotation_range, rotation_range)\n",
    "    dx = np.random.uniform(-translation_range, translation_range)\n",
    "    dy = np.random.uniform(-translation_range, translation_range)\n",
    "    \n",
    "    # Random flip decisions (same for all agents in scene)\n",
    "    do_horizontal_flip = np.random.random() < flip_prob\n",
    "    do_vertical_flip = np.random.random() < flip_prob\n",
    "    \n",
    "    for agent_idx in range(sample.shape[0]):\n",
    "        trajectory = sample[agent_idx, :, :]  # Shape (timesteps, 6)\n",
    "        \n",
    "        # Skip if trajectory is all zeros (padding/inactive agent)\n",
    "        if np.all(trajectory[:, :2] == 0):  # Check if positions are all zero\n",
    "            continue\n",
    "            \n",
    "        # Apply transformations\n",
    "        trajectory = rotate_trajectory(trajectory, angle)\n",
    "        trajectory = translate_trajectory(trajectory, dx, dy)\n",
    "        \n",
    "        if do_horizontal_flip:\n",
    "            trajectory = flip_horizontal(trajectory)\n",
    "        \n",
    "        if do_vertical_flip:\n",
    "            trajectory = flip_vertical(trajectory)\n",
    "            \n",
    "        augmented[agent_idx, :, :] = trajectory\n",
    "    \n",
    "    return augmented\n",
    "\n",
    "def augment_batch_worker(batch_data: np.ndarray,\n",
    "                        rotation_range: float,\n",
    "                        translation_range: float,\n",
    "                        flip_prob: float) -> np.ndarray:\n",
    "    \"\"\"Process a batch of samples for parallel augmentation.\"\"\"\n",
    "    return np.array([augment_single_sample(sample,\n",
    "                                          rotation_range,\n",
    "                                          translation_range,\n",
    "                                          flip_prob)\n",
    "                     for sample in batch_data])\n",
    "\n",
    "def augment_dataset(data: np.ndarray, \n",
    "                   num_augmentations: int = 5,\n",
    "                   rotation_range: float = np.pi/4,\n",
    "                   translation_range: float = 5.0,\n",
    "                   flip_prob: float = 0.5,\n",
    "                   return_original: bool = True,\n",
    "                   n_jobs: Optional[int] = None,\n",
    "                   batch_size: Optional[int] = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Augment entire dataset.\n",
    "    \n",
    "    Args:\n",
    "        data: Shape (scenes, agents, timesteps, 6) dataset\n",
    "        num_augmentations: Number of augmented versions per sample\n",
    "        rotation_range: Maximum rotation angle in radians\n",
    "        translation_range: Maximum translation distance\n",
    "        flip_prob: Probability of applying flips\n",
    "        return_original: Whether to include original data in output\n",
    "        n_jobs: Number of parallel jobs\n",
    "        batch_size: Size of batches for parallel processing\n",
    "        \n",
    "    Returns:\n",
    "        Augmented dataset with shape (scenes*(1+num_augmentations), agents, timesteps, 6)\n",
    "    \"\"\"\n",
    "    if len(data.shape) != 4 or data.shape[3] != 6:\n",
    "        raise ValueError(f\"Expected shape (scenes, agents, timesteps, 6), got {data.shape}\")\n",
    "    \n",
    "    original_size = data.shape[0]\n",
    "    augmented_samples = []\n",
    "    \n",
    "    if return_original:\n",
    "        augmented_samples.append(data)\n",
    "\n",
    "    if n_jobs is None:\n",
    "        n_jobs = min(os.cpu_count(), 8)\n",
    "    elif n_jobs == -1:\n",
    "        n_jobs = os.cpu_count()\n",
    "\n",
    "    if batch_size is None:\n",
    "        batch_size = max(1, original_size // n_jobs)\n",
    "\n",
    "    print(f\"Using {n_jobs} jobs with batch size {batch_size}\")\n",
    "    \n",
    "    for aug_idx in tqdm(range(num_augmentations), desc=\"Augmentations\"):\n",
    "        batches = [data[i:i + batch_size] for i in range(0, original_size, batch_size)]\n",
    "\n",
    "        augmented_batches = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(augment_batch_worker)(\n",
    "                batch,\n",
    "                rotation_range,\n",
    "                translation_range,\n",
    "                flip_prob\n",
    "            ) for batch in tqdm(batches, desc=f\"Processing aug {aug_idx + 1}\", leave=False)\n",
    "        )\n",
    "\n",
    "        augmented_batch = np.concatenate(augmented_batches, axis=0)\n",
    "        augmented_samples.append(augmented_batch)\n",
    "\n",
    "    return np.concatenate(augmented_samples, axis=0)\n",
    "\n",
    "def visualize_augmentations(original_sample: np.ndarray, \n",
    "                           num_examples: int = 4,\n",
    "                           agent_idx: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    Visualize original and augmented trajectories for comparison.\n",
    "    \n",
    "    Args:\n",
    "        original_sample: Single sample of shape (agents, timesteps, 6)\n",
    "        num_examples: Number of augmented examples to show\n",
    "        agent_idx: Which agent's trajectory to visualize\n",
    "    \"\"\"\n",
    "    if len(original_sample.shape) != 3 or original_sample.shape[2] != 6:\n",
    "        raise ValueError(f\"Expected shape (agents, timesteps, 6), got {original_sample.shape}\")\n",
    "    \n",
    "    if agent_idx >= original_sample.shape[0]:\n",
    "        raise ValueError(f\"agent_idx {agent_idx} >= number of agents {original_sample.shape[0]}\")\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_examples + 1, figsize=(15, 3))\n",
    "    \n",
    "    # Extract original trajectory (position_x, position_y)\n",
    "    orig_traj = original_sample[agent_idx, :, :2]  # Shape (timesteps, 2)\n",
    "    \n",
    "    # Plot original\n",
    "    axes[0].plot(orig_traj[:, 0], orig_traj[:, 1], 'b-o', markersize=3)\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].grid(True)\n",
    "    axes[0].axis('equal')\n",
    "    \n",
    "    # Plot augmented versions\n",
    "    for i in range(num_examples):\n",
    "        aug_sample = augment_single_sample(original_sample)\n",
    "        aug_traj = aug_sample[agent_idx, :, :2]  # Shape (timesteps, 2)\n",
    "        \n",
    "        axes[i + 1].plot(aug_traj[:, 0], aug_traj[:, 1], 'r-o', markersize=3)\n",
    "        axes[i + 1].set_title(f'Augmented {i + 1}')\n",
    "        axes[i + 1].grid(True)\n",
    "        axes[i + 1].axis('equal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d2b355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABdwAAAEiCAYAAADj4hAeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACw8klEQVR4nOzde1xUZf4H8M/MAANYEDolIghqeUV/ukIKukuYQGmrZuqSm4aSd0odNANLwRJLATXd7MbitmKupZaXrRjTckvUWbt5ab1k6I46S5aGhcAI5/fH6YwMzAwX587n/Xrx0jnnmTPPw8DDme/5nu8jEwRBABERERERERERERER3RK5sztAREREREREREREROQJGHAnIiIiIiIiIiIiIrIBBtyJiIiIiIiIiIiIiGyAAXciIiIiIiIiIiIiIhtgwJ2IiIiIiIiIiIiIyAYYcCciIiIiIiIiIiIisgEG3ImIiIiIiIiIiIiIbIABdyIiIiIiIiIiIiIiG2DAnYiIiIiIiIiIiIjIBhhwJ5s4ePAgxo0bhw4dOsDHxwfBwcEYO3YsSkpKmnyMrKwsyGSyFr3+J598AplMhk8++aRFz2+q++67D/fdd59dX4OotXr55Zchk8kQGRnp7K44VUVFBbKysuwynzV1rrx27RqefvppJCYm4s4774RMJkNWVpbN+0PkTjhHiVxhjtq7dy+mTJmCHj16oE2bNujYsSNGjRqFI0eO2LxPRO6Cc5TIFeaor776CiNGjECnTp3g5+eHtm3bIiYmBhs3brR5n4jcBecokSvMUfW9+eabkMlkuO2222zep9aMAXe6ZWvXrsXgwYOh0+mwYsUK7NmzB7m5ubhw4QKGDBmCdevWNek4TzzxRLMC9HX97ne/Q0lJCX73u9+16PlE5Hx//etfAQDHjx/HoUOHnNwb56moqEB2drbdLyBa8+OPP+L1119HVVUVRo8e7bR+ELkSzlEiV5ij1q9fj9LSUsyZMwf//Oc/sWbNGpSVlWHQoEHYu3ev0/pF5Eyco0SuMEddvXoVYWFhyMnJwT//+U+89dZbiIiIwMSJE/HCCy84rV9EzsQ5SuQKc1RdFy5cwPz58xESEuLsrngcL2d3gNzb559/jrlz52L48OHYvn07vLxu/kglJyfj4Ycfxpw5c9C/f38MHjzY7DEqKirg7++P0NBQhIaGtqgfAQEBGDRoUIueS0TO9+9//xtff/01RowYgd27d6OgoAADBw50drdarfDwcFy5cgUymQyXL1/Gm2++6ewuETkV5yjX8pe//AV33XWXybYHHngAd999N3JycjB06FAn9YzIOThHuRZzd0U/9NBD+P777/H666/j2WefdU7HiJyEc5TrmjFjBv7whz+gbdu2ePfdd53dHY/CDHe6JcuXL4dMJsP69etNgu0A4OXlhVdeeQUymQwvvvgigJtlY7744guMHTsWQUFB6Nq1q8m+uqqqqpCeno7g4GD4+/vjD3/4A44cOYKIiAikpKQY25m7dSYlJQW33XYbzpw5g+HDh+O2225DWFgY0tPTUVVVZfI62dnZGDhwINq2bYuAgAD87ne/Q0FBAQRBsOF3i4gsKSgoAAC8+OKLiI2NxebNm1FRUWHSxtItcqWlpZDJZNiwYYPJ9jfeeAPdunWDUqlEr169sGnTJqSkpCAiIqLBc1euXImXXnoJERER8PPzw3333YdTp07BYDDgmWeeQUhICAIDA/Hwww+jrKysQf//8Y9/ICYmBm3atMFtt92GpKQkfPnllyZtmjInlZaW4s477wQgzksymQwymcxkvjt9+jQmTJiAu+66C0qlEj179sRf/vKXBn36z3/+gwceeAD+/v5QqVSYMWMGrl27ZvV9kEivS0QizlGuNUfVD7YDwG233YZevXrhv//9b5OOQeRJOEe51hxliUqlavCZmag14BzlmnPUxo0b8emnn+KVV15p1vOoiQSiFrpx44bg7+8vDBw40Gq7e++9V/D39xdu3LghLFmyRAAghIeHCwsXLhQ0Go3w3nvvCYIgGPfV9eijjwpyuVx45plnhOLiYmH16tVCWFiYEBgYKDz++OPGdvv27RMACPv27TNue/zxxwUfHx+hZ8+eQm5urrBnzx5h8eLFgkwmE7Kzs01eJyUlRSgoKBA0Go2g0WiE559/XvDz82vQLi4uToiLi2v+N4uILKqoqBACAwOF6OhoQRAE4c033xQACBs2bDBpZ+73XBAE4fvvvxcACIWFhcZtr732mgBAeOSRR4Rdu3YJRUVFQrdu3YTw8HAhPDy8wXPDw8OFP/7xj8KuXbuEjRs3Cu3btxe6desmTJw4UZgyZYrwwQcfCK+++qpw2223CX/84x9NXn/ZsmWCTCYTpkyZIuzatUvYtm2bEBMTI7Rp00Y4fvy4sV1T5qTKykrhww8/FAAIqampQklJiVBSUiKcOXNGEARBOH78uBAYGCj06dNHeOutt4Ti4mIhPT1dkMvlQlZWlvG19Hq9cNdddwkdO3YUCgsLhX/+85/Cn//8Z6FTp05mv4fW/PDDDwIAYcmSJU1+DpEn4Rzl2nOU5OrVq0JgYKDw8MMPN/u5RO6Mc5TrzlE1NTWCwWAQysrKhL/85S+Cl5eX8OqrrzbpuUSegnOUa85R//vf/4R27doJf/nLX4z9b9OmTaPPo6ZjwJ1aTK/XCwCE5ORkq+3+9Kc/CQCE//3vf8ag+uLFixu0qx9wP378uABAWLhwoUm7t99+WwDQpIA7AGHLli0mzx8+fLjQvXt3i/2VToyWLl0qtGvXTqitrTXuY8CdyPbeeustAYDxA8i1a9eE2267Tfj9739v0q6pJ2E1NTVCcHBwg4uB586dE7y9vc2ehP3f//2fUFNTY9y+evVqAYAwcuRIk2PMnTtXACD8/PPPgiAIwvnz5wUvLy/hySefNGl37do1ITg4WBg/frxxW1PnJGsB7qSkJCE0NNT4+pK0tDTB19dX+OmnnwRBEISFCxcKMplM+Oqrr0zaJSQkMOBO1Eyco1x7jpL8+c9/Fry8vIR///vfzX4ukTvjHOW6c9T06dMFAAIAwcfHR3jllVea9DwiT8I5yjXnqEceeUSIjY01xrsYcLc9lpQhuxN+K8tStzzBI4880ujzPv30UwDA+PHjTbaPHTu2ybfiyWQy/PGPfzTZ1rdvX5w7d85k2969ezFs2DAEBgZCoVDA29sbixcvxo8//mj2liIisp2CggL4+fkhOTkZgFgWYNy4cfjXv/6F06dPN/t4J0+ehF6vbzB3dOrUyeJaEsOHD4dcfvNPYs+ePQEAI0aMMGknbT9//jwA4KOPPsKNGzcwadIk3Lhxw/jl6+uLuLi4BrdENnVOMqeyshIff/wxHn74Yfj7+5u83vDhw1FZWYmDBw8CAPbt24fevXvj//7v/0yOMWHChEZfh4hMcY5y/TnqueeeQ1FREVatWoUBAwa06BhE7opzlOvOUZmZmdBqtdi9ezemTJmCtLQ05ObmNusYRO6Oc5TrzVFbt27Fzp078cYbb7CMqB0x4E4tplKp4O/vj++//95qu9LSUvj7+6Nt27bGbR06dGj0+D/++CMAoH379ibbvby80K5duyb10d/fH76+vibblEolKisrjY8PHz6MxMREAGIdsM8//xxarRaLFi0CAFy/fr1Jr0VEzXfmzBns378fI0aMgCAIuHr1Kq5evYqxY8cCuLmafXNYmjssbQNgMj8BgI+Pj9Xt0hzyv//9DwAQHR0Nb29vk69//OMfuHz5ssnzmzInWRvXjRs3sHbt2gavNXz4cAAwvt6PP/6I4ODgBscwt42ILOMc5fpzVHZ2Nl544QUsW7YMaWlpzX4+kTvjHOXac1SnTp0QFRWF4cOHY/369Zg2bRoyMjLwww8/NOs4RO6Kc5TrzVG//PILZs+ejSeffBIhISHG96S6uhoAcPXqVfz666+NHocaxxU7qMUUCgXi4+Px4YcfQqfTITQ0tEEbnU6HI0eO4MEHH4RCoTBub8pVNCmo/r///Q8dO3Y0br9x44ZxkrWFzZs3w9vbG7t27TKZHN977z2bvQYRmffXv/4VgiDg3XffNbsq+t/+9je88MILUCgUxt/P+ose1z/RqTt31KfX623VdQDihUcAePfddxEeHm7TY9cXFBQEhUKBiRMnYvbs2WbbdO7cGYD4PTA3VluPn8jTcY5qOmfMUdnZ2cjKykJWVhYyMzOb32kiN8c5qulc4Tzq3nvvxauvvoqzZ88aF04k8mSco5rOUXPU5cuX8b///Q95eXnIy8sz249Ro0YxHmYDDLjTLcnIyMAHH3yAWbNmYfv27SZB9ZqaGsycOROCICAjI6PZx/7DH/4AQFwR+ne/+51x+7vvvosbN27ceud/I5PJ4OXlZdL369ev4+9//7vNXoOIGqqpqcHf/vY3dO3aFW+++WaD/bt27UJeXh4++OADPPTQQ8YV57/55hskJSUZ2+3YscPked27d0dwcDC2bNkCtVpt3H7+/HkcOHAAISEhNhtDUlISvLy88N133zWpVFZTKJVKAA3vrvH390d8fDy+/PJL9O3b15iBYU58fDxWrFiBr7/+2uRWw02bNtmkj0StAeco81xljnr++eeRlZWFZ599FkuWLGnmKIjcH+co81xljjJn3759kMvl6NKlyy0dh8gdcI4yz9lzVHBwMPbt29dg+4svvohPP/0UH3zwgfFCA90aBtzplgwePBirV6/G3LlzMWTIEKSlpaFTp044f/48/vKXv+DQoUNYvXo1YmNjm33s3r1749FHH0VeXh4UCgWGDh2K48ePIy8vD4GBgSY1uG7FiBEjkJ+fjwkTJmDatGn48ccfkZuba5wIicg+PvjgA1y8eBEvvfQS7rvvvgb7IyMjsW7dOhQUFOChhx5CcHAwhg0bhuXLlyMoKAjh4eH4+OOPsW3bNpPnyeVyZGdnY/r06Rg7diymTJmCq1evIjs7Gx06dLDZ3AEAERERWLp0KRYtWoSzZ8/igQceQFBQEP73v//h8OHDaNOmDbKzs5t1zNtvvx3h4eF4//33cf/996Nt27ZQqVSIiIjAmjVrMGTIEPz+97/HzJkzERERgWvXruHMmTPYuXMn9u7dCwCYO3cu/vrXv2LEiBF44YUX0L59exQVFeE///lPk/vxwQcf4Ndff8W1a9cAACdOnDBmpgwfPhz+/v7NGheRu+EcZZ4rzFF5eXlYvHgxHnjgAYwYMcJY01QyaNCgZo2JyB1xjjLPFeaoadOmISAgAPfeey/at2+Py5cv45133sE//vEPLFiwgNnt1CpwjjLP2XOUr6+v2fdjw4YNUCgUZvdRCzlrtVbyLCUlJcLYsWOF9u3bC15eXsJdd90ljBkzRjhw4IBJuyVLlggAhB9++KHBMaR9dVVWVgpqtVq46667BF9fX2HQoEFCSUmJEBgYKMybN8/YztyK1pZWWTb3On/961+F7t27C0qlUujSpYuwfPlyoaCgQAAgfP/998Z2cXFxQlxcXDO+M0RkyejRowUfHx+hrKzMYpvk5GTBy8tL0Ov1giAIwqVLl4SxY8cKbdu2FQIDA4XHHntM+Pe//22ycr3k9ddfF+6++27Bx8dH6Natm/DXv/5VGDVqlNC/f39jG2nl+pUrV5o8V5pT3nnnHZPthYWFAgBBq9WabH/vvfeE+Ph4ISAgQFAqlUJ4eLgwduxYYc+ePcY2zZmT9uzZI/Tv319QKpUCAOHxxx836fOUKVOEjh07Ct7e3sKdd94pxMbGCi+88ILJMU6cOCEkJCQIvr6+Qtu2bYXU1FTh/fffb/LK9eHh4QIAs19150UiT8U5SuSKc1RcXJzF+Ykfb6i14BwlcsU56q9//avw+9//XlCpVIKXl5dwxx13CHFxccLf//53q88j8iSco0SuOEeZY6n/1HIyQRAEewTyiezlwIEDGDx4MIqKipq9UjwRtV5Xr15Ft27dMHr0aLz++uvO7g4RkQnOUUTkyjhHEZEr4xxFroYBd3JpGo0GJSUlGDBgAPz8/PD111/jxRdfRGBgIL755psGK0ATEQHigjHLli1DfHw82rVrh3PnzmHVqlX4z3/+g3//+9/o3bu3s7tIRK0Y5ygicmWco4jIlXGOInfAGu7k0gICAlBcXIzVq1fj2rVrUKlUePDBB7F8+XIG24nIIqVSidLSUsyaNQs//fQT/P39MWjQILz66qs8ASMip+McRUSujHMUEbkyzlHkDpjhTkRERERERERERERkA7ZbvpeIiIiIiIiIiIiIqBVjwJ2IiIiIiIiIiIiIyAYYcCciIiIiIiIiIiIisoFWsWhqbW0tLl68iNtvvx0ymczZ3SEiMwRBwLVr1xASEgK5vHVdC+QcReT6OEdxjiJyZZyjOEcRuTLOUZyjiFyZPeaoVhFwv3jxIsLCwpzdDSJqgv/+978IDQ11djccinMUkfvgHEVEroxzFBG5Ms5RROTKbDlHtYqA++233w5A/MYFBAQAAAwGA4qLi5GYmAhvb29ndq9F2H/nYv9tr7y8HGFhYcbf19bE3BzlCVzx58wWPHVcgOeOzRbj4hzVtDnKE36GOAbXwDE0D+co9zmP8oSfbcAzxuEJYwDcYxyco259jnKH97k5OB7X1trGY485qlUE3KXbdgICAkwC7v7+/ggICHDLHx7237nYf/tpjbfZmZujPIEr/5zdCk8dF+C5Y7PluDhHNR5wd/efIY7BNXAMLcM5yvXPozzhZxvwjHF4whgA9xoH56hbC7i7y/vcFByPa2ut47HlHGX34lm7d+/GwIED4efnB5VKhTFjxpjsP3/+PP74xz+iTZs2UKlUeOqpp1BdXW3S5ujRo4iLi4Ofnx86duyIpUuXQhAEe3ediIiIiIiIiIiIiKjJ7Bpw37p1KyZOnIjJkyfj66+/xueff44JEyYY99fU1GDEiBH49ddf8dlnn2Hz5s3YunUr0tPTjW3Ky8uRkJCAkJAQaLVarF27Frm5ucjPz7dn14moFWjsgiAAbNiwAX379oWvry+Cg4ORlpZmsp8XBImIiIiIiIiISGK3kjI3btzAnDlzsHLlSqSmphq3d+/e3fj/4uJinDhxAv/9738REhICAMjLy0NKSgqWLVuGgIAAFBUVobKyEhs2bIBSqURkZCROnTqF/Px8qNXqVnlLEhHduq1bt2Lq1KnIycnB0KFDIQgCjh49atImPz8feXl5WLlyJQYOHIjKykqcPXvWuF+6IBgfHw+tVotTp04hJSUFbdq0MblwSERERERERERErYPdAu5ffPEFLly4ALlcjv79+0Ov16Nfv37Izc1F7969AQAlJSWIjIw0BtsBICkpCVVVVThy5Aji4+NRUlKCuLg4KJVKkzYZGRkoLS1F586dG7x2VVUVqqqqjI/Ly8sBiDV7DAaD8f91/3U37L9zsf+258i+NOWC4JUrV/Dss89i586duP/++43bpfkLAC8IEhERERERERGRCbsF3KUs0KysLOTn5yMiIgJ5eXmIi4vDqVOn0LZtW+j1erRv397keUFBQfDx8YFerwcA6PV6REREmLSRnqPX680G3JcvX47s7OwG24uLi+Hv72+yTaPRtHiMroD9dy7233YqKioc9lpNuSCo0WhQW1uLCxcuoGfPnrh27RpiY2ORl5eHsLAwAGjRBUGgaRcFPYErXtixBU8dF+C5Y7PFuDzte0JERERERET20eyAe1ZWltlgdl1arRa1tbUAgEWLFuGRRx4BABQWFiI0NBTvvPMOpk+fDsD8CrCCIJhsr99Gqo9sKXs0IyMDarXa+Li8vBxhYWFITEw0rgptMBig0WiQkJDglivusv/Oxf7bnhR0doSmXBA8e/YsamtrkZOTgzVr1iAwMBDPPvssEhIS8M033xgvDDb3giDQvIuCnsCVLuzYkqeOC/Dcsd3KuBx5UZCIiIiIiMil6HTA6dPAPfcAoaHO7o3La3bAPS0tDcnJyVbbRERE4Nq1awCAXr16GbcrlUp06dIF58+fBwAEBwfj0KFDJs+9cuUKDAaDMWgVHBxszHaXlJWVAUCD7Pi6r1M341Ti7e3dILhobps7Yf+di/23HVv0w5YXBGtra2EwGPDyyy8jMTERAPD2228jODgY+/btQ1JSEoDmXxAEmnZR0BO44oUdW/DUcQGeOzZbjMuRFwWJiIiIiIhcxsqVwNNPi/+Xy4HXXwfqlOelhpodcFepVFCpVI22GzBgAJRKJU6ePIkhQ4YAED/wlpaWIjw8HAAQExODZcuW4dKlS+jQoQMAMcNTqVRiwIABxjaZmZmorq6Gj4+PsU1ISEiDzFIiat1seUFQmpPqtrnzzjuhUqlMLho294Kg9FpNvSjoCTgu9+OpY7uVcXni94OIiIiIiMiq3NybwXYAqK0Fpk8HkpKY6W6F3F4HDggIwIwZM7BkyRIUFxfj5MmTmDlzJgBg3LhxAIDExET06tULEydOxJdffomPP/4Y8+fPx9SpU41ZnhMmTIBSqURKSgqOHTuG7du3IycnhwsSElEDKpUKPXr0sPrl6+trckFQUv+C4ODBgwHApM1PP/2Ey5cvm1w03L9/P6qrq41teEGQiIiIiIiIiNyeTgcsWNBwe00NcOaM4/vjRuwWcAeAlStXIjk5GRMnTkR0dDTOnTuHvXv3IigoCACgUCiwe/du+Pr6YvDgwRg/fjxGjx6N3Nxc4zECAwOh0Wig0+kQFRWFWbNmQa1Wm5RjICJqjqZcEOzWrRtGjRqFOXPm4MCBAzh27Bgef/xx9OjRA/Hx8QB4QZCIiIiIiIiIPJN8+XLzO2Qy4O67HdsZN9PskjLN4e3tjdzcXJMAen2dOnXCrl27rB6nT58+2L9/v627R0St2MqVK+Hl5YWJEyfi+vXrGDhwoMkFQQB46623MG/ePIwYMQJyuRxxcXH48MMPjaUlpAuCs2fPRlRUFIKCgnhBkIiIiIiIiIjcmu/ly5C/8Yb5ndOmsZxMI+wacCciclVNuSAYEBCAgoICFBQUWGzDC4JERERERERE5Em67NoFi/ftP/usI7viluxaUoaIiIiIiIiIiIiI3IROh7vfe8/8vhUrmN3eBAy4ExEREZFt6HRQHT0qLrBERERERERuR/7yy+az22fMML+IKjXAgDsRERER3bqCAnjdfTcGP/ccvO6+G7BSsouIiIiIiFyQVgv56tUNt8vlwKJFDu+Ou2LAnYiIiIhujU4HTJsGWW0tAIj/LljA+o5ERERERO6ioAAYONB8drtazVIyzcCAOxERERHdmtOngd+C7SaWLWPQnYiIiIjI1el0wNSpgCA03KdQAHPmOL5PbowBdyIiIiK6NffcI95mag6D7kRERERErm3NGvPBdrkceO01Zrc3EwPuRERERHRrQkOBl16CmVN00bJlwMqVjuwRERERERE1hU4H5OU12CzIZMDBg0BqqhM65d4YcCciIiKiWzd/PmqeecZy0H3hQkCrdWSPiIiIqJWKiIiATCZr8DV79mwYDAYsXLgQffr0QZs2bRASEoJJkybh4sWLJseoqqrCk08+CZVKhTZt2mDkyJHQ6XROGhGRHVnIbq+dNw+IjnZCh9wfA+5EREREZBPC0qU4OXas+aC7IAADB4qLqfLDKhEREdmRVqvFpUuXjF8ajQYAMG7cOFRUVOCLL77Ac889hy+++ALbtm3DqVOnMHLkSJNjzJ07F9u3b8fmzZvx2Wef4ZdffsFDDz2EmpoaZwyJyD6sZLfXpqU5oUOegQF3IiIiIrKZk489hppnnjG/UxCA3FygUyegoMCxHSMimygtLUVqaio6d+4MPz8/dO3aFUuWLEF1dbVJO61Wi/vvvx933HEHgoKCkJiYiK+++sqkzdGjRxEXFwc/Pz907NgRS5cuhWCufiwRUTPdeeedCA4ONn7t2rULXbt2RVxcHAIDA6HRaDB+/Hh0794dgwYNwtq1a3HkyBGcP38eAPDzzz+joKAAeXl5GDZsGPr374+NGzfi6NGj2LNnj5NHR2RDFrLbz4waxbrtt8DL2R0gIiIiIs8iLF0KtG0rlpExFzwTBGDaNKBvX96mSuRm/vOf/6C2thavvfYa7r77bhw7dgxTp07Fr7/+itzcXADAtWvXkJSUhFGjRuGVV17BjRs3sGTJEiQlJUGn08Hb2xvl5eVISEhAfHw8tFotTp06hZSUFLRp0wbp6elOHiUReZLq6mps3LgRarUaMpnMbJuff/4ZMpkMd9xxBwDgyJEjMBgMSExMNLYJCQlBZGQkDhw4gKSkJLPHqaqqQlVVlfFxeXk5AMBgMMBgMLR4DNJzb+UYroTjcRFaLbxyc1H/t0KQyXD2oYfQ0d3GY0Fj74893jcG3ImIiIjI9hYsAO67TywjYy7oXlsr7nvjDS7ERORGHnjgATzwwAPGx126dMHJkyexfv16Y8D95MmTuHLlCpYuXYqwsDAAwJIlS9C3b1+cP38eXbt2RVFRESorK7FhwwYolUpERkbi1KlTyM/PtxoUIyJqrvfeew9Xr15FSkqK2f2VlZV45plnMGHCBAQEBAAA9Ho9fHx8EBQUZNK2ffv20Ov1Fl9r+fLlyM7ObrC9uLgY/v7+LR/Eb6TSOJ6C43GeThoN+r3ySoNgOyBmt1eqVG41nqawNJ6KigqbvxYD7kRERERkH9HRYkB9+nTAXL1TZroTeYSff/4Zbdu2NT7u3r07VCoVCgoKkJmZiZqaGhQUFKB3794IDw8HAJSUlCAuLg5KpdL4vKSkJGRkZKC0tBSdO3c2+1r2yh51FLfNgqzHE8bhCWMA3GMczu5bQUEBHnzwQYSEhDTYZzAYkJycjNraWrzyyiuNHksQBKsXBDMyMqBWq42Py8vLERYWhsTERGMwvyUMBgM0Gg0SEhLg7e3d4uO4Co7HyXQ6eD38MGRmkmIEhQKhK1bgxIkT7jOeRjT2/kjnErbEgDsRERER2U9qKpCUJNaHzMtrmO3OTHcit/bdd99h7dq1yKuz4Nrtt9+OTz75BKNGjcLzzz8PAOjWrRs++ugjeHmJH0H1ej0iIiJMjtW+fXvjPksBd3tnjzqKp2QNesI4PGEMgGuPwx7Zo0117tw57NmzB9u2bWuwz2AwYPz48fj++++xd+9ek4B4cHAwqqurceXKFZMs97KyMsTGxlp8PaVSaXIhUeLt7W2TwKWtjuMqOB4neeUV83egyuWQvfYavCIigBMn3Gc8TWRpPPYYIwPuRERERGRfoaHAypXA+PHmS8ww053I6bKysswGsuvSarWIiooyPr548SIeeOABjBs3Dk888YRx+/Xr1zFlyhQMHjwYb7/9NmpqapCbm4vhw4dDq9XCz88PABpkiUoLpjoje9RR3C4L0gJPGIcnjAFwj3HYI3u0qQoLC3HXXXdhxIgRJtulYPvp06exb98+tGvXzmT/gAED4O3tbVxcFQAuXbqEY8eOYcWKFQ7rP5HN6XRiEkx9Mhlw8KB4Lu7Cd8y4CwbciYiIiFzU7t27sXTpUnzzzTdo06YN/vCHP5hkaGm1WjzzzDM4cuQIZDIZoqOjsWLFCvTr18/Y5ujRo0hLS8Phw4fRtm1bTJ8+Hc8995xz6iNLJWamTRMz2+uSMt3T04E5c8QgPRE5TFpaGpKTk622qZuRfvHiRcTHxyMmJgavv/66SbtNmzahtLQUJSUlkMvlxm1BQUF4//33kZycjODg4AZ1kMvKygDczHQ3x97Zo47ibv21xBPG4QljAFx7HM7qV21tLQoLC/H4448b764BgBs3bmDs2LH44osvsGvXLtTU1Bjno7Zt28LHxweBgYFITU1Feno62rVrh7Zt22L+/Pno06cPhg0b5pTxENnEmjXms9vT05n4YkMMuBMRERG5oK1bt2Lq1KnIycnB0KFDIQgCjh49atx/7do1JCUlYdSoUXjllVdw48YNLFmyBElJSdDpdPD29kZ5eTkSEhIQHx8PrVaLU6dOISUlBW3atEF6erpzBpaaKmayW8p0z80Vs25YYobIoVQqFVQqVZPaXrhwAfHx8RgwYAAKCwuNQXVJRUUF5HK5yYU96XHtbxfbYmJikJmZierqavj4+AAQy8KEhIQ0KDVDRNQSe/bswfnz5zFlyhST7TqdDjt27AAAkyQFANi3bx/uu+8+AMCqVavg5eWF8ePH4/r167j//vuxYcMGKBQKR3SfyPYsZbfL5WLCC9mMvPEmRERERORIN27cwJw5c7By5UrMmDED3bp1Q/fu3TF27Fhjm5MnT+LKlStYunQpunfvjt69e2PJkiUoKyvD+fPnAQBFRUWorKzEhg0bEBkZiTFjxiAzMxP5+fnG0g1OIWW6yy2cikolZrRax/aLiBp18eJF3HfffQgLC0Nubi5++OEH6PV6k2z1hIQEXLlyBbNnz8a3336L48ePY/LkyfDy8kJ8fDwAYMKECVAqlUhJScGxY8ewfft25OTkQK1WO+cOHCLyOImJiRAEAd26dTPZHhERAUEQzH5JwXYA8PX1xdq1a/Hjjz+ioqICO3fuRFhYmINHQWRDlrLb1WreXWpjzHAnIiIicjFffPEFLly4ALlcjv79+0Ov16Nfv37Izc1F7969AQDdu3eHSqVCQUEBMjMzUVNTg4KCAvTu3Rvh4eEAgJKSEsTFxZmUX0hKSkJGRgZKS0vNLkpYVVWFqqoq42Op7qrBYIChkXqO0v7G2gEAJk0CevaE15AhkJk78a+thTBwIGpefRXC5MmNH89GmjUGF8UxuAZHjsGR36fi4mKcOXMGZ86cQWi9D+fShbwePXpg586dyM7ORkxMjHEu+/DDD9GhQwcAQGBgIDQaDWbPno2oqCgEBQVBrVab1GcnIiIiG2F2u0Mx4E5ERETkYs6ePQtAXMQwPz8fERERyMvLQ1xcHE6dOoW2bdvi9ttvxyeffIJRo0bh+eefBwB069YNH330kbFOqV6vb1CaQaqNrNfrzQbcly9fbnbhxOLiYvj7+zep/xqNpslj7TRrFvqtXw9Z/ZruAGSCAMXMmShWKFDZxFIXttKcMbgqjsE1OGIMFRUVdn8NSUpKClJSUhptl5CQgISEBKtt+vTpg/3799uoZ0RERGQRs9sdigF3IiIiIgfJysoyG8yuS6vVGmscL1q0CI888ggAoLCwEKGhoXjnnXcwffp0XL9+HVOmTMHgwYPx9ttvo6amBrm5uRg+fDi0Wi38/PwAoEFpBikD1VLJhoyMDJMM0/LycoSFhSExMREBAQFW+24wGKDRaJCQkND0BdKGD8eN9HTI162DfNWqBtnustpaDPvwQ9SuWOGQDwMtGoOL4RhcgyPHIN2JQkRERNSATieuk1Qfs9vthgF3IiIiIgdJS0tDcnKy1TYRERG4du0aAKBXr17G7UqlEl26dDHWZ9+0aRNKS0tRUlJiXLBw06ZNCAoKwvvvv4/k5GQEBweb1FUGgLKyMgA3M93rUyqVJiVoJN7e3k0OGjanLQCgc2fxFtfkZLOLqSrefReKrVsdupBqs8fggjgG1+CIMbj794iIiIjsyFwpGYDZ7XbEgDsRERGRg6hUKqiaUBplwIABUCqVOHnyJIYMGQJAzJYtLS011mevqKiAXC43yVSXHksZ8jExMcjMzER1dTV8fHwAiKVhQkJCGpSacQnR0UB6uvkMHGkh1b59xXZERERERGSdVgusXt1wO7Pb7Uru7A4QERERkamAgADMmDEDS5YsQXFxMU6ePImZM2cCAMaNGwdArI985coVzJ49G99++y2OHz+OyZMnw8vLC/Hx8QCACRMmQKlUIiUlBceOHcP27duRk5MDtVptsaSM082ZA1jqW22tmAFfUODYPhERERERuZuCAvHc2Rxmt9sVA+5ERERELmjlypVITk7GxIkTER0djXPnzmHv3r0ICgoCAPTo0QM7d+7EN998g5iYGPz+97/HxYsX8eGHH6JDhw4AgMDAQGg0Guh0OkRFRWHWrFlQq9UmNdpdTmioWDpGoTC/X8p012od2y8iIiIiIneh0wFTp5pfKFWhYHa7nbGkDBEREZEL8vb2Rm5uLnLNlVf5TUJCAhISEqwep0+fPti/f7+tu2dfqalAUhKwZo1Yc7L+BwUp0z09XfywwOwcIiIiIqKb1qwxH2yXy4HXXuP5s53ZPcN99+7dGDhwIPz8/KBSqTBmzBjjvq+//hqPPvoowsLC4Ofnh549e2LNmjUNjnH06FHExcXBz88PHTt2xNKlSyGY+6EhIiIiIs8QGgqsXAkcOmS+xIwgiLXeO3ViiRkiIiIiIolOZ36hVJkMOHhQTG4hu7JrhvvWrVsxdepU5OTkYOjQoRAEAUePHjXuP3LkCO68805s3LgRYWFhOHDgAKZNmwaFQoG0tDQAQHl5ORISEhAfHw+tVotTp04hJSUFbdq0QXp6uj27T0RERETOFh0tlpiZNk3MbK+Pi6kSEREREd1kKbs9PZ3nyw5it4D7jRs3MGfOHKxcuRKpda6cdO/e3fj/KVOmmDynS5cuKCkpwbZt24wB96KiIlRWVmLDhg1QKpWIjIzEqVOnkJ+f79oLfhER2YNOB5w+DdxzD28BI6LWIzVVDKgPHGj+w4NUYuaNN5ixQ0REREStl6XsdrmcddsdyG4lZb744gtcuHABcrkc/fv3R4cOHfDggw/i+PHjVp/3888/o23btsbHJSUliIuLg1KpNG5LSkrCxYsXUVpaaq/uExG5noICIDwcGDpU/NdKXWciIo8jZbpzMVUiIiIiIvNWrzafoKJWM2nPgeyW4X727FkAQFZWFvLz8xEREYG8vDzExcXh1KlTJkF1SUlJCbZs2YLdu3cbt+n1ekRERJi0a9++vXFf586dGxynqqoKVVVVxsfl5eUAAIPBAIPBYPx/3X/dDfvvXOy/7blSX1ySTmdaTqG2FliwAPjqK+DFF/mHk4hah6YupspMdyIiIiJqbZjd7jKaHXDPyspCdna21TZarRa1vwWFFi1ahEceeQQAUFhYiNDQULzzzjuYPn26yXOOHz+OUaNGYfHixUhISDDZV79sjLRgqqVyMsuXLzfbx+LiYvj7+5ts02g0Vsfi6th/52L/baeiosLZXXBtp0+br11cVCR+rVwJzJ/v+H4RETmatJjq+PHmS8ywpjsRERERtUaW7oJndrvDNTvgnpaWhuTkZKttIiIicO3aNQBAr169jNuVSiW6dOmC8+fPm7Q/ceIEhg4diqlTp+LZZ5812RccHAy9Xm+yraysDMDNTPf6MjIyoFarjY/Ly8sRFhaGxMREBAQEABCzaTUaDRISEuDt7W11PK6I/Xcu9t/2pDtRHGn37t1YunQpvvnmG7Rp0wZ/+MMfsG3bNuN+rVaLZ555BkeOHIFMJkN0dDRWrFiBfv36GdscPXoUaWlpOHz4MNq2bYvp06fjueees/36EvfcI64obu7WMEDMdj9zBnj2Wf4hJaLWwdpiqlKme3q6mM3DeZGIiIiIPJlWK94FWh+z252i2QF3lUoFlUrVaLsBAwZAqVTi5MmTGDJkCAAxyFdaWorw8HBju+PHj2Po0KF4/PHHsWzZsgbHiYmJQWZmJqqrq+Hj4wNAzFQPCQlpUGpGolQqTWq+S7y9vRsEF81tcyfsv3Ox/7bj6H5s3boVU6dORU5ODoYOHQpBEHD06FHj/mvXriEpKQmjRo3CK6+8ghs3bmDJkiVISkqCTqeDt7c3ysvLkZCQgPj4eGi1Wpw6dQopKSlo06YN0tPTbdvh0FBgxQoxsG7Ja68Br7/OUgpE1HpYW0xVEMQsn7w8zotERERE5LkKCoCpU83vY3a7U9ht0dSAgADMmDEDS5YsQXFxMU6ePImZM2cCAMaNGwdADLbHx8cjISEBarUaer0eer0eP/zwg/E4EyZMgFKpREpKCo4dO4bt27cjJycHarXa9hmkRNQq3LhxA3PmzMHKlSsxY8YMdOvWDd27d8fYsWONbU6ePIkrV65g6dKl6N69O3r37o0lS5agrKzMeJdOUVERKisrsWHDBkRGRmLMmDHIzMxEfn6+sfSVTc2fDyxaZL0NFw0kotZGynSXWzit5bxIRERERJ5KpxOD7eZiEAoFs9udxG4BdwBYuXIlkpOTMXHiRERHR+PcuXPYu3cvgoKCAADvvPMOfvjhBxQVFaFDhw7Gr+g69TYDAwOh0Wig0+kQFRWFWbNmQa1Wm5SMISJqji+++AIXLlyAXC5H//790aFDBzz44IM4fvy4sU337t2hUqlQUFCA6upqXL9+HQUFBejdu7fxLp2SkhLExcWZ3FGTlJSEixcvorS01D6df+EFMdPdGqmUwoIF4h9fIiJPl5oKHDwolt4yR5oXCwoc2y8iIiIiIntas8Z8sF0uF++CZ3a7UzS7pExzeHt7Izc3F7kWivZnZWUhKyur0eP06dMH+/fvt3HviKi1Onv2LABxDsrPz0dERATy8vIQFxeHU6dOoW3btrj99tvxySefYNSoUXj++ecBAN26dcNHH30ELy9x6tTr9Q1KW0lrS+j1enTu3Nns61dVVaGqqsr4WKpfbzAYYDAYGh/A3LnA2LGQL18O+ZtvQmbuj+tvpRSEvDzUzp2L2iefdPgfWmksTRqTG/HUcQGeOzZbjMvTviceScp0nz4dqKlpuJ+LqRIRERGRJ9HpxPKJ9clkYjIKz3mdxq4BdyIiR8rKykJ2drbVNlqtFrW/La63aNEiPPLIIwCAwsJChIaG4p133sH06dNx/fp1TJkyBYMHD8bbb7+Nmpoa5ObmYvjw4dBqtfDz8wOABqWtpFIy1kpeLV++3Gw/i4uL4e/v3/QBjxgB34ED0WXXLtz93nsw94oyQYBi1SrIV63CmdGjcfahh1DZhHU4bEmj0Tj09RzFU8cFeO7YbmVcFRUVNuwJ2U1qKpCUJGb65OU1zPaRMt1Z052IiIiI3J2l7Pb0dAbbnYwBdyLyGGlpaUhOTrbaJiIiAteuXQMA9OrVy7hdqVSiS5cuxvrsmzZtQmlpKUpKSiD/rS7wpk2bEBQUhPfffx/JyckIDg6GXq83OX5ZWRmAm5nu5mRkZJiUxSovL0dYWBgSExMREBDQjBH/ZtIk3NBq4TVkiPlsdwAyAPe89x7ufv99h2W8GwwGaDQaJCQkuMzivLbgqeMCPHdsthiXdCcKuYHQUGDlSmD8eMuLqTLTnYiIiIjcmaXsdrmcddtdAAPuROQxVCoVVE3I3h4wYACUSiVOnjyJIUOGABADcqWlpcb67BUVFZDL5SaZ6tJjKUM+JiYGmZmZqK6uho+PDwAxSz0kJKRBqZm6lEqlSd13ibe3d8uDnLGx1ksp/EbKeFesXu2wDM9bGpcL89RxAZ47tlsZlyd+PzyeVGJm2jQxs70uKdM9PV38QMLalkRERETkTlavNp/drlbz3NYF2HXRVCIiVxQQEIAZM2ZgyZIlKC4uxsmTJzFz5kwAwLhx4wAACQkJuHLlCmbPno1vv/0Wx48fx+TJk+Hl5YX4+HgAwIQJE6BUKpGSkoJjx45h+/btyMnJgVqttlpSxm5SU4HSUmD+fPGqtjVShqdW65CuERE5hbXFVH9b6wKdOnExVSIiIiJyH8xud3kMuBNRq7Ry5UokJydj4sSJiI6Oxrlz57B3714EBQUBAHr06IGdO3fim2++QUxMDH7/+9/j4sWL+PDDD9GhQwcAQGBgIDQaDXQ6HaKiojBr1iyo1WqTcjEOJ5VSOHeu8cC7lOFpYWFrIiKPIGW6W5oPeQGSiIiIiNzJ4sXmtzO73WWwpAwRtUre3t7Izc1FrpVgc0JCAhISEqwep0+fPti/f7+tu3frpMD7nDniQir5+Q1LKgBioGnBAuDMGeDZZ/nHmYg8U2qqWLPdXE13wHQx1UmTHN8/IiIiIqKmyM0FCgsbbmd2u0thhjsRkSern/FuqdTNa6+JZRUWLBBvTyMi8jRSprtCYX4/M92JiIiIyJVpteJndnOY3e5SGHAnImoNpMD7oUOWg+516xkz8E5EnqjuWhfm5sLaWngNGYJOGo3Du0ZEREREZFFBATBokPl9zG53OQy4ExG1JtHRwIoV1ttwIUEi8mSNXICUCQL6vfIKM92JiIiIyDXodMDUqebLxALAiy8yu93FMOBORNTazJ8vBt2tLagKsLwCEXk2K4upygQBXkOG8G4fIiIiInK+NWvMr0Mkk4mJJJbKzJDTMOBORNQaLVhws667tcC7tJAgg05E5IlSU4GDBy1muvNuHyIiIiJyKp0OyMtruF0mE+/YnD/f8X2iRjHgTkTUWtVfUNVS4J213YnIk1nJdAfAu32IiIjcUEREBGQyWYOv2bNnAwAEQUBWVhZCQkLg5+eH++67D8ePHzc5RlVVFZ588kmoVCq0adMGI0eOhI6fhcjRLGW3p6eL57HkkhhwJyJq7eoH3rmoKhG1NlYy3QHcvNuHme5EAICRI0eiU6dO8PX1RYcOHTBx4kRcvHjRpM358+fxxz/+EW3atIFKpcJTTz2F6upqkzZHjx5FXFwc/Pz80LFjRyxduhSCuaACEVEzabVaXLp0yfil+W1B9HHjxgEAVqxYgfz8fKxbtw5arRbBwcFISEjAtWvXjMeYO3cutm/fjs2bN+Ozzz7DL7/8goceegg1NTVOGRO1Qpay27lIqstjwJ2IiESNLCRoxMA7EXmi3zLdBYXC/H5muhMZxcfHY8uWLTh58iS2bt2K7777DmPHjjXur6mpwYgRI/Drr7/is88+w+bNm7F161akp6cb25SXlyMhIQEhISHQarVYu3YtcnNzkZ+f74whEZGHufPOOxEcHGz82rVrF7p27Yq4uDgIgoDVq1dj0aJFGDNmDCIjI/G3v/0NFRUV2LRpEwDg559/RkFBAfLy8jBs2DD0798fGzduxNGjR7Fnzx4nj45aDUvZ7Wo1F0l1cQy4ExGRKam8gqWgk4T1jYnI06Sm4sbp0zg9ejQEcxcemelOBACYN28eBg0ahPDwcMTGxuKZZ57BwYMHYTAYAADFxcU4ceIENm7ciP79+2PYsGHIy8vDG2+8gfLycgBAUVERKisrsWHDBkRGRmLMmDHIzMxEfn4+s9yJ3IFOB+zb5xbJN9XV1di4cSOmTJkCmUyG77//Hnq9HomJicY2SqUScXFxOHDgAADgyJEjMBgMJm1CQkIQGRlpbENkV8xud2tezu4AERG5oNRUIClJvKKeny8GmSyRsj779mUNOSJyf6GhOJGSgogFC+A9ZEjDrCLOeUQmfvrpJxQVFSE2Nhbe3t4AgJKSEkRGRiIkJMTYLikpCVVVVThy5Aji4+NRUlKCuLg4KJVKkzYZGRkoLS1F586dzb5eVVUVqqqqjI+lAL7BYDAG/F2Z1Ed36Ks1njAOTxgD4IRx6HSQL18O+RtvQAZAkMtRs349hMmTG+2js7z33nu4evUqUlJSAAB6vR4A0L59e5N27du3x7lz54xtfHx8EBQU1KCN9Hxz7DVHecrPq4TjaZw8Px8KMxega+bORW379oAdv3et7f2xxzgZcCciIvOkEjNz5jQeeJeyPtPTxfa8vY2I3J10t8+0aQ3nPs55RFi4cCHWrVuHiooKDBo0CLt27TLu0+v1DQJZQUFB8PHxMQaq9Ho9IiIiTNpIz9Hr9RYD7suXL0d2dnaD7cXFxfD397+VITmUVE/a3XnCODxhDIBjxtF1+3b0/tvfUPceMFltLeQzZ0KjUKBSpTL7vIqKCrv3zZqCggI8+OCDJhcBAUBW7242QRAabKuvsTb2nqM85edVwvGYF3jqFOJWrWqwXZDJsKdXL1T+8582eZ3GtJb3xx5zFAPuRERkXVMD71KJmbw8MQg1a5bj+0pEZEupqWIm+8CB5jPdpTnvjTfEtkRuLCsry2yQqC6tVouoqCgAwIIFC5Camopz584hOzsbkyZNwq5du4yBKHMBqfqBKnPBLkvPlWRkZECtVhsfl5eXIywsDImJiQgICGhklM5nMBig0WiQkJBgvCPAHXnCODxhDICdx6HTQXbmDIQ2bSAvLIS8XrBdIq+txf3h4RDi4sweRsrydoZz585hz5492LZtm3FbcHAwAPHiXocOHYzby8rKjBf+goODUV1djStXrphkuZeVlSE2Ntbi69lrjvKUn1cJx2OZrLAQimeeMfu7VjtvHoZOmnRLx2+K1vb+2GOOYsCdiIiapn7gPS/P/AIuvwWhvPLy0GvUKDFYZSFLjYjI5VnLdAdYYoY8RlpaGpKTk622qZuRrlKpoFKp0K1bN/Ts2RNhYWE4ePAgYmJiEBwcjEOHDpk898qVKzAYDCbBrPplGcrKygA0LPNQl1KpNClDI/H29naroIC79dcSTxiHJ4wBsPE4dDrr5/v1yeXw6tEDsPD6zvz+FhYW4q677sKIESOM2zp37ozg4GBoNBr0798fgFjn/dNPP8VLL70EABgwYAC8vb2h0Wgwfvx4AMClS5dw7NgxrFixwuLr2XuO8pSfVwnHU49OB8yYYf73TqGAYt48KBz4/Wot7489xshFU4mIqHmkwPuhQ4CVDDSZIOCe996DV9euXGCQiNxbaipw8KDlOY+LqZIHUKlU6NGjh9UvX19fs8+VMtOlusUxMTE4duwYLl26ZGxTXFwMpVKJAQMGGNvs378f1dXVJm1CQkIalJohIgfR6YAFC4BOncS7uJq6gPGLL7pkebXa2loUFhbi8ccfh5fXzXxTmUyGuXPnIicnB9u3b8exY8eQkpICf39/TJgwAQAQGBiI1NRUpKen4+OPP8aXX36Jxx57DH369MGwYcOcNSTydGvWmP+9k8uB115zyd8zMo8BdyIiahkp61OhsNpMJmV/arUO6hgRkR00NudxrqNW4vDhw1i3bh2++uornDt3Dvv27cOECRPQtWtXxMTEAAASExPRq1cvTJw4EV9++SU+/vhjzJ8/H1OnTjWWVJgwYQKUSiVSUlJw7NgxbN++HTk5OVCr1Y3WUCYiG2tpoB0QE3EWLLBf327Bnj17cP78eUyZMqXBvqeffhpz587FrFmzEBUVhQsXLqC4uBi33367sc2qVaswevRojB8/HoMHD4a/vz927twJRSOff4haRKcT7yqpTyYTEz9YvtCtMOBOREQtl5oKlJYC8+eLV90tkbI/FywQTySIiNxR3TnPXECQme7UCvj5+WHbtm24//770b17d0yZMgWRkZH49NNPjWUUFAoFdu/eDV9fXwwePBjjx4/H6NGjkZubazxOYGAgNBoNdDodoqKiMGvWLKjVapPax0RkRzodsG+fGDAPD29eoF0mE8te/Pe/4t9EF5WYmAhBENCtW7cG+2QyGbKysnDp0iVUVlbi008/RWRkpEkbX19frF27Fj/++CMqKiqwc+dOhIWFOar71NpYym5PT2fZQjfEGu5ERHRrWrqo6pw5vCWOiNyPNOeNH295MVXWdCcP1qdPH+zdu7fRdp06dcKuXbsaPdb+/ftt1TUiaorm1mevS6EA5s3jeTyRrVnKbpfLxd83cjvMcCciItuQglDnzgHz50OwdDu4FHjv1IkZ70TkvqQSM+bu7mGmOxERuQopk12rbX7ZGLlczGA/fFg8RmmpeL7PYDuRbVnKbler+fvmphhwJyIi2/ot8H7js89g9TS+buCdQSkickfWFlNlTXciInKmunXZhw4F7r23+YH2c+fEAHt0NHDffQz8EdkDs9s9EgPuRERkH9HR+Gr2bAiNLSrEoBQRubOmZLrzbh4iInKUW1kAVaEwDbQzwE5kf8xu90gMuNej0wFbtgDr14v/8rMREVHLnU9IwI3Tp7moKhF5tsYy3Xk3DxER2VtLA+1yuRhcZ8kYIsfT6cTf1/qY3e727B5w3717NwYOHAg/Pz+oVCqMGTPGbLsff/wRoaGhkMlkuHr1qsm+o0ePIi4uDn5+fujYsSOWLl0KobmLezRBbi4QFgb86U/ArFniv2Fh4uLbjP8QEbVQvdruFgPvrO1OZPTJJ59AJpOZ/dLWuRvk/Pnz+OMf/4g2bdpApVLhqaeeQnV1tcmxHHUe1epZy3QHeDcPERHZh06HXoWF8OratfmBdimbff58lowhcobVq81vZ3a727NrwH3r1q2YOHEiJk+ejK+//hqff/45JkyYYLZtamoq+vbt22B7eXk5EhISEBISAq1Wi7Vr1yI3Nxf5+fk27atOBzz9tPl9r70mBt4XLBA/I+3bxzgQEVGz1Q+8N2VRVWaDUisVGxuLS5cumXw98cQTiIiIQFRUFACgpqYGI0aMwK+//orPPvsMmzdvxtatW5Genm48jqPOo+g31jLdAS6mSkREtvNbRrtX16645/33IWtqoJ1lY4hcg1bL2u0ezMteB75x4wbmzJmDlStXIjU11bi9e/fuDdquX78eV69exeLFi/HBBx+Y7CsqKkJlZSU2bNgApVKJyMhInDp1Cvn5+VCr1ZBZ+kDTTKdPN34hODf35p0ecrl4wWn8eOCXX4B77uHfKSKiJpEC7+PHi4EnS5OvlA3at6+YOUrUivj4+CA4ONj42GAwYMeOHUhLSzOe+xQXF+PEiRP473//i5CQEABAXl4eUlJSsGzZMgQEBDjsPIrqkDLdp08Hamoa7ufcRkRELaHTiYGL224D/vEPY6Cu0b/kdYMXv/4K3H03gxdEzlZQAEydan4fs9s9gt0y3L/44gtcuHABcrkc/fv3R4cOHfDggw/i+PHjJu1OnDiBpUuX4q233oLczC24JSUliIuLg1KpNG5LSkrCxYsXUVpaarP+3nOP9fLC9dXWisH3e+8VF/wOD2cFBCKiZpGCUtYWVWVtdyIAwI4dO3D58mWkpKQYt5WUlCAyMtIYbAfEc6SqqiocOXLE2MYR51FUT2qqWAfX0t08zHQnIqKmqlubfehQMQhhLiu2vrolY1auFM+9WTaGyPl0OjHYbi7xTKFgdruHsFuG+9mzZwEAWVlZyM/PR0REBPLy8hAXF4dTp06hbdu2qKqqwqOPPoqVK1eiU6dOxufUpdfrERERYbKtffv2xn2dO3du8JyqqipUVVUZH5eXlwMQs8MMBoPx/3X/bd8eWL9ehpkzFaitbX62lxSAz8sTMHduLcaOrcWvv8pw992CXf6e1e+/u2H/ncsV++9KfSEHSk0FkpLEldnz88XJtD6pxExeHpCeLp6A8IMCtTIFBQVISkpCWFiYcZterzeeE0mCgoLg4+MDvV5vbGOP8yhLXPHvS3PZbAzt2wM5OcDDD8NryJCGt/oLAoRp03CjZ0+bZ7rzfXANjhyDO3+fiMgCnU48R87La3pdduBmRjvPmYlc05o15n+n5XKxpjV/bz1CswPuWVlZyM7OttpGq9Wi9regyaJFi/DII48AAAoLCxEaGop33nkH06dPR0ZGBnr27InHHnvM6vHq3+4sLfRl6Tbo5cuXm+1jcXEx/P39TbZpNBrj/9u3B15/3Rf/+U8QtNpgfPppGJpwg1a9vsmwapUCq1bJAcggkwl45JGT+L//+xEdOvwClaqyWcdrTN3+uyP237lcqf8VFRXO7gI5i1RiZs4c6x8qGHgnD9DU8yipTjsA6HQ6fPTRR9iyZUuDtubOhQRBMNluz/MoS1zp70tL2XIMnWbNQr9XXmkQdJfV1sJr8GB8NXs2zick2Oz1JHwfXIMjxsDzKCIP0sJAuyCXQ8ZAO5Fr0+nM36Eik4nrALHcoMdodsA9LS0NycnJVttERETg2rVrAIBevXoZtyuVSnTp0gXnz58HAOzduxdHjx7Fu+++C+DmB0CVSoVFixYhOzsbwcHBxiwtSVlZGQA0yOqSZGRkQK1WGx+Xl5cjLCwMiYmJCAgIACBmgWg0GiQkJMDb29vscXS6Gzh4UIZ9+2QoKJD/lvkuoGlBeNlvY5Lh3Xe74913ZZDLBcyZY5vs96b035Wx/87liv2XMiipFWtObXcp8P7GG2KWPJGbaOp5VF2FhYVo164dRo4cabI9ODgYhw4dMtl25coVGAwG4zmSvc6jLHHFvy/NZZcxDB+OGxMmmM10lwHot349IidMsNmHLL4PrsGRY+B5FJEHuIVA+5mRIxGRnw9vM3euEZELsZTdnp7OYLuHaXbAXaVSQaVSNdpuwIABUCqVOHnyJIYMGQJAPOksLS1FeHg4AGDr1q24fv268TlarRZTpkzBv/71L3Tt2hUAEBMTg8zMTFRXV8PHxweAmGEVEhLS4AOpRKlUmtQqlXh7ezc42TW3TdK5s/j16KPA4sXAmTNAmzYybNliufKBeWLwvbZWyn4X6xXb4k4va/13B+y/c7lS/12lH+QCGltwUMKFB8kNNfU8SiIIAgoLCzFp0qQG82RMTAyWLVuGS5cuoUOHDgDEcySlUokBAwYY29jzPMoSV/r70lI2H0NsrDi3TZvW4CRSVlsL7yFDbH73Dt8H1+CIMbj794ioVaq7COrmzWKQoTkUCmDePNyYNQsnvvkGEcxqJ3JtlrLb5XLWbfdAdls0NSAgADNmzMCSJUtQXFyMkydPYubMmQCAcePGAQC6du2KyMhI45dUR7Rnz5646667AAATJkyAUqlESkoKjh07hu3btyMnJwdqtdrirdD2EBoqri8SHS0mYJ47B+zbBxw+LK5D0pwFVyVS3fdOncQ1ULRa8ZhcF5CIWr26Cw5am2C5qCp5uL179+L7779Hqpk7ORITE9GrVy9MnDgRX375JT7++GPMnz8fU6dONWaiu8p5FP0mNVW8Xdjc9166e6dTJy6mSkTkycwtgtqUYLu0COrhw2LgoLRUDE4w0E7kHl54wXx2u1rN32MPZLeAOwCsXLkSycnJmDhxIqKjo3Hu3Dns3bsXQUFBTT5GYGAgNBoNdDodoqKiMGvWLKjVapNbnZ3BXAC+pYF36fPVvfeKf2/DwxmAJyIylphpbIKtG6Ri4J08TEFBAWJjY9GzZ88G+xQKBXbv3g1fX18MHjwY48ePx+jRo5Gbm2ts46rnUa2adBePtTlt2jTxRJCIiDxH3UB7bm7Ty8ZIgfZz58Rz4+hoMRjBAB2R+8jNFRdErY/Z7R6r2SVlmsPb2xu5ubkmH/ysue+++4x13Ovq06cP9u/fb+vu2VTdNf/OnAE0GuDFF5tTduYmKfNd+rZxkXEiatW4qCq1Yps2bbK6v1OnTti1a5fVNu5wHtXqpKaK5bAsrVch3b3DdSqIiNxfC2uzMxBA5CF0OuDpp83vY3a7x7JrhntrJGW+L1tmm7IzgPnSM598IsPly7427TsRkUuTAu+HDpkvxyBhWQYicgdSprtCYX4/M92JiNybrTLaGYwjcm+WFkpldrtHY8Ddjmxd971u6ZnERC9MnZqIhQvlLD1D1EyffPIJZDKZ2S9tncDG+fPn8cc//hFt2rSBSqXCU089herqapNjHT16FHFxcfDz80PHjh2xdOlSs3fqkA01FqSSMFhFRK6u7noV5i4kSpnuvHhIROT6dDrxg7lWK95tGRbWvEC7QsFAO5Gn0WrNL5QKiGUx+HvusRhwdyBb1n0HAEGQYdUqRYPa7wy8E1kXGxuLS5cumXw98cQTiIiIQFRUFACgpqYGI0aMwK+//orPPvsMmzdvxtatW5Genm48Tnl5ORISEhASEgKtVou1a9ciNzcX+U1Z9IhuDRdVJSJP0djdO7x4SETk2rgIKhGZU1AADBpk/qLbjBnivEEeiwF3J6q7HqC9Ss8w852oIR8fHwQHBxu/2rVrhx07dmDKlCmQ/RbsKC4uxokTJ7Bx40b0798fw4YNQ15eHt544w2Ul5cDAIqKilBZWYkNGzYgMjISY8aMQWZmJvLz85nl7ghcVJWIPIm1xVSZ6U5E5Hq4CCoRWaLTAVOnml/YUaEAFi1yfJ/Ioey6aCo1TWjozb+t0dE3F15t0wbYskW8ON6cxVel2BIXXSVqmh07duDy5ctISUkxbispKUFkZCRCQkKM25KSklBVVYUjR44gPj4eJSUliIuLg1KpNGmTkZGB0tJSdO7c2ezrVVVVoaqqyvhYCuAbDAYYDAYbj855pLHYfUzt2wM5OcCsWZCvWwf5qlWQWVlUVcjLQ82rr0KYPLlFL+ewcTmBp47NFuPytO8JuShri6lKme59+4onjERE5BxcBJWIGmOtbvtrr3EOaAUYcHdB5gLwa9Y0P/AukTLf8/LEUnLjxwO//ALccw9/x4kAoKCgAElJSQgLCzNu0+v1aN++vUm7oKAg+Pj4QK/XG9tERESYtJGeo9frLQbcly9fjuzs7Abbi4uL4e/vfytDcUkajcZxL/aHPyAwOBhxTz8NS8uqygQBihkz8OnPP+Pnbt1a/FIOHZeDeerYbmVcFRUVNuwJkRVSpvu0aQ1P/KRM9/R0BmyIiBxNCrRLmW1NxUA7Ueui05mv2y6TAQcPMnGilWDA3Q1IVRPqZr5v3lyDVatkEISm15+xlPnOADx5iqysLLOB7Lq0Wq2xTjsA6HQ6fPTRR9iyZUuDtjIztXQFQTDZXr+NVErG3HMlGRkZUKvVxsfl5eUICwtDYmIiAgICrPbfnRgMBmg0GiQkJMDb29txLzx8OGoCA6GYNQuymhqzTWSCgLiFC1E7dy5qn3yyWZOf08blAJ46NluMS7oThcghGst0lzIp3nhDbEtERLan0wGnTwO33QZs2gSsXt285ysUwLx5DLQTtTaWstvT0xlsb0UYcHcjdTPf+/WrRa9eexEefj8CA71aVHpGynxn6RnyFGlpaUhOTrbapn5GemFhIdq1a4eRI0eabA8ODsahQ4dMtl25cgUGg8GYxR4cHGzMdpeUlZUBQIPs+LqUSqVJGRqJt7e3RwU5JU4Z17RpwPDhVm8PkgkCFKtWQbF6dYuyRT31/QI8d2y3Mi5P/H6Qi7OW6Q6wxAwRkb3casmY8eOBX38F7r6bH6yJWhtL2e1yufh5k1oNLprqxlSqSsTFCYiObtq6gY3hoqvk7lQqFXr06GH1y9fX19heEAQUFhZi0qRJDYJpMTExOHbsGC5dumTcVlxcDKVSiQEDBhjb7N+/H9XV1SZtQkJCGgT2yQnqL6pq6a4DLqpKRK4qNVW89djS/MXFVImIbIeLoBLRLZKvXWt+7lCrOSe0Mgy4e5C6saV9+4DDh1sWgJdiT/feCwwdCoSHMwBPnmnv3r34/vvvkWrmdvzExET06tULEydOxJdffomPP/4Y8+fPx9SpU41lXyZMmAClUomUlBQcO3YM27dvR05ODtRqtdWSMuRg0uR46JDloBVgGnhn8IqIXIWU6a5QmN8vZbprtY7tFxGRp7BVoJ3BNKJWzffyZcjNlZ5idnurxIC7BwoNFS+o2zrzvX4AnoF3cncFBQWIjY1Fz549G+xTKBTYvXs3fH19MXjwYIwfPx6jR49Gbp1FkgIDA6HRaKDT6RAVFYVZs2ZBrVab1GcnF9JY0ErC4BURuZrUVKC01PLdOsx0JyJqOp1OzCTTatGrsBBeXbow0E5Et6zLrl2QMbudfsMa7q2AuUVXW1LzXSIF4PPyxLLHXHSV3NWmTZus7u/UqRN27dpltU2fPn2wf/9+W3aL7Ck1FUhKslrbHcDN4FULarsTEdmFdEI3frzlxVSlmu79+jmli0RELq1ebXYvAPc05/lcBJWILNHpcPd77zXczuz2VosZ7q2Iucx3e5SeYeY7Ebm0+rXdLU1+rO1ORK5IulvH3Nz128VCWWGh4/tFROSqLJSMabQApJTJfviw+MG5tJQZ7URklnztWvNzCrPbWy0G3Fsxe5We4aKrROQWWrKoKss1EJErsLaYqiBAMXMmAk+dcny/qNUYOXIkOnXqBF9fX3To0AETJ07ExYsXjfu//vprPProowgLC4Ofnx969uyJNWvWNDjO0aNHERcXBz8/P3Ts2BFLly6F0NSyHkSN4SKoROQIWi3kq1Y13M7s9laNAXcy4qKrRNQqNWdRVdZ2JyJXYSXTXVZbi7inn4Z84UKeeJFdxMfHY8uWLTh58iS2bt2K7777DmPHjjXuP3LkCO68805s3LgRx48fx6JFi5CRkYF169YZ25SXlyMhIQEhISHQarVYu3YtcnNzkZ+f74whkSfhIqj0mwsXLuCxxx5Du3bt4O/vj379+uHIkSPG/b/88gvS0tIQGhpqvDi4fv16k2NUVVXhySefhEqlQps2bTBy5Ejo+LeVJAUF4t2F5vYxu71VYw13aiA09OacEB1967Xfpcx3aa1J8SKfHL17+9q+80RELSUFr6ZPB2pqzLeprYXXkCHoNWqUWCe5c2fH9pGIqK7UVHEuMlPTXQZAsWoVsHq1OLelpjqli+SZ5s2bZ/x/eHg4nnnmGYwePRoGgwHe3t6YMmWKSfsuXbqgpKQE27ZtQ1paGgCgqKgIlZWV2LBhA5RKJSIjI3Hq1Cnk5+dDrVZDZu0iOFFdOh1w+jRw223A5s3iB9YmECDOlYJCARlrs3ucK1euYPDgwYiPj8cHH3yAu+66C9999x3uuOMOY5t58+Zh37592LhxIyIiIlBcXIxZs2YhJCQEo0aNAgDMnTsXO3fuxObNm9GuXTukp6fjoYcewpEjR6BQKJw0OnIJOh0wdar5i3oKBbPbWzlmuFOj7FF6ZtUqBZ54IhELF8qZ+U5EriM1VazPaWWSkwkC7nnvPXh17cra7kTkfNZqugO8O4fs7qeffkJRURFiY2Ph7e1tsd3PP/+Mtm3bGh+XlJQgLi4OSqXSuC0pKQkXL15EaWmpPbtMnqJuJvvQoeIt1k0Jtv+WyX7j88/x2fPP48bp08xo90AvvfQSwsLCUFhYiHvvvRcRERG4//770bVrV2ObkpISPP7447jvvvsQERGBadOm4f/+7//w73//G4A4bxUUFCAvLw/Dhg1D//79sXHjRhw9ehR79uxx1tDIVaxZYz7YLpcDr73GOaWVY4Y7NZtUfeFWM98BGVatUkAqdSWXi3fcMLGAiJyq7iS3Zg2Ql2f2REom1c/KywPS0zl5EZHzWMl0B2BcTJWZ7mRLCxcuxLp161BRUYFBgwZh165dFtuWlJRgy5Yt2L17t3GbXq9HRESESbv27dsb93W2cBdZVVUVqqqqjI/Ly8sBAAaDAQaDoaXDcRipj+7QV2ucOg6dDvJ16yBftUo8H2siQS5H7dy5qE1LA0JDYTAY8OMPP8DQvj3gxu+HO/xMOaNvO3bsQFJSEsaNG4dPP/0UHTt2xKxZszB16lRjmyFDhmDHjh2YMmUKQkJC8Mknn+DUqVPGNSeOHDkCg8GAxMRE43NCQkIQGRmJAwcOICkpyeHjIheh04mfA+sRZDLIDh4UEyKoVWPAnVrMXOmZNWtaEngXSaVnpNjV+PHAL78A99zDGBYROYEUeB8/3nIQC7i5cEVeHoNZROQ8jZXFkjLd+/blh0AyKysrC9nZ2VbbaLVaREVFAQAWLFiA1NRUnDt3DtnZ2Zg0aRJ27drVoBTM8ePHMWrUKCxevBgJCQkm++q3lRZMtVZOZvny5Wb7WVxcDH9/f6v9dyUajcbZXbAJR47D9/JldNm5E3e//775eskWCDIZzowahbMPPYRKlQr45hvx6zd8L+yvoqLC4a959uxZrF+/Hmq1GpmZmTh8+DCeeuopKJVKTJo0CQDw8ssvY+rUqQgNDYWXlxfkcjnefPNNDBkyBIB48c/HxwdBQUEmx27fvj30er3Z17XXRUF3uLDSHO4+Hnl+PhRmPh8a5syBrF8/t76IB7j/+1NfY+OxxzgZcCebsVXmuxS7qlvzXa1mAJ6InKQptd0BBrOIyPlSU4GkJNSsWgV5fn7DgBQz3cmKtLQ0JCcnW21TNyNdpVJBpVKhW7du6NmzJ8LCwnDw4EHExMQY25w4cQJDhw7F1KlT8eyzz5ocKzg4uEHAqqysDMDNTHdzMjIyoFarjY/Ly8sRFhaGxMREBAQENDpOZzMYDNBoNEhISLBagsfVOXQcNshojwgNRUS9/XwvHEcKOjtSbW0toqKikJOTAwDo378/jh8/jvXr15sE3A8ePIgdO3YgPDwc+/fvx6xZs9ChQwcMGzbM4rEFQbB4YdDeFwVd+cJKS7jjeHwvX0aiVKqhDkEmw77ISFT+859O6JV9uOP7Y42l8djjoiAD7mRzjlh0laVniMihfgtiYc0aCPn5kFmaxKRg1ooVwIABvEJIRI4XGoraF1/Ev4KDEbdwYcPglCCIFxBvvx2IjeUcRUZSAL0lpMz0ulmdx48fx9ChQ/H4449j2bJlDZ4TExODzMxMVFdXw8fHB4AYkAoJCWlQaqYupVJpUvdd4u3t7bLBRnPcrb+W2HwcdRdA/eUX4PBhICPD8p2G5igUwLx5kM2ZA0VoKBpb1pLvhf05o18dOnRAr169TLb17NkTW7duBQBcv34dmZmZ2L59O0aMGAEA6Nu3L7766ivk5uZi2LBhCA4ORnV1Na5cuWKS5V5WVobY2Fizr2uvi4LucGGlOdx5PPKFC83eZXNm1Cj8/tFH3W485rjz+2NOY+Oxx0VBBtzJ7swF4FetqsGqVTIIQvNXXq1bekaKaUnnY4xtEZHd/HYbz41Zs1CqVuPuHTvMB94FQVzAC+AVQiJymp+7dUPNq6/Ca+bMhpkONTXAn/4kzlGvv85sd2qWw4cP4/DhwxgyZAiCgoJw9uxZLF68GF27djVmtx8/fhzx8fFITEyEWq02ZrIrFArceeedAIAJEyYgOzsbKSkpyMzMxOnTp5GTk4PFixdbLSlDHkqns7p2jlV1b4n+9Vfg7rt53kUYPHgwTp48abLt1KlTCA8PB3CzxIu83qLjCoUCtb/93RwwYAC8vb2h0Wgwfvx4AMClS5dw7NgxrFixwuzr2vuioCtfWGkJtxuPTgesXt1gsyCX4+xDDyHC3cbTCLd7fxphaTz2GGPzo51Etyg0FHjxxVq88YYGGs0NHD4MzJ8vnic1hxTTkhakHzoUCA8Xt+l09uk7ERFCQ3EiJQU3zpwRJy9rQQHpCmGnTkBBgeP6SEQEQJg8GTh40PI8VVsrlsLSah3bMXJrfn5+2LZtG+6//350794dU6ZMQWRkJD799FNjkOmdd97BDz/8gKKiInTo0MH4FV2n5FpgYCA0Gg10Oh2ioqIwa9YsqNVqk8xQagV0OvEDXKdO4jlTc4Ltcrl4LnbunFjbNDoauO8+BtsJADBv3jwcPHgQOTk5OHPmDDZt2oTXX38ds2fPBgAEBAQgLi4OCxYswCeffILvv/8eGzZswFtvvYWHH34YgDhPpaamIj09HR9//DG+/PJLPPbYY+jTp4/VkjPkwdasMTtP1c6dK64RQfQbZriT06hUlYiLE+DtbZtFVwEuvEpEDtTURVUB1ncnIudpbB0KqRRWejrvxqEm6dOnD/bu3Wu1TVZWFrKyspp0rP3799uoZ+RWbJHRzjmLrIiOjsb27duRkZGBpUuXonPnzli9ejX+/Oc/G9ts3rwZGRkZ+POf/4yffvoJ4eHhWLZsGWbMmGFss2rVKnh5eWH8+PG4fv067r//fmzYsAEKRWPFisjj6HQ3ax3XJZejNi3NZDFmIma4k8uQYlfnzgH79qHFme/AzYVX62e+a7XisZkBT0Q2IwWzGjvploJavA2HiBwtNRUoLRUX0zGX7S6dOPFuHCKyt1vJaFcoTDPaGWynRjz00EM4evQoKisr8e2332Lq1Kkm+4ODg1FYWIgLFy7g+vXr+M9//gO1Wm1S1srX1xdr167Fjz/+iIqKCuzcuRNhYWGOHgq5grw889vVas5H1AAD7uRyQkPFOwGjo20XgJcy31l6hojsQgpm7dsnLi5hKfheN6jFSYiIHCk0FBg3TrxAaOlkSrobhyVmiMhWdDrx/EirbVmgXaEQPxTu2yeeazHQTkTOoNWard0OuVy824aoHgbcyeVZCsBbi2k1pm5ZZWa+E5FNSJPVggXiB0Jr9d0ZeCciZ0lNbbyu+8CBzHQnoltTN5NdWnSrKYF2qS774cM3g+zz57M2OxE5T0GBeG5kDrPbyQIG3Mnt1I9p3Ur2u6XSM4x9EdEtkWpkHTpkfVFVlnEgImdorBQWM92JqKVaWjKGC6ASkSvS6YCpU83PZQoFs9vJIrsH3Hfv3o2BAwfCz88PKpUKY8aMadBmw4YN6Nu3L3x9fREcHIy0tDST/UePHkVcXBz8/PzQsWNHLF26FEJzF1Yhj2Qu+72lZWcAZr4TkY01tb47g1tE5GhSKSxLd+Mw052ImsNWgXYG2InIlaxZY34+k8uB117jnEUW2TXgvnXrVkycOBGTJ0/G119/jc8//xwTJkwwaZOfn49FixbhmWeewfHjx/Hxxx8jKSnJuL+8vBwJCQkICQmBVqvF2rVrkZubi/z8fHt2ndyUrRZe5aKrRGQzdYNa1iYjLqpKRI7W2N04vBhIRI1hoJ2IPJVOZ36hVJlMLM+Xmur4PpHb8LLXgW/cuIE5c+Zg5cqVSK3zQ9i9e3fj/69cuYJnn30WO3fuxP3332/c3rt3b+P/i4qKUFlZiQ0bNkCpVCIyMhKnTp1Cfn5+g9WjiSShoTfP2aKjxbt8zpwB2rQBtmwB8vPF2FZTSZnvubniY7ncCyNH9kLfvkDnzrbvPxF5GCmoNWeOmCVhaRKSrvbl5QHp6WJ7fgAlInuT7saZNq3h3CRdDHzjDX6wJKKbdDr0KiyE144dTQ+yA+Jdf/Pm8RyHiFyfpez29HTx3InICrsF3L/44gtcuHABcrkc/fv3h16vR79+/ZCbm2sMqGs0GtTW1uLChQvo2bMnrl27htjYWOTl5SEsLAwAUFJSgri4OCiVSuOxk5KSkJGRgdLSUnQ2E+2sqqpCVVWV8XF5eTkAwGAwwGAwGP9f9193w/43T/v24hcA9OsHzJoFrFsnx+rVctTWygAIAJp+8aa2Vob33rsH778vYO7cGowdW4tff5Xh7rsFtzhvdMWfH1fqC5Hd1A+85+WZP4lj4J2IHC01FejbVwyu15+XpEz3vn35AZOotdLpgNOngdtuA/7xD3jl5eGepjxPLhcXFRw/Hvj1V+Duu3lOQ0Suz1J2u1zOuu3UJHYLuJ89exYAkJWVhfz8fERERCAvLw9xcXE4deoU2rZti7Nnz6K2thY5OTlYs2YNAgMD8eyzzyIhIQHffPMNfHx8oNfrERERYXLs9r9FTvV6vdmA+/Lly5Gdnd1ge3FxMfz9/U22aTQaG43YOdj/lvvDH4BevXxx6VIbKJU3cOBAR7z//t0QhKYH3gVBhlWrFFi1Sg5ABplMwKhRZxAbewFVVd7o0OEXqFSV9hvELXKln5+Kigpnd4HIcaTA+/jx5oNbkrqBd2aXEpG9NSXTnRcBiVoXnc5skkCjn5ikQDvnCyJyR6tXm/+MplZzTqMmaXbAPSsry2wwuy6tVova307SFy1ahEceeQQAUFhYiNDQULzzzjuYPn06amtrYTAY8PLLLyMxMREA8PbbbyM4OBj79u0z1nKvXzZGWjDVUjmZjIwMqNVq4+Py8nKEhYUhMTERAQEBAMRsWo1Gg4SEBHh7ezf32+B07L/tzZ0L6HQ3Wpj5LrYRBDHz/b337gYgg1wuYM6cWjz5ZK1Lzcmu+P2X7kQhalWk4Nb06UBNjeV2zC4lIkdpLNOdFwGJWgcLgfZGMdBORO6O2e1kA80OuKelpSE5Odlqm4iICFy7dg0A0KtXL+N2pVKJLl264Pz58wCADh06NGhz5513QqVSGdsEBwdDr9ebHL+srAzAzUz3+pRKpUkJGom3t3eD4KK5be6E/betzp3FeXXePKnmu6xFNd+lAHxtrZgBv3q1AunpYjLrL78A99zjGuefrvT9d5V+EDlcaiqQlGS9tjvA7FIichxrme4ALwISeTIG2omotTMXbAeY3U7NIm/uE1QqFXr06GH1y9fXFwMGDIBSqcTJkyeNzzUYDCgtLUV4eDgAYPDgwQBg0uann37C5cuXjW1iYmKwf/9+VFdXG9sUFxcjJCSkQakZIlsJDQXuu0/8DLlyJXDuHLBvH3D4MDB/PiCXN+PkEzcTwu69Fxg6FAgPBxYsEM9niYiMJWbOnZMmGfPtpMmkUydOIkRkX6mpwMGDgIU7So0XAQsKHNsvIrIPnU48t+jUSTzXaGKwXZDLxXOXc+fEcxkGo4jInWm1YjmZ+pjdTs3U7IB7UwUEBGDGjBlYsmQJiouLcfLkScycORMAMG7cOABAt27dMGrUKMyZMwcHDhzAsWPH8Pjjj6NHjx6Ij48HAEyYMAFKpRIpKSk4duwYtm/fjpycHKjVaoslZYhsrX4A/syZGxg9+nSzA++S2lrTmJlWKwb0GTsjauXqB94t/Z1j4J2IHEHKdFcozO+XMt21Wsf2i4hunU4nfgDRasVzjrCw5gXaFQqcHj0aN86cYaCdiDxDQYGYTGAOs9upmewWcAeAlStXIjk5GRMnTkR0dDTOnTuHvXv3IigoyNjmrbfewsCBAzFixAjExcXB29sbH374obG8RGBgIDQaDXQ6HaKiojBr1iyo1WqTGu1EjhYaCqSknMCZMzfqZb437ziWMt8ZgCdq5aTA+6FDloPugGngnVmmRGQPqalAaanli4DMdCdyL3Uz2YcOFT+IWCqfUJeUyX74MLBvH26cPo0TKSkMQBGRZ9DpgKlTzV90VCiY3U7NZteAu7e3N3Jzc/G///0P5eXl0Gg06N27t0mbgIAAFBQU4MqVK/jxxx+xbds2hIWFmbTp06cP9u/fj8rKSly6dAlLlixhdju5hMZLzzTveFLmO0vPEBGAxrNLJcwy9TiffPIJZDKZ2S/tb+/z119/jUcffRRhYWHw8/NDz549sWbNmgbHOnr0KOLi4uDn54eOHTti6dKlxgXoiZqksYuAnIOIXF8LS8agfsmY6GjxAxAD7UTkSdasMT8vyuXAa69xzqNms2vAnai1MReAb0ngXcLSM0Rkkl1qbTKRskx5lc4jxMbG4tKlSyZfTzzxBCIiIhAVFQUAOHLkCO68805s3LgRx48fx6JFi5CRkYF169YZj1NeXo6EhASEhIRAq9Vi7dq1yM3NRX5+vrOGRu5Mughobi7iHETkmmwVaGewiYg8lU5n/k4fmUxczyY11fF9IrfHgDuRHdUtx8zSM0TUYlxUtdXx8fFBcHCw8atdu3bYsWMHpkyZYrzLb8qUKXj55ZcRFxeHLl264LHHHsPkyZOxbds243GKiopQWVmJDRs2IDIyEmPGjEFmZiby8/OZ5U4tY20xVZa5InIdDLQTETXNCy+YnyPT08VkA6IWYMCdyAHslfnO0jNErQwXVW21duzYgcuXLyMlJcVqu59//hlt27Y1Pi4pKUFcXByUSqVxW1JSEi5evIjS0lI79ZY8nrVMd4AlZoicoe4iqOnpzV4EFQoFA+1E1Prk5oolY+qTy1m3nW6Jl7M7QNQaSTGzOXOAM2eANm2ALVuA/HwxmN5cUgA+L088vx4/HvjlF+Cee3iuTOSRpElk/HixhIOlD9NS4D0vTwyO8XZIt1VQUICkpKQG69zUVVJSgi1btmD37t3GbXq9HhERESbt2rdvb9zXuXPnBsepqqpCVVWV8XF5eTkAwGAwwGAwWO2ntL+xdq6MY2iiSZOAnj3hNWQIZObmoNpaCAMHoubVVyFMntzsw/N9aNlrUSuk04m1h/Pymh5cB8Rgklotnkv8+itw99384EBErYtOBzz9tPl9ajXnRLolDLgTOVFo6M05PDr61gPwUmwtN1d8LJ1Hz5nDvxVEHknKMp0+HaipsdxOyjbt25e3RTpZVlYWsrOzrbbRarXGOu0AoNPp8NFHH2HLli0Wn3P8+HGMGjUKixcvRkJCgsm++gvNS6VkLC1Av3z5crN9LC4uhr+/v9W+SzQaTZPauTKOoWk6zZqFfuvXQ2bmhEUmCFDMmIFPf/4ZP3fr1qLj831omoqKCru/BrmYWw208wMCEbV21hZKZXY73SIG3IlciLkA/Jo1ts98r5fs2Op88skniI+PN7vv8OHDiI6Oxtdff40XX3wRn332GS5fvoyIiAjMmDEDc+r94T169CjS0tJw+PBhtG3bFtOnT8dzzz1nMZBFZHOpqUBSUuOThbSgYXo6P2Q7UVpaGpKTk622qZ+RXlhYiHbt2mHkyJFm2584cQJDhw7F1KlT8eyzz5rsCw4Ohl6vN9lWVlYG4Game30ZGRlQq9XGx+Xl5QgLC0NiYiICAgKs9t1gMECj0SAhIQHe3t5W27oqjqGZhg/HjfR0yNetg3zVqgbZ7jJBQNzChc3OdOf70DzSnSjUCjDQTkR06ywtlAoAL77IeZJuGQPuRC7MVqVnGma+e2HkyF7o2xcwU03A48XGxuLSpUsm25577jns2bPHmFV65MgR3Hnnndi4cSPCwsJw4MABTJs2DQqFAmlpaQDED7cJCQmIj4+HVqvFqVOnkJKSgjZt2iA9Pd3h46JWrO5kYS3wXrfEDAPvTqFSqaBSqZrcXhAEFBYWYtKkSWYDdsePH8fQoUPx+OOPY9myZQ32x8TEIDMzE9XV1fDx8QEgZqqHhIQ0COxLlEqlSc13ibe3d5ODhs1p66o4hmbo3FmcV5KTzZa5kgkCvGbOBPr3b/ZdNnwfmv4a5OEYaCcish1L2e0zZohrYBHdIi6aSuQGzC26um8fcPhwyxZfra2V4b337kHXrl5YsEBcW2nfvtazrqKPjw+Cg4ONX+3atcOOHTswZcoUY2b6lClT8PLLLyMuLg5dunTBY489hsmTJ2Pbtm3G4xQVFaGyshIbNmxAZGQkxowZg8zMTOTn5xtLNhA5VEsWVS0ocGwfqVn27t2L77//Hqlm6u8fP34c8fHxSEhIgFqthl6vh16vxw8//GBsM2HCBCiVSqSkpODYsWPYvn07cnJyoFareScO2Z61xVSlu2w45xA1DRdBJSKyD63WfHa7XA4sWuT4/pBHYoY7kRuyVekZQZCZrfne2hZd3bFjBy5fvoyUlBSr7X7++We0bdvW+LikpARxcXEmmaBJSUnIyMhAaWmp2cUIgVtbkNCdeMKCd+a4xbjatwdycoCHH7a8oCEACAKEadNwo2dPIDraPcbWArYYl7O+JwUFBYiNjUXPnj0b7HvnnXfwww8/oKioCEVFRcbt4eHhKC0tBQAEBgZCo9Fg9uzZiIqKQlBQENRqtUnJGCKbSk0V14swt6Az15MgahwXQSUisp+CAvFcxNz8yoVSyYYYcCfyALYqPSPVfG9ti64WFBQgKSkJYWFhFtuUlJRgy5Yt2L17t3GbXq9vUJJBqoms1+stBtxtsSChO/GEBe/McZdxWVvQEABktbXwGjwYZ0aPxtmHHgJUKrcZW3PdyrictSDhpk2bLO7LyspCVlZWo8fo06cP9u/fb8NeETVCynSfNq3hiQjXkyAyjyVjiIjsS6cDpk41P8cqFFwolWyKAXciD2LPRVdXrAAGDABuu811s9+zsrLMBrLr0mq1xjrtAKDT6fDRRx9hy5YtFp9z/PhxjBo1CosXL0ZCQoLJvvolGaRSMtZKNdzKgoTuxBMWvDPH7cZVd0HD1avNBt5lAO557z3c/f77ODNqFEJXrICXB62ubIv3jAsSEjVTY5nu0gnGG2+IbYlaKwbaiYgcw1LddrkceO01zqVkUwy4E3kwy5nvAmprm167VxAarhviiuf4aWlpSE5OttqmfkZ6YWEh2rVrh5EjR5ptf+LECQwdOhRTp07Fs88+a7IvODgYer3eZFtZWRmAm5nu5thiQUJ3wnG5AGlBw3nzrH6olwkC7nnvPQjvvw+ZB2af3sp75jbvNZErsZbpDrDEDLVOOh1UR48Cd94JbN/OQDsRkSPodObrtstkwMGDPA8hm+OiqUStQP1FV8+cuYHRo09DLm/5wp5S9nunTnCZhVdVKhV69Ohh9cvX19fYXhAEFBYWYtKkSWaDadKChI8//jiWLVvWYH9MTAz279+P6upq47bi4mKEhIQ0COwTuQTpKtyhQ5YXVIUYeOeiqkRkE6mp4gdZS3MOF1Ol1kKnAxYsgFfXrhj83HPwGjyYi6ASETmKpez29HQG28kuGHAnaoVCQ4GUlBM4c+YG9u0DDh8Wz9/lLZgRpLjcvfcCQ4cC4eHAjBliJr0zg+9NsXfvXnz//fdINXMruxRsT0hIgFqthl6vh16vxw8//GBsM2HCBCiVSqSkpODYsWPYvn07cnJyoFarrZaUIXI6KetUobDeTso+1Wod0y8i8kyNzTmca8iT/RZoR6dOQG6ucSHzRs8U5XLxBP3wYTGrpbSUgXYiopawlN0ul7NuO9kNA+5ErVj9zPdz53DLAfjaWrH82Z/+BISFicF3Vw28FxQUIDY2Fj179myw75133sEPP/yAoqIidOjQwfgVXefqd2BgIDQaDXQ6HaKiojBr1iyo1WqT+uxELis1Vfzw3tgvu5R9umCB6/4yE5HrqzvnmLsozUx3tzJy5Eh06tQJvr6+6NChAyZOnIiLFy+abfvjjz8iNDQUMpkMV69eNdl39OhRxMXFwc/PDx07dsTSpUuN6+G4vXqB9iZnskuBdimTPTpaPGFnoJ2IqGUsZber1ZxbyW4YcCciI0sB+BUrGk+EteS118TAuyt+ft60aRM+//xzs/uysrIgCEKDr9LSUpN2ffr0wf79+1FZWYlLly5hyZIlzG4n9yGVmDl3Dpg/H4KlwHvdEjMMvBNRSzVW1oqZ7m4jPj4eW7ZswcmTJ7F161Z89913GDt2rNm2qamp6Nu3b4Pt5eXlSEhIQEhICLRaLdauXYvc3Fzk5+fbu/v2odOJJ85arW0C7QwCERHdOma3k5Mw4E5EFkkB+AULxKS0W8l+nzaNMToil/VbEOzGmTM4PXo0BEsXjRh4JyJbkErMmDuZ+C3TXb5wIXwvX3Z836hJ5s2bh0GDBiE8PByxsbF45plncPDgQRgMBpN269evx9WrVzF//vwGxygqKkJlZSU2bNiAyMhIjBkzBpmZmcjPz3evLPe6mexDh4p1FpsQaDfuZW12IiL7YXY7OQkD7kTUJOay35sTeK+tBc6csWsXiehWhYbiREoKbnz2mdVFVcFFVYnoVllbTFUQoFi1ColPPAFZYaHj+0bN8tNPP6GoqAixsbEmi9CfOHECS5cuxVtvvQW5mRPGkpISxMXFQalUGrclJSXh4sWLDe4odEktLBkjyOU4PXo0bnz+OWuzE9nZhQsX8Nhjj6Fdu3bw9/dHv379cOTIEZM23377LUaOHInAwEDcfvvtGDRoEM6fP2/cX1VVhSeffBIqlQpt2rTByJEjoWPSiXvQapndTk7j5ewOEJF7ku4KnzNHDKS3aSMulJqba769XA7cfbdj+0hELSRln06fDtTUWG4nlX/o21d8DhFRc0hzzbRp4pX5emQAFDNnAv37c45xQQsXLsS6detQUVGBQYMGYdeuXcZ9VVVVePTRR7Fy5Up06tQJZ8+ebfB8vV6PiIgIk23t27c37uvcubPZ162qqkJVVZXxcXl5OQDAYDA0yLC3F1l+PhQZGcYFUJtCkMtRO3cuqmfMwIkTJ9CxXz9AukDhoH7bkvS9dtT33B48YQyAe4zDGX27cuUKBg8ejPj4eHzwwQe466678N133+GOO+4wtvnuu+8wZMgQpKamIjs7G4GBgfj222/h6+trbDN37lzs3LkTmzdvRrt27ZCeno6HHnoIR44cgaKldVfJ/goKxPMLZreTkzDgTkS3JDT05t+q6GgxAP/CC2LtdolMBrz+Ov+mEbmV1FQgKUm8DTM/32wwDMDNhQ7T08UJgL/oRNQcqaniRbuBA81+KJZJc8wbb4htyW6ysrKQnZ1ttY1Wq0VUVBQAYMGCBUhNTcW5c+eQnZ2NSZMmYdeuXZDJZMjIyEDPnj3x2GOPWT1e/XVvpFIy1tbDWb58udl+FhcXw9/f3+rrtZTv5cu47dIlGJRKhO/Zg4jiYjR1xR5BJsOZUaNw9qGHUKlSASdOAAA0Go1d+uponjAOTxgD4NrjqKiocPhrvvTSSwgLC0NhnTul6l/kW7RoEYYPH44VK1YYt3Xp0sX4/59//hkFBQX4+9//jmHDhgEANm7ciLCwMOzZswdJSUn2HQS1jE4HTJ1qPtiuUDC7nRyCAXcisqnQUODVV4FnnwVKSsRtMTGMwRG5pbq3slgLvEslZvLyGHgnouZr7K4a3k3jEGlpaUhOTrbapm6wSqVSQaVSoVu3bujZsyfCwsJw8OBBxMTEYO/evTh69CjeffddADcD6SqVCosWLUJ2djaCg4Oh1+tNjl9WVgbgZqa7ORkZGVCr1cbH5eXlCAsLQ2JiIgICApo15kbpdJCvWwf5qlWQCQIEoNFAu9RGUChQO2cOatPSEBEaiojf9hsMBmg0GiQkJJiU4HE3njAOTxgD4B7jkO5EcaQdO3YgKSkJ48aNw6effoqOHTti1qxZmDp1KgCgtrYWu3fvxtNPP42kpCR8+eWX6Ny5MzIyMjB69GgAwJEjR2AwGJCYmGg8bkhICCIjI3HgwAGzAXd73YXjDncyNIc9xyPPz4fCTLBdkMtR88orENq3t/mdRXx/XFtj47HHOBlwJyK7CA0Fxo1zdi+IyCbqB97z8sxnjDDwTkQtVfeuGnNzDDPd7U4KoLeEFFCXgkxbt27F9evXjfu1Wi2mTJmCf/3rX+jatSsAICYmBpmZmaiuroaPjw8AMUs9JCSkQRZqXUql0qTuu8Tb29t2wUadzuzPotVgu1wOqNWQjR8P/PorZHffDUVoKCwVnLBpf53IE8bhCWMAXHsczujX2bNnsX79eqjVamRmZuLw4cN46qmnoFQqMWnSJJSVleGXX37Biy++iBdeeAEvvfQSPvzwQ4wZMwb79u1DXFwc9Ho9fHx8EBQUZHLs9u3bN7hgKLH3XTiufCdDS9h6PL6XLyNx1aoG2wUAn774In5u3x745z9t+pp18f1xbZbGY4+7cBhwJyIioqaRAu/jx1ss/wDANPDO4BgRNVWdOUYYOLBhfWxmuruEw4cP4/DhwxgyZAiCgoJw9uxZLF68GF27dkVMTAwAGIPqksuXLwMAevbsaayfPGHCBGRnZyMlJQWZmZk4ffo0cnJysHjxYqslZezKQqC9UdOni7d38iIzkcuora1FVFQUcnJyAAD9+/fH8ePHsX79ekyaNAm1v921OWrUKMybNw8A0K9fPxw4cACvvvoq4uLiLB5bEASL85S97sJxhzsZmsNe45EvXGj24mitWo3Bc+fa7HXq4/vj2hobjz3uwmHAnYiIiJqHi6oSkT1FR6Pm1VehmDGjYdCdme5O5+fnh23btmHJkiX49ddf0aFDBzzwwAPYvHmz2cxzSwIDA6HRaDB79mxERUUhKCgIarXaJFBldzodcPo0cNttwJYtzQ+0y2TAihXA/Pn26yMRtUiHDh3Qq1cvk209e/bE1q1bAYh39Xh5eZlt89lnnwEAgoODUV1djStXrphkuZeVlSE2Ntbs69r7LhxXvpOhJWx+d9Lq1Q23y+VQzJsHhQO+b3x/XJul8dhjjAy4ExERUfNxUVUisiNh8mR8+vPPiFu4kJnuLqZPnz7Yu3dvs55z3333GcvO1D/W/v37bdW1ptPpgOefB15/vWXPVyiAefP4d43IhQ0ePBgnT5402Xbq1CmEh4cDAHx8fBAdHW21zYABA+Dt7Q2NRoPx48cDAC5duoRjx46ZLLRKLmLNGvMXTdVqztXkcHJnd4CIiIjclFT+4dw5MbtPbuG0Qiox06kTsGCBGOggImrEz926oebVV83PLdLFPM4p1BxaLfCnPwFhYc0Ltsvl4t+5w4eBffuA0lLx7x8DOEQua968eTh48CBycnJw5swZbNq0Ca+//jpmz55tbLNgwQL84x//wBtvvIEzZ85g3bp12LlzJ2bNmgVAvBMnNTUV6enp+Pjjj/Hll1/iscceQ58+fTBs2DBnDY3M0enEu5Tqk8vFi6NEDsaAOxEREd2a+oF3S7V36wbeCwoc20cickvC5MnAwYPm5xXOKdQcKSnAvfeKpWOaSgq0nzsn/p2Ljgbuu4+BdiI3EB0dje3bt+Ptt99GZGQknn/+eaxevRp//vOfjW0efvhhvPrqq1ixYgX69OmDN998E1u3bsWQIUOMbVatWoXRo0dj/PjxGDx4MPz9/bFz504oFJaWRCanYHY7uRi7B9x3796NgQMHws/PDyqVCmPGjDHZr9Vqcf/99+OOO+5AUFAQEhMT8dVXX5m0OXr0KOLi4uDn54eOHTti6dKlZm9JJCIiIieSAu+HDlkOugM3y0FotY7rGxG5L2ndCGt30XBOIWu0WuBvf2t6+/qBdgZriNzSQw89hKNHj6KyshLffvstpk6d2qDNlClTcPr0aVy/fh1fffUVRo0aZbLf19cXa9euxY8//oiKigrs3LkTYWFhjhoCNYVOJ16Ar4/Z7eREdg24b926FRMnTsTkyZPx9ddf4/PPP8eECROM+69du4akpCR06tQJhw4dwmeffYaAgAAkJSXBYDAAEFeKTUhIQEhICLRaLdauXYvc3Fzk5+fbs+tERETUUlJwzFrmD8tBEFFzpKZaznQHbs4pzHQnc/71r6a1UygYaCcicjerVpnfzux2ciK7Bdxv3LiBOXPmYOXKlZgxYwa6deuG7t27Y+zYscY2J0+exJUrV7B06VJ0794dvXv3xpIlS1BWVobz588DAIqKilBZWYkNGzYgMjISY8aMQWZmJvLz85nlTkRE5KpSU8Uat6ztTkS20tjFPGa6kyW//73lfTIZsGgRa7MTEbkjrRYwl5DL7HZyMrsF3L/44gtcuHABcrkc/fv3R4cOHfDggw/i+PHjxjbdu3eHSqVCQUEBqqurcf36dRQUFKB3797GVaFLSkoQFxcHpVJpfF5SUhIuXryI0tJSe3WfiIiIblVLarsz8E5E1tS9mGduTmGmO5kTHQ08/rjptrg4sZ77+fPACy+wNjsRkbspKBD/5pvD7HZyMi97Hfjs2bMAgKysLOTn5yMiIgJ5eXmIi4vDqVOn0LZtW9x+++345JNPMGrUKDz//PMAgG7duuGjjz6Cl5fYNb1ej4iICJNjt2/f3rivc+fODV67qqoKVVVVxsfl5eUAAIPBYCxVU/9fd8P+Oxf7b3uu1BcisjEp8D5+vHhSbOkONSnwnpcnZrGmpjq2n0TkHhqbU6RM9759xUArEQBs2ADMng18/jkweDB/NoiI3JlOB0ydav5zhULB7HZyumYH3LOyspCdnW21jVarRW1tLQBg0aJFeOSRRwAAhYWFCA0NxTvvvIPp06fj+vXrmDJlCgYPHoy3334bNTU1yM3NxfDhw6HVauHn5wcAkNXLXpFKydTfLlm+fLnZPhYXF8Pf399km0ajacKoXRf771zsv+1UVFQ4uwtEZG9SOYjp04GaGsvtGCwjoqaQ5pRp08TM9rqkTPf0dPFDN7PcCBB/Zvh3hYjI/a1ZYz7YLpcDr73Gv/vkdM0OuKelpSE5Odlqm4iICFy7dg0A0KtXL+N2pVKJLl26GOuzb9q0CaWlpSgpKYH8t/qumzZtQlBQEN5//30kJycjODgYer3e5PhlZWUAbma615eRkQG1Wm18XF5ejrCwMCQmJiIgIACAmE2r0WiQkJAAb2/v5nwLXAL771zsv+1Jd6IQkYdLTQWSksST5Pz8hkEyCYNlRNQUqanixTlLme68a4aIiMiz6HTi3/b6ZDJxgXVeWCUX0OyAu0qlgkqlarTdgAEDoFQqcfLkSQwZMgSAGOQrLS011mevqKiAXC43yVSXHksZ8jExMcjMzER1dTV8fHwAiJnqISEhDUrNSJRKpUnNd4m3t3eD4KK5be6E/Xcu9t92XKUfROQAUjmIOXOsB97rBssYeCciS6xlugO8a4aIiMiTWMpuT0/n33lyGXZbNDUgIAAzZszAkiVLUFxcjJMnT2LmzJkAgHHjxgEAEhIScOXKFcyePRvffvstjh8/jsmTJ8PLywvx8fEAgAkTJkCpVCIlJQXHjh3D9u3bkZOTA7VabbGkDBEREbmBliyqyoUQicic1FQxq83SPMLFVImIiNyfpex2uZx128ml2C3gDgArV65EcnIyJk6ciOjoaJw7dw579+5FUFAQAKBHjx7YuXMnvvnmG8TExOD3v/89Ll68iA8//BAdOnQAAAQGBkKj0UCn0yEqKgqzZs2CWq02KRlDREREbkwKvB86ZDlYBtzMUtVqHdc3InIfUqa7QmF+P+cQIiIi92Ypu12t5p2w5FKaXVKmOby9vZGbm4vc3FyLbRISEpCQkGD1OH369MH+/ftt3T0iIiJyJU1ZVJW13YnImrrrROTlNfxQLs0hrOlORETkXnQ68a7X+pjdTi7IrhnuRERERM2SmgqUloolZuQWTlPqlphZsEA8+SYikjR21wwz3YmIiNxPfr757cxuJxfEgDsRERG5FtZ2JyJbkO6aMXfxjjXdiYiI3IdOB6xa1XA7s9vJRTHgTkRERK6pObXdp08HtmxhtjsRmbK2mCoz3YmIiNzDsmXmtzO7nVwUA+5ERETk2hpbCBEQa77/6U9AeDjLzBCRqaZkunPeICIick1aLfDqqw23M7udXBgD7kREROT6mlLbHRCDZ6zvTkT1NZbpzvJURERErmflSuDee83vY3Y7uTAG3ImIiMg91K/tbi3wXieAJissdFwfich1Wct0B1hihoiIyJXk5gJPP21+n0LB7HZyaQy4ExERkXupG3jfsqXR+u6KmTMReOqU4/pHRK7LWqY7wMVUiYiIXIFOZznYLpcDr73G7HZyaQy4ExERkXsKDQXGjWu0vrusthZxTz8N+cKFLDFDRI2vC8FMdyIiIudas0b8e1yfTCZeOE9NdXyfiJqBAXciIiJyb02o7y4DoFi1irXdiUhUd94wl+3OTHciIiLn0OmAvDzz+156SbxwTuTiGHAnIiIi91e/vrulchF1F0fMzXVsH4nItUjzxqFDlhdTZaY7ERGRY1nKbp8xQ0ycIXIDDLgTUavzySefQCaTmf3SmvlQ/eOPPyI0NBQymQxXr1412Xf06FHExcXBz88PHTt2xNKlSyGYOzkgIsdoLIAmEQTxhP2xx1wy253zFJEDWVtMlZnuREREjmMpu10uBxYtcnx/iFqIAXcianViY2Nx6dIlk68nnngCERERiIqKatA+NTUVffv2bbC9vLwcCQkJCAkJgVarxdq1a5Gbm4v8/HxHDIOIrGmsRrOkqAgIC3O5YBrnKSIHs7aYKjPdiYiIHMNSdrtazUVSya0w4E5ErY6Pjw+Cg4ONX+3atcOOHTswZcoUyOp90F6/fj2uXr2K+fPnNzhOUVERKisrsWHDBkRGRmLMmDHIzMxEfn4+s0eJXMFvNZpr1GoI1rLdATGY5kKZ7pyniJygKZnuXAOCiIjIPqxlt8+Z4/j+EN0CBtyJqNXbsWMHLl++jJSUFJPtJ06cwNKlS/HWW29BbubDd0lJCeLi4qBUKo3bkpKScPHiRZSWltq510TUJKGhqH3xRRS/8QZqpk613K62FjhzxnH9aibOU0QO0limu7QGhIvdFUNEROT2mN1OHsTL2R0gInK2goICJCUlISwszLitqqoKjz76KFauXIlOnTrh7NmzDZ6n1+sRERFhsq19+/bGfZ07dzb7elVVVaiqqjI+Li8vBwAYDAYYDIZbHY7LkMbiSWMCPHdcgOeOzWAwoFKlQtXq1fBp1w6KF19E/VCaIJfjRng4YGHszv6eOHKeupU5yhN+hjgG1+DUMfTrB9mrr0IxcyZktbUN9wsChGnTcKNnTzEr3gJHjsGd32siIiJoteJF7fqY3U5uigF3IvIYWVlZyM7OttpGq9Wa1D/W6XT46KOPsGXLFpN2GRkZ6NmzJx577DGrx6tf2kEq0VB/e13Lly8328/i4mL4+/tbfT13pNFonN0Fu/DUcQGeOzaNRgMMGoSujz+O3n/7mzHoXiuT4euZM3H+m2+Ab74x+9yKigqb9MEd5ilbzFGe8DPEMbgGp42hfXsEvvgi4p5+usEFOgCQ1dbCa/BgfDV7Ns4nJFg9lCPGYKs5ioiIyOEKCgBLd6Iyu53cFAPuROQx0tLSkJycbLVN/UzPwsJCtGvXDiNHjjTZvnfvXhw9ehTvvvsugJsBKpVKhUWLFiE7OxvBwcHQ6/UmzysrKwNwM4PUnIyMDKjVauPj8vJyhIWFITExEQEBAdYH6UYMBgM0Gg0SEhLg7e3t7O7YjKeOC/DcsTUY1/DhuLFkCWQHDwIAhEGDEBkaikgrx5CyvG+VO8xTtzJHecLPEMfgGlxiDMOHoyYwEIpZsyCrqWmwWwag3/r1iJwwwWymuyPHYKs5qqlGjhyJr776CmVlZQgKCsKwYcPw0ksvISQkxKTdhg0bkJ+fj1OnTuGOO+7A2LFjsW7dOuP+o0ePIi0tDYcPH0bbtm0xffp0PPfcc1YTF4iIyIPodGKw3VwpGYWC2e3kthhwJyKPoVKpoFKpmtxeEAQUFhZi0qRJDT4Ib926FdevXzc+1mq1mDJlCv71r3+ha9euAICYmBhkZmaiuroaPj4+AMQM0JCQkAYBs7qUSqVJPWWJt7e32wZGrOG43I+njs1kXJ07i1/NeK4tuMM8ZYs5yhN+hjgG1+D0MUybBgwfLtaVzctrEBCQ1dbCe8gQcbHV1FSzh3DEGBz9PYqPj0dmZiY6dOiACxcuYP78+Rg7diwOHDhgbJOfn4+8vDysXLkSAwcORGVlpUnpq/LyciQkJCA+Ph5arRanTp1CSkoK2rRpg/T0dIeOh4iInEO+dq35YLtcDrz2GrPbyW0x4E5ErdbevXvx/fffI9XMB2QpWCW5fPkyAKBnz5644447AAATJkxAdnY2UlJSkJmZidOnTyMnJweLFy9mZhYR2QTnKSIXEBoKrFwJjB8PDBzYMDAgCGJgvm9fqzXdPcm8efOM/w8PD8czzzyD0aNHw2AwwNvbG1euXMGzzz6LnTt34v777ze27d27t/H/RUVFqKysxIYNG6BUKhEZGYlTp04hPz8farWacxQRkYfzvXwZ8tWrG+6QycQFzFvJ31TyTAy4E1GrVVBQgNjYWPTs2bNFzw8MDIRGo8Hs2bMRFRWFoKAgqNVqk1IMRES3gvMUkQuJjhYz2adNA+ovplpbKwbjrWS6e6qffvoJRUVFiI2NNWbaazQa1NbW4sKFC+jZsyeuXbuG2NhY5OXlGRd/LikpQVxcnMkdNUlJScjIyEBpaanHLj7vCYsaA54xDk8YA+Ae43DlvpHzdNm1CzJz2e3p6Qy2k9tjwJ2IWq1NmzY1ue19991nrI9cV58+fbB//35bdouIyIjzFJGLSU0VM9mZ6Y6FCxdi3bp1qKiowKBBg7Br1y7jvrNnz6K2thY5OTlYs2YNAgMD8eyzzyIhIQHffPMNfHx8oNfrG5S2ktaW0Ov1FgPunrL4vCcsagx4xjg8YQyAa4/DWQs7X7hwAQsXLsQHH3yA69evo1u3bigoKMCAAQMatJ0+fTpef/11rFq1CnPnzjVur6qqwvz58/H222/j+vXruP/++/HKK68glKVObo1Oh7vfe6/hdrmcddvJIzDgTkRERERE1FRNyXRPTwdmzXJO/1ooKyvLbCC7Lq1Wi6ioKADAggULkJqainPnziE7OxuTJk3Crl27IJPJUFtbC4PBgJdffhmJiYkAgLfffhvBwcHYt28fkpKSAKBB2RjpoqG1cjLuvvi8SywIbAOeMA5PGAPgHuNw9MLOAHDlyhUMHjwY8fHx+OCDD3DXXXfhu+++M5bdq+u9997DoUOHGiz8DABz587Fzp07sXnzZrRr1w7p6el46KGHcOTIESgUCgeMxDPJc3JgdqZXq1m3nTwCA+5ERERERETN0Vime24uvPLy0GnWLHHRVTeQlpaG5ORkq23qZqRLi0B369YNPXv2RFhYGA4ePIiYmBh06NABANCrVy9j+zvvvBMqlQrnz58HAAQHB0Ov15scv6ysDMDNTHdzPGXxeXfrryWeMA5PGAPg2uNwRr9eeuklhIWFobCw0LjN3ILxFy5cQFpaGj766COMGDHCZN/PP/+MgoIC/P3vf8ewYcMAABs3bkRYWBj27NljvHhIzZSbC/mbbzbczux28iByZ3eAiIiIiIjI7UiZ7nLzH6lkgoB+r7wCaLUO7ljLqFQq9OjRw+qXr6+v2edKmelSbfXBgwcDAE6ePGls89NPP+Hy5csIDw8HAMTExGD//v2orq42tikuLkZISIjZoBgRUXPs2LEDUVFRGDduHO666y70798fb7zxhkmb2tpaTJw4EQsWLDBZ1Fly5MgRGAwG4506ABASEoLIyEgcOHDA7mPwSDod8PTTzG4nj8cMdyIiIiIiopawlukOMejuNWSIRy2mevjwYRw+fBhDhgxBUFAQzp49i8WLF6Nr166IiYkBAHTr1g2jRo3CnDlz8PrrryMgIAAZGRno0aMH4uPjAQATJkxAdnY2UlJSkJmZidOnTyMnJweLFy+2WlKGiKgpzp49i/Xr10OtViMzMxOHDx/GU089BaVSiUmTJgEQs+C9vLzw1FNPmT2GXq+Hj48PgoKCTLa3b9++wR06Enst7OwOi+M2hTw/Hwozfy8FuRw3Zs0C3HR8nvL+SFrbeOwxTgbciYiIiIiIWkrKdJ8+HaipabBbJgjivttvB2Jj3T57z8/PD9u2bcOSJUvw66+/okOHDnjggQewefNmk1Ivb731FubNm4cRI0ZALpf/f3v3HhZVnf8B/A02DBeBVIThouB2E8PSxBRsIzVhezT12WczLylspJmitlBrmqV2UUslXX+beSG0Mq3NLFpLxdSlXakILUEf74CCEI+lwuZyST6/P9g5yzAzzKADc87wfj3PPMU53zl+PufyPd/5zne+B3Fxcdi1a5cytYS/vz+ys7Mxc+ZMREdHo0uXLkhNTTWZn52I6Ho1NDQgOjoaS5YsAQD0798fR48exdq1azFlyhTk5+dj9erVOHToUKu/5BMRq+9p6wc7q/nhuLZ4XryI+DfeMFsuAI5OnowzR44AR460f2AOpOXjY0lHyactHuzMDnciIiIiIqIbkZwMJCQAq1cDK1eaj3a/dg149NHG6WfWr9f0aPe+ffti3759Nsv5+fkhIyMDGRkZLW4rJyfHkeEREQEAgoODTZ4jAQCRkZHYvn07AOCrr75CZWUlevbsqay/du0a0tLSsGrVKhQXF8NgMKCurg6XLl0yGeVeWVmJ2NhYi/9uWz3YWQsPx7XFfe5ci1PJNEydijv++lfc0e4ROY4rHJ+mOlo+bfFgZ3a4ExERERER3aiwMGD5cmDcOKtTzKChAZg2rXEamoED2z9GIqIOYsiQISbPkQCAkydPKs+RmDx5svIgVKOEhARMnjwZf/zjHwEAAwYMgE6nQ3Z2NsaNGwcAKC8vR2FhIV5//XWL/25bP9hZzQ/HbVFpKbBqldlicXdHpxdfRCct5mSBZo+PFR0ln7bIsc0emnrgwAG4ublZfOU1eXDQuXPn8PDDD8PHxwcBAQGYPXu2yYNzAKCgoABxcXHw8vJCaGgoXnrpJeXBPERERERERKrx3ylmpFMny+sbGho75FsY+U1ERDfmT3/6E77++mssWbIEp0+fxvvvv4/169dj5syZAIBu3bohKirK5KXT6WAwGHDHHY1jrf39/ZGcnIy0tDR8+eWXOHz4MB577DH07dvXrLOebFi1yuIX0Q1PP635qdaILGmzDvfY2FiUl5ebvJ544glEREQgOjoaQOPPdUaOHIlffvkF//znP7Ft2zZs374daWlpynaqqqowYsQIhISEIC8vD2vWrMGKFSuQnp7eVqETERERERFdv+Rk/HrqFL595hmIpXl+RRpHujcZiERERI4zcOBA7NixA1u3bkVUVBRefvllrFq1CpMmTWrVdt544w2MHTsW48aNw5AhQ+Dt7Y3PPvsMnax9qUrmSksbp1trRtzc0JCS4oSAiNpem00p4+HhAYPBoPxdX1+PrKwspKSkKA+X2LNnD44dO4bz588jJCQEALBy5UokJSXh1VdfhZ+fH7Zs2YKamhps2rQJer0eUVFROHnyJNLT05Gamson2BMRERERkfqEhaH8vvtw7bbbcNNTTzWObG/KONJ9wwZNz+lORKRWo0aNwqhRo+wuX1xcbLbM09MTa9aswZo1axwYWQfz2msWF58eMwYRHN1OLqrd5nDPysrCxYsXkZSUpCzLzc1FVFSU0tkONM6ZVVtbi/z8fAwdOhS5ubmIi4szmQMrISEB8+bNQ3FxMXr16mX2b9XW1qK2tlb52zj5fX19Perr65X/b/pfrWH8zsX4HU9NsRARERE5ivzxj0D//pbndTeOdOec7kRE5Iry8oD/+z+zxeLujrOjRiGi/SMiahft1uGekZGBhIQE9OjRQ1lWUVGBoKAgk3JdunSBh4cHKioqlDIREREmZYzvqaiosNjhvnTpUixevNhs+Z49e+Dt7W2yLDs7+7ryUQvG71yM33GuXr3q7BCIiIiI2sZ/53XHtGkc6U5ERB3D8uXAn/9scVXD00+jJiCgnQMiaj+t7nBftGiRxc7spvLy8pR52gGgtLQUu3fvxocffmhW1tKUMCJisrx5GeMDU61NJzNv3jykpqYqf1dVVaFHjx6Ij4+Hn58fgMbRtNnZ2RgxYoQmn7jL+J2L8Tue8ZcoRERERC4pOblxJDtHuhMRkatbscJqZzs6dWqcu/3IkfaNiagdtbrDPSUlBePHj2+xTPMR6ZmZmejWrRtGjx5tstxgMOCbb74xWXbp0iXU19cro9gNBoMy2t2osrISAMxGxxvp9XqTKWiMdDqdWeeipWVawvidi/E7jlriICIiImoz9ox0T0sD5swBOK8tERFpUWmp9c52d3dg3brGexw73MmFubf2DQEBAejdu3eLL09PT6W8iCAzMxNTpkwx61CLiYlBYWEhysvLlWV79uyBXq/HgAEDlDI5OTmoq6szKRMSEmLWsU9ERERERKRqycnA118Dln6tK9I4KrBnz8b/EhERac3q1ea/5AIa73tff83p06hDaHWHe2vt27cPRUVFSLZwQcXHx6NPnz6YPHkyDh8+jC+//BLPPPMMpk6dqkz9MnHiROj1eiQlJaGwsBA7duzAkiVLkJqaanVKGSIiIiIiItUyjnR3t/JxTAR49tnG+W+JiIi0orQUWLnS8rrXXuO0adRhtHmHe0ZGBmJjYxEZGWm2rlOnTti5cyc8PT0xZMgQjBs3DmPHjsWKJqM5/P39kZ2djdLSUkRHR2PGjBlITU01maOdiIiIiIhIU1oa6W40dy6Ql9d+MREREd0Ia6Pbp09v/CKZqINo9RzurfX++++3uL5nz574+9//3mKZvn37Iicnx5FhEREREREROZdxpPuTTwLXrpmvFwHuvRfYuJE/wSciInWzNrrd3R14/vn2j4fIidp8hDsRERERERFZkZwMFBc3jv6zZtq0xo4MIiIitbI2uj01lQ8Cpw6HHe5ERERERETOFBYGrF3bONLdkoYG4PTp9o2JiIjIXi2Nbp8zp/3jIXIydrgTERERERGpwYIFlud0d3cHbr21/eMhIiKyxyuvcHQ7URPscCciIiIiIlKDsLDGOd3dm3xMc3MD1q9nhwUREanTihXAunXmyzm6nTqwNn9oKhEREREREdkpORlISABycxv/jolhZzsREalTaSnw5z9bXsfR7dSBscOdiIiIiIhITcLCgEcecXYURERELbM2lQxHt1MHxylliIiIiIiIiIiIyH7WppIBgGXLOLqdOjR2uBMREREREREREZF9SkuBZ5+1vG76dOvriDoIdrgTERERERERERGRfV55xfJyNzfg+efbNxYiFWKHOxEREREREREREdlWWgqsX2953bRpnEqGCOxwJyIiIiIiIiIiInucOmX5QakAsGBB+8ZCpFLscCciIiIiIiIiIiLbbrsNcLfQnfj66xzdTvRf7HAnIiIiIiIiIiIi28LCGqeU6dSp8W93d2D5cj4olaiJm5wdABEREREREREREWlEcjKQkACcPg3ceitHthM1ww53IiIiIiIiIiIisl9YGDvaiazglDJE1OEcOHAAbm5uFl95eXkmZTdt2oS77roLnp6eMBgMSElJMVlfUFCAuLg4eHl5ITQ0FC+99BLE2gNkiIiIiIiIiIjIpXGEOxF1OLGxsSgvLzdZ9sILL2Dv3r2Ijo5WlqWnp2PlypVYvnw5Bg0ahJqaGpw9e1ZZX1VVhREjRmDo0KHIy8vDyZMnkZSUBB8fH6SlpbVbPkREREREREREpA7scCeiDsfDwwMGg0H5u76+HllZWUhJSYGbmxsA4NKlS1iwYAE+++wzDB8+XCl75513Kv+/ZcsW1NTUYNOmTdDr9YiKisLJkyeRnp6O1NRUZVtERERERERERNQxsMOdiDq8rKwsXLx4EUlJScqy7OxsNDQ0oKysDJGRkaiurkZsbCxWrlyJHj16AAByc3MRFxcHvV6vvC8hIQHz5s1DcXExevXqZfHfq62tRW1trfJ3VVUVgMaO//r6+jbI0DmMubhSToDr5gW4bm6OyMvV9gkRERERERG1jQ7R4W6cT9nYqQU0fnC+evUqqqqqoNPpnBXadWP8zsX4Hc94fTpj/vOMjAwkJCQoHekAcPbsWTQ0NGDJkiVYvXo1/P39sWDBAowYMQJHjhyBh4cHKioqEBERYbKtoKAgAEBFRYXVDvelS5di8eLFZss/+eQTeHt7Oy4xlfj000+dHUKbcNW8ANfN7Ubyunr1KgDn1FHOZqkdZY0a7y+txRzUgTm0jjPbUc7WmjpKDVzh3AZcIw9XyAHQRh6so268jtLCcW4N5qNuHS2ftqijOkSHe3V1NQCYdKYRkTpVV1fD39//ut67aNEiix3ZTeXl5ZnM015aWordu3fjww8/NCnX0NCA+vp6/OUvf0F8fDwAYOvWrTAYDNi/fz8SEhIAwGzaGGMF3dJ0MvPmzUNqaqryd1lZGfr06YMnnnjCjiyJyJlupI7SKrajiLSDdRQRqRnrKCJSM0fWUR2iwz0kJATnz5+Hr6+v0glWVVWFHj164Pz58/Dz83NyhK3H+J2L8TueiKC6uhohISHXvY2UlBSMHz++xTLNR6RnZmaiW7duGD16tMny4OBgAECfPn2UZd27d0dAQADOnTsHADAYDKioqDB5X2VlJYD/jXS3RK/Xm0xD07lzZ7M6yhWo8TxzBFfNC3Dd3ByRlyPqKK2y1I6yxhXOIeagDsyhdVhHaacd5QrnNuAaebhCDoA28mAddeN1lBaOc2swH3XraPm0RR3VITrc3d3dERYWZnGdn5+fpk8exu9cjN+xbvSbxICAAAQEBNhdXkSQmZmJKVOmmP2saMiQIQCAEydOKPXHzz//jIsXLyI8PBwAEBMTg/nz56Ourg4eHh4AgD179iAkJMSsY78lLdVRrkBt55mjuGpegOvmdqN5dbQRWUbXU0e5wjnEHNSBOdiPdZS2uMK5DbhGHq6QA6D+PFhHOYbaj3NrMR9160j5OLqOcnfo1oiINGTfvn0oKipCcnKy2brbb78dY8aMwZw5c3Dw4EEUFhYiMTERvXv3xtChQwEAEydOhF6vR1JSEgoLC7Fjxw4sWbIEqampmhhhRUREREREREREjsUOdyLqsDIyMhAbG4vIyEiL69955x0MGjQII0eORFxcHHQ6HXbt2qWMhvf390d2djZKS0sRHR2NGTNmIDU11WR+diIiIiIiIiIi6jg6xJQyluj1eixcuNBkHmUtYfzOxfhdw/vvv9/iej8/P2RkZCAjI8Nqmb59+yInJ8fRobkEVz3PXDUvwHVzc9W81MgV9jVzUAfmQK7KVc4LV8jDFXIAXCcPapmrHWfmo27M58a5iYi0279GREREREREREREROSiOKUMEREREREREREREZEDsMOdiIiIiIiIiIiIiMgB2OFOREREREREREREROQA7HAnIiIiIiIiIiIiInIAl+pwX7p0KQYOHAhfX18EBgZi7NixOHHihLK+vr4ec+fORd++feHj44OQkBBMmTIFFy5cMNnOAw88ADc3N5PX+PHjnR4/ACQlJZnFNnjwYJMytbW1mDVrFgICAuDj44PRo0ejtLRUFfE3j934Wr58uVLGWft/7dq1uOuuu+Dn5wc/Pz/ExMTgiy++UNaLCBYtWoSQkBB4eXnhgQcewNGjR0224ax9byt+tZ/7pF0REREWr+mZM2cCsK/OUoOcnBw8/PDDCAkJgZubGz755BOT9Wq//lvSUm5arhtsHTM13y9d2c6dOzFo0CB4eXkhICAAv//9703Wnzt3Dg8//DB8fHwQEBCA2bNno66uzknRWldbW4t+/frBzc0N33//vck6NedQXFyM5ORk9OrVC15eXrjllluwcOFCs/jUnAMAvPnmm+jVqxc8PT0xYMAAfPXVV84OySp72r/23ENI+8rKyvDYY4+hW7du8Pb2Rr9+/ZCfn6+s10JboqUctNRmsHUstNJGsJWHmj9b0/Wz516+adMmq8e/srJS2Y6l9bt27VJdPoDl8/mtt94yKVNQUIC4uDh4eXkhNDQUL730EkREVbn88MMPmDBhAnr06AEvLy9ERkZi9erVZtvR0rGxp93o7GNj9OqrryI2Nhbe3t64+eabzda367UjLiQhIUEyMzOlsLBQvv/+exk5cqT07NlT/v3vf4uIyOXLl+XBBx+UDz74QI4fPy65ubkyaNAgGTBggMl24uLiZOrUqVJeXq68Ll++7PT4RUQSExPld7/7nUlsP/30k8l2pk+fLqGhoZKdnS2HDh2SoUOHyt133y2//vqr0+NvGnd5ebm8/fbb4ubmJmfOnFHKOGv/Z2Vlyc6dO+XEiRNy4sQJmT9/vuh0OiksLBQRkWXLlomvr69s375dCgoK5NFHH5Xg4GCpqqpStuGsfW8rfrWf+6RdlZWVJudLdna2AJD9+/eLiH11lhp8/vnn8vzzz8v27dsFgOzYscNkvdqv/5a0lJuW6wZbx0zN90tX9dFHH0mXLl1k7dq1cuLECTl+/Lj87W9/U9b/+uuvEhUVJUOHDpVDhw5Jdna2hISESEpKihOjtmz27Nny0EMPCQA5fPiwslztOXzxxReSlJQku3fvljNnzsinn34qgYGBkpaWppRRew7btm0TnU4nGzZskGPHjsmcOXPEx8dHSkpKnB2aRfa0f+25h5C2/fzzzxIeHi5JSUnyzTffSFFRkezdu1dOnz6tlFF7W8JWDlppM9hzLLTQRrAnDzV/tqbrZ8+9/OrVq2bHPyEhQeLi4pQyRUVFAkD27t1rUq62tlZ1+YiIAJDMzEyTWK9evaqsv3LligQFBcn48eOloKBAtm/fLr6+vrJixQpV5ZKRkSGzZs2SAwcOyJkzZ+Tdd98VLy8vWbNmjVJGS8fGnnajGo6N0Ysvvijp6emSmpoq/v7+Zuvb89pxqQ735iorKwWA/OMf/7Ba5ttvvxUAJo34uLg4mTNnTjtE2DJL8ScmJsqYMWOsvufy5cui0+lk27ZtyrKysjJxd3eXXbt2tWW4ZuzZ/2PGjJFhw4aZLFPL/hcR6dKli2zcuFEaGhrEYDDIsmXLlHU1NTXi7+8vb731loioa98bGeO3RM3nPmnXnDlz5JZbbpGGhgYRsV1nqVHzzlutXv+WWOqYbk6LdYO1Dnet3C9dQX19vYSGhlq954g0fkni7u4uZWVlyrKtW7eKXq+XK1eutEeYdvn888+ld+/ecvToUbMOd63k0NTrr78uvXr1Uv5Wew733nuvTJ8+3WRZ79695bnnnnNSRK3TvP1rzz2EtG/u3Lly3333WV2vhbaErRwsUWObwZ48tNBGuJ7jofbP1nT9mt/Lm6usrBSdTifvvPOOsszYadi0HaMWlvKx9TnlzTffFH9/f6mpqVGWLV26VEJCQpTPns5g69iIiMyYMUOGDh2q/K2lY2NPu1GNxyYzM9Nih3tzbXntuNSUMs1duXIFANC1a9cWy7i5uZn91GDLli0ICAjAnXfeiWeeeQbV1dVtGarV2ADz+A8cOIDAwEDcfvvtmDp1qvKzBwDIz89HfX094uPjlWUhISGIiorCwYMH2yfw/7K1/3/88Ufs3LkTycnJZuucvf+vXbuGbdu24ZdffkFMTAyKiopQUVFhsl/1ej3i4uKU/aqmfd88fkvUfO6TNtXV1eG9997D448/Djc3N2V5S3WWFmjt+r9RrlQ3aOV+6QoOHTqEsrIyuLu7o3///ggODsZDDz1kMl1Cbm4uoqKiEBISoixLSEhAbW2tyU/knenHH3/E1KlT8e6778Lb29tsvRZyaO7KlSsmbTE151BXV4f8/HyT6xIA4uPjNXNdNm//2nMPIe3LyspCdHQ0HnnkEQQGBqJ///7YsGGDsl4LbQlbOViixjaDvXmovY3Q2uOh5s/WdOOa38ube+edd+Dt7Y0//OEPZutGjx6NwMBADBkyBB999FFbhmk3a/mkpKQgICAAAwcOxFtvvYWGhgZlXW5uLuLi4qDX65VlCQkJuHDhAoqLi9sjbItsHZuWymjh2NjTblTrsbFHW147NzkiQDUSEaSmpuK+++5DVFSUxTI1NTV47rnnMHHiRPj5+SnLJ02ahF69esFgMKCwsBDz5s3DDz/8gOzs7PYK32r8Dz30EB555BGEh4ejqKgIL7zwAoYNG4b8/Hzo9XpUVFTAw8MDXbp0MdleUFAQKioqnB5/U5s3b4avr6/Z/K7O3P8FBQWIiYlBTU0NOnfujB07dqBPnz5KwyooKMikfFBQEEpKSgBAFfveWvzNqfncJ+365JNPcPnyZSQlJSnLbNVZWmC8ftV+/TuCK9UNWrlfuoqzZ88CABYtWoT09HRERERg5cqViIuLw8mTJ9G1a1dUVFSYXUddunSBh4eHKva5iCApKQnTp09HdHS0xQ8Ias+huTNnzmDNmjVYuXKlskzNOVy8eBHXrl2zWN86OzZ7WGr/2nMPIe07e/Ys1q5di9TUVMyfPx/ffvstZs+eDb1ejylTpmiiLWErh+bU2mawJw8ttBFaezzU+NmaHMPSvby5t99+GxMnToSXl5eyrHPnzkhPT8eQIUPg7u6OrKwsPProo9i8eTMee+yx9gjdImv5vPzyyxg+fDi8vLzw5ZdfIi0tDRcvXsSCBQsANNaRERERJu8x1qkVFRXo1atXu8TflD3HJjc3Fx9++CF27typLNPSsbGn3ajGY2OvNr12bmh8vIrNmDFDwsPD5fz58xbX19XVyZgxY6R///42fz773XffCQDJz89vi1AtshW/0YULF0Sn08n27dtFRGTLli3i4eFhVu7BBx+UJ598sk1itcSe+O+44w675gttz/1fW1srp06dkry8PHnuueckICBAjh49Kv/6178EgFy4cMGk/BNPPCEJCQkioo59by3+ptR+7pN2xcfHy6hRo1os07zOUiM0+zmjVq5/ezTPrSkt1w0t5WWk1vul2i1cuFAAtPjKy8uTLVu2CABZt26d8t6amhoJCAhQpkuYOnWqxMfHm/0bOp1Otm7d6vQcVq9eLbGxscr8vJZ+Tqr2HJoqKyuTW2+9VZKTk02WOysHe5SVlQkAOXjwoMnyV155Re644w4nRWU/S+1fe+4hpH06nU5iYmJMls2aNUsGDx4sItpoS9jKoSk1txlak4eRGtsIrc1DjZ+tyZQj7+VNHTx4UADId999ZzOGlJQU6du37w3nItJ2+RitWLFC/Pz8lL9HjBgh06ZNMylTWloqACQ3N1eVuRQWFkr37t3l5ZdfthmDWo+NPe3Gtjw215uPPVPKtPW145Ij3GfNmoWsrCzk5OQgLCzMbH19fT3GjRuHoqIi7Nu3z+QbeUvuuece6HQ6nDp1Cvfcc09bha2wFX9TwcHBCA8Px6lTpwAABoMBdXV1uHTpksk38pWVlYiNjW3TuI3sif+rr77CiRMn8MEHH9jcXnvufw8PD9x6660AgOjoaOTl5WH16tWYO3cugMZv54KDg5XylZWVyjd3atj31uJft24dAPWf+6RdJSUl2Lt3Lz7++OMWyzWvs7TAYDAAUP/1fyM6Qt2gxvulFqSkpGD8+PEtlomIiFB+nt70V1V6vR6/+c1vcO7cOQCN+/ybb74xee+lS5dQX19vNnLGkezN4ZVXXsHXX39t9uub6OhoTJo0CZs3b1Z9DkYXLlzA0KFDERMTg/Xr15uUc1YO9ggICECnTp3MRpA2rW/Vylr71557CGlfcHCw2a9KIyMjsX37dgDaaEvYysFI7W0Ge/No/h61tRFak4daP1uTKUfey5vauHEj+vXrhwEDBtiMYfDgwdi4caPdMbekrfIxGjx4MKqqqvDjjz8iKCgIBoPBYvsAMP/1UGu1RS7Hjh3DsGHDMHXqVGWUfkvUemzsaTe25bEBWp+Pvdr82mlV97zKNTQ0yMyZMyUkJEROnjxpsUxdXZ2MHTtW7rzzTqmsrLRruwUFBTYf/ukI9sTf3MWLF0Wv18vmzZtF5H8PePnggw+UMhcuXGiXB7y0Jv7ExESzJ9pb017735Jhw4ZJYmKi8qCj1157TVlXW1tr8UFHztj31hjjF1H3uU/at3DhQjEYDFJfX99iueZ1lhrBykNTtXb9W9I8NxHXqBss5dWcmu6XrujKlSui1+tNHppaV1cngYGByqh340OXmo7w3LZtm2oe1llSUiIFBQXKa/fu3QJAPvroI2XEstpzEGkcUXTbbbfJ+PHjldH6Tak9h3vvvVeeeuopk2WRkZGqfWiqrfavPfcQ0r4JEyaYPeDy6aefVkYoa6EtYSsHEW20GezJozk1thFak4dWPluT/Wzdy42qq6ulc+fOsmbNGru2m5aWZvMBn23B3nyaWrNmjXh6eioP4nzzzTfl5ptvltraWqXMsmXL2v3BnPbkUlhYKIGBgfLss8/avV21Hht72o1qOTZN2Rrh3h7Xjkt1uD/11FPi7+8vBw4ckPLycuV19epVERGpr6+X0aNHS1hYmHz//fcmZYwnxunTp2Xx4sWSl5cnRUVFsnPnTundu7f079/f7oqhreKvrq6WtLQ0OXjwoBQVFcn+/fslJiZGQkNDpaqqStnO9OnTJSwsTPbu3SuHDh2SYcOGyd133+30+I2uXLki3t7esnbtWrNtOHP/z5s3T3JycqSoqEiOHDki8+fPF3d3d9mzZ4+INFYY/v7+8vHHH0tBQYFMmDBBgoODVbHvbcWv9nOftO3atWvSs2dPmTt3rslye+ssNaiurpbDhw/L4cOHBYCkp6fL4cOHpaSkRETUf/23pKXctFw3tJSX2u+XrmrOnDkSGhoqu3fvluPHj0tycrIEBgbKzz//LCIiv/76q0RFRcnw4cPl0KFDsnfvXgkLC7PrJ/DOYGlKGbXnYPw58LBhw6S0tNTkmjZSew7btm0TnU4nGRkZcuzYMXn66afFx8dHiouLnR2aRfa0f+25h5C2ffvtt3LTTTfJq6++KqdOnZItW7aIt7e3vPfee0oZtbclbOWglTaDrTy00kaw55wSUe9na7p+9tzLjTZu3Cienp5KW6upTZs2yZYtW+TYsWNy/PhxWb58ueh0OklPT2+PNBT25JOVlSXr16+XgoICOX36tGzYsEH8/Pxk9uzZSpnLly9LUFCQTJgwQQoKCuTjjz8WPz8/WbFihapyMU4jM2nSJJP1Tb+k1NKxsafdqIZjY1RSUiKHDx+WxYsXS+fOnZXPi9XV1Sbl2uPacakOd1iZyyczM1NE/vfBydJr//79IiJy7tw5uf/++6Vr167i4eEht9xyi8yePVt++uknp8d/9epViY+Pl+7du4tOp5OePXtKYmKinDt3zmQ7//nPfyQlJUW6du0qXl5eMmrUKLMyzojfaN26deLl5SWXL18224Yz9//jjz8u4eHh4uHhId27d5fhw4crne0ijSNTjKN49Xq93H///VJQUGCyDWfte1vxq/3cJ20zjgI9ceKEyXJ76yw12L9/v8Xrw/gLEbVf/y1pKTct1w0t5aX2+6Wrqqurk7S0NAkMDBRfX1958MEHpbCw0KRMSUmJjBw5Ury8vKRr166SkpKijFxSG0sd7iLqziEzM9PqNd2UmnMQEfnrX/+qtGnuueceVY/EtKf9a889hLTvs88+k6ioKNHr9dK7d29Zv369yXottCVaykFLbYaW8tBSG8HWOSWi3s/WdP3svZeLiMTExMjEiRMtbmfTpk0SGRkp3t7e4uvrKwMGDJB33323rcM3Y08+X3zxhfTr1086d+4s3t7eEhUVJatWrTL79fSRI0fkt7/9rej1ejEYDLJo0aJ2HUFtTy7W5hsPDw9Xymjp2IjY12509rExSkxMbPE+ZdQe146biAiIiIiIiIiIiIiIiOiGuDs7ACIiIiIiIiIiIiIiV8AOdyIiIiIiIiIiIiIiB2CHOxERERERERERERGRA7DDnYiIiIiIiIiIiIjIAdjhTkRERERERERERETkAOxwJyIiIiIiIiIiIiJyAHa4ExERERERERERERE5ADvciYiIiIiIiIiIiIgcgB3uREREREREREREREQOwA53IiIiIiIiIiIiIiIHYIc7EREREREREREREZEDsMOdiIiIiIiIiIiIiMgB/h8dHdRZHtXCQQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_augmentations(train_data[0], agent_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "614217f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:59:34.405790Z",
     "start_time": "2025-05-30T19:59:34.403969Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def standardize_data_dimensions(scenario_data):\n",
    "    \"\"\"\n",
    "    Standardize position data by centering a single scenario at the origin.\n",
    "    \n",
    "    :param scenario_data: numpy array of shape (50, 110, 6)\n",
    "                         where dimensions are [position_x, position_y, velocity_x, velocity_y, heading, object_type]\n",
    "    :returns: tuple of (standardized_data, min_values)\n",
    "             - standardized_data: same shape as input with centered positions\n",
    "             - min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    \"\"\"\n",
    "    # Copy the data to avoid modifying the original\n",
    "    standardized_data = scenario_data.copy()\n",
    "    \n",
    "    # Extract position data (first 2 dimensions)\n",
    "    positions = scenario_data[:, :, :2]  # Shape: (50, 110, 2)\n",
    "    \n",
    "    # Create mask for non-zero positions (to ignore padding)\n",
    "    # We consider a position valid if it's not (0,0) or if the object_type is not 0\n",
    "    object_types = scenario_data[:, :, 5]  # Shape: (50, 110)\n",
    "    valid_mask = (positions[:, :, 0] != 0) | (positions[:, :, 1] != 0) | (object_types != 0)\n",
    "    \n",
    "    # Find min values across all valid positions in this scenario\n",
    "    if np.any(valid_mask):\n",
    "        valid_positions = positions[valid_mask]  # Shape: (num_valid_points, 2)\n",
    "        min_x = np.min(valid_positions[:, 0])\n",
    "        min_y = np.min(valid_positions[:, 1])\n",
    "    else:\n",
    "        # If no valid positions found, use 0 as min values\n",
    "        min_x = 0\n",
    "        min_y = 0\n",
    "    \n",
    "    # Store min values\n",
    "    min_values = np.array([min_x, min_y])\n",
    "    \n",
    "    # Standardize positions by subtracting min values\n",
    "    # Only modify non-zero positions to preserve padding\n",
    "    for agent_idx in range(scenario_data.shape[0]):\n",
    "        for time_idx in range(scenario_data.shape[1]):\n",
    "            if valid_mask[agent_idx, time_idx]:\n",
    "                standardized_data[agent_idx, time_idx, 0] -= min_x  # position_x\n",
    "                standardized_data[agent_idx, time_idx, 1] -= min_y  # position_y\n",
    "    \n",
    "    return standardized_data, min_values\n",
    "\n",
    "\n",
    "def denormalize_predictions(predictions, min_values):\n",
    "    \"\"\"\n",
    "    Helper function to add back the min values to predicted positions.\n",
    "    \n",
    "    :param predictions: predicted data with standardized positions, shape (50, 110, 6) or similar\n",
    "    :param min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    :returns: predictions with original coordinate system restored\n",
    "    \"\"\"\n",
    "    denormalized = predictions.copy()\n",
    "    \n",
    "    # Add back the min values to restore original coordinate system\n",
    "    # Assuming predictions have position_x and position_y as first two dimensions\n",
    "    denormalized[:, :, 0] += min_values[0]  # position_x\n",
    "    denormalized[:, :, 1] += min_values[1]  # position_y\n",
    "    \n",
    "    return denormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f93de194",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:59:34.405790Z",
     "start_time": "2025-05-30T19:59:34.403969Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def standardize_data_dimensions(scenario_data):\n",
    "    \"\"\"\n",
    "    Standardize position data by centering a single scenario at the origin.\n",
    "    \n",
    "    :param scenario_data: numpy array of shape (50, 110, 6)\n",
    "                         where dimensions are [position_x, position_y, velocity_x, velocity_y, heading, object_type]\n",
    "    :returns: tuple of (standardized_data, min_values)\n",
    "             - standardized_data: same shape as input with centered positions\n",
    "             - min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    \"\"\"\n",
    "    # Copy the data to avoid modifying the original\n",
    "    standardized_data = scenario_data.copy()\n",
    "    \n",
    "    # Extract position data (first 2 dimensions)\n",
    "    positions = scenario_data[:, :, :2]  # Shape: (50, 110, 2)\n",
    "    \n",
    "    # Create mask for non-zero positions (to ignore padding)\n",
    "    # We consider a position valid if it's not (0,0) or if the object_type is not 0\n",
    "    object_types = scenario_data[:, :, 5]  # Shape: (50, 110)\n",
    "    valid_mask = (positions[:, :, 0] != 0) | (positions[:, :, 1] != 0) | (object_types != 0)\n",
    "    \n",
    "    # Find min values across all valid positions in this scenario\n",
    "    if np.any(valid_mask):\n",
    "        valid_positions = positions[valid_mask]  # Shape: (num_valid_points, 2)\n",
    "        min_x = np.min(valid_positions[:, 0])\n",
    "        min_y = np.min(valid_positions[:, 1])\n",
    "    else:\n",
    "        # If no valid positions found, use 0 as min values\n",
    "        min_x = 0\n",
    "        min_y = 0\n",
    "    \n",
    "    # Store min values\n",
    "    min_values = np.array([min_x, min_y])\n",
    "    \n",
    "    # Standardize positions by subtracting min values\n",
    "    # Only modify non-zero positions to preserve padding\n",
    "    for agent_idx in range(scenario_data.shape[0]):\n",
    "        for time_idx in range(scenario_data.shape[1]):\n",
    "            if valid_mask[agent_idx, time_idx]:\n",
    "                standardized_data[agent_idx, time_idx, 0] -= min_x  # position_x\n",
    "                standardized_data[agent_idx, time_idx, 1] -= min_y  # position_y\n",
    "    \n",
    "    return standardized_data, min_values\n",
    "\n",
    "\n",
    "def denormalize_predictions(predictions, min_values):\n",
    "    \"\"\"\n",
    "    Helper function to add back the min values to predicted positions.\n",
    "    \n",
    "    :param predictions: predicted data with standardized positions, shape (50, 110, 6) or similar\n",
    "    :param min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    :returns: predictions with original coordinate system restored\n",
    "    \"\"\"\n",
    "    denormalized = predictions.copy()\n",
    "    \n",
    "    # Add back the min values to restore original coordinate system\n",
    "    # Assuming predictions have position_x and position_y as first two dimensions\n",
    "    denormalized[:, :, 0] += min_values[0]  # position_x\n",
    "    denormalized[:, :, 1] += min_values[1]  # position_y\n",
    "    \n",
    "    return denormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba31f6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:59:35.013159Z",
     "start_time": "2025-05-30T19:59:34.999388Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "def standardize_single_scene(scene_data):\n",
    "    \"\"\"\n",
    "    Wrapper function to standardize a single scene and return both standardized data and min values.\n",
    "    This function will be called in parallel.\n",
    "    \"\"\"\n",
    "    standardized_scene, min_vals = standardize_data_dimensions(scene_data)\n",
    "    return standardized_scene, min_vals\n",
    "\n",
    "def parallel_standardize_training_data(train_data, n_jobs=-1, verbose=True):\n",
    "    \"\"\"\n",
    "    Parallelize the standardization of training data across all scenes.\n",
    "    \n",
    "    :param train_data: numpy array of shape (10000, 50, 110, 6)\n",
    "    :param n_jobs: number of parallel jobs (-1 uses all available cores)\n",
    "    :param verbose: whether to show progress bar\n",
    "    :returns: tuple of (standardized_data, min_values_array)\n",
    "    \"\"\"\n",
    "    print(f\"Standardizing {train_data.shape[0]} scenes using {multiprocessing.cpu_count() if n_jobs == -1 else n_jobs} cores...\")\n",
    "    \n",
    "    # Use joblib to parallelize the processing\n",
    "    if verbose:\n",
    "        # With progress bar\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(standardize_single_scene)(train_data[i]) \n",
    "            for i in tqdm(range(train_data.shape[0]), desc=\"Processing scenes\")\n",
    "        )\n",
    "    else:\n",
    "        # Without progress bar\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(standardize_single_scene)(train_data[i]) \n",
    "            for i in range(train_data.shape[0])\n",
    "        )\n",
    "    \n",
    "    # Unpack results\n",
    "    standardized_scenes, min_values_list = zip(*results)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    standardized_data = np.array(standardized_scenes)\n",
    "    min_values_array = np.array(min_values_list)\n",
    "    \n",
    "    print(f\"Standardization complete!\")\n",
    "    print(f\"Standardized data shape: {standardized_data.shape}\")\n",
    "    print(f\"Min values shape: {min_values_array.shape}\")\n",
    "    \n",
    "    return standardized_data, min_values_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f2eab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:, :5, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "id": "c024cd93",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# full agents are too much data; only want 5 agents worth\n",
    "train_data = train_data[:, :5, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5136d75",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-30T19:59:35.583428Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data not found. Running augmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting chunk 1/5...\n",
      "Using 40 jobs with batch size 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmentations:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Processing aug 1:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Processing aug 1:  50%|█████     | 40/80 [00:01<00:01, 30.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Processing aug 1: 100%|██████████| 80/80 [00:01<00:00, 61.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                 \u001b[A\u001b[A\n",
      "Augmentations:  20%|██        | 1/5 [00:02<00:08,  2.24s/it]\u001b[A\n",
      "\n",
      "Processing aug 2:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  40%|████      | 2/5 [00:02<00:03,  1.15s/it]\u001b[A\n",
      "\n",
      "Processing aug 3:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  60%|██████    | 3/5 [00:03<00:01,  1.25it/s]\u001b[A\n",
      "\n",
      "Processing aug 4:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  80%|████████  | 4/5 [00:03<00:00,  1.56it/s]\u001b[A\n",
      "\n",
      "Processing aug 5:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations: 100%|██████████| 5/5 [00:03<00:00,  1.34it/s]\u001b[A\n",
      "Processing chunks:  20%|██        | 1/5 [00:03<00:15,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting chunk 2/5...\n",
      "Using 40 jobs with batch size 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmentations:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Processing aug 1:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  20%|██        | 1/5 [00:00<00:01,  2.93it/s]\u001b[A\n",
      "\n",
      "Processing aug 2:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  40%|████      | 2/5 [00:00<00:01,  2.72it/s]\u001b[A\n",
      "\n",
      "Processing aug 3:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  60%|██████    | 3/5 [00:01<00:00,  2.77it/s]\u001b[A\n",
      "\n",
      "Processing aug 4:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  80%|████████  | 4/5 [00:01<00:00,  2.80it/s]\u001b[A\n",
      "\n",
      "Processing aug 5:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations: 100%|██████████| 5/5 [00:01<00:00,  2.83it/s]\u001b[A\n",
      "Processing chunks:  40%|████      | 2/5 [00:05<00:08,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting chunk 3/5...\n",
      "Using 40 jobs with batch size 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmentations:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Processing aug 1:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  20%|██        | 1/5 [00:00<00:01,  3.16it/s]\u001b[A\n",
      "\n",
      "Processing aug 2:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  40%|████      | 2/5 [00:00<00:01,  2.97it/s]\u001b[A\n",
      "\n",
      "Processing aug 3:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  60%|██████    | 3/5 [00:01<00:00,  2.87it/s]\u001b[A\n",
      "\n",
      "Processing aug 4:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  80%|████████  | 4/5 [00:01<00:00,  2.71it/s]\u001b[A\n",
      "\n",
      "Processing aug 5:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations: 100%|██████████| 5/5 [00:01<00:00,  2.77it/s]\u001b[A\n",
      "Processing chunks:  60%|██████    | 3/5 [00:07<00:04,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting chunk 4/5...\n",
      "Using 40 jobs with batch size 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmentations:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Processing aug 1:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  20%|██        | 1/5 [00:00<00:01,  2.09it/s]\u001b[A\n",
      "\n",
      "Processing aug 2:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  40%|████      | 2/5 [00:00<00:01,  2.43it/s]\u001b[A\n",
      "\n",
      "Processing aug 3:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  60%|██████    | 3/5 [00:01<00:00,  2.67it/s]\u001b[A\n",
      "\n",
      "Processing aug 4:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  80%|████████  | 4/5 [00:01<00:00,  2.54it/s]\u001b[A\n",
      "\n",
      "Processing aug 5:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations: 100%|██████████| 5/5 [00:01<00:00,  2.55it/s]\u001b[A\n",
      "Processing chunks:  80%|████████  | 4/5 [00:10<00:02,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting chunk 5/5...\n",
      "Using 40 jobs with batch size 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmentations:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Processing aug 1:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  20%|██        | 1/5 [00:00<00:01,  2.87it/s]\u001b[A\n",
      "\n",
      "Processing aug 2:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  40%|████      | 2/5 [00:00<00:01,  2.81it/s]\u001b[A\n",
      "\n",
      "Processing aug 3:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  60%|██████    | 3/5 [00:01<00:00,  2.83it/s]\u001b[A\n",
      "\n",
      "Processing aug 4:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  80%|████████  | 4/5 [00:01<00:00,  2.89it/s]\u001b[A\n",
      "\n",
      "Processing aug 5:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations: 100%|██████████| 5/5 [00:01<00:00,  2.88it/s]\u001b[A\n",
      "Processing chunks: 100%|██████████| 5/5 [00:12<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation done. Preparing to dump to pickle...\n",
      "Original shape: (10000, 5, 110, 6)\n",
      "Augmented shape: (60000, 5, 110, 6)\n"
     ]
    }
   ],
   "source": [
    "# Main execution code\n",
    "augmented_pkl_path = Path(\"augmented_train.pkl\")\n",
    "\n",
    "# Check if the file exists\n",
    "if augmented_pkl_path.exists():\n",
    "    print(\"Loading augmented data from pickle file...\")\n",
    "    with open(augmented_pkl_path, \"rb\") as f:\n",
    "        augmented_train = pickle.load(f)\n",
    "else:\n",
    "    print(\"Augmented data not found. Running augmentation...\")\n",
    "    # Split into 5 chunks\n",
    "    num_chunks = 5\n",
    "    chunk_size = len(train_data) // num_chunks\n",
    "    chunks = [train_data[i * chunk_size: (i + 1) * chunk_size] for i in range(num_chunks - 1)]\n",
    "    chunks.append(train_data[(num_chunks - 1) * chunk_size:])  # last chunk\n",
    "    \n",
    "    augmented_chunks = []\n",
    "    for i, chunk in enumerate(tqdm(chunks, desc=\"Processing chunks\")):\n",
    "        print(f\"Augmenting chunk {i+1}/{num_chunks}...\")\n",
    "        augmented_chunk = augment_dataset(\n",
    "            chunk, \n",
    "            num_augmentations=5,\n",
    "            n_jobs=-1,\n",
    "            batch_size=25\n",
    "        )\n",
    "        augmented_chunks.append(augmented_chunk)\n",
    "        \n",
    "        # Force cleanup\n",
    "        del augmented_chunk\n",
    "        del chunk\n",
    "        gc.collect()\n",
    "    \n",
    "    # Concatenate all augmented chunks\n",
    "    augmented_train = np.concatenate(augmented_chunks, axis=0)\n",
    "    print(\"Augmentation done. Preparing to dump to pickle...\")\n",
    "    \n",
    "    # Uncomment to save to pickle\n",
    "    # with open(augmented_pkl_path, \"wb\") as f:\n",
    "    #     pickle.dump(augmented_train, f)\n",
    "    # print(\"Dumped to pickle.\")\n",
    "\n",
    "print(f\"Original shape: {train_data.shape}\")\n",
    "print(f\"Augmented shape: {augmented_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dce1544",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:41:35.979602Z",
     "start_time": "2025-05-30T19:41:35.938072Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing 60000 scenes using 40 cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing scenes: 100%|██████████| 60000/60000 [00:11<00:00, 5384.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardization complete!\n",
      "Standardized data shape: (60000, 5, 110, 6)\n",
      "Min values shape: (60000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 5, 110, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_train_data, min_values = parallel_standardize_training_data(\n",
    "    augmented_train, \n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=True\n",
    ")\n",
    "standardized_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "504ea3f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T17:40:42.779341Z",
     "start_time": "2025-05-02T17:40:37.771284Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 21:59:06.259398: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-30 21:59:06.259462: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-30 21:59:06.261209: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-30 21:59:06.271348: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, RepeatVector, TimeDistributed, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4575fed9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T17:40:42.786049Z",
     "start_time": "2025-05-02T17:40:42.783787Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def angle_change_loss(y_pred):\n",
    "    \"\"\"\n",
    "    Penalize large changes in direction between consecutive deltas.\n",
    "\n",
    "    Args:\n",
    "        y_pred: Tensor of shape (batch_size, Tpred, 2)\n",
    "\n",
    "    Returns:\n",
    "        Scalar loss penalizing angle differences\n",
    "    \"\"\"\n",
    "    # Normalize deltas to unit vectors\n",
    "    delta_unit = tf.math.l2_normalize(y_pred, axis=-1)  # shape: (B, T, 2)\n",
    "\n",
    "    # Compute cosine similarity between consecutive deltas\n",
    "    dot_products = tf.reduce_sum(delta_unit[:, 1:, :] * delta_unit[:, :-1, :], axis=-1)  # shape: (B, T-1)\n",
    "\n",
    "    # Clamp for numerical stability (to avoid NaNs in arccos)\n",
    "    dot_products = tf.clip_by_value(dot_products, -1.0, 1.0)\n",
    "\n",
    "    # Compute angle in radians between -1 and 1 (cos⁻¹)\n",
    "    angle_diff = tf.acos(dot_products)  # shape: (B, T-1)\n",
    "\n",
    "    # Mean angle difference per sequence\n",
    "    return tf.reduce_mean(angle_diff)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    # Check if there are NaN values in y_true or y_pred\n",
    "    nan_check = tf.reduce_any(tf.math.is_nan(y_true)) | tf.reduce_any(tf.math.is_nan(y_pred))\n",
    "\n",
    "    # Use tf.cond to perform the check\n",
    "    def return_nan_loss():\n",
    "        return tf.constant(float('nan'))\n",
    "\n",
    "    def calculate_loss():\n",
    "        mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "        angle_loss = angle_change_loss(y_pred)\n",
    "        return mse_loss + 0.5 * angle_loss\n",
    "\n",
    "    return tf.cond(nan_check, return_nan_loss, calculate_loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01d59fe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T18:15:51.012605Z",
     "start_time": "2025-05-02T18:15:51.003936Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_lstm_encoder_decoder(input_dim, output_dim, timesteps_in, timesteps_out, lstm_units=512, num_layers=3, loss_fn='mse', lr=0.001):\n",
    "    inputs = Input(shape=(timesteps_in, input_dim))\n",
    "\n",
    "    # Encoder\n",
    "    x = inputs\n",
    "    for _ in range(num_layers):\n",
    "        x = LSTM(lstm_units, return_sequences=True)(x)\n",
    "        # x = Dropout(0.2)(x)\n",
    "    encoded = LSTM(lstm_units)(x)  # Final encoder output\n",
    "\n",
    "    # Decoder\n",
    "    x = RepeatVector(timesteps_out)(encoded)\n",
    "    for _ in range(num_layers):\n",
    "        x = LSTM(lstm_units, return_sequences=True)(x)\n",
    "        # x = Dropout(0.2)(x)\n",
    "    \n",
    "    \n",
    "    x = TimeDistributed(Dense(128, activation='relu'))(x)\n",
    "    x = TimeDistributed(Dense(64, activation='relu'))(x)\n",
    "    outputs = TimeDistributed(Dense(output_dim))(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae']) \n",
    "\n",
    "    # model.compile(optimizer=Adam(learning_rate=1e-5), loss=combined_loss) #switch loss back to 'mse' for older solution \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7558da9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T19:20:44.861403Z",
     "start_time": "2025-05-02T19:20:44.758718Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.src.callbacks import LearningRateScheduler, EarlyStopping, Callback\n",
    "from keras.src.optimizers import Adam\n",
    "from keras import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def exponential_decay_schedule(epoch, lr):\n",
    "    decay_rate = 0.9\n",
    "    decay_steps = 5\n",
    "    if epoch % decay_steps == 0 and epoch:\n",
    "        print('Learning rate update:', lr * decay_rate)\n",
    "        return lr * decay_rate\n",
    "    return lr\n",
    "\n",
    "\n",
    "# Custom callback to monitor LR and stop training\n",
    "class LRThresholdCallback(Callback):\n",
    "    def __init__(self, threshold=9e-5):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "        self.should_stop = False\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = float(self.model.optimizer.learning_rate.numpy())\n",
    "        if lr < self.threshold:\n",
    "            print(f\"\\nLearning rate {lr:.6f} < threshold {self.threshold}, moving to Phase 2.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "def train_model(train_data, batch_size=32, validation_split=0.2, Tobs=50, Tpred=60):\n",
    "    n_scenarios = train_data.shape[0]\n",
    "    X_train_raw = []\n",
    "    y_train_deltas = []\n",
    "\n",
    "    for i in range(n_scenarios):\n",
    "        ego_data = train_data[i, 0, :, :]\n",
    "        if np.all(ego_data == 0):\n",
    "            continue\n",
    "\n",
    "        observed = ego_data[:Tobs]            # shape (50, 6)\n",
    "        future = ego_data[Tobs:Tobs+Tpred, :2]\n",
    "        last_obs_pos = observed[-1, :2]\n",
    "\n",
    "        if np.any(np.all(observed == 0, axis=1)) or np.any(np.all(future == 0, axis=1)):\n",
    "            continue\n",
    "\n",
    "        # Compute deltas w.r.t. previous future timestep\n",
    "        delta = np.diff(np.vstack([last_obs_pos, future]), axis=0)  # (60, 2)\n",
    "\n",
    "        X_train_raw.append(observed)\n",
    "        y_train_deltas.append(delta)\n",
    "    \n",
    "\n",
    "    X_train = np.array(X_train_raw)\n",
    "    y_train = np.array(y_train_deltas)\n",
    "\n",
    "    print(f\"Training on {X_train.shape[0]} valid sequences.\")\n",
    "    print(f\"Input shape: {X_train.shape}, Delta Output shape: {y_train.shape}\")\n",
    "    \n",
    "    # --- Normalize Input and Output ---\n",
    "    X_mean = X_train.mean(axis=(0, 1), keepdims=True)  # shape: (1, 1, 6)\n",
    "    X_std = X_train.std(axis=(0, 1), keepdims=True) + 1e-8\n",
    "\n",
    "    y_mean = y_train.mean(axis=(0, 1), keepdims=True)  # shape: (1, 1, 2)\n",
    "    y_std = y_train.std(axis=(0, 1), keepdims=True) + 1e-8\n",
    "\n",
    "    X_train = (X_train - X_mean) / X_std\n",
    "    y_train = (y_train - y_mean) / y_std\n",
    "    \n",
    "    print(X_train[:2])\n",
    "    print(y_train[:2])\n",
    "\n",
    "    model = create_lstm_encoder_decoder(\n",
    "        input_dim=X_train.shape[-1],\n",
    "        output_dim=2,\n",
    "        timesteps_in=Tobs,\n",
    "        timesteps_out=Tpred,\n",
    "        loss_fn='mse',\n",
    "        lr=0.001\n",
    "    )\n",
    "\n",
    "    phase1_callbacks = [\n",
    "        LearningRateScheduler(exponential_decay_schedule),\n",
    "        EarlyStopping(patience=4, restore_best_weights=True, monitor='val_loss'),\n",
    "        LRThresholdCallback(threshold=9e-5)\n",
    "    ]\n",
    "\n",
    "    print(\"\\n--- Phase 1: Training ---\")\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=phase1_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Phase 2: Fine-tuning ---\")\n",
    "    model.compile(optimizer=Adam(1e-4), loss='mse', metrics=['mae'])\n",
    "    phase2_callbacks = [\n",
    "        LearningRateScheduler(exponential_decay_schedule),\n",
    "        EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss')\n",
    "    ]\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=10,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=phase2_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Return model and normalization parameters\n",
    "    return model, X_mean, X_std, y_mean, y_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05d03f52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T19:20:47.293888Z",
     "start_time": "2025-05-02T19:20:47.285992Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(model, filepath='lstm_1.pkl'):\n",
    "    \"\"\"Save model and scaler together in a pickle file\"\"\"\n",
    "    model_json = model.to_json()\n",
    "    model_weights = model.get_weights()\n",
    "    data = {\n",
    "        'model_json': model_json,\n",
    "        'model_weights': model_weights,\n",
    "    }\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Model saved to {filepath}\")\n",
    "\n",
    "def load_model(filepath='lstm_1.pkl'):\n",
    "    \"\"\"Load model and scaler from pickle file\"\"\"\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    # Reconstruct model\n",
    "    model = tf.keras.models.model_from_json(data['model_json'])\n",
    "    model.set_weights(data['model_weights'])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1bc4b4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T18:42:28.285866Z",
     "start_time": "2025-05-02T18:41:59.875150Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first check that the model can overfit on small data\n",
    "# model, X_mean, X_std, y_mean, y_std  = train_model(train_data[:20], batch_size=20, validation_split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a51c06da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T18:42:54.682368Z",
     "start_time": "2025-05-02T18:42:54.675886Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_mae_by_timestep(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Visualize MAE across timesteps in the prediction horizon.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): shape (N, Tpred, 2)\n",
    "        y_pred (np.ndarray): shape (N, Tpred, 2)\n",
    "    \"\"\"\n",
    "    mae_per_timestep = np.mean(np.abs(y_true - y_pred), axis=(0, 2))  # shape (Tpred,)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(mae_per_timestep, label='MAE per Timestep')\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.ylabel('MAE (meters)')\n",
    "    plt.title('Mean Absolute Error Over Prediction Horizon')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "978306dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T18:42:55.168565Z",
     "start_time": "2025-05-02T18:42:55.165875Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reconstruct_absolute_positions(pred_deltas, last_observed_positions):\n",
    "    \"\"\"\n",
    "    Reconstruct absolute predicted positions by adding deltas to the last observed position.\n",
    "\n",
    "    Args:\n",
    "        pred_deltas: np.ndarray of shape (N, Tpred, 2)\n",
    "        last_observed_positions: np.ndarray of shape (N, 2)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray of shape (N, Tpred, 2)\n",
    "    \"\"\"\n",
    "    return last_observed_positions[:, None, :] + np.cumsum(pred_deltas, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def forecast_positions(scenario_data, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std):\n",
    "    \"\"\"\n",
    "    Use normalized LSTM model to forecast future deltas and reconstruct absolute positions.\n",
    "\n",
    "    Args:\n",
    "        scenario_data (numpy.ndarray): Shape (agents, time_steps, dimensions)\n",
    "        Tobs (int): Number of observed time steps\n",
    "        Tpred (int): Number of future time steps to predict\n",
    "        model (Model): Trained LSTM model that predicts normalized deltas\n",
    "        X_mean, X_std: Normalization stats for input\n",
    "        y_mean, y_std: Normalization stats for output\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Predicted absolute positions of shape (agents, Tpred, 2)\n",
    "    \"\"\"\n",
    "    agents, _, _ = scenario_data.shape\n",
    "    predicted_positions = np.zeros((agents, Tpred, 2))\n",
    "    pred_deltas_all = []\n",
    "\n",
    "    for agent_idx in range(agents):\n",
    "        agent_data = scenario_data[agent_idx, :Tobs, :]  # shape (Tobs, 6)\n",
    "\n",
    "        # Skip if fully padded\n",
    "        if np.all(agent_data == 0):\n",
    "            continue\n",
    "\n",
    "        # Normalize input\n",
    "        X_pred = np.expand_dims(agent_data, axis=0)  # shape (1, Tobs, 6)\n",
    "        X_pred_norm = (X_pred - X_mean) / X_std\n",
    "\n",
    "        # Predict normalized deltas\n",
    "        pred_deltas_norm = model.predict(X_pred_norm, verbose=0)  # shape (1, Tpred, 2)\n",
    "\n",
    "        # Denormalize deltas\n",
    "        pred_deltas = pred_deltas_norm * y_std + y_mean\n",
    "        pred_deltas_all.append(pred_deltas[0])\n",
    "\n",
    "        # Reconstruct absolute positions\n",
    "        last_pos = agent_data[Tobs - 1, :2]  # shape (2,)\n",
    "        abs_positions = reconstruct_absolute_positions(\n",
    "            pred_deltas=pred_deltas,\n",
    "            last_observed_positions=np.expand_dims(last_pos, axis=0)\n",
    "        )[0]\n",
    "\n",
    "        predicted_positions[agent_idx] = abs_positions\n",
    "\n",
    "    return predicted_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59698794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T18:42:56.727430Z",
     "start_time": "2025-05-02T18:42:56.726626Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def make_gif(data_matrix1, data_matrix2, name='comparison'):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.animation as animation\n",
    "\n",
    "    cmap1 = plt.cm.get_cmap('viridis', 50)\n",
    "    cmap2 = plt.cm.get_cmap('plasma', 50)\n",
    "\n",
    "    assert data_matrix1.shape[1] == data_matrix2.shape[1], \"Both matrices must have same number of timesteps\"\n",
    "    timesteps = data_matrix1.shape[1]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "    ax1, ax2 = axes\n",
    "\n",
    "    def update(frame):\n",
    "        for ax in axes:\n",
    "            ax.clear()\n",
    "\n",
    "        for i in range(data_matrix1.shape[0]):\n",
    "            for (data_matrix, ax, cmap) in [(data_matrix1, ax1, cmap1), (data_matrix2, ax2, cmap2)]:\n",
    "                x = data_matrix[i, frame, 0]\n",
    "                y = data_matrix[i, frame, 1]\n",
    "                if x != 0 and y != 0:\n",
    "                    xs = data_matrix[i, :frame+1, 0]\n",
    "                    ys = data_matrix[i, :frame+1, 1]\n",
    "                    mask = (xs != 0) & (ys != 0)\n",
    "                    xs = xs[mask]\n",
    "                    ys = ys[mask]\n",
    "                    if len(xs) > 0 and len(ys) > 0:\n",
    "                        color = cmap(i)\n",
    "                        ax.plot(xs, ys, alpha=0.9, color=color)\n",
    "                        ax.scatter(x, y, s=80, color=color)\n",
    "\n",
    "        # Plot ego vehicle (index 0) on both\n",
    "        ax1.plot(data_matrix1[0, :frame, 0], data_matrix1[0, :frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "        ax1.scatter(data_matrix1[0, frame, 0], data_matrix1[0, frame, 1], s=80, color='tab:orange')\n",
    "        ax1.set_title('Prediction')\n",
    "\n",
    "        ax2.plot(data_matrix2[0, :frame, 0], data_matrix2[0, :frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "        ax2.scatter(data_matrix2[0, frame, 0], data_matrix2[0, frame, 1], s=80, color='tab:orange')\n",
    "        ax2.set_title('Actual')\n",
    "\n",
    "        for ax, data_matrix in zip(axes, [data_matrix1, data_matrix2]):\n",
    "            ax.set_xlim(data_matrix[:, :, 0][data_matrix[:, :, 0] != 0].min() - 10,\n",
    "                        data_matrix[:, :, 0][data_matrix[:, :, 0] != 0].max() + 10)\n",
    "            ax.set_ylim(data_matrix[:, :, 1][data_matrix[:, :, 1] != 0].min() - 10,\n",
    "                        data_matrix[:, :, 1][data_matrix[:, :, 1] != 0].max() + 10)\n",
    "            ax.legend()\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "\n",
    "        # Compute MSE over non-zero entries up to current frame\n",
    "        mask = (data_matrix2[:, :frame+1, :] != 0) & (data_matrix1[:, :frame+1, :] != 0)\n",
    "        mse = np.mean((data_matrix1[:, :frame+1, :][mask] - data_matrix2[:, :frame+1, :][mask]) ** 2)\n",
    "\n",
    "        fig.suptitle(f\"Timestep {frame} - MSE: {mse:.4f}\", fontsize=16)\n",
    "        return ax1.collections + ax1.lines + ax2.collections + ax2.lines\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, update, frames=list(range(0, timesteps, 3)), interval=100, blit=True)\n",
    "    anim.save(f'trajectory_visualization_{name}.gif', writer='pillow')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3908f5da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T01:00:46.798817Z",
     "start_time": "2025-05-03T01:00:35.906297Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_958706/849000278.py:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap1 = plt.cm.get_cmap('viridis', 50)\n",
      "/tmp/ipykernel_958706/849000278.py:10: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap2 = plt.cm.get_cmap('plasma', 50)\n"
     ]
    }
   ],
   "source": [
    "# visualize prediction\n",
    "\n",
    "# model = load_model()\n",
    "\n",
    "# Parameters\n",
    "Tobs = 50\n",
    "Tpred = 60\n",
    "\n",
    "data = train_data[5000]\n",
    "\n",
    "# Select a test scenario (can use any valid index)\n",
    "test_scenario = data.copy()  # shape (agents, time_steps, features)\n",
    "\n",
    "# Forecast future positions\n",
    "predicted_positions = forecast_positions(test_scenario, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std)\n",
    "\n",
    "# Create combined matrix of past observed + predicted for ego agent (agent 0)\n",
    "ego_past = test_scenario[0, :Tobs, :2]               # shape (Tobs, 2)\n",
    "ego_future = predicted_positions[0]                  # shape (Tpred, 2)\n",
    "ego_full = np.concatenate([ego_past, ego_future], axis=0)  # shape (Tobs + Tpred, 2)\n",
    "\n",
    "# Create updated scenario with predicted ego and original others\n",
    "updated_scenario = test_scenario.copy()\n",
    "updated_scenario[0, :Tobs+Tpred, :2] = ego_full  # Replace ego trajectory\n",
    "\n",
    "# Visualize\n",
    "make_gif(updated_scenario, data, name='lstm1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57d252d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T22:42:07.483287Z",
     "start_time": "2025-05-02T19:20:54.021001Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 59177 valid sequences.\n",
      "Input shape: (59177, 50, 6), Delta Output shape: (59177, 60, 2)\n",
      "[[[-0.13970156 -0.24849051 -1.02788938  0.32343215  1.02491015\n",
      "    0.        ]\n",
      "  [-0.14015124 -0.24827328 -1.02788938  0.32343215  1.02486038\n",
      "    0.        ]\n",
      "  [-0.14070611 -0.24800505 -2.05106962  0.66404411  1.02479781\n",
      "    0.        ]\n",
      "  [-0.14136238 -0.24768753 -2.03929605  0.6638565   1.02472513\n",
      "    0.        ]\n",
      "  [-0.14211274 -0.24732411 -2.03699826  0.66559847  1.02464859\n",
      "    0.        ]\n",
      "  [-0.14294496 -0.24692063 -2.04646197  0.66753463  1.02457093\n",
      "    0.        ]\n",
      "  [-0.1438432  -0.24648478 -2.02514729  0.6604432   1.02448983\n",
      "    0.        ]\n",
      "  [-0.14478756 -0.24602615 -2.02626388  0.66091089  1.02440815\n",
      "    0.        ]\n",
      "  [-0.14575411 -0.24555641 -2.04854177  0.66841902  1.02432519\n",
      "    0.        ]\n",
      "  [-0.14671496 -0.2450891  -2.03612317  0.66681081  1.02424241\n",
      "    0.        ]\n",
      "  [-0.14763835 -0.24463947 -2.02383453  0.66521943  1.02417101\n",
      "    0.        ]\n",
      "  [-0.14853453 -0.24420263 -2.04846553  0.67341831  1.02411584\n",
      "    0.        ]\n",
      "  [-0.14943133 -0.24376535 -2.04788325  0.67299875  1.02407092\n",
      "    0.        ]\n",
      "  [-0.1503284  -0.24332771 -2.0309427   0.66582025  1.02403614\n",
      "    0.        ]\n",
      "  [-0.15122561 -0.24288974 -2.03680975  0.66709513  1.02401069\n",
      "    0.        ]\n",
      "  [-0.15212378 -0.2424512  -2.0346552   0.66701077  1.02398747\n",
      "    0.        ]\n",
      "  [-0.1530217  -0.24201281 -2.0339907   0.66658077  1.0239647\n",
      "    0.        ]\n",
      "  [-0.15391893 -0.2415749  -2.03608768  0.66903911  1.02394369\n",
      "    0.        ]\n",
      "  [-0.15481622 -0.24113723 -2.03883972  0.67192     1.02392045\n",
      "    0.        ]\n",
      "  [-0.15571277 -0.24070012 -2.03977614  0.67052224  1.02389505\n",
      "    0.        ]\n",
      "  [-0.15660707 -0.24026414 -2.04171351  0.66962676  1.02387031\n",
      "    0.        ]\n",
      "  [-0.15750031 -0.23982856 -2.03162116  0.66611823  1.02384537\n",
      "    0.        ]\n",
      "  [-0.15839257 -0.23939333 -2.03026296  0.66496963  1.02381888\n",
      "    0.        ]\n",
      "  [-0.15928244 -0.23895924 -2.0293257   0.66426242  1.02378729\n",
      "    0.        ]\n",
      "  [-0.16017062 -0.238526   -2.01056915  0.65807588  1.02374476\n",
      "    0.        ]\n",
      "  [-0.16105736 -0.23809358 -2.01115636  0.65902461  1.02368886\n",
      "    0.        ]\n",
      "  [-0.16194295 -0.23766176 -2.00861925  0.65900888  1.02362326\n",
      "    0.        ]\n",
      "  [-0.16282768 -0.23723027 -1.99680149  0.65586663  1.02355646\n",
      "    0.        ]\n",
      "  [-0.16371143 -0.2367991  -1.99632746  0.65637053  1.02349711\n",
      "    0.        ]\n",
      "  [-0.16459426 -0.23636833 -2.01499763  0.66280404  1.02344424\n",
      "    0.        ]\n",
      "  [-0.16547689 -0.23593753 -2.00185603  0.65628642  1.02339631\n",
      "    0.        ]\n",
      "  [-0.16635909 -0.23550684 -1.9983275   0.654786    1.02334705\n",
      "    0.        ]\n",
      "  [-0.16724139 -0.23507628 -2.02338717  0.66343282  1.02329662\n",
      "    0.        ]\n",
      "  [-0.16812421 -0.2346454  -2.01444389  0.6605872   1.02325819\n",
      "    0.        ]\n",
      "  [-0.16900699 -0.23421442 -2.00835735  0.66036728  1.02323657\n",
      "    0.        ]\n",
      "  [-0.16988962 -0.23378379 -1.99977847  0.65576635  1.0232254\n",
      "    0.        ]\n",
      "  [-0.17077159 -0.23335393 -1.99136543  0.65125437  1.02321522\n",
      "    0.        ]\n",
      "  [-0.17165256 -0.23292487 -1.99860703  0.65513966  1.02320537\n",
      "    0.        ]\n",
      "  [-0.17253253 -0.23249651 -2.00581742  0.65900821  1.02319786\n",
      "    0.        ]\n",
      "  [-0.17341255 -0.23206823 -1.99841752  0.65375188  1.02319259\n",
      "    0.        ]\n",
      "  [-0.17429215 -0.23164033 -2.0050447   0.65536639  1.02318917\n",
      "    0.        ]\n",
      "  [-0.17517116 -0.2312129  -1.99866913  0.65722817  1.02318919\n",
      "    0.        ]\n",
      "  [-0.17605104 -0.23078513 -1.99240041  0.64954761  1.02319125\n",
      "    0.        ]\n",
      "  [-0.17693199 -0.2303569  -1.99197427  0.64400644  1.02319486\n",
      "    0.        ]\n",
      "  [-0.17781399 -0.22992809 -1.99425182  0.65028459  1.02320028\n",
      "    0.        ]\n",
      "  [-0.17869695 -0.22949887 -2.01045782  0.6593075   1.02320112\n",
      "    0.        ]\n",
      "  [-0.17958061 -0.2290695  -2.01272698  0.65967997  1.02319507\n",
      "    0.        ]\n",
      "  [-0.18046513 -0.22863972 -2.01496522  0.66004735  1.02318326\n",
      "    0.        ]\n",
      "  [-0.18135072 -0.22820923 -2.00953845  0.65769279  1.02316219\n",
      "    0.        ]\n",
      "  [-0.18223716 -0.22777818 -2.01624624  0.66036416  1.02312515\n",
      "    0.        ]]\n",
      "\n",
      " [[-0.23121351 -0.12556694  0.48298695 -0.60219454 -0.30493638\n",
      "    0.        ]\n",
      "  [-0.23098682 -0.12595556  0.48298695 -0.60219454 -0.30479688\n",
      "    0.        ]\n",
      "  [-0.23070413 -0.12644019  0.98700084 -1.20005626 -0.30463165\n",
      "    0.        ]\n",
      "  [-0.23036685 -0.12701836  1.01431574 -1.23058488 -0.30444202\n",
      "    0.        ]\n",
      "  [-0.22997835 -0.12768426  1.03574003 -1.25475409 -0.30422868\n",
      "    0.        ]\n",
      "  [-0.22954383 -0.12842895  1.04837356 -1.27168646 -0.30399178\n",
      "    0.        ]\n",
      "  [-0.22907092 -0.12923936  1.06496045 -1.29145201 -0.30373968\n",
      "    0.        ]\n",
      "  [-0.22856917 -0.13009889  1.07789296 -1.30504971 -0.30348731\n",
      "    0.        ]\n",
      "  [-0.22805008 -0.13098768  1.08671957 -1.31559124 -0.303249\n",
      "    0.        ]\n",
      "  [-0.22752796 -0.13188121  1.0958899  -1.32674773 -0.30303337\n",
      "    0.        ]\n",
      "  [-0.22701917 -0.13275139  1.1019333  -1.33362363 -0.30284955\n",
      "    0.        ]\n",
      "  [-0.22651991 -0.13360491  1.11075806 -1.34250024 -0.30269836\n",
      "    0.        ]\n",
      "  [-0.22601784 -0.13446292  1.12267716 -1.35560894 -0.30257155\n",
      "    0.        ]\n",
      "  [-0.22551348 -0.13532448  1.13153387 -1.36543702 -0.30246603\n",
      "    0.        ]\n",
      "  [-0.22500776 -0.13618807  1.13169988 -1.36440784 -0.3023795\n",
      "    0.        ]\n",
      "  [-0.22450151 -0.13705246  1.13916394 -1.37068814 -0.30231203\n",
      "    0.        ]\n",
      "  [-0.22399505 -0.13791709  1.13986311 -1.37338031 -0.30227051\n",
      "    0.        ]\n",
      "  [-0.22348872 -0.13878162  1.12880518 -1.36270491 -0.30225631\n",
      "    0.        ]\n",
      "  [-0.2229829  -0.13964564  1.13211302 -1.36632043 -0.30226666\n",
      "    0.        ]\n",
      "  [-0.22247798 -0.14050867  1.13060145 -1.36575898 -0.30229525\n",
      "    0.        ]\n",
      "  [-0.22197431 -0.14137026  1.12657548 -1.36016404 -0.30233097\n",
      "    0.        ]\n",
      "  [-0.22147202 -0.14223017  1.1143893  -1.34743641 -0.3023688\n",
      "    0.        ]\n",
      "  [-0.22097108 -0.14308836  1.10830982 -1.34264347 -0.3024058\n",
      "    0.        ]\n",
      "  [-0.22047106 -0.14394549  1.11693967 -1.35147891 -0.30243903\n",
      "    0.        ]\n",
      "  [-0.2199716  -0.14480206  1.12017428 -1.35740987 -0.30247197\n",
      "    0.        ]\n",
      "  [-0.2194726  -0.14565797  1.11865052 -1.35943955 -0.30250882\n",
      "    0.        ]\n",
      "  [-0.21897319 -0.14651465  1.11678238 -1.35569749 -0.30254362\n",
      "    0.        ]\n",
      "  [-0.21847327 -0.14737229  1.11479043 -1.35206011 -0.30257148\n",
      "    0.        ]\n",
      "  [-0.21797291 -0.14823064  1.11675257 -1.35339251 -0.30259095\n",
      "    0.        ]\n",
      "  [-0.21747151 -0.14909071  1.11804532 -1.35311664 -0.3026034\n",
      "    0.        ]\n",
      "  [-0.21696947 -0.14995158  1.11918755 -1.35440414 -0.30261043\n",
      "    0.        ]\n",
      "  [-0.2164672  -0.15081245  1.12670957 -1.36332295 -0.3026135\n",
      "    0.        ]\n",
      "  [-0.21596438 -0.15167377  1.12707607 -1.36370685 -0.30261711\n",
      "    0.        ]\n",
      "  [-0.21546123 -0.15253515  1.12147535 -1.35747324 -0.30261832\n",
      "    0.        ]\n",
      "  [-0.21495759 -0.15339689  1.13584369 -1.37381322 -0.30261234\n",
      "    0.        ]\n",
      "  [-0.21445354 -0.15425909  1.12484931 -1.36025402 -0.30260332\n",
      "    0.        ]\n",
      "  [-0.2139497  -0.15512064  1.11634876 -1.34971729 -0.30259757\n",
      "    0.        ]\n",
      "  [-0.21344654 -0.15598073  1.12720166 -1.36097511 -0.30259423\n",
      "    0.        ]\n",
      "  [-0.21294454 -0.15683867  1.11283627 -1.34311168 -0.30258929\n",
      "    0.        ]\n",
      "  [-0.21244428 -0.15769357  1.12454894 -1.35551563 -0.30258576\n",
      "    0.        ]\n",
      "  [-0.21194645 -0.15854419  1.12592505 -1.35807448 -0.30258585\n",
      "    0.        ]\n",
      "  [-0.21145107 -0.15939037  1.10329047 -1.33333094 -0.30258403\n",
      "    0.        ]\n",
      "  [-0.21095858 -0.16023132  1.10571422 -1.334309   -0.30258137\n",
      "    0.        ]\n",
      "  [-0.21046979 -0.16106576  1.09390556 -1.3195792  -0.30258477\n",
      "    0.        ]\n",
      "  [-0.20998418 -0.16189447  1.07731933 -1.30111058 -0.30259791\n",
      "    0.        ]\n",
      "  [-0.20950283 -0.16271566  1.07287461 -1.29610461 -0.30262342\n",
      "    0.        ]\n",
      "  [-0.20902701 -0.16352737  1.06042208 -1.28267185 -0.30265267\n",
      "    0.        ]\n",
      "  [-0.20855676 -0.16432964  1.04842443 -1.26666548 -0.30268481\n",
      "    0.        ]\n",
      "  [-0.20809261 -0.16512136  1.03765374 -1.25020433 -0.30273228\n",
      "    0.        ]\n",
      "  [-0.2076345  -0.16590245  1.03065059 -1.24102484 -0.30279076\n",
      "    0.        ]]]\n",
      "[[[-2.04095272  0.66773253]\n",
      "  [-2.04481326  0.67019744]\n",
      "  [-2.04679596  0.67165048]\n",
      "  [-2.04756983  0.67210686]\n",
      "  [-2.04816903  0.67274658]\n",
      "  [-2.04996068  0.67431911]\n",
      "  [-2.05151608  0.67587229]\n",
      "  [-2.05183952  0.67677931]\n",
      "  [-2.05134117  0.67747601]\n",
      "  [-2.05184361  0.67842062]\n",
      "  [-2.05227527  0.67895203]\n",
      "  [-2.05252255  0.6787775 ]\n",
      "  [-2.05300869  0.67805742]\n",
      "  [-2.0528082   0.67698894]\n",
      "  [-2.05162808  0.67567231]\n",
      "  [-2.05103461  0.67447984]\n",
      "  [-2.05123175  0.6734231 ]\n",
      "  [-2.05205081  0.67273961]\n",
      "  [-2.05276855  0.67214695]\n",
      "  [-2.05149788  0.67070051]\n",
      "  [-2.04918755  0.66887476]\n",
      "  [-2.04845443  0.66775729]\n",
      "  [-2.04862675  0.66731195]\n",
      "  [-2.04882404  0.66737711]\n",
      "  [-2.04729585  0.66698815]\n",
      "  [-2.04456458  0.6663983 ]\n",
      "  [-2.04370448  0.66682675]\n",
      "  [-2.04307867  0.6670924 ]\n",
      "  [-2.04163502  0.66675836]\n",
      "  [-2.03914518  0.66591196]\n",
      "  [-2.03609568  0.66497224]\n",
      "  [-2.03250336  0.66420539]\n",
      "  [-2.02829282  0.6631186 ]\n",
      "  [-2.02418961  0.66175295]\n",
      "  [-2.01908466  0.65987793]\n",
      "  [-2.01225916  0.65732653]\n",
      "  [-2.0051473   0.65427327]\n",
      "  [-1.99828233  0.6514044 ]\n",
      "  [-1.99082221  0.64879422]\n",
      "  [-1.98399434  0.64648988]\n",
      "  [-1.97706928  0.64436299]\n",
      "  [-1.97019136  0.64205186]\n",
      "  [-1.96179712  0.63916614]\n",
      "  [-1.95262216  0.63651389]\n",
      "  [-1.94496436  0.63424256]\n",
      "  [-1.93585764  0.63100076]\n",
      "  [-1.92431264  0.62698988]\n",
      "  [-1.9125232   0.62262018]\n",
      "  [-1.90146801  0.6183219 ]\n",
      "  [-1.89087791  0.61419961]\n",
      "  [-1.9330876   0.62707688]\n",
      "  [-1.99403518  0.64583205]\n",
      "  [-1.99231382  0.64378105]\n",
      "  [-1.93623624  0.62381252]\n",
      "  [-1.83454751  0.58890801]\n",
      "  [-1.69380865  0.54160643]\n",
      "  [-1.52194936  0.48430008]\n",
      "  [-1.32876497  0.41987208]\n",
      "  [-1.12173524  0.35098722]\n",
      "  [-0.90789742  0.27984628]]\n",
      "\n",
      " [[ 1.02020721 -1.23243054]\n",
      "  [ 1.00363502 -1.21359947]\n",
      "  [ 0.9875461  -1.19497428]\n",
      "  [ 0.97111519 -1.17546315]\n",
      "  [ 0.95318614 -1.15439924]\n",
      "  [ 0.93460022 -1.13289054]\n",
      "  [ 0.9147908  -1.11009499]\n",
      "  [ 0.89399314 -1.08605078]\n",
      "  [ 0.8727237  -1.06097171]\n",
      "  [ 0.85150055 -1.03569298]\n",
      "  [ 0.82856551 -1.00864412]\n",
      "  [ 0.80494604 -0.98084258]\n",
      "  [ 0.78102536 -0.95284642]\n",
      "  [ 0.75593436 -0.92393323]\n",
      "  [ 0.73080632 -0.8951137 ]\n",
      "  [ 0.70652962 -0.8671525 ]\n",
      "  [ 0.68281898 -0.83965818]\n",
      "  [ 0.65780849 -0.81092484]\n",
      "  [ 0.63293213 -0.78276766]\n",
      "  [ 0.60906171 -0.75555747]\n",
      "  [ 0.58596422 -0.72863643]\n",
      "  [ 0.56337995 -0.70190336]\n",
      "  [ 0.54049921 -0.67499803]\n",
      "  [ 0.51746098 -0.6480149 ]\n",
      "  [ 0.49432714 -0.62077547]\n",
      "  [ 0.47164974 -0.59369607]\n",
      "  [ 0.44972971 -0.56704453]\n",
      "  [ 0.42681341 -0.53932175]\n",
      "  [ 0.40345893 -0.51124785]\n",
      "  [ 0.38118076 -0.48462225]\n",
      "  [ 0.35965405 -0.45911482]\n",
      "  [ 0.33889323 -0.43431534]\n",
      "  [ 0.31874409 -0.41002123]\n",
      "  [ 0.29939601 -0.38678514]\n",
      "  [ 0.2802959  -0.36389702]\n",
      "  [ 0.26178065 -0.34173598]\n",
      "  [ 0.2442477  -0.32089049]\n",
      "  [ 0.22736231 -0.30081269]\n",
      "  [ 0.21130012 -0.28155892]\n",
      "  [ 0.1960451  -0.26319964]\n",
      "  [ 0.18172982 -0.24619506]\n",
      "  [ 0.16817902 -0.23034168]\n",
      "  [ 0.15557093 -0.21546653]\n",
      "  [ 0.14387163 -0.20119675]\n",
      "  [ 0.13250461 -0.18725853]\n",
      "  [ 0.12120978 -0.17366809]\n",
      "  [ 0.11141556 -0.16187889]\n",
      "  [ 0.10246851 -0.15109846]\n",
      "  [ 0.09385562 -0.14059015]\n",
      "  [ 0.08553778 -0.13021607]\n",
      "  [ 0.07890297 -0.12200019]\n",
      "  [ 0.07292606 -0.11480526]\n",
      "  [ 0.06563726 -0.1060822 ]\n",
      "  [ 0.05793569 -0.09701396]\n",
      "  [ 0.04946208 -0.08708524]\n",
      "  [ 0.04097506 -0.07708549]\n",
      "  [ 0.03256662 -0.06724798]\n",
      "  [ 0.02448343 -0.05789998]\n",
      "  [ 0.01708589 -0.04937066]\n",
      "  [ 0.01003943 -0.0412249 ]]]\n",
      "\n",
      "--- Phase 1: Training ---\n",
      "Epoch 1/50\n",
      "1480/1480 [==============================] - 139s 85ms/step - loss: 0.1684 - mae: 0.2624 - val_loss: 0.1146 - val_mae: 0.2188 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1480/1480 [==============================] - 124s 83ms/step - loss: 0.1042 - mae: 0.2034 - val_loss: 0.0978 - val_mae: 0.1989 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0954 - mae: 0.1919 - val_loss: 0.0936 - val_mae: 0.1901 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0903 - mae: 0.1856 - val_loss: 0.0859 - val_mae: 0.1799 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0869 - mae: 0.1811 - val_loss: 0.0858 - val_mae: 0.1798 - lr: 0.0010\n",
      "Learning rate update: 0.0009000000427477062\n",
      "Epoch 6/50\n",
      "1480/1480 [==============================] - 123s 83ms/step - loss: 0.0799 - mae: 0.1710 - val_loss: 0.0767 - val_mae: 0.1687 - lr: 9.0000e-04\n",
      "Epoch 7/50\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0760 - mae: 0.1659 - val_loss: 0.0816 - val_mae: 0.1770 - lr: 9.0000e-04\n",
      "Epoch 8/50\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0738 - mae: 0.1637 - val_loss: 0.0757 - val_mae: 0.1656 - lr: 9.0000e-04\n",
      "Epoch 9/50\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0723 - mae: 0.1611 - val_loss: 0.0741 - val_mae: 0.1650 - lr: 9.0000e-04\n",
      "Epoch 10/50\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0709 - mae: 0.1589 - val_loss: 0.0708 - val_mae: 0.1541 - lr: 9.0000e-04\n",
      "Learning rate update: 0.0008100000384729356\n",
      "Epoch 11/50\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0680 - mae: 0.1542 - val_loss: 0.0756 - val_mae: 0.1634 - lr: 8.1000e-04\n",
      "Epoch 12/50\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0677 - mae: 0.1542 - val_loss: 0.0662 - val_mae: 0.1461 - lr: 8.1000e-04\n",
      "Epoch 13/50\n",
      "1480/1480 [==============================] - 123s 83ms/step - loss: 0.0664 - mae: 0.1524 - val_loss: 0.0680 - val_mae: 0.1486 - lr: 8.1000e-04\n",
      "Epoch 14/50\n",
      "1480/1480 [==============================] - 123s 83ms/step - loss: 0.0657 - mae: 0.1510 - val_loss: 0.0677 - val_mae: 0.1508 - lr: 8.1000e-04\n",
      "Epoch 15/50\n",
      "1480/1480 [==============================] - 123s 83ms/step - loss: 0.0646 - mae: 0.1494 - val_loss: 0.0665 - val_mae: 0.1490 - lr: 8.1000e-04\n",
      "Learning rate update: 0.0007290000503417104\n",
      "Epoch 16/50\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0629 - mae: 0.1465 - val_loss: 0.0670 - val_mae: 0.1502 - lr: 7.2900e-04\n",
      "\n",
      "--- Phase 2: Fine-tuning ---\n",
      "Epoch 1/10\n",
      "1480/1480 [==============================] - 139s 86ms/step - loss: 0.0590 - mae: 0.1352 - val_loss: 0.0639 - val_mae: 0.1393 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0578 - mae: 0.1336 - val_loss: 0.0637 - val_mae: 0.1401 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0572 - mae: 0.1332 - val_loss: 0.0634 - val_mae: 0.1381 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0565 - mae: 0.1324 - val_loss: 0.0636 - val_mae: 0.1392 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0559 - mae: 0.1318 - val_loss: 0.0633 - val_mae: 0.1381 - lr: 1.0000e-04\n",
      "Learning rate update: 8.999999772640876e-05\n",
      "Epoch 6/10\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0552 - mae: 0.1308 - val_loss: 0.0631 - val_mae: 0.1356 - lr: 9.0000e-05\n",
      "Epoch 7/10\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0546 - mae: 0.1302 - val_loss: 0.0637 - val_mae: 0.1389 - lr: 9.0000e-05\n",
      "Epoch 8/10\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0540 - mae: 0.1296 - val_loss: 0.0640 - val_mae: 0.1378 - lr: 9.0000e-05\n",
      "Epoch 9/10\n",
      "1480/1480 [==============================] - 124s 84ms/step - loss: 0.0534 - mae: 0.1288 - val_loss: 0.0642 - val_mae: 0.1378 - lr: 9.0000e-05\n",
      "Model saved to lstm_1.pkl\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model, X_mean, X_std, y_mean, y_std = train_model(standardized_train_data)\n",
    "\n",
    "# Save the model \n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6054870a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T01:01:38.098690Z",
     "start_time": "2025-05-03T01:01:38.097196Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def evaluate_mse(train_data, model, Tobs=50, Tpred=60):\n",
    "    \"\"\"\n",
    "    Computes LSTM prediction for ego agent and evaluates MSE with progress reporting.\n",
    "    \"\"\"\n",
    "    N = train_data.shape[0]\n",
    "    mse_list = []\n",
    "    valid_scenarios = 0\n",
    "    \n",
    "    print(f\"Evaluating {N} scenarios...\")\n",
    "    \n",
    "    # Progress reporting variables\n",
    "    report_interval = max(1, N // 10)  # Report at 10% intervals\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Progress reporting\n",
    "        if i % report_interval == 0 or i == N-1:\n",
    "            print(f\"Processing scenario {i+1}/{N} ({(i+1)/N*100:.1f}%)\")\n",
    "        \n",
    "        scenario_data = train_data[i]\n",
    "        ego_agent_data = scenario_data[0]\n",
    "        ground_truth = ego_agent_data[Tobs:Tobs+Tpred, :2]\n",
    "        \n",
    "        # Skip if ground truth contains all zeros (padded)\n",
    "        if np.all(ground_truth == 0):\n",
    "            continue\n",
    "            \n",
    "        valid_scenarios += 1\n",
    "        \n",
    "        # Forecast future positions\n",
    "        predicted_positions = forecast_positions(\n",
    "            ego_agent_data[np.newaxis, :, :],\n",
    "            Tobs, Tpred, model, X_mean, X_std, y_mean, y_std\n",
    "        )\n",
    "        \n",
    "        # Compute MSE\n",
    "        mse = mean_squared_error(ground_truth, predicted_positions[0])\n",
    "        mse_list.append(mse)\n",
    "        \n",
    "        # Occasional MSE reporting\n",
    "        if i % report_interval == 0:\n",
    "            print(f\"  Current scenario MSE: {mse:.4f}\")\n",
    "    \n",
    "    # Final results\n",
    "    if mse_list:\n",
    "        overall_mse = np.mean(mse_list)\n",
    "        print(f\"Evaluation complete: {valid_scenarios} valid scenarios\")\n",
    "        print(f\"Mean Squared Error (MSE): {overall_mse:.4f}\")\n",
    "        print(f\"Min MSE: {np.min(mse_list):.4f}, Max MSE: {np.max(mse_list):.4f}\")\n",
    "        return overall_mse\n",
    "    else:\n",
    "        print(\"No valid scenarios for evaluation.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c394951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T01:12:28.986816Z",
     "start_time": "2025-05-03T01:04:00.357291Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 2066 scenarios...\n",
      "Processing scenario 1/2066 (0.0%)\n",
      "  Current scenario MSE: 4.6116\n",
      "Processing scenario 207/2066 (10.0%)\n",
      "  Current scenario MSE: 0.4051\n",
      "Processing scenario 413/2066 (20.0%)\n",
      "  Current scenario MSE: 9.9705\n",
      "Processing scenario 619/2066 (30.0%)\n",
      "  Current scenario MSE: 2.7963\n",
      "Processing scenario 825/2066 (39.9%)\n",
      "  Current scenario MSE: 0.1236\n",
      "Processing scenario 1031/2066 (49.9%)\n",
      "  Current scenario MSE: 0.3290\n",
      "Processing scenario 1237/2066 (59.9%)\n",
      "  Current scenario MSE: 26.2397\n",
      "Processing scenario 1443/2066 (69.8%)\n",
      "  Current scenario MSE: 4.0677\n",
      "Processing scenario 1649/2066 (79.8%)\n",
      "  Current scenario MSE: 9.9667\n",
      "Processing scenario 1855/2066 (89.8%)\n",
      "  Current scenario MSE: 1.8468\n",
      "Processing scenario 2061/2066 (99.8%)\n",
      "  Current scenario MSE: 2.7505\n",
      "Processing scenario 2066/2066 (100.0%)\n",
      "Evaluation complete: 2066 valid scenarios\n",
      "Mean Squared Error (MSE): 6.5405\n",
      "Min MSE: 0.0002, Max MSE: 132.5785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.5404825890229645"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on training data\n",
    "evaluate_mse(standardized_train_data[3234:5300], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c67b4ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T06:16:59.708670Z",
     "start_time": "2025-05-03T06:15:13.300547Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'lstm_submission.csv' saved with shape (126000, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_submission(data, output_csv, Tobs=50, Tpred=60):\n",
    "    \"\"\"\n",
    "    Applies forecasting and generates a submission CSV with format:\n",
    "    index,x,y where index is auto-generated and matches submission key.\n",
    "    \n",
    "    Args:\n",
    "        data (np.ndarray): Test data of shape (num_scenarios, 50, 50, 6).\n",
    "        output_csv (str): Output CSV file path.\n",
    "        Tobs (int): Observed time steps (default 50).\n",
    "        Tpred (int): Prediction time steps (default 60).\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        scenario_data = data[i]            # Shape: (50, 50, 6)\n",
    "        \n",
    "        # Step 1: Standardize the scene data\n",
    "        standardized_scenario, min_values = standardize_data_dimensions(scenario_data)\n",
    "        \n",
    "        # Extract ego agent data from standardized scenario\n",
    "        ego_agent_data = standardized_scenario[0]  # Shape: (50, 6)\n",
    "\n",
    "        # Step 2: Predict future positions for the ego agent using standardized data\n",
    "        predicted_positions = forecast_positions(\n",
    "            ego_agent_data[np.newaxis, :, :], Tobs, Tpred, model, X_mean, X_std, y_mean, y_std\n",
    "        )  # Shape: (1, 60, 2)\n",
    "\n",
    "        # Step 3: Denormalize the predictions to restore original coordinate system\n",
    "        # Create a dummy array with the same structure as the standardized data for denormalization\n",
    "        # We only need to denormalize the x,y positions (first 2 columns)\n",
    "        dummy_predictions = np.zeros((1, Tpred, 6))  # Shape: (1, 60, 6)\n",
    "        dummy_predictions[0, :, :2] = predicted_positions[0]  # Insert predicted x,y positions\n",
    "        \n",
    "        # Denormalize the predictions\n",
    "        denormalized_predictions = denormalize_predictions(dummy_predictions, min_values)\n",
    "        \n",
    "        # Extract only the x,y positions from denormalized predictions\n",
    "        final_positions = denormalized_predictions[0, :, :2]  # Shape: (60, 2)\n",
    "\n",
    "        # Append 60 predictions (x, y) for this scenario\n",
    "        predictions.extend(final_positions)  # Shape: (60, 2)\n",
    "\n",
    "    # Create DataFrame without explicit ID\n",
    "    submission_df = pd.DataFrame(predictions, columns=[\"x\", \"y\"])\n",
    "    submission_df.index.name = 'index'  # Match Kaggle format\n",
    "\n",
    "    # Save CSV with index\n",
    "    submission_df.to_csv(output_csv)\n",
    "    print(f\"Submission file '{output_csv}' saved with shape {submission_df.shape}\")\n",
    "\n",
    "# Generate submission with standardization\n",
    "generate_submission(test_data, 'lstm_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb89c0f4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
