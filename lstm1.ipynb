{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-25T08:55:30.166101Z",
     "start_time": "2025-05-25T08:55:28.321662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape (10000, 50, 110, 6)\n",
      "test_data's shape (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import numpy as np\n",
    "train_file = np.load('data/train.npz')\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape\", train_data.shape)\n",
    "test_file = np.load('data/test_input.npz')\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# some kind of missing trajectory handling? "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T08:55:30.178356Z",
     "start_time": "2025-05-25T08:55:30.169452Z"
    }
   },
   "id": "c5df04a84c63e60f",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehul/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, RepeatVector, TimeDistributed, Dropout"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T08:55:35.052478Z",
     "start_time": "2025-05-25T08:55:30.177389Z"
    }
   },
   "id": "db97d754762b390b",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_lstm_encoder_decoder(input_dim, output_dim, timesteps_in, timesteps_out,\n",
    "                                lstm_units=512, num_layers=3, loss_fn='mse', lr=0.001):\n",
    "    inputs = Input(shape=(timesteps_in, input_dim))\n",
    "\n",
    "    # Encoder\n",
    "    x = inputs\n",
    "    for _ in range(num_layers):\n",
    "        x = LSTM(lstm_units, return_sequences=True)(x)\n",
    "        # x = Dropout(0.2)(x)\n",
    "    encoded = LSTM(lstm_units)(x)  # Final encoder output\n",
    "\n",
    "    # Decoder\n",
    "    x = RepeatVector(timesteps_out)(encoded)\n",
    "    for _ in range(num_layers):\n",
    "        x = LSTM(lstm_units, return_sequences=True)(x)\n",
    "        # x = Dropout(0.2)(x)\n",
    "    \n",
    "    \n",
    "    x = TimeDistributed(Dense(128, activation='relu'))(x)\n",
    "    x = TimeDistributed(Dense(64, activation='relu'))(x)\n",
    "    outputs = TimeDistributed(Dense(output_dim))(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr, clipnorm=0.5), loss='mse', metrics=['mae']) \n",
    "\n",
    "    # model.compile(optimizer=Adam(learning_rate=1e-5), loss=combined_loss) #switch loss back to 'mse' for older solution \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T08:55:35.058089Z",
     "start_time": "2025-05-25T08:55:35.055792Z"
    }
   },
   "id": "d7f20fc814e583a3",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.src.callbacks import LearningRateScheduler, EarlyStopping, Callback\n",
    "from keras.src.optimizers import Adam\n",
    "from keras import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def exponential_decay_schedule(epoch, lr):\n",
    "    decay_rate = 0.9\n",
    "    decay_steps = 5\n",
    "    if epoch % decay_steps == 0 and epoch:\n",
    "        print('Learning rate update:', lr * decay_rate)\n",
    "        return lr * decay_rate\n",
    "    return lr\n",
    "\n",
    "\n",
    "# Custom callback to monitor LR and stop training\n",
    "class LRThresholdCallback(Callback):\n",
    "    def __init__(self, threshold=9e-5):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "        self.should_stop = False\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = float(self.model.optimizer.learning_rate.numpy())\n",
    "        if lr < self.threshold:\n",
    "            print(f\"\\nLearning rate {lr:.6f} < threshold {self.threshold}, moving to next phase.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "def train_model(train_data, batch_size=32, validation_split=0.2, Tobs=50, Tpred=60):\n",
    "    n_scenarios = train_data.shape[0]\n",
    "    X_train_raw = []\n",
    "    y_train_deltas = []\n",
    "\n",
    "    for i in range(n_scenarios):\n",
    "        ego_data = train_data[i, 0, :, :]\n",
    "        if np.all(ego_data == 0):\n",
    "            continue\n",
    "\n",
    "        observed = ego_data[:Tobs]            # shape (50, 6)\n",
    "        future = ego_data[Tobs:Tobs+Tpred, :2]\n",
    "        last_obs_pos = observed[-1, :2]\n",
    "\n",
    "        if np.any(np.all(observed == 0, axis=1)) or np.any(np.all(future == 0, axis=1)):\n",
    "            continue\n",
    "\n",
    "        # Compute deltas w.r.t. previous future timestep\n",
    "        delta = np.diff(np.vstack([last_obs_pos, future]), axis=0)  # (60, 2)\n",
    "\n",
    "        X_train_raw.append(observed)\n",
    "        y_train_deltas.append(delta)\n",
    "    \n",
    "\n",
    "    X_train = np.array(X_train_raw)\n",
    "    y_train = np.array(y_train_deltas)\n",
    "\n",
    "    print(f\"Training on {X_train.shape[0]} valid sequences.\")\n",
    "    print(f\"Input shape: {X_train.shape}, Delta Output shape: {y_train.shape}\")\n",
    "    \n",
    "    # --- Normalize Input and Output ---\n",
    "    X_mean = X_train.mean(axis=(0, 1), keepdims=True)  # shape: (1, 1, 6)\n",
    "    X_std = X_train.std(axis=(0, 1), keepdims=True) + 1e-8\n",
    "\n",
    "    y_mean = y_train.mean(axis=(0, 1), keepdims=True)  # shape: (1, 1, 2)\n",
    "    y_std = y_train.std(axis=(0, 1), keepdims=True) + 1e-8\n",
    "\n",
    "    X_train = (X_train - X_mean) / X_std\n",
    "    y_train = (y_train - y_mean) / y_std\n",
    "    \n",
    "    print(X_train[:2])\n",
    "    print(y_train[:2])\n",
    "\n",
    "    model = create_lstm_encoder_decoder(\n",
    "        input_dim=X_train.shape[-1],\n",
    "        output_dim=2,\n",
    "        timesteps_in=Tobs,\n",
    "        timesteps_out=Tpred,\n",
    "        loss_fn='mse',\n",
    "        lr=0.001\n",
    "    )\n",
    "\n",
    "    phase1_callbacks = [\n",
    "        LearningRateScheduler(exponential_decay_schedule),\n",
    "        EarlyStopping(patience=4, restore_best_weights=True, monitor='val_loss'),\n",
    "        LRThresholdCallback(threshold=9e-5)\n",
    "    ]\n",
    "\n",
    "    print(\"\\n--- Phase 1: Training ---\")\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=phase1_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Phase 2: Fine-tuning ---\")\n",
    "    model.compile(optimizer=Adam(1e-4, clipnorm=0.5), loss='mse', metrics=['mae'])\n",
    "    phase2_callbacks = [\n",
    "        LearningRateScheduler(exponential_decay_schedule),\n",
    "        EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss')\n",
    "    ]\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=10,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=phase2_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"X_mean:{X_mean}, X_std:{X_std}, y_mean:{y_mean}, y_std:{y_std}\")\n",
    "\n",
    "    # Return model and normalization parameters\n",
    "    return model, X_mean, X_std, y_mean, y_std\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T08:55:35.067197Z",
     "start_time": "2025-05-25T08:55:35.061794Z"
    }
   },
   "id": "4d68034c165292c5",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(model, filepath='lstm_1.pkl'):\n",
    "    \"\"\"Save model and scaler together in a pickle file\"\"\"\n",
    "    model_json = model.to_json()\n",
    "    model_weights = model.get_weights()\n",
    "    data = {\n",
    "        'model_json': model_json,\n",
    "        'model_weights': model_weights,\n",
    "    }\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Model saved to {filepath}\")\n",
    "\n",
    "def load_model(filepath='lstm_1.pkl'):\n",
    "    \"\"\"Load model and scaler from pickle file\"\"\"\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    # Reconstruct model\n",
    "    model = tf.keras.models.model_from_json(data['model_json'])\n",
    "    model.set_weights(data['model_weights'])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T01:14:03.127113Z",
     "start_time": "2025-05-25T01:14:02.709536Z"
    }
   },
   "id": "e3d667b335d4a0a",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 20 valid sequences.\n",
      "Input shape: (20, 50, 6), Delta Output shape: (20, 60, 2)\n",
      "[[[-0.93319447 -1.58222329 -1.15350628  0.31547822  2.00816888\n",
      "    0.        ]\n",
      "  [-0.93342124 -1.58211054 -1.15350628  0.31547822  2.00806527\n",
      "    0.        ]\n",
      "  [-0.93370104 -1.58197133 -2.07190382  0.82509541  2.007935\n",
      "    0.        ]\n",
      "  [-0.93403198 -1.58180654 -2.06133597  0.82481471  2.00778369\n",
      "    0.        ]\n",
      "  [-0.93441037 -1.58161792 -2.05927348  0.82742101  2.00762435\n",
      "    0.        ]\n",
      "  [-0.93483003 -1.58140851 -2.06776803  0.83031786  2.00746266\n",
      "    0.        ]\n",
      "  [-0.93528299 -1.5811823  -2.04863616  0.81970779  2.00729382\n",
      "    0.        ]\n",
      "  [-0.93575921 -1.58094427 -2.0496384   0.82040755  2.00712379\n",
      "    0.        ]\n",
      "  [-0.93624661 -1.58070047 -2.06963483  0.83164106  2.00695107\n",
      "    0.        ]\n",
      "  [-0.93673114 -1.58045793 -2.05848802  0.8292349   2.00677872\n",
      "    0.        ]\n",
      "  [-0.93719679 -1.58022457 -2.04745784  0.82685391  2.00663008\n",
      "    0.        ]\n",
      "  [-0.9376487  -1.57999785 -2.0695664   0.83912091  2.00651523\n",
      "    0.        ]\n",
      "  [-0.93810093 -1.5797709  -2.06904376  0.83849318  2.00642171\n",
      "    0.        ]\n",
      "  [-0.93855331 -1.57954376 -2.05383807  0.82775284  2.0063493\n",
      "    0.        ]\n",
      "  [-0.93900575 -1.57931645 -2.05910428  0.82966029  2.00629632\n",
      "    0.        ]\n",
      "  [-0.93945867 -1.57908885 -2.05717038  0.82953407  2.00624796\n",
      "    0.        ]\n",
      "  [-0.93991146 -1.57886132 -2.05657393  0.82889071  2.00620057\n",
      "    0.        ]\n",
      "  [-0.94036391 -1.57863404 -2.05845615  0.83256883  2.00615682\n",
      "    0.        ]\n",
      "  [-0.94081639 -1.57840689 -2.06092637  0.83687917  2.00610845\n",
      "    0.        ]\n",
      "  [-0.9412685  -1.57818002 -2.06176689  0.83478787  2.00605557\n",
      "    0.        ]\n",
      "  [-0.94171947 -1.57795375 -2.06350585  0.83344807  2.00600407\n",
      "    0.        ]\n",
      "  [-0.94216991 -1.57772768 -2.05444705  0.82819867  2.00595214\n",
      "    0.        ]\n",
      "  [-0.94261985 -1.57750179 -2.05322794  0.82648016  2.00589699\n",
      "    0.        ]\n",
      "  [-0.94306858 -1.57727649 -2.05238667  0.82542204  2.00583121\n",
      "    0.        ]\n",
      "  [-0.94351647 -1.57705164 -2.03555095  0.81616585  2.00574269\n",
      "    0.        ]\n",
      "  [-0.94396363 -1.57682721 -2.03607802  0.81758533  2.0056263\n",
      "    0.        ]\n",
      "  [-0.94441021 -1.5766031  -2.03380074  0.81756179  2.00548973\n",
      "    0.        ]\n",
      "  [-0.94485635 -1.57637915 -2.02319322  0.81286043  2.00535066\n",
      "    0.        ]\n",
      "  [-0.94530201 -1.57615537 -2.02276774  0.81361434  2.0052271\n",
      "    0.        ]\n",
      "  [-0.94574719 -1.5759318  -2.03952592  0.82324005  2.00511703\n",
      "    0.        ]\n",
      "  [-0.94619228 -1.57570821 -2.02773014  0.8134885   2.00501724\n",
      "    0.        ]\n",
      "  [-0.94663715 -1.57548468 -2.02456296  0.81124359  2.00491468\n",
      "    0.        ]\n",
      "  [-0.94708207 -1.57526121 -2.0470563   0.82418081  2.0048097\n",
      "    0.        ]\n",
      "  [-0.94752725 -1.57503759 -2.03902888  0.81992325  2.00472969\n",
      "    0.        ]\n",
      "  [-0.94797242 -1.5748139  -2.03356565  0.8195942   2.00468469\n",
      "    0.        ]\n",
      "  [-0.9484175  -1.5745904  -2.02586533  0.81271039  2.00466144\n",
      "    0.        ]\n",
      "  [-0.94886225 -1.5743673  -2.01831386  0.80595964  2.00464024\n",
      "    0.        ]\n",
      "  [-0.94930651 -1.57414462 -2.02481386  0.81177275  2.00461973\n",
      "    0.        ]\n",
      "  [-0.94975025 -1.5739223  -2.03128584  0.8175608   2.00460409\n",
      "    0.        ]\n",
      "  [-0.95019402 -1.57370002 -2.02464376  0.80969637  2.00459311\n",
      "    0.        ]\n",
      "  [-0.95063758 -1.57347794 -2.03059225  0.81211197  2.004586\n",
      "    0.        ]\n",
      "  [-0.95108084 -1.5732561  -2.0248696   0.81489753  2.00458605\n",
      "    0.        ]\n",
      "  [-0.95152454 -1.57303408 -2.01924285  0.80340601  2.00459034\n",
      "    0.        ]\n",
      "  [-0.95196878 -1.57281183 -2.01886035  0.79511542  2.00459785\n",
      "    0.        ]\n",
      "  [-0.95241355 -1.57258927 -2.02090466  0.80450867  2.00460914\n",
      "    0.        ]\n",
      "  [-0.9528588  -1.57236651 -2.03545102  0.81800859  2.00461089\n",
      "    0.        ]\n",
      "  [-0.95330441 -1.57214366 -2.0374878   0.81856586  2.00459828\n",
      "    0.        ]\n",
      "  [-0.95375045 -1.5719206  -2.03949682  0.81911554  2.00457371\n",
      "    0.        ]\n",
      "  [-0.95419703 -1.57169717 -2.0346258   0.81559268  2.00452984\n",
      "    0.        ]\n",
      "  [-0.95464403 -1.57147345 -2.04064665  0.81958954  2.00445272\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.26103253  0.07754491  0.20264296 -1.06942696 -0.76041742\n",
      "    0.        ]\n",
      "  [ 0.26114684  0.07734321  0.20264296 -1.06942696 -0.76012699\n",
      "    0.        ]\n",
      "  [ 0.26128939  0.07709169  0.65504137 -1.96393638 -0.759783\n",
      "    0.        ]\n",
      "  [ 0.26145947  0.07679161  0.67955898 -2.00961273 -0.75938822\n",
      "    0.        ]\n",
      "  [ 0.26165538  0.07644601  0.69878924 -2.04577425 -0.75894408\n",
      "    0.        ]\n",
      "  [ 0.2618745   0.07605951  0.71012898 -2.07110813 -0.75845089\n",
      "    0.        ]\n",
      "  [ 0.26211298  0.0756389   0.72501723 -2.10068098 -0.75792605\n",
      "    0.        ]\n",
      "  [ 0.26236599  0.0751928   0.73662533 -2.1210256  -0.75740063\n",
      "    0.        ]\n",
      "  [ 0.26262776  0.07473151  0.74454802 -2.13679764 -0.7569045\n",
      "    0.        ]\n",
      "  [ 0.26289105  0.07426776  0.75277923 -2.15348977 -0.75645558\n",
      "    0.        ]\n",
      "  [ 0.26314762  0.07381613  0.75820373 -2.16377737 -0.75607289\n",
      "    0.        ]\n",
      "  [ 0.26339938  0.07337315  0.76612475 -2.17705838 -0.75575812\n",
      "    0.        ]\n",
      "  [ 0.26365256  0.07292784  0.77682324 -2.19667136 -0.75549412\n",
      "    0.        ]\n",
      "  [ 0.2639069   0.07248069  0.78477294 -2.21137595 -0.75527444\n",
      "    0.        ]\n",
      "  [ 0.26416191  0.07203247  0.78492195 -2.20983612 -0.7550943\n",
      "    0.        ]\n",
      "  [ 0.26441721  0.07158385  0.79162163 -2.21923258 -0.75495383\n",
      "    0.        ]\n",
      "  [ 0.2646726   0.0711351   0.79224919 -2.22326055 -0.7548674\n",
      "    0.        ]\n",
      "  [ 0.26492793  0.07068641  0.78232369 -2.20728822 -0.75483783\n",
      "    0.        ]\n",
      "  [ 0.265183    0.07023797  0.78529278 -2.21269769 -0.75485938\n",
      "    0.        ]\n",
      "  [ 0.26543762  0.06979006  0.78393601 -2.21185767 -0.75491891\n",
      "    0.        ]\n",
      "  [ 0.2656916   0.06934288  0.78032233 -2.20348662 -0.75499327\n",
      "    0.        ]\n",
      "  [ 0.2659449   0.06889659  0.76938413 -2.18444378 -0.75507202\n",
      "    0.        ]\n",
      "  [ 0.26619751  0.06845118  0.76392724 -2.17727267 -0.75514905\n",
      "    0.        ]\n",
      "  [ 0.26644965  0.06800632  0.77167331 -2.19049209 -0.75521824\n",
      "    0.        ]\n",
      "  [ 0.26670152  0.06756176  0.77457668 -2.19936588 -0.75528682\n",
      "    0.        ]\n",
      "  [ 0.26695315  0.06711754  0.77320896 -2.20240265 -0.75536353\n",
      "    0.        ]\n",
      "  [ 0.26720499  0.06667291  0.77153214 -2.19680386 -0.75543599\n",
      "    0.        ]\n",
      "  [ 0.26745709  0.06622779  0.76974418 -2.19136167 -0.75549398\n",
      "    0.        ]\n",
      "  [ 0.2677094   0.0657823   0.77150537 -2.19335519 -0.75553451\n",
      "    0.        ]\n",
      "  [ 0.26796225  0.06533592  0.77266574 -2.19294243 -0.75556043\n",
      "    0.        ]\n",
      "  [ 0.26821541  0.06488913  0.77369099 -2.19486876 -0.75557508\n",
      "    0.        ]\n",
      "  [ 0.26846869  0.06444233  0.78044269 -2.20821292 -0.75558145\n",
      "    0.        ]\n",
      "  [ 0.26872225  0.0639953   0.78077166 -2.20878731 -0.75558898\n",
      "    0.        ]\n",
      "  [ 0.26897598  0.06354824  0.7757445  -2.1994607  -0.75559149\n",
      "    0.        ]\n",
      "  [ 0.26922995  0.06310098  0.7886414  -2.22390827 -0.75557905\n",
      "    0.        ]\n",
      "  [ 0.26948413  0.0626535   0.77877293 -2.20362125 -0.75556026\n",
      "    0.        ]\n",
      "  [ 0.2697382   0.06220635  0.77114292 -2.18785639 -0.7555483\n",
      "    0.        ]\n",
      "  [ 0.26999193  0.06175996  0.78088439 -2.20470013 -0.75554134\n",
      "    0.        ]\n",
      "  [ 0.27024507  0.06131468  0.76799014 -2.1779732  -0.75553106\n",
      "    0.        ]\n",
      "  [ 0.27049734  0.06087098  0.77850333 -2.19653176 -0.75552371\n",
      "    0.        ]\n",
      "  [ 0.27074838  0.06042951  0.77973851 -2.20036027 -0.7555239\n",
      "    0.        ]\n",
      "  [ 0.27099819  0.05999033  0.75942192 -2.16333944 -0.7555201\n",
      "    0.        ]\n",
      "  [ 0.27124654  0.05955387  0.76159745 -2.1648028  -0.75551457\n",
      "    0.        ]\n",
      "  [ 0.27149303  0.05912079  0.75099811 -2.14276435 -0.75552165\n",
      "    0.        ]\n",
      "  [ 0.27173791  0.05869069  0.73611045 -2.11513195 -0.755549\n",
      "    0.        ]\n",
      "  [ 0.27198064  0.05826449  0.73212091 -2.10764211 -0.7556021\n",
      "    0.        ]\n",
      "  [ 0.27222058  0.0578432   0.72094363 -2.08754427 -0.755663\n",
      "    0.        ]\n",
      "  [ 0.27245771  0.05742682  0.71017464 -2.06359584 -0.75572992\n",
      "    0.        ]\n",
      "  [ 0.27269177  0.05701591  0.70050696 -2.03896698 -0.75582875\n",
      "    0.        ]\n",
      "  [ 0.27292279  0.05661052  0.694221   -2.0252328  -0.75595049\n",
      "    0.        ]]]\n",
      "[[[-2.03044005  1.30579896]\n",
      "  [-2.03390544  1.31002332]\n",
      "  [-2.0356852   1.31251356]\n",
      "  [-2.03637986  1.3132957 ]\n",
      "  [-2.03691773  1.31439204]\n",
      "  [-2.038526    1.31708705]\n",
      "  [-2.0399222   1.31974889]\n",
      "  [-2.04021253  1.32130335]\n",
      "  [-2.03976519  1.32249735]\n",
      "  [-2.0402162   1.32411623]\n",
      "  [-2.04060368  1.32502697]\n",
      "  [-2.04082565  1.32472785]\n",
      "  [-2.04126204  1.32349377]\n",
      "  [-2.04108206  1.32166262]\n",
      "  [-2.04002273  1.31940617]\n",
      "  [-2.03949     1.31736251]\n",
      "  [-2.03966697  1.31555146]\n",
      "  [-2.0404022   1.31438011]\n",
      "  [-2.04104647  1.3133644 ]\n",
      "  [-2.03990586  1.31088549]\n",
      "  [-2.037832    1.30775652]\n",
      "  [-2.03717392  1.3058414 ]\n",
      "  [-2.0373286   1.30507817]\n",
      "  [-2.0375057   1.30518984]\n",
      "  [-2.03613392  1.30452324]\n",
      "  [-2.03368221  1.30351234]\n",
      "  [-2.03291014  1.30424664]\n",
      "  [-2.03234839  1.30470191]\n",
      "  [-2.03105251  1.30412943]\n",
      "  [-2.02881751  1.30267886]\n",
      "  [-2.02608014  1.30106837]\n",
      "  [-2.02285551  1.29975414]\n",
      "  [-2.01907594  1.29789159]\n",
      "  [-2.01539271  1.29555114]\n",
      "  [-2.01081027  1.29233773]\n",
      "  [-2.00468339  1.28796513]\n",
      "  [-1.99829946  1.28273245]\n",
      "  [-1.99213715  1.27781577]\n",
      "  [-1.98544061  1.27334243]\n",
      "  [-1.9793116   1.26939326]\n",
      "  [-1.97309535  1.26574818]\n",
      "  [-1.96692141  1.26178737]\n",
      "  [-1.95938636  1.25684182]\n",
      "  [-1.95115049  1.25229638]\n",
      "  [-1.9442765   1.24840378]\n",
      "  [-1.9361019   1.24284797]\n",
      "  [-1.92573858  1.23597411]\n",
      "  [-1.91515584  1.22848531]\n",
      "  [-1.90523219  1.2211189 ]\n",
      "  [-1.89572604  1.21405411]\n",
      "  [-1.93361538  1.2361232 ]\n",
      "  [-1.98832471  1.26826586]\n",
      "  [-1.98677954  1.26475086]\n",
      "  [-1.93644175  1.23052875]\n",
      "  [-1.8451613   1.17070932]\n",
      "  [-1.71882767  1.08964376]\n",
      "  [-1.56455891  0.99143201]\n",
      "  [-1.39114777  0.88101516]\n",
      "  [-1.20530842  0.76296012]\n",
      "  [-1.01335783  0.64103862]]\n",
      "\n",
      " [[ 0.717397   -1.95070487]\n",
      "  [ 0.70252105 -1.91843214]\n",
      "  [ 0.68807889 -1.88651224]\n",
      "  [ 0.67332976 -1.85307402]\n",
      "  [ 0.65723582 -1.81697465]\n",
      "  [ 0.64055225 -1.78011299]\n",
      "  [ 0.62277041 -1.74104593]\n",
      "  [ 0.60410148 -1.69983889]\n",
      "  [ 0.58500906 -1.65685833]\n",
      "  [ 0.56595819 -1.61353559]\n",
      "  [ 0.54537065 -1.56717919]\n",
      "  [ 0.52416874 -1.51953284]\n",
      "  [ 0.50269644 -1.47155297]\n",
      "  [ 0.48017361 -1.42200147]\n",
      "  [ 0.45761753 -1.3726105 ]\n",
      "  [ 0.43582566 -1.32469052]\n",
      "  [ 0.41454191 -1.27757069]\n",
      "  [ 0.39209134 -1.22832743]\n",
      "  [ 0.36976119 -1.18007158]\n",
      "  [ 0.34833401 -1.1334387 ]\n",
      "  [ 0.32760065 -1.08730137]\n",
      "  [ 0.30732798 -1.04148617]\n",
      "  [ 0.28678918 -0.99537575]\n",
      "  [ 0.26610901 -0.949132  ]\n",
      "  [ 0.24534302 -0.90244901]\n",
      "  [ 0.22498674 -0.85604026]\n",
      "  [ 0.20531033 -0.81036479]\n",
      "  [ 0.18473961 -0.76285343]\n",
      "  [ 0.16377556 -0.71474032]\n",
      "  [ 0.14377766 -0.66910931]\n",
      "  [ 0.12445429 -0.62539462]\n",
      "  [ 0.10581843 -0.58289321]\n",
      "  [ 0.08773165 -0.5412579 ]\n",
      "  [ 0.07036393 -0.50143584]\n",
      "  [ 0.0532188  -0.46221013]\n",
      "  [ 0.03659866 -0.42423049]\n",
      "  [ 0.02086028 -0.38850544]\n",
      "  [ 0.00570318 -0.35409606]\n",
      "  [-0.00871497 -0.32109891]\n",
      "  [-0.02240858 -0.28963473]\n",
      "  [-0.03525862 -0.26049224]\n",
      "  [-0.04742244 -0.23332268]\n",
      "  [-0.05874004 -0.20782962]\n",
      "  [-0.06924187 -0.18337403]\n",
      "  [-0.07944543 -0.15948668]\n",
      "  [-0.08958418 -0.13619535]\n",
      "  [-0.09837592 -0.115991  ]\n",
      "  [-0.1064072  -0.09751546]\n",
      "  [-0.11413852 -0.0795063 ]\n",
      "  [-0.12160499 -0.06172719]\n",
      "  [-0.1275607  -0.04764678]\n",
      "  [-0.13292585 -0.0353161 ]\n",
      "  [-0.13946861 -0.0203665 ]\n",
      "  [-0.14638189 -0.00482533]\n",
      "  [-0.15398819  0.01219054]\n",
      "  [-0.16160653  0.02932812]\n",
      "  [-0.16915433  0.04618768]\n",
      "  [-0.17641017  0.0622083 ]\n",
      "  [-0.18305054  0.07682586]\n",
      "  [-0.18937576  0.09078608]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 01:55:47.109105: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2025-05-25 01:55:47.109192: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-05-25 01:55:47.109242: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-05-25 01:55:47.109309: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-25 01:55:47.109331: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 1: Training ---\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 01:55:49.696398: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 9s/step - loss: 1.0000 - mae: 0.6578 - learning_rate: 0.0010\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehul/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,learning_rate\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 678ms/step - loss: 0.7533 - mae: 0.5748 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 434ms/step - loss: 13.0180 - mae: 3.0718 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 428ms/step - loss: 2.1036 - mae: 1.1626 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 467ms/step - loss: 1.5254 - mae: 0.8527 - learning_rate: 0.0010\n",
      "Learning rate update: 0.0009000000427477062\n",
      "Epoch 6/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 419ms/step - loss: 1.0376 - mae: 0.7983 - learning_rate: 9.0000e-04\n",
      "Epoch 7/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 475ms/step - loss: 0.7796 - mae: 0.6735 - learning_rate: 9.0000e-04\n",
      "Epoch 8/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 473ms/step - loss: 0.7343 - mae: 0.6298 - learning_rate: 9.0000e-04\n",
      "Epoch 9/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 580ms/step - loss: 0.7316 - mae: 0.6232 - learning_rate: 9.0000e-04\n",
      "Epoch 10/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 426ms/step - loss: 1.3386 - mae: 0.8597 - learning_rate: 9.0000e-04\n",
      "Learning rate update: 0.0008100000384729356\n",
      "Epoch 11/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 408ms/step - loss: 0.9711 - mae: 0.8631 - learning_rate: 8.1000e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 419ms/step - loss: 2.0307 - mae: 1.1650 - learning_rate: 8.1000e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 398ms/step - loss: 2.6282 - mae: 1.3352 - learning_rate: 8.1000e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 388ms/step - loss: 2.2250 - mae: 1.2076 - learning_rate: 8.1000e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 394ms/step - loss: 1.6231 - mae: 1.0281 - learning_rate: 8.1000e-04\n",
      "Learning rate update: 0.0007290000503417104\n",
      "Epoch 16/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 410ms/step - loss: 1.3716 - mae: 0.9321 - learning_rate: 7.2900e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 389ms/step - loss: 1.4183 - mae: 0.9096 - learning_rate: 7.2900e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 378ms/step - loss: 1.3206 - mae: 0.8234 - learning_rate: 7.2900e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 384ms/step - loss: 1.1244 - mae: 0.7714 - learning_rate: 7.2900e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 368ms/step - loss: 0.9602 - mae: 0.7436 - learning_rate: 7.2900e-04\n",
      "Learning rate update: 0.0006561000715009868\n",
      "Epoch 21/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 374ms/step - loss: 0.9988 - mae: 0.7406 - learning_rate: 6.5610e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 363ms/step - loss: 0.8603 - mae: 0.6702 - learning_rate: 6.5610e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 384ms/step - loss: 0.7338 - mae: 0.6172 - learning_rate: 6.5610e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 390ms/step - loss: 0.8517 - mae: 0.6915 - learning_rate: 6.5610e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 390ms/step - loss: 1.0160 - mae: 0.7951 - learning_rate: 6.5610e-04\n",
      "Learning rate update: 0.0005904900433961303\n",
      "Epoch 26/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 380ms/step - loss: 0.9312 - mae: 0.7564 - learning_rate: 5.9049e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 369ms/step - loss: 0.8617 - mae: 0.6955 - learning_rate: 5.9049e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 385ms/step - loss: 0.8377 - mae: 0.6621 - learning_rate: 5.9049e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 377ms/step - loss: 0.8240 - mae: 0.7019 - learning_rate: 5.9049e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 374ms/step - loss: 0.8097 - mae: 0.7060 - learning_rate: 5.9049e-04\n",
      "Learning rate update: 0.0005314410547725857\n",
      "Epoch 31/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 387ms/step - loss: 0.8413 - mae: 0.7160 - learning_rate: 5.3144e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 511ms/step - loss: 0.8521 - mae: 0.7184 - learning_rate: 5.3144e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 447ms/step - loss: 0.8534 - mae: 0.7059 - learning_rate: 5.3144e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 445ms/step - loss: 0.8328 - mae: 0.7034 - learning_rate: 5.3144e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 434ms/step - loss: 0.8302 - mae: 0.7220 - learning_rate: 5.3144e-04\n",
      "Learning rate update: 0.00047829695977270604\n",
      "Epoch 36/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 404ms/step - loss: 0.7378 - mae: 0.6577 - learning_rate: 4.7830e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 395ms/step - loss: 0.7445 - mae: 0.6472 - learning_rate: 4.7830e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 391ms/step - loss: 0.7030 - mae: 0.6409 - learning_rate: 4.7830e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 414ms/step - loss: 0.7397 - mae: 0.6809 - learning_rate: 4.7830e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 390ms/step - loss: 0.6850 - mae: 0.6051 - learning_rate: 4.7830e-04\n",
      "Learning rate update: 0.0004304672533180565\n",
      "Epoch 41/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 419ms/step - loss: 0.7014 - mae: 0.5812 - learning_rate: 4.3047e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 442ms/step - loss: 0.6812 - mae: 0.5859 - learning_rate: 4.3047e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 434ms/step - loss: 0.6983 - mae: 0.6102 - learning_rate: 4.3047e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 535ms/step - loss: 0.6612 - mae: 0.5652 - learning_rate: 4.3047e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 752ms/step - loss: 0.7019 - mae: 0.5952 - learning_rate: 4.3047e-04\n",
      "Learning rate update: 0.00038742052274756136\n",
      "Epoch 46/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 608ms/step - loss: 0.6953 - mae: 0.6219 - learning_rate: 3.8742e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 507ms/step - loss: 0.6633 - mae: 0.6278 - learning_rate: 3.8742e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1s/step - loss: 0.7193 - mae: 0.6793 - learning_rate: 3.8742e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 971ms/step - loss: 0.6848 - mae: 0.6490 - learning_rate: 3.8742e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 604ms/step - loss: 0.6403 - mae: 0.5710 - learning_rate: 3.8742e-04\n",
      "\n",
      "--- Phase 2: Fine-tuning ---\n",
      "Epoch 1/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 7s/step - loss: 0.6714 - mae: 0.5648 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 559ms/step - loss: 0.6567 - mae: 0.6262 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 407ms/step - loss: 0.5958 - mae: 0.6189 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 422ms/step - loss: 0.5396 - mae: 0.5675 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 441ms/step - loss: 0.5080 - mae: 0.5428 - learning_rate: 1.0000e-04\n",
      "Learning rate update: 8.999999772640876e-05\n",
      "Epoch 6/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 430ms/step - loss: 0.5261 - mae: 0.5684 - learning_rate: 9.0000e-05\n",
      "Epoch 7/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 407ms/step - loss: 0.5198 - mae: 0.5689 - learning_rate: 9.0000e-05\n",
      "Epoch 8/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 391ms/step - loss: 0.4917 - mae: 0.5511 - learning_rate: 9.0000e-05\n",
      "Epoch 9/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 391ms/step - loss: 0.4819 - mae: 0.5519 - learning_rate: 9.0000e-05\n",
      "Epoch 10/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 404ms/step - loss: 0.4893 - mae: 0.5710 - learning_rate: 9.0000e-05\n",
      "X_mean:[[[2.52857957e+03 1.60114665e+03 1.40866666e+00 6.08522079e-01\n",
      "   1.80982428e-01 0.00000000e+00]]], X_std:[[[2.34676309e+03 1.43681516e+03 5.83789383e+00 3.19090653e+00\n",
      "   1.32740173e+00 1.00000000e-08]]], y_mean:[[[ 0.12058788 -0.03723199]]], y_std:[[[0.57707299 0.27537905]]]\n"
     ]
    }
   ],
   "source": [
    "# first check that the model can overfit on small data\n",
    "model, X_mean, X_std, y_mean, y_std  = train_model(train_data[:20], batch_size=20, validation_split=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T08:56:32.208884Z",
     "start_time": "2025-05-25T08:55:47.084565Z"
    }
   },
   "id": "deeaeac04573c115",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_mae_by_timestep(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Visualize MAE across timesteps in the prediction horizon.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): shape (N, Tpred, 2)\n",
    "        y_pred (np.ndarray): shape (N, Tpred, 2)\n",
    "    \"\"\"\n",
    "    mae_per_timestep = np.mean(np.abs(y_true - y_pred), axis=(0, 2))  # shape (Tpred,)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(mae_per_timestep, label='MAE per Timestep')\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.ylabel('MAE (meters)')\n",
    "    plt.title('Mean Absolute Error Over Prediction Horizon')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T00:43:54.091154Z",
     "start_time": "2025-05-25T00:43:54.069141Z"
    }
   },
   "id": "8ce3811f963721e2",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def reconstruct_absolute_positions(pred_deltas, last_observed_positions):\n",
    "    \"\"\"\n",
    "    Reconstruct absolute predicted positions by adding deltas to the last observed position.\n",
    "\n",
    "    Args:\n",
    "        pred_deltas: np.ndarray of shape (N, Tpred, 2)\n",
    "        last_observed_positions: np.ndarray of shape (N, 2)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray of shape (N, Tpred, 2)\n",
    "    \"\"\"\n",
    "    return last_observed_positions[:, None, :] + np.cumsum(pred_deltas, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def forecast_positions(scenario_data, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std):\n",
    "    \"\"\"\n",
    "    Use normalized LSTM model to forecast future deltas and reconstruct absolute positions.\n",
    "\n",
    "    Args:\n",
    "        scenario_data (numpy.ndarray): Shape (agents, time_steps, dimensions)\n",
    "        Tobs (int): Number of observed time steps\n",
    "        Tpred (int): Number of future time steps to predict\n",
    "        model (Model): Trained LSTM model that predicts normalized deltas\n",
    "        X_mean, X_std: Normalization stats for input\n",
    "        y_mean, y_std: Normalization stats for output\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Predicted absolute positions of shape (agents, Tpred, 2)\n",
    "    \"\"\"\n",
    "    agents, _, _ = scenario_data.shape\n",
    "    predicted_positions = np.zeros((agents, Tpred, 2))\n",
    "    pred_deltas_all = []\n",
    "\n",
    "    for agent_idx in range(agents):\n",
    "        agent_data = scenario_data[agent_idx, :Tobs, :]  # shape (Tobs, 6)\n",
    "\n",
    "        # Skip if fully padded\n",
    "        if np.all(agent_data == 0):\n",
    "            continue\n",
    "\n",
    "        # Normalize input\n",
    "        X_pred = np.expand_dims(agent_data, axis=0)  # shape (1, Tobs, 6)\n",
    "        X_pred_norm = (X_pred - X_mean) / X_std\n",
    "\n",
    "        # Predict normalized deltas\n",
    "        pred_deltas_norm = model.predict(X_pred_norm, verbose=0)  # shape (1, Tpred, 2)\n",
    "\n",
    "        # Denormalize deltas\n",
    "        pred_deltas = pred_deltas_norm * y_std + y_mean\n",
    "        pred_deltas_all.append(pred_deltas[0])\n",
    "\n",
    "        # Reconstruct absolute positions\n",
    "        last_pos = agent_data[Tobs - 1, :2]  # shape (2,)\n",
    "        abs_positions = reconstruct_absolute_positions(\n",
    "            pred_deltas=pred_deltas,\n",
    "            last_observed_positions=np.expand_dims(last_pos, axis=0)\n",
    "        )[0]\n",
    "\n",
    "        predicted_positions[agent_idx] = abs_positions\n",
    "\n",
    "    return predicted_positions\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T00:43:54.092151Z",
     "start_time": "2025-05-25T00:43:54.074249Z"
    }
   },
   "id": "49143614a59770d",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def make_gif(data_matrix1, data_matrix2, name='comparison'):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.animation as animation\n",
    "\n",
    "    cmap1 = plt.cm.get_cmap('viridis', 50)\n",
    "    cmap2 = plt.cm.get_cmap('plasma', 50)\n",
    "\n",
    "    assert data_matrix1.shape[1] == data_matrix2.shape[1], \"Both matrices must have same number of timesteps\"\n",
    "    timesteps = data_matrix1.shape[1]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "    ax1, ax2 = axes\n",
    "\n",
    "    def update(frame):\n",
    "        for ax in axes:\n",
    "            ax.clear()\n",
    "\n",
    "        for i in range(data_matrix1.shape[0]):\n",
    "            for (data_matrix, ax, cmap) in [(data_matrix1, ax1, cmap1), (data_matrix2, ax2, cmap2)]:\n",
    "                x = data_matrix[i, frame, 0]\n",
    "                y = data_matrix[i, frame, 1]\n",
    "                if x != 0 and y != 0:\n",
    "                    xs = data_matrix[i, :frame+1, 0]\n",
    "                    ys = data_matrix[i, :frame+1, 1]\n",
    "                    mask = (xs != 0) & (ys != 0)\n",
    "                    xs = xs[mask]\n",
    "                    ys = ys[mask]\n",
    "                    if len(xs) > 0 and len(ys) > 0:\n",
    "                        color = cmap(i)\n",
    "                        ax.plot(xs, ys, alpha=0.9, color=color)\n",
    "                        ax.scatter(x, y, s=80, color=color)\n",
    "\n",
    "        # Plot ego vehicle (index 0) on both\n",
    "        ax1.plot(data_matrix1[0, :frame, 0], data_matrix1[0, :frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "        ax1.scatter(data_matrix1[0, frame, 0], data_matrix1[0, frame, 1], s=80, color='tab:orange')\n",
    "        ax1.set_title('Prediction')\n",
    "\n",
    "        ax2.plot(data_matrix2[0, :frame, 0], data_matrix2[0, :frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "        ax2.scatter(data_matrix2[0, frame, 0], data_matrix2[0, frame, 1], s=80, color='tab:orange')\n",
    "        ax2.set_title('Actual')\n",
    "\n",
    "        for ax, data_matrix in zip(axes, [data_matrix1, data_matrix2]):\n",
    "            ax.set_xlim(data_matrix[:, :, 0][data_matrix[:, :, 0] != 0].min() - 10,\n",
    "                        data_matrix[:, :, 0][data_matrix[:, :, 0] != 0].max() + 10)\n",
    "            ax.set_ylim(data_matrix[:, :, 1][data_matrix[:, :, 1] != 0].min() - 10,\n",
    "                        data_matrix[:, :, 1][data_matrix[:, :, 1] != 0].max() + 10)\n",
    "            ax.legend()\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "\n",
    "        # Compute MSE over non-zero entries up to current frame\n",
    "        mask = (data_matrix2[:, :frame+1, :] != 0) & (data_matrix1[:, :frame+1, :] != 0)\n",
    "        mse = np.mean((data_matrix1[:, :frame+1, :][mask] - data_matrix2[:, :frame+1, :][mask]) ** 2)\n",
    "\n",
    "        fig.suptitle(f\"Timestep {frame} - MSE: {mse:.4f}\", fontsize=16)\n",
    "        return ax1.collections + ax1.lines + ax2.collections + ax2.lines\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, update, frames=list(range(0, timesteps, 3)), interval=100, blit=True)\n",
    "    anim.save(f'trajectory_visualization_{name}.gif', writer='pillow')\n",
    "    plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T00:43:54.113163Z",
     "start_time": "2025-05-25T00:43:54.084177Z"
    }
   },
   "id": "658c258cac06616e",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wv/j6ybhf8906j4bmnp171wtn680000gn/T/ipykernel_12440/3735350324.py:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap1 = plt.cm.get_cmap('viridis', 50)\n",
      "/var/folders/wv/j6ybhf8906j4bmnp171wtn680000gn/T/ipykernel_12440/3735350324.py:10: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap2 = plt.cm.get_cmap('plasma', 50)\n"
     ]
    }
   ],
   "source": [
    "# visualize prediction\n",
    "\n",
    "# model = load_model()\n",
    "\n",
    "# Parameters\n",
    "Tobs = 50\n",
    "Tpred = 60\n",
    "\n",
    "data = train_data[5000]\n",
    "\n",
    "# Select a test scenario (can use any valid index)\n",
    "test_scenario = data.copy()  # shape (agents, time_steps, features)\n",
    "\n",
    "# Forecast future positions\n",
    "predicted_positions = forecast_positions(test_scenario, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std)\n",
    "\n",
    "# Create combined matrix of past observed + predicted for ego agent (agent 0)\n",
    "ego_past = test_scenario[0, :Tobs, :2]               # shape (Tobs, 2)\n",
    "ego_future = predicted_positions[0]                  # shape (Tpred, 2)\n",
    "ego_full = np.concatenate([ego_past, ego_future], axis=0)  # shape (Tobs + Tpred, 2)\n",
    "\n",
    "# Create updated scenario with predicted ego and original others\n",
    "updated_scenario = test_scenario.copy()\n",
    "updated_scenario[0, :Tobs+Tpred, :2] = ego_full  # Replace ego trajectory\n",
    "\n",
    "# Visualize\n",
    "make_gif(updated_scenario, data, name='lstm1')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T00:44:04.932891Z",
     "start_time": "2025-05-25T00:43:54.096790Z"
    }
   },
   "id": "5a5f4cc76c3c72d3",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 10000 valid sequences.\n",
      "Input shape: (10000, 50, 6), Delta Output shape: (10000, 60, 2)\n",
      "[[[-0.70963494 -0.99812224 -0.9788003   0.3573056   1.55063073\n",
      "    0.        ]\n",
      "  [-0.70979287 -0.99802844 -0.9788003   0.3573056   1.55055584\n",
      "    0.        ]\n",
      "  [-0.70998773 -0.99791262 -1.98200353  0.70357905  1.55046169\n",
      "    0.        ]\n",
      "  [-0.71021821 -0.99777552 -1.97045983  0.70338832  1.55035232\n",
      "    0.        ]\n",
      "  [-0.71048173 -0.9976186  -1.9682069   0.70515924  1.55023716\n",
      "    0.        ]\n",
      "  [-0.710774   -0.99744439 -1.97748584  0.70712759  1.55012029\n",
      "    0.        ]\n",
      "  [-0.71108946 -0.99725619 -1.95658731  0.69991828  1.54999826\n",
      "    0.        ]\n",
      "  [-0.71142111 -0.99705816 -1.9576821   0.70039375  1.54987536\n",
      "    0.        ]\n",
      "  [-0.71176055 -0.99685533 -1.97952503  0.70802667  1.54975052\n",
      "    0.        ]\n",
      "  [-0.71209799 -0.99665355 -1.9673489   0.70639174  1.54962596\n",
      "    0.        ]\n",
      "  [-0.71242228 -0.99645941 -1.95530018  0.70477391  1.54951852\n",
      "    0.        ]\n",
      "  [-0.71273701 -0.99627079 -1.97945028  0.71310906  1.54943551\n",
      "    0.        ]\n",
      "  [-0.71305196 -0.99608197 -1.97887937  0.71268253  1.54936792\n",
      "    0.        ]\n",
      "  [-0.71336701 -0.99589301 -1.96226957  0.70538471  1.54931559\n",
      "    0.        ]\n",
      "  [-0.7136821  -0.9957039  -1.96802207  0.70668078  1.54927729\n",
      "    0.        ]\n",
      "  [-0.71399753 -0.99551454 -1.96590959  0.70659502  1.54924234\n",
      "    0.        ]\n",
      "  [-0.71431287 -0.99532525 -1.96525807  0.70615787  1.54920809\n",
      "    0.        ]\n",
      "  [-0.71462797 -0.99513617 -1.96731409  0.70865707  1.54917646\n",
      "    0.        ]\n",
      "  [-0.7149431  -0.99494718 -1.97001241  0.71158585  1.5491415\n",
      "    0.        ]\n",
      "  [-0.71525795 -0.99475845 -1.97093055  0.71016485  1.54910328\n",
      "    0.        ]\n",
      "  [-0.71557203 -0.9945702  -1.97283009  0.70925449  1.54906606\n",
      "    0.        ]\n",
      "  [-0.71588573 -0.99438212 -1.96293478  0.70568764  1.54902853\n",
      "    0.        ]\n",
      "  [-0.71619908 -0.99419419 -1.9616031   0.70451995  1.54898866\n",
      "    0.        ]\n",
      "  [-0.71651159 -0.99400676 -1.96068415  0.70380098  1.54894112\n",
      "    0.        ]\n",
      "  [-0.71682352 -0.99381969 -1.9422938   0.69751161  1.54887714\n",
      "    0.        ]\n",
      "  [-0.71713493 -0.99363298 -1.94286955  0.69847612  1.54879302\n",
      "    0.        ]\n",
      "  [-0.71744595 -0.99344652 -1.94038197  0.69846012  1.54869431\n",
      "    0.        ]\n",
      "  [-0.71775666 -0.99326021 -1.92879495  0.69526565  1.54859379\n",
      "    0.        ]\n",
      "  [-0.71806702 -0.99307404 -1.92833018  0.69577792  1.54850448\n",
      "    0.        ]\n",
      "  [-0.71837706 -0.99288804 -1.94663582  0.70231837  1.54842493\n",
      "    0.        ]\n",
      "  [-0.71868704 -0.99270202 -1.93375081  0.69569241  1.5483528\n",
      "    0.        ]\n",
      "  [-0.71899686 -0.99251606 -1.93029117  0.69416705  1.54827868\n",
      "    0.        ]\n",
      "  [-0.71930672 -0.99233014 -1.95486156  0.7029576   1.5482028\n",
      "    0.        ]\n",
      "  [-0.71961676 -0.9921441  -1.94609289  0.70006468  1.54814497\n",
      "    0.        ]\n",
      "  [-0.71992678 -0.991958   -1.94012518  0.6998411   1.54811244\n",
      "    0.        ]\n",
      "  [-0.72023676 -0.99177206 -1.9317138   0.6951637   1.54809564\n",
      "    0.        ]\n",
      "  [-0.72054649 -0.99158645 -1.92346503  0.69057672  1.54808032\n",
      "    0.        ]\n",
      "  [-0.72085589 -0.99140119 -1.93056523  0.6945266   1.54806549\n",
      "    0.        ]\n",
      "  [-0.72116492 -0.99121623 -1.93763484  0.69845945  1.54805419\n",
      "    0.        ]\n",
      "  [-0.72147398 -0.99103131 -1.93037943  0.69311575  1.54804625\n",
      "    0.        ]\n",
      "  [-0.72178289 -0.99084655 -1.93687721  0.69475709  1.54804111\n",
      "    0.        ]\n",
      "  [-0.72209159 -0.99066199 -1.93062612  0.69664982  1.54804115\n",
      "    0.        ]\n",
      "  [-0.7224006  -0.99047728 -1.9244798   0.68884159  1.54804425\n",
      "    0.        ]\n",
      "  [-0.72270998 -0.99029238 -1.92406198  0.68320832  1.54804967\n",
      "    0.        ]\n",
      "  [-0.72301973 -0.99010722 -1.92629506  0.68959082  1.54805784\n",
      "    0.        ]\n",
      "  [-0.72332982 -0.98992189 -1.94218465  0.69876371  1.5480591\n",
      "    0.        ]\n",
      "  [-0.72364015 -0.98973649 -1.9444095   0.69914236  1.54804999\n",
      "    0.        ]\n",
      "  [-0.72395079 -0.98955092 -1.94660404  0.69951586  1.54803223\n",
      "    0.        ]\n",
      "  [-0.7242618  -0.98936504 -1.94128322  0.69712216  1.54800052\n",
      "    0.        ]\n",
      "  [-0.72457311 -0.98917892 -1.94786005  0.69983793  1.54794478\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.1220636   0.38272125  0.50257703 -0.5837064  -0.45043471\n",
      "    0.        ]\n",
      "  [ 0.1221432   0.38255344  0.50257703 -0.5837064  -0.4502248\n",
      "    0.        ]\n",
      "  [ 0.12224249  0.38234419  0.99675034 -1.19150547 -0.44997618\n",
      "    0.        ]\n",
      "  [ 0.12236093  0.38209454  1.02353193 -1.22254153 -0.44969083\n",
      "    0.        ]\n",
      "  [ 0.12249737  0.38180702  1.04453793 -1.24711247 -0.44936983\n",
      "    0.        ]\n",
      "  [ 0.12264997  0.38148547  1.05692479 -1.26432628 -0.44901336\n",
      "    0.        ]\n",
      "  [ 0.12281606  0.38113554  1.07318783 -1.28442036 -0.44863401\n",
      "    0.        ]\n",
      "  [ 0.12299227  0.38076441  1.08586784 -1.29824407 -0.44825426\n",
      "    0.        ]\n",
      "  [ 0.12317457  0.38038064  1.09452212 -1.30896082 -0.44789567\n",
      "    0.        ]\n",
      "  [ 0.12335793  0.37999483  1.1035134  -1.32030275 -0.4475712\n",
      "    0.        ]\n",
      "  [ 0.12353661  0.37961909  1.10943881 -1.32729294 -0.4472946\n",
      "    0.        ]\n",
      "  [ 0.12371195  0.37925055  1.11809127 -1.33631709 -0.44706709\n",
      "    0.        ]\n",
      "  [ 0.12388827  0.37888008  1.12977766 -1.34964367 -0.44687628\n",
      "    0.        ]\n",
      "  [ 0.1240654   0.37850807  1.13846145 -1.35963511 -0.4467175\n",
      "    0.        ]\n",
      "  [ 0.124243    0.37813518  1.13862421 -1.35858883 -0.4465873\n",
      "    0.        ]\n",
      "  [ 0.1244208   0.37776195  1.14594255 -1.36497352 -0.44648577\n",
      "    0.        ]\n",
      "  [ 0.12459866  0.37738861  1.14662806 -1.36771043 -0.4464233\n",
      "    0.        ]\n",
      "  [ 0.12477648  0.37701532  1.13578603 -1.35685759 -0.44640193\n",
      "    0.        ]\n",
      "  [ 0.12495412  0.37664224  1.13902929 -1.36053321 -0.4464175\n",
      "    0.        ]\n",
      "  [ 0.12513144  0.3762696   1.13754724 -1.35996243 -0.44646053\n",
      "    0.        ]\n",
      "  [ 0.12530833  0.37589757  1.13359987 -1.35427449 -0.44651428\n",
      "    0.        ]\n",
      "  [ 0.12548473  0.37552628  1.12165162 -1.34133531 -0.4465712\n",
      "    0.        ]\n",
      "  [ 0.12566066  0.37515572  1.11569083 -1.3364627  -0.44662687\n",
      "    0.        ]\n",
      "  [ 0.12583626  0.37478562  1.12415219 -1.345445   -0.44667688\n",
      "    0.        ]\n",
      "  [ 0.12601167  0.37441577  1.12732365 -1.35147454 -0.44672644\n",
      "    0.        ]\n",
      "  [ 0.12618691  0.3740462   1.12582964 -1.35353796 -0.44678189\n",
      "    0.        ]\n",
      "  [ 0.1263623   0.37367629  1.12399797 -1.3497337  -0.44683426\n",
      "    0.        ]\n",
      "  [ 0.12653787  0.37330598  1.12204492 -1.34603586 -0.44687618\n",
      "    0.        ]\n",
      "  [ 0.12671359  0.37293535  1.12396874 -1.34739041 -0.44690547\n",
      "    0.        ]\n",
      "  [ 0.12688968  0.37256398  1.12523626 -1.34710995 -0.44692421\n",
      "    0.        ]\n",
      "  [ 0.12706599  0.37219227  1.12635618 -1.34841885 -0.44693479\n",
      "    0.        ]\n",
      "  [ 0.12724238  0.37182056  1.13373134 -1.35748591 -0.4469394\n",
      "    0.        ]\n",
      "  [ 0.12741897  0.37144865  1.13409068 -1.35787619 -0.44694484\n",
      "    0.        ]\n",
      "  [ 0.12759567  0.37107672  1.12859931 -1.35153897 -0.44694666\n",
      "    0.        ]\n",
      "  [ 0.12777254  0.37070463  1.14268712 -1.36815054 -0.44693766\n",
      "    0.        ]\n",
      "  [ 0.12794957  0.37033234  1.1319074  -1.35436597 -0.44692409\n",
      "    0.        ]\n",
      "  [ 0.12812651  0.36996033  1.12357282 -1.3436541  -0.44691544\n",
      "    0.        ]\n",
      "  [ 0.12830321  0.36958896  1.13421382 -1.35509904 -0.44691041\n",
      "    0.        ]\n",
      "  [ 0.12847951  0.36921851  1.1201289  -1.33693869 -0.44690298\n",
      "    0.        ]\n",
      "  [ 0.1286552   0.36884938  1.13161289 -1.34954882 -0.44689766\n",
      "    0.        ]\n",
      "  [ 0.12883004  0.36848209  1.13296214 -1.3521502  -0.4468978\n",
      "    0.        ]\n",
      "  [ 0.12900401  0.36811672  1.11076948 -1.32699538 -0.44689506\n",
      "    0.        ]\n",
      "  [ 0.12917697  0.36775361  1.11314591 -1.3279897  -0.44689106\n",
      "    0.        ]\n",
      "  [ 0.12934863  0.36739331  1.10156781 -1.31301507 -0.44689618\n",
      "    0.        ]\n",
      "  [ 0.12951917  0.36703549  1.08530542 -1.29423948 -0.44691594\n",
      "    0.        ]\n",
      "  [ 0.12968822  0.36668091  1.08094747 -1.2891503  -0.44695433\n",
      "    0.        ]\n",
      "  [ 0.12985532  0.36633042  1.06873808 -1.27549427 -0.44699834\n",
      "    0.        ]\n",
      "  [ 0.13002047  0.36598401  1.05697467 -1.25922184 -0.44704671\n",
      "    0.        ]\n",
      "  [ 0.13018347  0.36564216  1.04641427 -1.24248708 -0.44711814\n",
      "    0.        ]\n",
      "  [ 0.13034436  0.36530489  1.03954786 -1.23315502 -0.44720613\n",
      "    0.        ]]]\n",
      "[[[-1.96812164  0.71590395]\n",
      "  [-1.97190249  0.71840515]\n",
      "  [-1.97384426  0.7198796 ]\n",
      "  [-1.97460216  0.7203427 ]\n",
      "  [-1.97518899  0.72099183]\n",
      "  [-1.97694366  0.72258751]\n",
      "  [-1.97846696  0.72416356]\n",
      "  [-1.97878372  0.72508395]\n",
      "  [-1.97829565  0.7257909 ]\n",
      "  [-1.97878772  0.72674942]\n",
      "  [-1.97921048  0.72728866]\n",
      "  [-1.97945265  0.72711156]\n",
      "  [-1.97992876  0.72638087]\n",
      "  [-1.9797324   0.72529666]\n",
      "  [-1.97857664  0.72396064]\n",
      "  [-1.97799542  0.72275061]\n",
      "  [-1.9781885   0.72167831]\n",
      "  [-1.97899065  0.72098477]\n",
      "  [-1.97969358  0.72038337]\n",
      "  [-1.97844913  0.71891564]\n",
      "  [-1.97618648  0.717063  ]\n",
      "  [-1.97546851  0.71592908]\n",
      "  [-1.97563726  0.71547718]\n",
      "  [-1.97583048  0.7155433 ]\n",
      "  [-1.97433383  0.71514861]\n",
      "  [-1.97165894  0.71455007]\n",
      "  [-1.97081659  0.71498484]\n",
      "  [-1.9702037   0.7152544 ]\n",
      "  [-1.96878986  0.71491544]\n",
      "  [-1.9663514   0.71405657]\n",
      "  [-1.96336485  0.71310302]\n",
      "  [-1.95984669  0.71232488]\n",
      "  [-1.95572305  0.71122208]\n",
      "  [-1.95170454  0.70983633]\n",
      "  [-1.94670496  0.7079337 ]\n",
      "  [-1.94002034  0.70534472]\n",
      "  [-1.93305529  0.70224651]\n",
      "  [-1.92633201  0.69933539]\n",
      "  [-1.91902589  0.69668677]\n",
      "  [-1.91233894  0.69434851]\n",
      "  [-1.90555683  0.69219029]\n",
      "  [-1.89882087  0.68984514]\n",
      "  [-1.89059991  0.68691693]\n",
      "  [-1.88161432  0.68422562]\n",
      "  [-1.87411459  0.68192085]\n",
      "  [-1.86519585  0.67863131]\n",
      "  [-1.85388915  0.67456137]\n",
      "  [-1.84234306  0.67012733]\n",
      "  [-1.83151606  0.66576576]\n",
      "  [-1.82114456  0.66158277]\n",
      "  [-1.86248299  0.67464965]\n",
      "  [-1.92217253  0.69368099]\n",
      "  [-1.9204867   0.69159979]\n",
      "  [-1.86556663  0.67133723]\n",
      "  [-1.76597689  0.63591876]\n",
      "  [-1.62814305  0.58792067]\n",
      "  [-1.45983114  0.52977049]\n",
      "  [-1.27063431  0.4643938 ]\n",
      "  [-1.06787792  0.39449462]\n",
      "  [-0.85845398  0.32230614]]\n",
      "\n",
      " [[ 1.02985222 -1.21223871]\n",
      "  [ 1.0136221  -1.19313035]\n",
      "  [ 0.99786527 -1.17423091]\n",
      "  [ 0.98177352 -1.15443248]\n",
      "  [ 0.96421454 -1.13305841]\n",
      "  [ 0.94601226 -1.111233  ]\n",
      "  [ 0.92661173 -1.08810179]\n",
      "  [ 0.90624336 -1.06370352]\n",
      "  [ 0.88541295 -1.03825517]\n",
      "  [ 0.86462787 -1.01260422]\n",
      "  [ 0.84216623 -0.98515707]\n",
      "  [ 0.8190343  -0.95694615]\n",
      "  [ 0.79560737 -0.92853776]\n",
      "  [ 0.77103428 -0.89919882]\n",
      "  [ 0.74642491 -0.86995493]\n",
      "  [ 0.72264932 -0.841582  ]\n",
      "  [ 0.69942809 -0.81368283]\n",
      "  [ 0.67493384 -0.7845264 ]\n",
      "  [ 0.65057097 -0.75595461]\n",
      "  [ 0.62719326 -0.72834375]\n",
      "  [ 0.60457254 -0.70102631]\n",
      "  [ 0.58245443 -0.6738996 ]\n",
      "  [ 0.56004598 -0.64659809]\n",
      "  [ 0.53748328 -0.61921764]\n",
      "  [ 0.51482695 -0.59157712]\n",
      "  [ 0.49261764 -0.56409897]\n",
      "  [ 0.47115007 -0.53705499]\n",
      "  [ 0.44870679 -0.508924  ]\n",
      "  [ 0.42583438 -0.48043672]\n",
      "  [ 0.40401606 -0.45341906]\n",
      "  [ 0.38293368 -0.42753604]\n",
      "  [ 0.36260138 -0.40237139]\n",
      "  [ 0.34286815 -0.37771955]\n",
      "  [ 0.32391944 -0.35414131]\n",
      "  [ 0.30521358 -0.33091617]\n",
      "  [ 0.2870805  -0.30842882]\n",
      "  [ 0.26990945 -0.28727638]\n",
      "  [ 0.2533726  -0.26690294]\n",
      "  [ 0.23764196 -0.24736566]\n",
      "  [ 0.22270181 -0.22873604]\n",
      "  [ 0.20868203 -0.21148107]\n",
      "  [ 0.19541093 -0.19539425]\n",
      "  [ 0.18306308 -0.18030007]\n",
      "  [ 0.17160527 -0.16582017]\n",
      "  [ 0.16047288 -0.15167671]\n",
      "  [ 0.14941119 -0.13788615]\n",
      "  [ 0.13981914 -0.12592336]\n",
      "  [ 0.13105676 -0.11498419]\n",
      "  [ 0.12262166 -0.10432114]\n",
      "  [ 0.11447551 -0.09379431]\n",
      "  [ 0.10797765 -0.08545745]\n",
      "  [ 0.10212411 -0.07815658]\n",
      "  [ 0.09498576 -0.06930507]\n",
      "  [ 0.08744316 -0.06010331]\n",
      "  [ 0.07914445 -0.05002838]\n",
      "  [ 0.07083261 -0.03988139]\n",
      "  [ 0.06259773 -0.02989902]\n",
      "  [ 0.0546814  -0.02041338]\n",
      "  [ 0.04743654 -0.01175847]\n",
      "  [ 0.04053554 -0.00349276]]]\n",
      "\n",
      "--- Phase 1: Training ---\n",
      "Epoch 1/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m69s\u001B[0m 256ms/step - loss: 0.8942 - mae: 0.6727 - val_loss: 0.9588 - val_mae: 0.7116 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m67s\u001B[0m 264ms/step - loss: 0.9840 - mae: 0.7087 - val_loss: 0.9136 - val_mae: 0.6982 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m59s\u001B[0m 234ms/step - loss: 0.9355 - mae: 0.7129 - val_loss: 0.8946 - val_mae: 0.6697 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m54s\u001B[0m 217ms/step - loss: 0.8972 - mae: 0.7010 - val_loss: 0.8922 - val_mae: 0.6895 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m56s\u001B[0m 225ms/step - loss: 0.9647 - mae: 0.7029 - val_loss: 0.9952 - val_mae: 0.7040 - learning_rate: 0.0010\n",
      "Learning rate update: 0.0009000000427477062\n",
      "Epoch 6/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m50s\u001B[0m 198ms/step - loss: 1.0300 - mae: 0.7078 - val_loss: 0.9694 - val_mae: 0.6492 - learning_rate: 9.0000e-04\n",
      "Epoch 7/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m51s\u001B[0m 204ms/step - loss: 1.0179 - mae: 0.7013 - val_loss: 0.9739 - val_mae: 0.6717 - learning_rate: 9.0000e-04\n",
      "Epoch 8/50\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 262ms/step - loss: 0.9907 - mae: 0.6832 - val_loss: 0.9733 - val_mae: 0.6731 - learning_rate: 9.0000e-04\n",
      "\n",
      "--- Phase 2: Fine-tuning ---\n",
      "Epoch 1/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m81s\u001B[0m 289ms/step - loss: 0.9214 - mae: 0.7006 - val_loss: 0.8520 - val_mae: 0.6802 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m61s\u001B[0m 241ms/step - loss: 0.8948 - mae: 0.6938 - val_loss: 0.8756 - val_mae: 0.6853 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m51s\u001B[0m 202ms/step - loss: 0.8900 - mae: 0.6854 - val_loss: 0.8683 - val_mae: 0.6859 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m58s\u001B[0m 233ms/step - loss: 0.9102 - mae: 0.7080 - val_loss: 0.8372 - val_mae: 0.6606 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 254ms/step - loss: 0.8576 - mae: 0.6873 - val_loss: 0.8348 - val_mae: 0.6666 - learning_rate: 1.0000e-04\n",
      "Learning rate update: 8.999999772640876e-05\n",
      "Epoch 6/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m82s\u001B[0m 321ms/step - loss: 0.8602 - mae: 0.6865 - val_loss: 0.7968 - val_mae: 0.6554 - learning_rate: 9.0000e-05\n",
      "Epoch 7/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m60s\u001B[0m 233ms/step - loss: 0.8381 - mae: 0.6743 - val_loss: 0.8237 - val_mae: 0.6748 - learning_rate: 9.0000e-05\n",
      "Epoch 8/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m59s\u001B[0m 234ms/step - loss: 0.8910 - mae: 0.6997 - val_loss: 0.9772 - val_mae: 0.6457 - learning_rate: 9.0000e-05\n",
      "Epoch 9/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m80s\u001B[0m 318ms/step - loss: 0.9706 - mae: 0.6879 - val_loss: 0.8207 - val_mae: 0.6730 - learning_rate: 9.0000e-05\n",
      "X_mean:[[[ 2.72984436e+03  1.05158719e+03 -9.42919519e-02 -6.27655270e-02\n",
      "   -1.15795715e-03  0.00000000e+00]]], X_std:[[[3.36969193e+03 1.72704592e+03 5.34438802e+00 4.69611759e+00\n",
      "   1.83653476e+00 1.00000000e-08]]], y_mean:[[[-0.010136   -0.01060693]]], y_std:[[[0.52892474 0.46509677]]]\n",
      "Model saved to lstm_1.pkl\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model, X_mean, X_std, y_mean, y_std = train_model(train_data)\n",
    "\n",
    "# Save the model \n",
    "save_model(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T01:01:59.634998Z",
     "start_time": "2025-05-25T00:44:04.932226Z"
    }
   },
   "id": "3338be4ed075b368",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def evaluate_mse(train_data, model, Tobs=50, Tpred=60):\n",
    "    \"\"\"\n",
    "    Computes LSTM prediction for ego agent and evaluates MSE with progress reporting.\n",
    "    \"\"\"\n",
    "    N = train_data.shape[0]\n",
    "    mse_list = []\n",
    "    valid_scenarios = 0\n",
    "    \n",
    "    print(f\"Evaluating {N} scenarios...\")\n",
    "    \n",
    "    # Progress reporting variables\n",
    "    report_interval = max(1, N // 10)  # Report at 10% intervals\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Progress reporting\n",
    "        if i % report_interval == 0 or i == N-1:\n",
    "            print(f\"Processing scenario {i+1}/{N} ({(i+1)/N*100:.1f}%)\")\n",
    "        \n",
    "        scenario_data = train_data[i]\n",
    "        ego_agent_data = scenario_data[0]\n",
    "        ground_truth = ego_agent_data[Tobs:Tobs+Tpred, :2]\n",
    "        \n",
    "        # Skip if ground truth contains all zeros (padded)\n",
    "        if np.all(ground_truth == 0):\n",
    "            continue\n",
    "            \n",
    "        valid_scenarios += 1\n",
    "        \n",
    "        # Forecast future positions\n",
    "        predicted_positions = forecast_positions(\n",
    "            ego_agent_data[np.newaxis, :, :],\n",
    "            Tobs, Tpred, model, X_mean, X_std, y_mean, y_std\n",
    "        )\n",
    "        \n",
    "        # Compute MSE\n",
    "        mse = mean_squared_error(ground_truth, predicted_positions[0])\n",
    "        mse_list.append(mse)\n",
    "        \n",
    "        # Occasional MSE reporting\n",
    "        if i % report_interval == 0:\n",
    "            print(f\"  Current scenario MSE: {mse:.4f}\")\n",
    "    \n",
    "    # Final results\n",
    "    if mse_list:\n",
    "        overall_mse = np.mean(mse_list)\n",
    "        print(f\"Evaluation complete: {valid_scenarios} valid scenarios\")\n",
    "        print(f\"Mean Squared Error (MSE): {overall_mse:.4f}\")\n",
    "        print(f\"Min MSE: {np.min(mse_list):.4f}, Max MSE: {np.max(mse_list):.4f}\")\n",
    "        return overall_mse\n",
    "    else:\n",
    "        print(\"No valid scenarios for evaluation.\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T01:02:00.433495Z",
     "start_time": "2025-05-25T01:01:59.661897Z"
    }
   },
   "id": "e8bf6a02ebcd4b24",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 10000 scenarios...\n",
      "Processing scenario 1/10000 (0.0%)\n",
      "  Current scenario MSE: 794.9454\n",
      "Processing scenario 1001/10000 (10.0%)\n",
      "  Current scenario MSE: 35.9505\n",
      "Processing scenario 2001/10000 (20.0%)\n",
      "  Current scenario MSE: 21.9280\n",
      "Processing scenario 3001/10000 (30.0%)\n",
      "  Current scenario MSE: 191.4277\n",
      "Processing scenario 4001/10000 (40.0%)\n",
      "  Current scenario MSE: 6.9946\n",
      "Processing scenario 5001/10000 (50.0%)\n",
      "  Current scenario MSE: 216.6343\n",
      "Processing scenario 6001/10000 (60.0%)\n",
      "  Current scenario MSE: 259.2617\n",
      "Processing scenario 7001/10000 (70.0%)\n",
      "  Current scenario MSE: 157.7297\n",
      "Processing scenario 8001/10000 (80.0%)\n",
      "  Current scenario MSE: 578.7442\n",
      "Processing scenario 9001/10000 (90.0%)\n",
      "  Current scenario MSE: 21.9427\n",
      "Processing scenario 10000/10000 (100.0%)\n",
      "Evaluation complete: 10000 valid scenarios\n",
      "Mean Squared Error (MSE): 246.7998\n",
      "Min MSE: 0.4408, Max MSE: 1698.7627\n"
     ]
    },
    {
     "data": {
      "text/plain": "246.7998011068636"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on training data\n",
    "evaluate_mse(train_data, model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T01:11:55.098314Z",
     "start_time": "2025-05-25T01:02:00.460191Z"
    }
   },
   "id": "6ae1b88910d7e8bb",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'lstm_submission.csv' saved with shape (126000, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_submission(data, output_csv, Tobs=50, Tpred=60):\n",
    "    \"\"\"\n",
    "    Applies forecasting and generates a submission CSV with format:\n",
    "    index,x,y where index is auto-generated and matches submission key.\n",
    "    \n",
    "    Args:\n",
    "        data (np.ndarray): Test data of shape (num_scenarios, 50, 50, 6).\n",
    "        output_csv (str): Output CSV file path.\n",
    "        Tobs (int): Observed time steps (default 50).\n",
    "        Tpred (int): Prediction time steps (default 60).\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        scenario_data = data[i]            # Shape: (50, 50, 6)\n",
    "        ego_agent_data = scenario_data[0]  # Shape: (50, 6)\n",
    "\n",
    "        # Predict future positions for the ego agent\n",
    "        predicted_positions = forecast_positions(\n",
    "            ego_agent_data[np.newaxis, :, :], Tobs, Tpred, model, X_mean, X_std, y_mean, y_std\n",
    "        )  # Shape: (1, 60, 2)\n",
    "\n",
    "        # Append 60 predictions (x, y) for this scenario\n",
    "        predictions.extend(predicted_positions[0])  # Shape: (60, 2)\n",
    "\n",
    "    # Create DataFrame without explicit ID\n",
    "    submission_df = pd.DataFrame(predictions, columns=[\"x\", \"y\"])\n",
    "    submission_df.index.name = 'index'  # Match Kaggle format\n",
    "\n",
    "    # Save CSV with index\n",
    "    submission_df.to_csv(output_csv)\n",
    "    print(f\"Submission file '{output_csv}' saved with shape {submission_df.shape}\")\n",
    "\n",
    "generate_submission(test_data, 'lstm_submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T01:14:02.645229Z",
     "start_time": "2025-05-25T01:11:55.098314Z"
    }
   },
   "id": "bbc4fc43197afaf",
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
