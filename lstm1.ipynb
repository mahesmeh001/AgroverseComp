{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:59:33.423576Z",
     "start_time": "2025-05-30T19:59:32.069696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape (10000, 50, 110, 6)\n",
      "test_data's shape (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import numpy as np\n",
    "train_file = np.load('data/train.npz')\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape\", train_data.shape)\n",
    "test_file = np.load('data/test_input.npz')\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45afcf8c11c217fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:59:34.294156Z",
     "start_time": "2025-05-30T19:59:34.066491Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Optional\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def rotate_trajectory(trajectory: np.ndarray, angle: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Rotate trajectory by given angle around the origin.\n",
    "    Updates position, velocity, and heading.\n",
    "    \n",
    "    Args:\n",
    "        trajectory: Shape (timesteps, 6) where columns are [pos_x, pos_y, vel_x, vel_y, heading, obj_type]\n",
    "        angle: Rotation angle in radians\n",
    "        \n",
    "    Returns:\n",
    "        Rotated trajectory of same shape\n",
    "    \"\"\"\n",
    "    if trajectory.shape[-1] < 6:\n",
    "        raise ValueError(\"Trajectory must have 6 features\")\n",
    "        \n",
    "    cos_a, sin_a = np.cos(angle), np.sin(angle)\n",
    "    rotation_matrix = np.array([[cos_a, -sin_a],\n",
    "                               [sin_a, cos_a]])\n",
    "    \n",
    "    rotated_trajectory = trajectory.copy()\n",
    "    \n",
    "    # Rotate positions (columns 0, 1)\n",
    "    pos_xy = trajectory[:, :2]  # position_x, position_y\n",
    "    rotated_pos = pos_xy @ rotation_matrix.T\n",
    "    rotated_trajectory[:, :2] = rotated_pos\n",
    "    \n",
    "    # Rotate velocities (columns 2, 3)\n",
    "    vel_xy = trajectory[:, 2:4]  # velocity_x, velocity_y\n",
    "    rotated_vel = vel_xy @ rotation_matrix.T\n",
    "    rotated_trajectory[:, 2:4] = rotated_vel\n",
    "    \n",
    "    # Update heading (column 4)\n",
    "    rotated_trajectory[:, 4] = trajectory[:, 4] + angle\n",
    "    \n",
    "    # Keep object_type unchanged (column 5)\n",
    "    \n",
    "    return rotated_trajectory\n",
    "\n",
    "def translate_trajectory(trajectory: np.ndarray, dx: float, dy: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Translate trajectory by given offsets.\n",
    "    Only affects position coordinates.\n",
    "    \n",
    "    Args:\n",
    "        trajectory: Shape (timesteps, 6)\n",
    "        dx: Translation in x direction\n",
    "        dy: Translation in y direction\n",
    "        \n",
    "    Returns:\n",
    "        Translated trajectory of same shape\n",
    "    \"\"\"\n",
    "    if trajectory.shape[-1] < 6:\n",
    "        raise ValueError(\"Trajectory must have 6 features\")\n",
    "        \n",
    "    translated_trajectory = trajectory.copy()\n",
    "    translated_trajectory[:, 0] += dx  # position_x\n",
    "    translated_trajectory[:, 1] += dy  # position_y\n",
    "    \n",
    "    return translated_trajectory\n",
    "\n",
    "def flip_horizontal(trajectory: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Flip trajectory horizontally (mirror across y-axis).\n",
    "    Updates position, velocity, and heading.\n",
    "    \"\"\"\n",
    "    if trajectory.shape[-1] < 6:\n",
    "        raise ValueError(\"Trajectory must have 6 features\")\n",
    "        \n",
    "    flipped = trajectory.copy()\n",
    "    flipped[:, 0] = -flipped[:, 0]  # Negate position_x\n",
    "    flipped[:, 2] = -flipped[:, 2]  # Negate velocity_x\n",
    "    flipped[:, 4] = np.pi - flipped[:, 4]  # Mirror heading across y-axis\n",
    "    \n",
    "    return flipped\n",
    "\n",
    "def flip_vertical(trajectory: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Flip trajectory vertically (mirror across x-axis).\n",
    "    Updates position, velocity, and heading.\n",
    "    \"\"\"\n",
    "    if trajectory.shape[-1] < 6:\n",
    "        raise ValueError(\"Trajectory must have 6 features\")\n",
    "        \n",
    "    flipped = trajectory.copy()\n",
    "    flipped[:, 1] = -flipped[:, 1]  # Negate position_y\n",
    "    flipped[:, 3] = -flipped[:, 3]  # Negate velocity_y\n",
    "    flipped[:, 4] = -flipped[:, 4]  # Mirror heading across x-axis\n",
    "    \n",
    "    return flipped\n",
    "\n",
    "def augment_single_sample(sample: np.ndarray, \n",
    "                         rotation_range: float = np.pi/4,\n",
    "                         translation_range: float = 5.0,\n",
    "                         flip_prob: float = 0.5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply random augmentations to a single sample.\n",
    "    \n",
    "    Args:\n",
    "        sample: Shape (agents, timesteps, 6) for single scene\n",
    "        rotation_range: Maximum rotation angle in radians\n",
    "        translation_range: Maximum translation distance\n",
    "        flip_prob: Probability of applying flips\n",
    "        \n",
    "    Returns:\n",
    "        Augmented sample of same shape\n",
    "    \"\"\"\n",
    "    if len(sample.shape) != 3 or sample.shape[2] != 6:\n",
    "        raise ValueError(f\"Expected shape (agents, timesteps, 6), got {sample.shape}\")\n",
    "    \n",
    "    augmented = sample.copy()\n",
    "    \n",
    "    # Random rotation, translation parameters (same for all agents in scene)\n",
    "    angle = np.random.uniform(-rotation_range, rotation_range)\n",
    "    dx = np.random.uniform(-translation_range, translation_range)\n",
    "    dy = np.random.uniform(-translation_range, translation_range)\n",
    "    \n",
    "    # Random flip decisions (same for all agents in scene)\n",
    "    do_horizontal_flip = np.random.random() < flip_prob\n",
    "    do_vertical_flip = np.random.random() < flip_prob\n",
    "    \n",
    "    for agent_idx in range(sample.shape[0]):\n",
    "        trajectory = sample[agent_idx, :, :]  # Shape (timesteps, 6)\n",
    "        \n",
    "        # Skip if trajectory is all zeros (padding/inactive agent)\n",
    "        if np.all(trajectory[:, :2] == 0):  # Check if positions are all zero\n",
    "            continue\n",
    "            \n",
    "        # Apply transformations\n",
    "        trajectory = rotate_trajectory(trajectory, angle)\n",
    "        trajectory = translate_trajectory(trajectory, dx, dy)\n",
    "        \n",
    "        if do_horizontal_flip:\n",
    "            trajectory = flip_horizontal(trajectory)\n",
    "        \n",
    "        if do_vertical_flip:\n",
    "            trajectory = flip_vertical(trajectory)\n",
    "            \n",
    "        augmented[agent_idx, :, :] = trajectory\n",
    "    \n",
    "    return augmented\n",
    "\n",
    "def augment_batch_worker(batch_data: np.ndarray,\n",
    "                        rotation_range: float,\n",
    "                        translation_range: float,\n",
    "                        flip_prob: float) -> np.ndarray:\n",
    "    \"\"\"Process a batch of samples for parallel augmentation.\"\"\"\n",
    "    return np.array([augment_single_sample(sample,\n",
    "                                          rotation_range,\n",
    "                                          translation_range,\n",
    "                                          flip_prob)\n",
    "                     for sample in batch_data])\n",
    "\n",
    "def augment_dataset(data: np.ndarray, \n",
    "                   num_augmentations: int = 5,\n",
    "                   rotation_range: float = np.pi/4,\n",
    "                   translation_range: float = 5.0,\n",
    "                   flip_prob: float = 0.5,\n",
    "                   return_original: bool = True,\n",
    "                   n_jobs: Optional[int] = None,\n",
    "                   batch_size: Optional[int] = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Augment entire dataset.\n",
    "    \n",
    "    Args:\n",
    "        data: Shape (scenes, agents, timesteps, 6) dataset\n",
    "        num_augmentations: Number of augmented versions per sample\n",
    "        rotation_range: Maximum rotation angle in radians\n",
    "        translation_range: Maximum translation distance\n",
    "        flip_prob: Probability of applying flips\n",
    "        return_original: Whether to include original data in output\n",
    "        n_jobs: Number of parallel jobs\n",
    "        batch_size: Size of batches for parallel processing\n",
    "        \n",
    "    Returns:\n",
    "        Augmented dataset with shape (scenes*(1+num_augmentations), agents, timesteps, 6)\n",
    "    \"\"\"\n",
    "    if len(data.shape) != 4 or data.shape[3] != 6:\n",
    "        raise ValueError(f\"Expected shape (scenes, agents, timesteps, 6), got {data.shape}\")\n",
    "    \n",
    "    original_size = data.shape[0]\n",
    "    augmented_samples = []\n",
    "    \n",
    "    if return_original:\n",
    "        augmented_samples.append(data)\n",
    "\n",
    "    if n_jobs is None:\n",
    "        n_jobs = min(os.cpu_count(), 8)\n",
    "    elif n_jobs == -1:\n",
    "        n_jobs = os.cpu_count()\n",
    "\n",
    "    if batch_size is None:\n",
    "        batch_size = max(1, original_size // n_jobs)\n",
    "\n",
    "    print(f\"Using {n_jobs} jobs with batch size {batch_size}\")\n",
    "    \n",
    "    for aug_idx in tqdm(range(num_augmentations), desc=\"Augmentations\"):\n",
    "        batches = [data[i:i + batch_size] for i in range(0, original_size, batch_size)]\n",
    "\n",
    "        augmented_batches = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(augment_batch_worker)(\n",
    "                batch,\n",
    "                rotation_range,\n",
    "                translation_range,\n",
    "                flip_prob\n",
    "            ) for batch in tqdm(batches, desc=f\"Processing aug {aug_idx + 1}\", leave=False)\n",
    "        )\n",
    "\n",
    "        augmented_batch = np.concatenate(augmented_batches, axis=0)\n",
    "        augmented_samples.append(augmented_batch)\n",
    "\n",
    "    return np.concatenate(augmented_samples, axis=0)\n",
    "\n",
    "def visualize_augmentations(original_sample: np.ndarray, \n",
    "                           num_examples: int = 4,\n",
    "                           agent_idx: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    Visualize original and augmented trajectories for comparison.\n",
    "    \n",
    "    Args:\n",
    "        original_sample: Single sample of shape (agents, timesteps, 6)\n",
    "        num_examples: Number of augmented examples to show\n",
    "        agent_idx: Which agent's trajectory to visualize\n",
    "    \"\"\"\n",
    "    if len(original_sample.shape) != 3 or original_sample.shape[2] != 6:\n",
    "        raise ValueError(f\"Expected shape (agents, timesteps, 6), got {original_sample.shape}\")\n",
    "    \n",
    "    if agent_idx >= original_sample.shape[0]:\n",
    "        raise ValueError(f\"agent_idx {agent_idx} >= number of agents {original_sample.shape[0]}\")\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_examples + 1, figsize=(15, 3))\n",
    "    \n",
    "    # Extract original trajectory (position_x, position_y)\n",
    "    orig_traj = original_sample[agent_idx, :, :2]  # Shape (timesteps, 2)\n",
    "    \n",
    "    # Plot original\n",
    "    axes[0].plot(orig_traj[:, 0], orig_traj[:, 1], 'b-o', markersize=3)\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].grid(True)\n",
    "    axes[0].axis('equal')\n",
    "    \n",
    "    # Plot augmented versions\n",
    "    for i in range(num_examples):\n",
    "        aug_sample = augment_single_sample(original_sample)\n",
    "        aug_traj = aug_sample[agent_idx, :, :2]  # Shape (timesteps, 2)\n",
    "        \n",
    "        axes[i + 1].plot(aug_traj[:, 0], aug_traj[:, 1], 'r-o', markersize=3)\n",
    "        axes[i + 1].set_title(f'Augmented {i + 1}')\n",
    "        axes[i + 1].grid(True)\n",
    "        axes[i + 1].axis('equal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c54ccb3c-a6eb-4e11-9aa0-dce275879ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_augmentations(train_data[0], agent_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebc13946088b8bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:59:34.405790Z",
     "start_time": "2025-05-30T19:59:34.403969Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def standardize_data_dimensions(scenario_data):\n",
    "    \"\"\"\n",
    "    Standardize position data by centering a single scenario at the origin.\n",
    "    \n",
    "    :param scenario_data: numpy array of shape (50, 110, 6)\n",
    "                         where dimensions are [position_x, position_y, velocity_x, velocity_y, heading, object_type]\n",
    "    :returns: tuple of (standardized_data, min_values)\n",
    "             - standardized_data: same shape as input with centered positions\n",
    "             - min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    \"\"\"\n",
    "    # Copy the data to avoid modifying the original\n",
    "    standardized_data = scenario_data.copy()\n",
    "    \n",
    "    # Extract position data (first 2 dimensions)\n",
    "    positions = scenario_data[:, :, :2]  # Shape: (50, 110, 2)\n",
    "    \n",
    "    # Create mask for non-zero positions (to ignore padding)\n",
    "    # We consider a position valid if it's not (0,0) or if the object_type is not 0\n",
    "    object_types = scenario_data[:, :, 5]  # Shape: (50, 110)\n",
    "    valid_mask = (positions[:, :, 0] != 0) | (positions[:, :, 1] != 0) | (object_types != 0)\n",
    "    \n",
    "    # Find min values across all valid positions in this scenario\n",
    "    if np.any(valid_mask):\n",
    "        valid_positions = positions[valid_mask]  # Shape: (num_valid_points, 2)\n",
    "        min_x = np.min(valid_positions[:, 0])\n",
    "        min_y = np.min(valid_positions[:, 1])\n",
    "    else:\n",
    "        # If no valid positions found, use 0 as min values\n",
    "        min_x = 0\n",
    "        min_y = 0\n",
    "    \n",
    "    # Store min values\n",
    "    min_values = np.array([min_x, min_y])\n",
    "    \n",
    "    # Standardize positions by subtracting min values\n",
    "    # Only modify non-zero positions to preserve padding\n",
    "    for agent_idx in range(scenario_data.shape[0]):\n",
    "        for time_idx in range(scenario_data.shape[1]):\n",
    "            if valid_mask[agent_idx, time_idx]:\n",
    "                standardized_data[agent_idx, time_idx, 0] -= min_x  # position_x\n",
    "                standardized_data[agent_idx, time_idx, 1] -= min_y  # position_y\n",
    "    \n",
    "    return standardized_data, min_values\n",
    "\n",
    "\n",
    "def denormalize_predictions(predictions, min_values):\n",
    "    \"\"\"\n",
    "    Helper function to add back the min values to predicted positions.\n",
    "    \n",
    "    :param predictions: predicted data with standardized positions, shape (50, 110, 6) or similar\n",
    "    :param min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    :returns: predictions with original coordinate system restored\n",
    "    \"\"\"\n",
    "    denormalized = predictions.copy()\n",
    "    \n",
    "    # Add back the min values to restore original coordinate system\n",
    "    # Assuming predictions have position_x and position_y as first two dimensions\n",
    "    denormalized[:, :, 0] += min_values[0]  # position_x\n",
    "    denormalized[:, :, 1] += min_values[1]  # position_y\n",
    "    \n",
    "    return denormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f224a01-94ff-4c81-8d39-4de095b71aab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:59:34.405790Z",
     "start_time": "2025-05-30T19:59:34.403969Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def standardize_data_dimensions(scenario_data):\n",
    "    \"\"\"\n",
    "    Standardize position data by centering a single scenario at the origin.\n",
    "    \n",
    "    :param scenario_data: numpy array of shape (50, 110, 6)\n",
    "                         where dimensions are [position_x, position_y, velocity_x, velocity_y, heading, object_type]\n",
    "    :returns: tuple of (standardized_data, min_values)\n",
    "             - standardized_data: same shape as input with centered positions\n",
    "             - min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    \"\"\"\n",
    "    # Copy the data to avoid modifying the original\n",
    "    standardized_data = scenario_data.copy()\n",
    "    \n",
    "    # Extract position data (first 2 dimensions)\n",
    "    positions = scenario_data[:, :, :2]  # Shape: (50, 110, 2)\n",
    "    \n",
    "    # Create mask for non-zero positions (to ignore padding)\n",
    "    # We consider a position valid if it's not (0,0) or if the object_type is not 0\n",
    "    object_types = scenario_data[:, :, 5]  # Shape: (50, 110)\n",
    "    valid_mask = (positions[:, :, 0] != 0) | (positions[:, :, 1] != 0) | (object_types != 0)\n",
    "    \n",
    "    # Find min values across all valid positions in this scenario\n",
    "    if np.any(valid_mask):\n",
    "        valid_positions = positions[valid_mask]  # Shape: (num_valid_points, 2)\n",
    "        min_x = np.min(valid_positions[:, 0])\n",
    "        min_y = np.min(valid_positions[:, 1])\n",
    "    else:\n",
    "        # If no valid positions found, use 0 as min values\n",
    "        min_x = 0\n",
    "        min_y = 0\n",
    "    \n",
    "    # Store min values\n",
    "    min_values = np.array([min_x, min_y])\n",
    "    \n",
    "    # Standardize positions by subtracting min values\n",
    "    # Only modify non-zero positions to preserve padding\n",
    "    for agent_idx in range(scenario_data.shape[0]):\n",
    "        for time_idx in range(scenario_data.shape[1]):\n",
    "            if valid_mask[agent_idx, time_idx]:\n",
    "                standardized_data[agent_idx, time_idx, 0] -= min_x  # position_x\n",
    "                standardized_data[agent_idx, time_idx, 1] -= min_y  # position_y\n",
    "    \n",
    "    return standardized_data, min_values\n",
    "\n",
    "\n",
    "def denormalize_predictions(predictions, min_values):\n",
    "    \"\"\"\n",
    "    Helper function to add back the min values to predicted positions.\n",
    "    \n",
    "    :param predictions: predicted data with standardized positions, shape (50, 110, 6) or similar\n",
    "    :param min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    :returns: predictions with original coordinate system restored\n",
    "    \"\"\"\n",
    "    denormalized = predictions.copy()\n",
    "    \n",
    "    # Add back the min values to restore original coordinate system\n",
    "    # Assuming predictions have position_x and position_y as first two dimensions\n",
    "    denormalized[:, :, 0] += min_values[0]  # position_x\n",
    "    denormalized[:, :, 1] += min_values[1]  # position_y\n",
    "    \n",
    "    return denormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e5cbe220c8bdd64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:59:35.013159Z",
     "start_time": "2025-05-30T19:59:34.999388Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "def standardize_single_scene(scene_data):\n",
    "    \"\"\"\n",
    "    Wrapper function to standardize a single scene and return both standardized data and min values.\n",
    "    This function will be called in parallel.\n",
    "    \"\"\"\n",
    "    standardized_scene, min_vals = standardize_data_dimensions(scene_data)\n",
    "    return standardized_scene, min_vals\n",
    "\n",
    "def parallel_standardize_training_data(train_data, n_jobs=-1, verbose=True):\n",
    "    \"\"\"\n",
    "    Parallelize the standardization of training data across all scenes.\n",
    "    \n",
    "    :param train_data: numpy array of shape (10000, 50, 110, 6)\n",
    "    :param n_jobs: number of parallel jobs (-1 uses all available cores)\n",
    "    :param verbose: whether to show progress bar\n",
    "    :returns: tuple of (standardized_data, min_values_array)\n",
    "    \"\"\"\n",
    "    print(f\"Standardizing {train_data.shape[0]} scenes using {multiprocessing.cpu_count() if n_jobs == -1 else n_jobs} cores...\")\n",
    "    \n",
    "    # Use joblib to parallelize the processing\n",
    "    if verbose:\n",
    "        # With progress bar\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(standardize_single_scene)(train_data[i]) \n",
    "            for i in tqdm(range(train_data.shape[0]), desc=\"Processing scenes\")\n",
    "        )\n",
    "    else:\n",
    "        # Without progress bar\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(standardize_single_scene)(train_data[i]) \n",
    "            for i in range(train_data.shape[0])\n",
    "        )\n",
    "    \n",
    "    # Unpack results\n",
    "    standardized_scenes, min_values_list = zip(*results)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    standardized_data = np.array(standardized_scenes)\n",
    "    min_values_array = np.array(min_values_list)\n",
    "    \n",
    "    print(f\"Standardization complete!\")\n",
    "    print(f\"Standardized data shape: {standardized_data.shape}\")\n",
    "    print(f\"Min values shape: {min_values_array.shape}\")\n",
    "    \n",
    "    return standardized_data, min_values_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1173eb5f0afb2d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-30T19:59:35.583428Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data not found. Running augmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting chunk 1/5...\n",
      "Using 40 jobs with batch size 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmentations:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Processing aug 1:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Processing aug 1:  50%|     | 40/80 [00:01<00:01, 30.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Processing aug 1: 100%|| 80/80 [00:02<00:00, 37.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                 \u001b[A\u001b[A\n",
      "Augmentations:  20%|        | 1/5 [00:05<00:21,  5.44s/it]\u001b[A\n",
      "\n",
      "Processing aug 2:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Processing aug 2: 100%|| 80/80 [00:00<00:00, 232.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                  \u001b[A\u001b[A\n",
      "Augmentations:  40%|      | 2/5 [00:09<00:13,  4.37s/it]\u001b[A\n",
      "\n",
      "Processing aug 3:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# Main execution code\n",
    "augmented_pkl_path = Path(\"augmented_train.pkl\")\n",
    "\n",
    "# Check if the file exists\n",
    "if augmented_pkl_path.exists():\n",
    "    print(\"Loading augmented data from pickle file...\")\n",
    "    with open(augmented_pkl_path, \"rb\") as f:\n",
    "        augmented_train = pickle.load(f)\n",
    "else:\n",
    "    print(\"Augmented data not found. Running augmentation...\")\n",
    "    # Split into 5 chunks\n",
    "    num_chunks = 5\n",
    "    chunk_size = len(train_data) // num_chunks\n",
    "    chunks = [train_data[i * chunk_size: (i + 1) * chunk_size] for i in range(num_chunks - 1)]\n",
    "    chunks.append(train_data[(num_chunks - 1) * chunk_size:])  # last chunk\n",
    "    \n",
    "    augmented_chunks = []\n",
    "    for i, chunk in enumerate(tqdm(chunks, desc=\"Processing chunks\")):\n",
    "        print(f\"Augmenting chunk {i+1}/{num_chunks}...\")\n",
    "        augmented_chunk = augment_dataset(\n",
    "            chunk, \n",
    "            num_augmentations=5,\n",
    "            n_jobs=-1,\n",
    "            batch_size=25\n",
    "        )\n",
    "        augmented_chunks.append(augmented_chunk)\n",
    "        \n",
    "        # Force cleanup\n",
    "        del augmented_chunk\n",
    "        del chunk\n",
    "        gc.collect()\n",
    "    \n",
    "    # Concatenate all augmented chunks\n",
    "    augmented_train = np.concatenate(augmented_chunks, axis=0)\n",
    "    print(\"Augmentation done. Preparing to dump to pickle...\")\n",
    "    \n",
    "    # Uncomment to save to pickle\n",
    "    # with open(augmented_pkl_path, \"wb\") as f:\n",
    "    #     pickle.dump(augmented_train, f)\n",
    "    # print(\"Dumped to pickle.\")\n",
    "\n",
    "print(f\"Original shape: {train_data.shape}\")\n",
    "print(f\"Augmented shape: {augmented_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725ea8a66d2174ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:41:35.979602Z",
     "start_time": "2025-05-30T19:41:35.938072Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'augmented_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m standardized_train_data, min_values \u001b[38;5;241m=\u001b[39m parallel_standardize_training_data(\n\u001b[0;32m----> 2\u001b[0m     \u001b[43maugmented_train\u001b[49m, \n\u001b[1;32m      3\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Use all available cores\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m standardized_train_data\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'augmented_train' is not defined"
     ]
    }
   ],
   "source": [
    "standardized_train_data, min_values = parallel_standardize_training_data(\n",
    "    augmented_train, \n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=True\n",
    ")\n",
    "standardized_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db97d754762b390b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T17:40:42.779341Z",
     "start_time": "2025-05-02T17:40:37.771284Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 20:47:54.813487: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-29 20:47:54.855668: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-29 20:47:54.855698: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-29 20:47:54.856762: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-29 20:47:54.863970: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, RepeatVector, TimeDistributed, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43f0094b638b0ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T17:40:42.786049Z",
     "start_time": "2025-05-02T17:40:42.783787Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def angle_change_loss(y_pred):\n",
    "    \"\"\"\n",
    "    Penalize large changes in direction between consecutive deltas.\n",
    "\n",
    "    Args:\n",
    "        y_pred: Tensor of shape (batch_size, Tpred, 2)\n",
    "\n",
    "    Returns:\n",
    "        Scalar loss penalizing angle differences\n",
    "    \"\"\"\n",
    "    # Normalize deltas to unit vectors\n",
    "    delta_unit = tf.math.l2_normalize(y_pred, axis=-1)  # shape: (B, T, 2)\n",
    "\n",
    "    # Compute cosine similarity between consecutive deltas\n",
    "    dot_products = tf.reduce_sum(delta_unit[:, 1:, :] * delta_unit[:, :-1, :], axis=-1)  # shape: (B, T-1)\n",
    "\n",
    "    # Clamp for numerical stability (to avoid NaNs in arccos)\n",
    "    dot_products = tf.clip_by_value(dot_products, -1.0, 1.0)\n",
    "\n",
    "    # Compute angle in radians between -1 and 1 (cos)\n",
    "    angle_diff = tf.acos(dot_products)  # shape: (B, T-1)\n",
    "\n",
    "    # Mean angle difference per sequence\n",
    "    return tf.reduce_mean(angle_diff)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    # Check if there are NaN values in y_true or y_pred\n",
    "    nan_check = tf.reduce_any(tf.math.is_nan(y_true)) | tf.reduce_any(tf.math.is_nan(y_pred))\n",
    "\n",
    "    # Use tf.cond to perform the check\n",
    "    def return_nan_loss():\n",
    "        return tf.constant(float('nan'))\n",
    "\n",
    "    def calculate_loss():\n",
    "        mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "        angle_loss = angle_change_loss(y_pred)\n",
    "        return mse_loss + 0.5 * angle_loss\n",
    "\n",
    "    return tf.cond(nan_check, return_nan_loss, calculate_loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f20fc814e583a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T18:15:51.012605Z",
     "start_time": "2025-05-02T18:15:51.003936Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def create_lstm_encoder_decoder(input_dim, output_dim, timesteps_in, timesteps_out, lstm_units=512, num_layers=3, loss_fn='mse', lr=0.001):\n",
    "    inputs = Input(shape=(timesteps_in, input_dim))\n",
    "\n",
    "    # Encoder\n",
    "    x = inputs\n",
    "    for _ in range(num_layers):\n",
    "        x = LSTM(lstm_units, return_sequences=True)(x)\n",
    "        # x = Dropout(0.2)(x)\n",
    "    encoded = LSTM(lstm_units)(x)  # Final encoder output\n",
    "\n",
    "    # Decoder\n",
    "    x = RepeatVector(timesteps_out)(encoded)\n",
    "    for _ in range(num_layers):\n",
    "        x = LSTM(lstm_units, return_sequences=True)(x)\n",
    "        # x = Dropout(0.2)(x)\n",
    "    \n",
    "    \n",
    "    x = TimeDistributed(Dense(128, activation='relu'))(x)\n",
    "    x = TimeDistributed(Dense(64, activation='relu'))(x)\n",
    "    outputs = TimeDistributed(Dense(output_dim))(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae']) \n",
    "\n",
    "    # model.compile(optimizer=Adam(learning_rate=1e-5), loss=combined_loss) #switch loss back to 'mse' for older solution \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d68034c165292c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T19:20:44.861403Z",
     "start_time": "2025-05-02T19:20:44.758718Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.src.callbacks import LearningRateScheduler, EarlyStopping, Callback\n",
    "from keras.src.optimizers import Adam\n",
    "from keras import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def exponential_decay_schedule(epoch, lr):\n",
    "    decay_rate = 0.9\n",
    "    decay_steps = 5\n",
    "    if epoch % decay_steps == 0 and epoch:\n",
    "        print('Learning rate update:', lr * decay_rate)\n",
    "        return lr * decay_rate\n",
    "    return lr\n",
    "\n",
    "\n",
    "# Custom callback to monitor LR and stop training\n",
    "class LRThresholdCallback(Callback):\n",
    "    def __init__(self, threshold=9e-5):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "        self.should_stop = False\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = float(self.model.optimizer.learning_rate.numpy())\n",
    "        if lr < self.threshold:\n",
    "            print(f\"\\nLearning rate {lr:.6f} < threshold {self.threshold}, moving to Phase 2.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "def train_model(train_data, batch_size=32, validation_split=0.2, Tobs=50, Tpred=60):\n",
    "    n_scenarios = train_data.shape[0]\n",
    "    X_train_raw = []\n",
    "    y_train_deltas = []\n",
    "\n",
    "    for i in range(n_scenarios):\n",
    "        ego_data = train_data[i, 0, :, :]\n",
    "        if np.all(ego_data == 0):\n",
    "            continue\n",
    "\n",
    "        observed = ego_data[:Tobs]            # shape (50, 6)\n",
    "        future = ego_data[Tobs:Tobs+Tpred, :2]\n",
    "        last_obs_pos = observed[-1, :2]\n",
    "\n",
    "        if np.any(np.all(observed == 0, axis=1)) or np.any(np.all(future == 0, axis=1)):\n",
    "            continue\n",
    "\n",
    "        # Compute deltas w.r.t. previous future timestep\n",
    "        delta = np.diff(np.vstack([last_obs_pos, future]), axis=0)  # (60, 2)\n",
    "\n",
    "        X_train_raw.append(observed)\n",
    "        y_train_deltas.append(delta)\n",
    "    \n",
    "\n",
    "    X_train = np.array(X_train_raw)\n",
    "    y_train = np.array(y_train_deltas)\n",
    "\n",
    "    print(f\"Training on {X_train.shape[0]} valid sequences.\")\n",
    "    print(f\"Input shape: {X_train.shape}, Delta Output shape: {y_train.shape}\")\n",
    "    \n",
    "    # --- Normalize Input and Output ---\n",
    "    X_mean = X_train.mean(axis=(0, 1), keepdims=True)  # shape: (1, 1, 6)\n",
    "    X_std = X_train.std(axis=(0, 1), keepdims=True) + 1e-8\n",
    "\n",
    "    y_mean = y_train.mean(axis=(0, 1), keepdims=True)  # shape: (1, 1, 2)\n",
    "    y_std = y_train.std(axis=(0, 1), keepdims=True) + 1e-8\n",
    "\n",
    "    X_train = (X_train - X_mean) / X_std\n",
    "    y_train = (y_train - y_mean) / y_std\n",
    "    \n",
    "    print(X_train[:2])\n",
    "    print(y_train[:2])\n",
    "\n",
    "    model = create_lstm_encoder_decoder(\n",
    "        input_dim=X_train.shape[-1],\n",
    "        output_dim=2,\n",
    "        timesteps_in=Tobs,\n",
    "        timesteps_out=Tpred,\n",
    "        loss_fn='mse',\n",
    "        lr=0.001\n",
    "    )\n",
    "\n",
    "    phase1_callbacks = [\n",
    "        LearningRateScheduler(exponential_decay_schedule),\n",
    "        EarlyStopping(patience=4, restore_best_weights=True, monitor='val_loss'),\n",
    "        LRThresholdCallback(threshold=9e-5)\n",
    "    ]\n",
    "\n",
    "    print(\"\\n--- Phase 1: Training ---\")\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=phase1_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Phase 2: Fine-tuning ---\")\n",
    "    model.compile(optimizer=Adam(1e-4), loss='mse', metrics=['mae'])\n",
    "    phase2_callbacks = [\n",
    "        LearningRateScheduler(exponential_decay_schedule),\n",
    "        EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss')\n",
    "    ]\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=10,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=phase2_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Return model and normalization parameters\n",
    "    return model, X_mean, X_std, y_mean, y_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d667b335d4a0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T19:20:47.293888Z",
     "start_time": "2025-05-02T19:20:47.285992Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(model, filepath='lstm_1.pkl'):\n",
    "    \"\"\"Save model and scaler together in a pickle file\"\"\"\n",
    "    model_json = model.to_json()\n",
    "    model_weights = model.get_weights()\n",
    "    data = {\n",
    "        'model_json': model_json,\n",
    "        'model_weights': model_weights,\n",
    "    }\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Model saved to {filepath}\")\n",
    "\n",
    "def load_model(filepath='lstm_1.pkl'):\n",
    "    \"\"\"Load model and scaler from pickle file\"\"\"\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    # Reconstruct model\n",
    "    model = tf.keras.models.model_from_json(data['model_json'])\n",
    "    model.set_weights(data['model_weights'])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deeaeac04573c115",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T18:42:28.285866Z",
     "start_time": "2025-05-02T18:41:59.875150Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 20 valid sequences.\n",
      "Input shape: (20, 50, 6), Delta Output shape: (20, 60, 2)\n",
      "[[[-0.93319447 -1.58222329 -1.15350628  0.31547822  2.00816888\n",
      "    0.        ]\n",
      "  [-0.93342124 -1.58211054 -1.15350628  0.31547822  2.00806527\n",
      "    0.        ]\n",
      "  [-0.93370104 -1.58197133 -2.07190382  0.82509541  2.007935\n",
      "    0.        ]\n",
      "  [-0.93403198 -1.58180654 -2.06133597  0.82481471  2.00778369\n",
      "    0.        ]\n",
      "  [-0.93441037 -1.58161792 -2.05927348  0.82742101  2.00762435\n",
      "    0.        ]\n",
      "  [-0.93483003 -1.58140851 -2.06776803  0.83031786  2.00746266\n",
      "    0.        ]\n",
      "  [-0.93528299 -1.5811823  -2.04863616  0.81970779  2.00729382\n",
      "    0.        ]\n",
      "  [-0.93575921 -1.58094427 -2.0496384   0.82040755  2.00712379\n",
      "    0.        ]\n",
      "  [-0.93624661 -1.58070047 -2.06963483  0.83164106  2.00695107\n",
      "    0.        ]\n",
      "  [-0.93673114 -1.58045793 -2.05848802  0.8292349   2.00677872\n",
      "    0.        ]\n",
      "  [-0.93719679 -1.58022457 -2.04745784  0.82685391  2.00663008\n",
      "    0.        ]\n",
      "  [-0.9376487  -1.57999785 -2.0695664   0.83912091  2.00651523\n",
      "    0.        ]\n",
      "  [-0.93810093 -1.5797709  -2.06904376  0.83849318  2.00642171\n",
      "    0.        ]\n",
      "  [-0.93855331 -1.57954376 -2.05383807  0.82775284  2.0063493\n",
      "    0.        ]\n",
      "  [-0.93900575 -1.57931645 -2.05910428  0.82966029  2.00629632\n",
      "    0.        ]\n",
      "  [-0.93945867 -1.57908885 -2.05717038  0.82953407  2.00624796\n",
      "    0.        ]\n",
      "  [-0.93991146 -1.57886132 -2.05657393  0.82889071  2.00620057\n",
      "    0.        ]\n",
      "  [-0.94036391 -1.57863404 -2.05845615  0.83256883  2.00615682\n",
      "    0.        ]\n",
      "  [-0.94081639 -1.57840689 -2.06092637  0.83687917  2.00610845\n",
      "    0.        ]\n",
      "  [-0.9412685  -1.57818002 -2.06176689  0.83478787  2.00605557\n",
      "    0.        ]\n",
      "  [-0.94171947 -1.57795375 -2.06350585  0.83344807  2.00600407\n",
      "    0.        ]\n",
      "  [-0.94216991 -1.57772768 -2.05444705  0.82819867  2.00595214\n",
      "    0.        ]\n",
      "  [-0.94261985 -1.57750179 -2.05322794  0.82648016  2.00589699\n",
      "    0.        ]\n",
      "  [-0.94306858 -1.57727649 -2.05238667  0.82542204  2.00583121\n",
      "    0.        ]\n",
      "  [-0.94351647 -1.57705164 -2.03555095  0.81616585  2.00574269\n",
      "    0.        ]\n",
      "  [-0.94396363 -1.57682721 -2.03607802  0.81758533  2.0056263\n",
      "    0.        ]\n",
      "  [-0.94441021 -1.5766031  -2.03380074  0.81756179  2.00548973\n",
      "    0.        ]\n",
      "  [-0.94485635 -1.57637915 -2.02319322  0.81286043  2.00535066\n",
      "    0.        ]\n",
      "  [-0.94530201 -1.57615537 -2.02276774  0.81361434  2.0052271\n",
      "    0.        ]\n",
      "  [-0.94574719 -1.5759318  -2.03952592  0.82324005  2.00511703\n",
      "    0.        ]\n",
      "  [-0.94619228 -1.57570821 -2.02773014  0.8134885   2.00501724\n",
      "    0.        ]\n",
      "  [-0.94663715 -1.57548468 -2.02456296  0.81124359  2.00491468\n",
      "    0.        ]\n",
      "  [-0.94708207 -1.57526121 -2.0470563   0.82418081  2.0048097\n",
      "    0.        ]\n",
      "  [-0.94752725 -1.57503759 -2.03902888  0.81992325  2.00472969\n",
      "    0.        ]\n",
      "  [-0.94797242 -1.5748139  -2.03356565  0.8195942   2.00468469\n",
      "    0.        ]\n",
      "  [-0.9484175  -1.5745904  -2.02586533  0.81271039  2.00466144\n",
      "    0.        ]\n",
      "  [-0.94886225 -1.5743673  -2.01831386  0.80595964  2.00464024\n",
      "    0.        ]\n",
      "  [-0.94930651 -1.57414462 -2.02481386  0.81177275  2.00461973\n",
      "    0.        ]\n",
      "  [-0.94975025 -1.5739223  -2.03128584  0.8175608   2.00460409\n",
      "    0.        ]\n",
      "  [-0.95019402 -1.57370002 -2.02464376  0.80969637  2.00459311\n",
      "    0.        ]\n",
      "  [-0.95063758 -1.57347794 -2.03059225  0.81211197  2.004586\n",
      "    0.        ]\n",
      "  [-0.95108084 -1.5732561  -2.0248696   0.81489753  2.00458605\n",
      "    0.        ]\n",
      "  [-0.95152454 -1.57303408 -2.01924285  0.80340601  2.00459034\n",
      "    0.        ]\n",
      "  [-0.95196878 -1.57281183 -2.01886035  0.79511542  2.00459785\n",
      "    0.        ]\n",
      "  [-0.95241355 -1.57258927 -2.02090466  0.80450867  2.00460914\n",
      "    0.        ]\n",
      "  [-0.9528588  -1.57236651 -2.03545102  0.81800859  2.00461089\n",
      "    0.        ]\n",
      "  [-0.95330441 -1.57214366 -2.0374878   0.81856586  2.00459828\n",
      "    0.        ]\n",
      "  [-0.95375045 -1.5719206  -2.03949682  0.81911554  2.00457371\n",
      "    0.        ]\n",
      "  [-0.95419703 -1.57169717 -2.0346258   0.81559268  2.00452984\n",
      "    0.        ]\n",
      "  [-0.95464403 -1.57147345 -2.04064665  0.81958954  2.00445272\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.26103253  0.07754491  0.20264296 -1.06942696 -0.76041742\n",
      "    0.        ]\n",
      "  [ 0.26114684  0.07734321  0.20264296 -1.06942696 -0.76012699\n",
      "    0.        ]\n",
      "  [ 0.26128939  0.07709169  0.65504137 -1.96393638 -0.759783\n",
      "    0.        ]\n",
      "  [ 0.26145947  0.07679161  0.67955898 -2.00961273 -0.75938822\n",
      "    0.        ]\n",
      "  [ 0.26165538  0.07644601  0.69878924 -2.04577425 -0.75894408\n",
      "    0.        ]\n",
      "  [ 0.2618745   0.07605951  0.71012898 -2.07110813 -0.75845089\n",
      "    0.        ]\n",
      "  [ 0.26211298  0.0756389   0.72501723 -2.10068098 -0.75792605\n",
      "    0.        ]\n",
      "  [ 0.26236599  0.0751928   0.73662533 -2.1210256  -0.75740063\n",
      "    0.        ]\n",
      "  [ 0.26262776  0.07473151  0.74454802 -2.13679764 -0.7569045\n",
      "    0.        ]\n",
      "  [ 0.26289105  0.07426776  0.75277923 -2.15348977 -0.75645558\n",
      "    0.        ]\n",
      "  [ 0.26314762  0.07381613  0.75820373 -2.16377737 -0.75607289\n",
      "    0.        ]\n",
      "  [ 0.26339938  0.07337315  0.76612475 -2.17705838 -0.75575812\n",
      "    0.        ]\n",
      "  [ 0.26365256  0.07292784  0.77682324 -2.19667136 -0.75549412\n",
      "    0.        ]\n",
      "  [ 0.2639069   0.07248069  0.78477294 -2.21137595 -0.75527444\n",
      "    0.        ]\n",
      "  [ 0.26416191  0.07203247  0.78492195 -2.20983612 -0.7550943\n",
      "    0.        ]\n",
      "  [ 0.26441721  0.07158385  0.79162163 -2.21923258 -0.75495383\n",
      "    0.        ]\n",
      "  [ 0.2646726   0.0711351   0.79224919 -2.22326055 -0.7548674\n",
      "    0.        ]\n",
      "  [ 0.26492793  0.07068641  0.78232369 -2.20728822 -0.75483783\n",
      "    0.        ]\n",
      "  [ 0.265183    0.07023797  0.78529278 -2.21269769 -0.75485938\n",
      "    0.        ]\n",
      "  [ 0.26543762  0.06979006  0.78393601 -2.21185767 -0.75491891\n",
      "    0.        ]\n",
      "  [ 0.2656916   0.06934288  0.78032233 -2.20348662 -0.75499327\n",
      "    0.        ]\n",
      "  [ 0.2659449   0.06889659  0.76938413 -2.18444378 -0.75507202\n",
      "    0.        ]\n",
      "  [ 0.26619751  0.06845118  0.76392724 -2.17727267 -0.75514905\n",
      "    0.        ]\n",
      "  [ 0.26644965  0.06800632  0.77167331 -2.19049209 -0.75521824\n",
      "    0.        ]\n",
      "  [ 0.26670152  0.06756176  0.77457668 -2.19936588 -0.75528682\n",
      "    0.        ]\n",
      "  [ 0.26695315  0.06711754  0.77320896 -2.20240265 -0.75536353\n",
      "    0.        ]\n",
      "  [ 0.26720499  0.06667291  0.77153214 -2.19680386 -0.75543599\n",
      "    0.        ]\n",
      "  [ 0.26745709  0.06622779  0.76974418 -2.19136167 -0.75549398\n",
      "    0.        ]\n",
      "  [ 0.2677094   0.0657823   0.77150537 -2.19335519 -0.75553451\n",
      "    0.        ]\n",
      "  [ 0.26796225  0.06533592  0.77266574 -2.19294243 -0.75556043\n",
      "    0.        ]\n",
      "  [ 0.26821541  0.06488913  0.77369099 -2.19486876 -0.75557508\n",
      "    0.        ]\n",
      "  [ 0.26846869  0.06444233  0.78044269 -2.20821292 -0.75558145\n",
      "    0.        ]\n",
      "  [ 0.26872225  0.0639953   0.78077166 -2.20878731 -0.75558898\n",
      "    0.        ]\n",
      "  [ 0.26897598  0.06354824  0.7757445  -2.1994607  -0.75559149\n",
      "    0.        ]\n",
      "  [ 0.26922995  0.06310098  0.7886414  -2.22390827 -0.75557905\n",
      "    0.        ]\n",
      "  [ 0.26948413  0.0626535   0.77877293 -2.20362125 -0.75556026\n",
      "    0.        ]\n",
      "  [ 0.2697382   0.06220635  0.77114292 -2.18785639 -0.7555483\n",
      "    0.        ]\n",
      "  [ 0.26999193  0.06175996  0.78088439 -2.20470013 -0.75554134\n",
      "    0.        ]\n",
      "  [ 0.27024507  0.06131468  0.76799014 -2.1779732  -0.75553106\n",
      "    0.        ]\n",
      "  [ 0.27049734  0.06087098  0.77850333 -2.19653176 -0.75552371\n",
      "    0.        ]\n",
      "  [ 0.27074838  0.06042951  0.77973851 -2.20036027 -0.7555239\n",
      "    0.        ]\n",
      "  [ 0.27099819  0.05999033  0.75942192 -2.16333944 -0.7555201\n",
      "    0.        ]\n",
      "  [ 0.27124654  0.05955387  0.76159745 -2.1648028  -0.75551457\n",
      "    0.        ]\n",
      "  [ 0.27149303  0.05912079  0.75099811 -2.14276435 -0.75552165\n",
      "    0.        ]\n",
      "  [ 0.27173791  0.05869069  0.73611045 -2.11513195 -0.755549\n",
      "    0.        ]\n",
      "  [ 0.27198064  0.05826449  0.73212091 -2.10764211 -0.7556021\n",
      "    0.        ]\n",
      "  [ 0.27222058  0.0578432   0.72094363 -2.08754427 -0.755663\n",
      "    0.        ]\n",
      "  [ 0.27245771  0.05742682  0.71017464 -2.06359584 -0.75572992\n",
      "    0.        ]\n",
      "  [ 0.27269177  0.05701591  0.70050696 -2.03896698 -0.75582875\n",
      "    0.        ]\n",
      "  [ 0.27292279  0.05661052  0.694221   -2.0252328  -0.75595049\n",
      "    0.        ]]]\n",
      "[[[-2.03044005  1.30579896]\n",
      "  [-2.03390544  1.31002332]\n",
      "  [-2.0356852   1.31251356]\n",
      "  [-2.03637986  1.3132957 ]\n",
      "  [-2.03691773  1.31439204]\n",
      "  [-2.038526    1.31708705]\n",
      "  [-2.0399222   1.31974889]\n",
      "  [-2.04021253  1.32130335]\n",
      "  [-2.03976519  1.32249735]\n",
      "  [-2.0402162   1.32411623]\n",
      "  [-2.04060368  1.32502697]\n",
      "  [-2.04082565  1.32472785]\n",
      "  [-2.04126204  1.32349377]\n",
      "  [-2.04108206  1.32166262]\n",
      "  [-2.04002273  1.31940617]\n",
      "  [-2.03949     1.31736251]\n",
      "  [-2.03966697  1.31555146]\n",
      "  [-2.0404022   1.31438011]\n",
      "  [-2.04104647  1.3133644 ]\n",
      "  [-2.03990586  1.31088549]\n",
      "  [-2.037832    1.30775652]\n",
      "  [-2.03717392  1.3058414 ]\n",
      "  [-2.0373286   1.30507817]\n",
      "  [-2.0375057   1.30518984]\n",
      "  [-2.03613392  1.30452324]\n",
      "  [-2.03368221  1.30351234]\n",
      "  [-2.03291014  1.30424664]\n",
      "  [-2.03234839  1.30470191]\n",
      "  [-2.03105251  1.30412943]\n",
      "  [-2.02881751  1.30267886]\n",
      "  [-2.02608014  1.30106837]\n",
      "  [-2.02285551  1.29975414]\n",
      "  [-2.01907594  1.29789159]\n",
      "  [-2.01539271  1.29555114]\n",
      "  [-2.01081027  1.29233773]\n",
      "  [-2.00468339  1.28796513]\n",
      "  [-1.99829946  1.28273245]\n",
      "  [-1.99213715  1.27781577]\n",
      "  [-1.98544061  1.27334243]\n",
      "  [-1.9793116   1.26939326]\n",
      "  [-1.97309535  1.26574818]\n",
      "  [-1.96692141  1.26178737]\n",
      "  [-1.95938636  1.25684182]\n",
      "  [-1.95115049  1.25229638]\n",
      "  [-1.9442765   1.24840378]\n",
      "  [-1.9361019   1.24284797]\n",
      "  [-1.92573858  1.23597411]\n",
      "  [-1.91515584  1.22848531]\n",
      "  [-1.90523219  1.2211189 ]\n",
      "  [-1.89572604  1.21405411]\n",
      "  [-1.93361538  1.2361232 ]\n",
      "  [-1.98832471  1.26826586]\n",
      "  [-1.98677954  1.26475086]\n",
      "  [-1.93644175  1.23052875]\n",
      "  [-1.8451613   1.17070932]\n",
      "  [-1.71882767  1.08964376]\n",
      "  [-1.56455891  0.99143201]\n",
      "  [-1.39114777  0.88101516]\n",
      "  [-1.20530842  0.76296012]\n",
      "  [-1.01335783  0.64103862]]\n",
      "\n",
      " [[ 0.717397   -1.95070487]\n",
      "  [ 0.70252105 -1.91843214]\n",
      "  [ 0.68807889 -1.88651224]\n",
      "  [ 0.67332976 -1.85307402]\n",
      "  [ 0.65723582 -1.81697465]\n",
      "  [ 0.64055225 -1.78011299]\n",
      "  [ 0.62277041 -1.74104593]\n",
      "  [ 0.60410148 -1.69983889]\n",
      "  [ 0.58500906 -1.65685833]\n",
      "  [ 0.56595819 -1.61353559]\n",
      "  [ 0.54537065 -1.56717919]\n",
      "  [ 0.52416874 -1.51953284]\n",
      "  [ 0.50269644 -1.47155297]\n",
      "  [ 0.48017361 -1.42200147]\n",
      "  [ 0.45761753 -1.3726105 ]\n",
      "  [ 0.43582566 -1.32469052]\n",
      "  [ 0.41454191 -1.27757069]\n",
      "  [ 0.39209134 -1.22832743]\n",
      "  [ 0.36976119 -1.18007158]\n",
      "  [ 0.34833401 -1.1334387 ]\n",
      "  [ 0.32760065 -1.08730137]\n",
      "  [ 0.30732798 -1.04148617]\n",
      "  [ 0.28678918 -0.99537575]\n",
      "  [ 0.26610901 -0.949132  ]\n",
      "  [ 0.24534302 -0.90244901]\n",
      "  [ 0.22498674 -0.85604026]\n",
      "  [ 0.20531033 -0.81036479]\n",
      "  [ 0.18473961 -0.76285343]\n",
      "  [ 0.16377556 -0.71474032]\n",
      "  [ 0.14377766 -0.66910931]\n",
      "  [ 0.12445429 -0.62539462]\n",
      "  [ 0.10581843 -0.58289321]\n",
      "  [ 0.08773165 -0.5412579 ]\n",
      "  [ 0.07036393 -0.50143584]\n",
      "  [ 0.0532188  -0.46221013]\n",
      "  [ 0.03659866 -0.42423049]\n",
      "  [ 0.02086028 -0.38850544]\n",
      "  [ 0.00570318 -0.35409606]\n",
      "  [-0.00871497 -0.32109891]\n",
      "  [-0.02240858 -0.28963473]\n",
      "  [-0.03525862 -0.26049224]\n",
      "  [-0.04742244 -0.23332268]\n",
      "  [-0.05874004 -0.20782962]\n",
      "  [-0.06924187 -0.18337403]\n",
      "  [-0.07944543 -0.15948668]\n",
      "  [-0.08958418 -0.13619535]\n",
      "  [-0.09837592 -0.115991  ]\n",
      "  [-0.1064072  -0.09751546]\n",
      "  [-0.11413852 -0.0795063 ]\n",
      "  [-0.12160499 -0.06172719]\n",
      "  [-0.1275607  -0.04764678]\n",
      "  [-0.13292585 -0.0353161 ]\n",
      "  [-0.13946861 -0.0203665 ]\n",
      "  [-0.14638189 -0.00482533]\n",
      "  [-0.15398819  0.01219054]\n",
      "  [-0.16160653  0.02932812]\n",
      "  [-0.16915433  0.04618768]\n",
      "  [-0.17641017  0.0622083 ]\n",
      "  [-0.18305054  0.07682586]\n",
      "  [-0.18937576  0.09078608]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 20:47:57.050703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9014 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:60:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 1: Training ---\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 20:48:07.430527: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 1.0013 - mae: 0.6583WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.0013 - mae: 0.6583 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8994 - mae: 0.6308WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8994 - mae: 0.6308 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5719 - mae: 1.0425WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.5719 - mae: 1.0425 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8936 - mae: 0.7176WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8936 - mae: 0.7176 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7588 - mae: 0.6095WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7588 - mae: 0.6095 - lr: 0.0010\n",
      "Learning rate update: 0.0009000000427477062\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8781 - mae: 0.6575WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8781 - mae: 0.6575 - lr: 9.0000e-04\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5678 - mae: 0.4957WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5678 - mae: 0.4957 - lr: 9.0000e-04\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5190 - mae: 0.4956WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5190 - mae: 0.4956 - lr: 9.0000e-04\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4387 - mae: 0.4888WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4387 - mae: 0.4888 - lr: 9.0000e-04\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3895 - mae: 0.4509WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3895 - mae: 0.4509 - lr: 9.0000e-04\n",
      "Learning rate update: 0.0008100000384729356\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5942 - mae: 0.5586WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5942 - mae: 0.5586 - lr: 8.1000e-04\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4630 - mae: 0.4944WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4630 - mae: 0.4944 - lr: 8.1000e-04\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4211 - mae: 0.4908WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4211 - mae: 0.4908 - lr: 8.1000e-04\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3535 - mae: 0.4419WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3535 - mae: 0.4419 - lr: 8.1000e-04\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3392 - mae: 0.4100WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3392 - mae: 0.4100 - lr: 8.1000e-04\n",
      "Learning rate update: 0.0007290000503417104\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3510 - mae: 0.4101WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3510 - mae: 0.4101 - lr: 7.2900e-04\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5330 - mae: 0.4997WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5330 - mae: 0.4997 - lr: 7.2900e-04\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3465 - mae: 0.3863WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3465 - mae: 0.3863 - lr: 7.2900e-04\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2731 - mae: 0.3509WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2731 - mae: 0.3509 - lr: 7.2900e-04\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2978 - mae: 0.3768WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2978 - mae: 0.3768 - lr: 7.2900e-04\n",
      "Learning rate update: 0.0006561000715009868\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3486 - mae: 0.4004WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3486 - mae: 0.4004 - lr: 6.5610e-04\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2497 - mae: 0.3577WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2497 - mae: 0.3577 - lr: 6.5610e-04\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2740 - mae: 0.3925WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2740 - mae: 0.3925 - lr: 6.5610e-04\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2826 - mae: 0.3451WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2826 - mae: 0.3451 - lr: 6.5610e-04\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2712 - mae: 0.3345WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2712 - mae: 0.3345 - lr: 6.5610e-04\n",
      "Learning rate update: 0.0005904900433961303\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2336 - mae: 0.3189WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2336 - mae: 0.3189 - lr: 5.9049e-04\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2216 - mae: 0.3180WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2216 - mae: 0.3180 - lr: 5.9049e-04\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2203 - mae: 0.3250WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2203 - mae: 0.3250 - lr: 5.9049e-04\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2151 - mae: 0.3279WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2151 - mae: 0.3279 - lr: 5.9049e-04\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1949 - mae: 0.3030WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1949 - mae: 0.3030 - lr: 5.9049e-04\n",
      "Learning rate update: 0.0005314410547725857\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1906 - mae: 0.2808WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1906 - mae: 0.2808 - lr: 5.3144e-04\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1821 - mae: 0.2676WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1821 - mae: 0.2676 - lr: 5.3144e-04\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1655 - mae: 0.2629WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1655 - mae: 0.2629 - lr: 5.3144e-04\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1661 - mae: 0.2699WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1661 - mae: 0.2699 - lr: 5.3144e-04\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1492 - mae: 0.2551WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1492 - mae: 0.2551 - lr: 5.3144e-04\n",
      "Learning rate update: 0.00047829695977270604\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1466 - mae: 0.2462WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1466 - mae: 0.2462 - lr: 4.7830e-04\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1355 - mae: 0.2351WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1355 - mae: 0.2351 - lr: 4.7830e-04\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1250 - mae: 0.2282WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1250 - mae: 0.2282 - lr: 4.7830e-04\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1249 - mae: 0.2264WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1249 - mae: 0.2264 - lr: 4.7830e-04\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1194 - mae: 0.2115WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1194 - mae: 0.2115 - lr: 4.7830e-04\n",
      "Learning rate update: 0.0004304672533180565\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1153 - mae: 0.2072WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1153 - mae: 0.2072 - lr: 4.3047e-04\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1097 - mae: 0.2134WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1097 - mae: 0.2134 - lr: 4.3047e-04\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1094 - mae: 0.2180WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1094 - mae: 0.2180 - lr: 4.3047e-04\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1042 - mae: 0.2037WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1042 - mae: 0.2037 - lr: 4.3047e-04\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1026 - mae: 0.1940WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1026 - mae: 0.1940 - lr: 4.3047e-04\n",
      "Learning rate update: 0.00038742052274756136\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0989 - mae: 0.1893WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0989 - mae: 0.1893 - lr: 3.8742e-04\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0983 - mae: 0.1888WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0983 - mae: 0.1888 - lr: 3.8742e-04\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0943 - mae: 0.1833WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0943 - mae: 0.1833 - lr: 3.8742e-04\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0916 - mae: 0.1799WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0916 - mae: 0.1799 - lr: 3.8742e-04\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0881 - mae: 0.1809WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0881 - mae: 0.1809 - lr: 3.8742e-04\n",
      "\n",
      "--- Phase 2: Fine-tuning ---\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0870 - mae: 0.1830WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.0870 - mae: 0.1830 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2073 - mae: 0.2673WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2073 - mae: 0.2673 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1480 - mae: 0.2187WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1480 - mae: 0.2187 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1033 - mae: 0.2137WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1033 - mae: 0.2137 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1519 - mae: 0.2585WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1519 - mae: 0.2585 - lr: 1.0000e-04\n",
      "Learning rate update: 8.999999772640876e-05\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1188 - mae: 0.2380WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1188 - mae: 0.2380 - lr: 9.0000e-05\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1036 - mae: 0.2224WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1036 - mae: 0.2224 - lr: 9.0000e-05\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1092 - mae: 0.2176WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1092 - mae: 0.2176 - lr: 9.0000e-05\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1100 - mae: 0.2097WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1100 - mae: 0.2097 - lr: 9.0000e-05\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1027 - mae: 0.1972WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1027 - mae: 0.1972 - lr: 9.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# first check that the model can overfit on small data\n",
    "model, X_mean, X_std, y_mean, y_std  = train_model(train_data[:20], batch_size=20, validation_split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ce3811f963721e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T18:42:54.682368Z",
     "start_time": "2025-05-02T18:42:54.675886Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_mae_by_timestep(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Visualize MAE across timesteps in the prediction horizon.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): shape (N, Tpred, 2)\n",
    "        y_pred (np.ndarray): shape (N, Tpred, 2)\n",
    "    \"\"\"\n",
    "    mae_per_timestep = np.mean(np.abs(y_true - y_pred), axis=(0, 2))  # shape (Tpred,)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(mae_per_timestep, label='MAE per Timestep')\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.ylabel('MAE (meters)')\n",
    "    plt.title('Mean Absolute Error Over Prediction Horizon')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49143614a59770d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T18:42:55.168565Z",
     "start_time": "2025-05-02T18:42:55.165875Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def reconstruct_absolute_positions(pred_deltas, last_observed_positions):\n",
    "    \"\"\"\n",
    "    Reconstruct absolute predicted positions by adding deltas to the last observed position.\n",
    "\n",
    "    Args:\n",
    "        pred_deltas: np.ndarray of shape (N, Tpred, 2)\n",
    "        last_observed_positions: np.ndarray of shape (N, 2)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray of shape (N, Tpred, 2)\n",
    "    \"\"\"\n",
    "    return last_observed_positions[:, None, :] + np.cumsum(pred_deltas, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def forecast_positions(scenario_data, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std):\n",
    "    \"\"\"\n",
    "    Use normalized LSTM model to forecast future deltas and reconstruct absolute positions.\n",
    "\n",
    "    Args:\n",
    "        scenario_data (numpy.ndarray): Shape (agents, time_steps, dimensions)\n",
    "        Tobs (int): Number of observed time steps\n",
    "        Tpred (int): Number of future time steps to predict\n",
    "        model (Model): Trained LSTM model that predicts normalized deltas\n",
    "        X_mean, X_std: Normalization stats for input\n",
    "        y_mean, y_std: Normalization stats for output\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Predicted absolute positions of shape (agents, Tpred, 2)\n",
    "    \"\"\"\n",
    "    agents, _, _ = scenario_data.shape\n",
    "    predicted_positions = np.zeros((agents, Tpred, 2))\n",
    "    pred_deltas_all = []\n",
    "\n",
    "    for agent_idx in range(agents):\n",
    "        agent_data = scenario_data[agent_idx, :Tobs, :]  # shape (Tobs, 6)\n",
    "\n",
    "        # Skip if fully padded\n",
    "        if np.all(agent_data == 0):\n",
    "            continue\n",
    "\n",
    "        # Normalize input\n",
    "        X_pred = np.expand_dims(agent_data, axis=0)  # shape (1, Tobs, 6)\n",
    "        X_pred_norm = (X_pred - X_mean) / X_std\n",
    "\n",
    "        # Predict normalized deltas\n",
    "        pred_deltas_norm = model.predict(X_pred_norm, verbose=0)  # shape (1, Tpred, 2)\n",
    "\n",
    "        # Denormalize deltas\n",
    "        pred_deltas = pred_deltas_norm * y_std + y_mean\n",
    "        pred_deltas_all.append(pred_deltas[0])\n",
    "\n",
    "        # Reconstruct absolute positions\n",
    "        last_pos = agent_data[Tobs - 1, :2]  # shape (2,)\n",
    "        abs_positions = reconstruct_absolute_positions(\n",
    "            pred_deltas=pred_deltas,\n",
    "            last_observed_positions=np.expand_dims(last_pos, axis=0)\n",
    "        )[0]\n",
    "\n",
    "        predicted_positions[agent_idx] = abs_positions\n",
    "\n",
    "    return predicted_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "658c258cac06616e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T18:42:56.727430Z",
     "start_time": "2025-05-02T18:42:56.726626Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def make_gif(data_matrix1, data_matrix2, name='comparison'):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.animation as animation\n",
    "\n",
    "    cmap1 = plt.cm.get_cmap('viridis', 50)\n",
    "    cmap2 = plt.cm.get_cmap('plasma', 50)\n",
    "\n",
    "    assert data_matrix1.shape[1] == data_matrix2.shape[1], \"Both matrices must have same number of timesteps\"\n",
    "    timesteps = data_matrix1.shape[1]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "    ax1, ax2 = axes\n",
    "\n",
    "    def update(frame):\n",
    "        for ax in axes:\n",
    "            ax.clear()\n",
    "\n",
    "        for i in range(data_matrix1.shape[0]):\n",
    "            for (data_matrix, ax, cmap) in [(data_matrix1, ax1, cmap1), (data_matrix2, ax2, cmap2)]:\n",
    "                x = data_matrix[i, frame, 0]\n",
    "                y = data_matrix[i, frame, 1]\n",
    "                if x != 0 and y != 0:\n",
    "                    xs = data_matrix[i, :frame+1, 0]\n",
    "                    ys = data_matrix[i, :frame+1, 1]\n",
    "                    mask = (xs != 0) & (ys != 0)\n",
    "                    xs = xs[mask]\n",
    "                    ys = ys[mask]\n",
    "                    if len(xs) > 0 and len(ys) > 0:\n",
    "                        color = cmap(i)\n",
    "                        ax.plot(xs, ys, alpha=0.9, color=color)\n",
    "                        ax.scatter(x, y, s=80, color=color)\n",
    "\n",
    "        # Plot ego vehicle (index 0) on both\n",
    "        ax1.plot(data_matrix1[0, :frame, 0], data_matrix1[0, :frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "        ax1.scatter(data_matrix1[0, frame, 0], data_matrix1[0, frame, 1], s=80, color='tab:orange')\n",
    "        ax1.set_title('Prediction')\n",
    "\n",
    "        ax2.plot(data_matrix2[0, :frame, 0], data_matrix2[0, :frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "        ax2.scatter(data_matrix2[0, frame, 0], data_matrix2[0, frame, 1], s=80, color='tab:orange')\n",
    "        ax2.set_title('Actual')\n",
    "\n",
    "        for ax, data_matrix in zip(axes, [data_matrix1, data_matrix2]):\n",
    "            ax.set_xlim(data_matrix[:, :, 0][data_matrix[:, :, 0] != 0].min() - 10,\n",
    "                        data_matrix[:, :, 0][data_matrix[:, :, 0] != 0].max() + 10)\n",
    "            ax.set_ylim(data_matrix[:, :, 1][data_matrix[:, :, 1] != 0].min() - 10,\n",
    "                        data_matrix[:, :, 1][data_matrix[:, :, 1] != 0].max() + 10)\n",
    "            ax.legend()\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "\n",
    "        # Compute MSE over non-zero entries up to current frame\n",
    "        mask = (data_matrix2[:, :frame+1, :] != 0) & (data_matrix1[:, :frame+1, :] != 0)\n",
    "        mse = np.mean((data_matrix1[:, :frame+1, :][mask] - data_matrix2[:, :frame+1, :][mask]) ** 2)\n",
    "\n",
    "        fig.suptitle(f\"Timestep {frame} - MSE: {mse:.4f}\", fontsize=16)\n",
    "        return ax1.collections + ax1.lines + ax2.collections + ax2.lines\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, update, frames=list(range(0, timesteps, 3)), interval=100, blit=True)\n",
    "    anim.save(f'trajectory_visualization_{name}.gif', writer='pillow')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a5f4cc76c3c72d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T01:00:46.798817Z",
     "start_time": "2025-05-03T01:00:35.906297Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_958706/849000278.py:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap1 = plt.cm.get_cmap('viridis', 50)\n",
      "/tmp/ipykernel_958706/849000278.py:10: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap2 = plt.cm.get_cmap('plasma', 50)\n"
     ]
    }
   ],
   "source": [
    "# visualize prediction\n",
    "\n",
    "# model = load_model()\n",
    "\n",
    "# Parameters\n",
    "Tobs = 50\n",
    "Tpred = 60\n",
    "\n",
    "data = train_data[5000]\n",
    "\n",
    "# Select a test scenario (can use any valid index)\n",
    "test_scenario = data.copy()  # shape (agents, time_steps, features)\n",
    "\n",
    "# Forecast future positions\n",
    "predicted_positions = forecast_positions(test_scenario, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std)\n",
    "\n",
    "# Create combined matrix of past observed + predicted for ego agent (agent 0)\n",
    "ego_past = test_scenario[0, :Tobs, :2]               # shape (Tobs, 2)\n",
    "ego_future = predicted_positions[0]                  # shape (Tpred, 2)\n",
    "ego_full = np.concatenate([ego_past, ego_future], axis=0)  # shape (Tobs + Tpred, 2)\n",
    "\n",
    "# Create updated scenario with predicted ego and original others\n",
    "updated_scenario = test_scenario.copy()\n",
    "updated_scenario[0, :Tobs+Tpred, :2] = ego_full  # Replace ego trajectory\n",
    "\n",
    "# Visualize\n",
    "make_gif(updated_scenario, data, name='lstm1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3338be4ed075b368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T22:42:07.483287Z",
     "start_time": "2025-05-02T19:20:54.021001Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 10000 valid sequences.\n",
      "Input shape: (10000, 50, 6), Delta Output shape: (10000, 60, 2)\n",
      "[[[-0.70963494 -0.99812224 -0.9788003   0.3573056   1.55063073\n",
      "    0.        ]\n",
      "  [-0.70979287 -0.99802844 -0.9788003   0.3573056   1.55055584\n",
      "    0.        ]\n",
      "  [-0.70998773 -0.99791262 -1.98200353  0.70357905  1.55046169\n",
      "    0.        ]\n",
      "  [-0.71021821 -0.99777552 -1.97045983  0.70338832  1.55035232\n",
      "    0.        ]\n",
      "  [-0.71048173 -0.9976186  -1.9682069   0.70515924  1.55023716\n",
      "    0.        ]\n",
      "  [-0.710774   -0.99744439 -1.97748584  0.70712759  1.55012029\n",
      "    0.        ]\n",
      "  [-0.71108946 -0.99725619 -1.95658731  0.69991828  1.54999826\n",
      "    0.        ]\n",
      "  [-0.71142111 -0.99705816 -1.9576821   0.70039375  1.54987536\n",
      "    0.        ]\n",
      "  [-0.71176055 -0.99685533 -1.97952503  0.70802667  1.54975052\n",
      "    0.        ]\n",
      "  [-0.71209799 -0.99665355 -1.9673489   0.70639174  1.54962596\n",
      "    0.        ]\n",
      "  [-0.71242228 -0.99645941 -1.95530018  0.70477391  1.54951852\n",
      "    0.        ]\n",
      "  [-0.71273701 -0.99627079 -1.97945028  0.71310906  1.54943551\n",
      "    0.        ]\n",
      "  [-0.71305196 -0.99608197 -1.97887937  0.71268253  1.54936792\n",
      "    0.        ]\n",
      "  [-0.71336701 -0.99589301 -1.96226957  0.70538471  1.54931559\n",
      "    0.        ]\n",
      "  [-0.7136821  -0.9957039  -1.96802207  0.70668078  1.54927729\n",
      "    0.        ]\n",
      "  [-0.71399753 -0.99551454 -1.96590959  0.70659502  1.54924234\n",
      "    0.        ]\n",
      "  [-0.71431287 -0.99532525 -1.96525807  0.70615787  1.54920809\n",
      "    0.        ]\n",
      "  [-0.71462797 -0.99513617 -1.96731409  0.70865707  1.54917646\n",
      "    0.        ]\n",
      "  [-0.7149431  -0.99494718 -1.97001241  0.71158585  1.5491415\n",
      "    0.        ]\n",
      "  [-0.71525795 -0.99475845 -1.97093055  0.71016485  1.54910328\n",
      "    0.        ]\n",
      "  [-0.71557203 -0.9945702  -1.97283009  0.70925449  1.54906606\n",
      "    0.        ]\n",
      "  [-0.71588573 -0.99438212 -1.96293478  0.70568764  1.54902853\n",
      "    0.        ]\n",
      "  [-0.71619908 -0.99419419 -1.9616031   0.70451995  1.54898866\n",
      "    0.        ]\n",
      "  [-0.71651159 -0.99400676 -1.96068415  0.70380098  1.54894112\n",
      "    0.        ]\n",
      "  [-0.71682352 -0.99381969 -1.9422938   0.69751161  1.54887714\n",
      "    0.        ]\n",
      "  [-0.71713493 -0.99363298 -1.94286955  0.69847612  1.54879302\n",
      "    0.        ]\n",
      "  [-0.71744595 -0.99344652 -1.94038197  0.69846012  1.54869431\n",
      "    0.        ]\n",
      "  [-0.71775666 -0.99326021 -1.92879495  0.69526565  1.54859379\n",
      "    0.        ]\n",
      "  [-0.71806702 -0.99307404 -1.92833018  0.69577792  1.54850448\n",
      "    0.        ]\n",
      "  [-0.71837706 -0.99288804 -1.94663582  0.70231837  1.54842493\n",
      "    0.        ]\n",
      "  [-0.71868704 -0.99270202 -1.93375081  0.69569241  1.5483528\n",
      "    0.        ]\n",
      "  [-0.71899686 -0.99251606 -1.93029117  0.69416705  1.54827868\n",
      "    0.        ]\n",
      "  [-0.71930672 -0.99233014 -1.95486156  0.7029576   1.5482028\n",
      "    0.        ]\n",
      "  [-0.71961676 -0.9921441  -1.94609289  0.70006468  1.54814497\n",
      "    0.        ]\n",
      "  [-0.71992678 -0.991958   -1.94012518  0.6998411   1.54811244\n",
      "    0.        ]\n",
      "  [-0.72023676 -0.99177206 -1.9317138   0.6951637   1.54809564\n",
      "    0.        ]\n",
      "  [-0.72054649 -0.99158645 -1.92346503  0.69057672  1.54808032\n",
      "    0.        ]\n",
      "  [-0.72085589 -0.99140119 -1.93056523  0.6945266   1.54806549\n",
      "    0.        ]\n",
      "  [-0.72116492 -0.99121623 -1.93763484  0.69845945  1.54805419\n",
      "    0.        ]\n",
      "  [-0.72147398 -0.99103131 -1.93037943  0.69311575  1.54804625\n",
      "    0.        ]\n",
      "  [-0.72178289 -0.99084655 -1.93687721  0.69475709  1.54804111\n",
      "    0.        ]\n",
      "  [-0.72209159 -0.99066199 -1.93062612  0.69664982  1.54804115\n",
      "    0.        ]\n",
      "  [-0.7224006  -0.99047728 -1.9244798   0.68884159  1.54804425\n",
      "    0.        ]\n",
      "  [-0.72270998 -0.99029238 -1.92406198  0.68320832  1.54804967\n",
      "    0.        ]\n",
      "  [-0.72301973 -0.99010722 -1.92629506  0.68959082  1.54805784\n",
      "    0.        ]\n",
      "  [-0.72332982 -0.98992189 -1.94218465  0.69876371  1.5480591\n",
      "    0.        ]\n",
      "  [-0.72364015 -0.98973649 -1.9444095   0.69914236  1.54804999\n",
      "    0.        ]\n",
      "  [-0.72395079 -0.98955092 -1.94660404  0.69951586  1.54803223\n",
      "    0.        ]\n",
      "  [-0.7242618  -0.98936504 -1.94128322  0.69712216  1.54800052\n",
      "    0.        ]\n",
      "  [-0.72457311 -0.98917892 -1.94786005  0.69983793  1.54794478\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.1220636   0.38272125  0.50257703 -0.5837064  -0.45043471\n",
      "    0.        ]\n",
      "  [ 0.1221432   0.38255344  0.50257703 -0.5837064  -0.4502248\n",
      "    0.        ]\n",
      "  [ 0.12224249  0.38234419  0.99675034 -1.19150547 -0.44997618\n",
      "    0.        ]\n",
      "  [ 0.12236093  0.38209454  1.02353193 -1.22254153 -0.44969083\n",
      "    0.        ]\n",
      "  [ 0.12249737  0.38180702  1.04453793 -1.24711247 -0.44936983\n",
      "    0.        ]\n",
      "  [ 0.12264997  0.38148547  1.05692479 -1.26432628 -0.44901336\n",
      "    0.        ]\n",
      "  [ 0.12281606  0.38113554  1.07318783 -1.28442036 -0.44863401\n",
      "    0.        ]\n",
      "  [ 0.12299227  0.38076441  1.08586784 -1.29824407 -0.44825426\n",
      "    0.        ]\n",
      "  [ 0.12317457  0.38038064  1.09452212 -1.30896082 -0.44789567\n",
      "    0.        ]\n",
      "  [ 0.12335793  0.37999483  1.1035134  -1.32030275 -0.4475712\n",
      "    0.        ]\n",
      "  [ 0.12353661  0.37961909  1.10943881 -1.32729294 -0.4472946\n",
      "    0.        ]\n",
      "  [ 0.12371195  0.37925055  1.11809127 -1.33631709 -0.44706709\n",
      "    0.        ]\n",
      "  [ 0.12388827  0.37888008  1.12977766 -1.34964367 -0.44687628\n",
      "    0.        ]\n",
      "  [ 0.1240654   0.37850807  1.13846145 -1.35963511 -0.4467175\n",
      "    0.        ]\n",
      "  [ 0.124243    0.37813518  1.13862421 -1.35858883 -0.4465873\n",
      "    0.        ]\n",
      "  [ 0.1244208   0.37776195  1.14594255 -1.36497352 -0.44648577\n",
      "    0.        ]\n",
      "  [ 0.12459866  0.37738861  1.14662806 -1.36771043 -0.4464233\n",
      "    0.        ]\n",
      "  [ 0.12477648  0.37701532  1.13578603 -1.35685759 -0.44640193\n",
      "    0.        ]\n",
      "  [ 0.12495412  0.37664224  1.13902929 -1.36053321 -0.4464175\n",
      "    0.        ]\n",
      "  [ 0.12513144  0.3762696   1.13754724 -1.35996243 -0.44646053\n",
      "    0.        ]\n",
      "  [ 0.12530833  0.37589757  1.13359987 -1.35427449 -0.44651428\n",
      "    0.        ]\n",
      "  [ 0.12548473  0.37552628  1.12165162 -1.34133531 -0.4465712\n",
      "    0.        ]\n",
      "  [ 0.12566066  0.37515572  1.11569083 -1.3364627  -0.44662687\n",
      "    0.        ]\n",
      "  [ 0.12583626  0.37478562  1.12415219 -1.345445   -0.44667688\n",
      "    0.        ]\n",
      "  [ 0.12601167  0.37441577  1.12732365 -1.35147454 -0.44672644\n",
      "    0.        ]\n",
      "  [ 0.12618691  0.3740462   1.12582964 -1.35353796 -0.44678189\n",
      "    0.        ]\n",
      "  [ 0.1263623   0.37367629  1.12399797 -1.3497337  -0.44683426\n",
      "    0.        ]\n",
      "  [ 0.12653787  0.37330598  1.12204492 -1.34603586 -0.44687618\n",
      "    0.        ]\n",
      "  [ 0.12671359  0.37293535  1.12396874 -1.34739041 -0.44690547\n",
      "    0.        ]\n",
      "  [ 0.12688968  0.37256398  1.12523626 -1.34710995 -0.44692421\n",
      "    0.        ]\n",
      "  [ 0.12706599  0.37219227  1.12635618 -1.34841885 -0.44693479\n",
      "    0.        ]\n",
      "  [ 0.12724238  0.37182056  1.13373134 -1.35748591 -0.4469394\n",
      "    0.        ]\n",
      "  [ 0.12741897  0.37144865  1.13409068 -1.35787619 -0.44694484\n",
      "    0.        ]\n",
      "  [ 0.12759567  0.37107672  1.12859931 -1.35153897 -0.44694666\n",
      "    0.        ]\n",
      "  [ 0.12777254  0.37070463  1.14268712 -1.36815054 -0.44693766\n",
      "    0.        ]\n",
      "  [ 0.12794957  0.37033234  1.1319074  -1.35436597 -0.44692409\n",
      "    0.        ]\n",
      "  [ 0.12812651  0.36996033  1.12357282 -1.3436541  -0.44691544\n",
      "    0.        ]\n",
      "  [ 0.12830321  0.36958896  1.13421382 -1.35509904 -0.44691041\n",
      "    0.        ]\n",
      "  [ 0.12847951  0.36921851  1.1201289  -1.33693869 -0.44690298\n",
      "    0.        ]\n",
      "  [ 0.1286552   0.36884938  1.13161289 -1.34954882 -0.44689766\n",
      "    0.        ]\n",
      "  [ 0.12883004  0.36848209  1.13296214 -1.3521502  -0.4468978\n",
      "    0.        ]\n",
      "  [ 0.12900401  0.36811672  1.11076948 -1.32699538 -0.44689506\n",
      "    0.        ]\n",
      "  [ 0.12917697  0.36775361  1.11314591 -1.3279897  -0.44689106\n",
      "    0.        ]\n",
      "  [ 0.12934863  0.36739331  1.10156781 -1.31301507 -0.44689618\n",
      "    0.        ]\n",
      "  [ 0.12951917  0.36703549  1.08530542 -1.29423948 -0.44691594\n",
      "    0.        ]\n",
      "  [ 0.12968822  0.36668091  1.08094747 -1.2891503  -0.44695433\n",
      "    0.        ]\n",
      "  [ 0.12985532  0.36633042  1.06873808 -1.27549427 -0.44699834\n",
      "    0.        ]\n",
      "  [ 0.13002047  0.36598401  1.05697467 -1.25922184 -0.44704671\n",
      "    0.        ]\n",
      "  [ 0.13018347  0.36564216  1.04641427 -1.24248708 -0.44711814\n",
      "    0.        ]\n",
      "  [ 0.13034436  0.36530489  1.03954786 -1.23315502 -0.44720613\n",
      "    0.        ]]]\n",
      "[[[-1.96812164  0.71590395]\n",
      "  [-1.97190249  0.71840515]\n",
      "  [-1.97384426  0.7198796 ]\n",
      "  [-1.97460216  0.7203427 ]\n",
      "  [-1.97518899  0.72099183]\n",
      "  [-1.97694366  0.72258751]\n",
      "  [-1.97846696  0.72416356]\n",
      "  [-1.97878372  0.72508395]\n",
      "  [-1.97829565  0.7257909 ]\n",
      "  [-1.97878772  0.72674942]\n",
      "  [-1.97921048  0.72728866]\n",
      "  [-1.97945265  0.72711156]\n",
      "  [-1.97992876  0.72638087]\n",
      "  [-1.9797324   0.72529666]\n",
      "  [-1.97857664  0.72396064]\n",
      "  [-1.97799542  0.72275061]\n",
      "  [-1.9781885   0.72167831]\n",
      "  [-1.97899065  0.72098477]\n",
      "  [-1.97969358  0.72038337]\n",
      "  [-1.97844913  0.71891564]\n",
      "  [-1.97618648  0.717063  ]\n",
      "  [-1.97546851  0.71592908]\n",
      "  [-1.97563726  0.71547718]\n",
      "  [-1.97583048  0.7155433 ]\n",
      "  [-1.97433383  0.71514861]\n",
      "  [-1.97165894  0.71455007]\n",
      "  [-1.97081659  0.71498484]\n",
      "  [-1.9702037   0.7152544 ]\n",
      "  [-1.96878986  0.71491544]\n",
      "  [-1.9663514   0.71405657]\n",
      "  [-1.96336485  0.71310302]\n",
      "  [-1.95984669  0.71232488]\n",
      "  [-1.95572305  0.71122208]\n",
      "  [-1.95170454  0.70983633]\n",
      "  [-1.94670496  0.7079337 ]\n",
      "  [-1.94002034  0.70534472]\n",
      "  [-1.93305529  0.70224651]\n",
      "  [-1.92633201  0.69933539]\n",
      "  [-1.91902589  0.69668677]\n",
      "  [-1.91233894  0.69434851]\n",
      "  [-1.90555683  0.69219029]\n",
      "  [-1.89882087  0.68984514]\n",
      "  [-1.89059991  0.68691693]\n",
      "  [-1.88161432  0.68422562]\n",
      "  [-1.87411459  0.68192085]\n",
      "  [-1.86519585  0.67863131]\n",
      "  [-1.85388915  0.67456137]\n",
      "  [-1.84234306  0.67012733]\n",
      "  [-1.83151606  0.66576576]\n",
      "  [-1.82114456  0.66158277]\n",
      "  [-1.86248299  0.67464965]\n",
      "  [-1.92217253  0.69368099]\n",
      "  [-1.9204867   0.69159979]\n",
      "  [-1.86556663  0.67133723]\n",
      "  [-1.76597689  0.63591876]\n",
      "  [-1.62814305  0.58792067]\n",
      "  [-1.45983114  0.52977049]\n",
      "  [-1.27063431  0.4643938 ]\n",
      "  [-1.06787792  0.39449462]\n",
      "  [-0.85845398  0.32230614]]\n",
      "\n",
      " [[ 1.02985222 -1.21223871]\n",
      "  [ 1.0136221  -1.19313035]\n",
      "  [ 0.99786527 -1.17423091]\n",
      "  [ 0.98177352 -1.15443248]\n",
      "  [ 0.96421454 -1.13305841]\n",
      "  [ 0.94601226 -1.111233  ]\n",
      "  [ 0.92661173 -1.08810179]\n",
      "  [ 0.90624336 -1.06370352]\n",
      "  [ 0.88541295 -1.03825517]\n",
      "  [ 0.86462787 -1.01260422]\n",
      "  [ 0.84216623 -0.98515707]\n",
      "  [ 0.8190343  -0.95694615]\n",
      "  [ 0.79560737 -0.92853776]\n",
      "  [ 0.77103428 -0.89919882]\n",
      "  [ 0.74642491 -0.86995493]\n",
      "  [ 0.72264932 -0.841582  ]\n",
      "  [ 0.69942809 -0.81368283]\n",
      "  [ 0.67493384 -0.7845264 ]\n",
      "  [ 0.65057097 -0.75595461]\n",
      "  [ 0.62719326 -0.72834375]\n",
      "  [ 0.60457254 -0.70102631]\n",
      "  [ 0.58245443 -0.6738996 ]\n",
      "  [ 0.56004598 -0.64659809]\n",
      "  [ 0.53748328 -0.61921764]\n",
      "  [ 0.51482695 -0.59157712]\n",
      "  [ 0.49261764 -0.56409897]\n",
      "  [ 0.47115007 -0.53705499]\n",
      "  [ 0.44870679 -0.508924  ]\n",
      "  [ 0.42583438 -0.48043672]\n",
      "  [ 0.40401606 -0.45341906]\n",
      "  [ 0.38293368 -0.42753604]\n",
      "  [ 0.36260138 -0.40237139]\n",
      "  [ 0.34286815 -0.37771955]\n",
      "  [ 0.32391944 -0.35414131]\n",
      "  [ 0.30521358 -0.33091617]\n",
      "  [ 0.2870805  -0.30842882]\n",
      "  [ 0.26990945 -0.28727638]\n",
      "  [ 0.2533726  -0.26690294]\n",
      "  [ 0.23764196 -0.24736566]\n",
      "  [ 0.22270181 -0.22873604]\n",
      "  [ 0.20868203 -0.21148107]\n",
      "  [ 0.19541093 -0.19539425]\n",
      "  [ 0.18306308 -0.18030007]\n",
      "  [ 0.17160527 -0.16582017]\n",
      "  [ 0.16047288 -0.15167671]\n",
      "  [ 0.14941119 -0.13788615]\n",
      "  [ 0.13981914 -0.12592336]\n",
      "  [ 0.13105676 -0.11498419]\n",
      "  [ 0.12262166 -0.10432114]\n",
      "  [ 0.11447551 -0.09379431]\n",
      "  [ 0.10797765 -0.08545745]\n",
      "  [ 0.10212411 -0.07815658]\n",
      "  [ 0.09498576 -0.06930507]\n",
      "  [ 0.08744316 -0.06010331]\n",
      "  [ 0.07914445 -0.05002838]\n",
      "  [ 0.07083261 -0.03988139]\n",
      "  [ 0.06259773 -0.02989902]\n",
      "  [ 0.0546814  -0.02041338]\n",
      "  [ 0.04743654 -0.01175847]\n",
      "  [ 0.04053554 -0.00349276]]]\n",
      "\n",
      "--- Phase 1: Training ---\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 25s 70ms/step - loss: 0.3009 - mae: 0.3692 - val_loss: 0.1893 - val_mae: 0.2956 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.1552 - mae: 0.2624 - val_loss: 0.1465 - val_mae: 0.2562 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.1336 - mae: 0.2403 - val_loss: 0.1449 - val_mae: 0.2522 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.1258 - mae: 0.2320 - val_loss: 0.1186 - val_mae: 0.2200 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.1158 - mae: 0.2197 - val_loss: 0.1318 - val_mae: 0.2319 - lr: 0.0010\n",
      "Learning rate update: 0.0009000000427477062\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.1106 - mae: 0.2113 - val_loss: 0.1022 - val_mae: 0.2031 - lr: 9.0000e-04\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.1062 - mae: 0.2068 - val_loss: 0.1063 - val_mae: 0.2074 - lr: 9.0000e-04\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.1044 - mae: 0.2055 - val_loss: 0.1086 - val_mae: 0.2068 - lr: 9.0000e-04\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.1018 - mae: 0.2016 - val_loss: 0.1000 - val_mae: 0.1975 - lr: 9.0000e-04\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.0975 - mae: 0.1958 - val_loss: 0.0941 - val_mae: 0.1865 - lr: 9.0000e-04\n",
      "Learning rate update: 0.0008100000384729356\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 13s 51ms/step - loss: 0.0932 - mae: 0.1897 - val_loss: 0.0901 - val_mae: 0.1790 - lr: 8.1000e-04\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 13s 52ms/step - loss: 0.0912 - mae: 0.1876 - val_loss: 0.0879 - val_mae: 0.1828 - lr: 8.1000e-04\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 13s 54ms/step - loss: 0.0897 - mae: 0.1867 - val_loss: 0.0936 - val_mae: 0.1961 - lr: 8.1000e-04\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.0923 - mae: 0.1903 - val_loss: 0.0914 - val_mae: 0.1862 - lr: 8.1000e-04\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.0873 - mae: 0.1834 - val_loss: 0.0891 - val_mae: 0.1856 - lr: 8.1000e-04\n",
      "Learning rate update: 0.0007290000503417104\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 13s 51ms/step - loss: 0.0847 - mae: 0.1801 - val_loss: 0.0893 - val_mae: 0.1844 - lr: 7.2900e-04\n",
      "\n",
      "--- Phase 2: Fine-tuning ---\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 22s 61ms/step - loss: 0.0770 - mae: 0.1640 - val_loss: 0.0793 - val_mae: 0.1576 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.0744 - mae: 0.1602 - val_loss: 0.0762 - val_mae: 0.1623 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 13s 52ms/step - loss: 0.0730 - mae: 0.1586 - val_loss: 0.0769 - val_mae: 0.1619 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 13s 52ms/step - loss: 0.0725 - mae: 0.1581 - val_loss: 0.0772 - val_mae: 0.1619 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 13s 54ms/step - loss: 0.0708 - mae: 0.1555 - val_loss: 0.0749 - val_mae: 0.1583 - lr: 1.0000e-04\n",
      "Learning rate update: 8.999999772640876e-05\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.0689 - mae: 0.1527 - val_loss: 0.0730 - val_mae: 0.1547 - lr: 9.0000e-05\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.0673 - mae: 0.1506 - val_loss: 0.0731 - val_mae: 0.1575 - lr: 9.0000e-05\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.0665 - mae: 0.1496 - val_loss: 0.0705 - val_mae: 0.1536 - lr: 9.0000e-05\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.0650 - mae: 0.1483 - val_loss: 0.0698 - val_mae: 0.1512 - lr: 9.0000e-05\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 13s 52ms/step - loss: 0.0647 - mae: 0.1477 - val_loss: 0.0707 - val_mae: 0.1525 - lr: 9.0000e-05\n",
      "Model saved to lstm_1.pkl\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model, X_mean, X_std, y_mean, y_std = train_model(train_data)\n",
    "\n",
    "# Save the model \n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8bf6a02ebcd4b24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T01:01:38.098690Z",
     "start_time": "2025-05-03T01:01:38.097196Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def evaluate_mse(train_data, model, Tobs=50, Tpred=60):\n",
    "    \"\"\"\n",
    "    Computes LSTM prediction for ego agent and evaluates MSE with progress reporting.\n",
    "    \"\"\"\n",
    "    N = train_data.shape[0]\n",
    "    mse_list = []\n",
    "    valid_scenarios = 0\n",
    "    \n",
    "    print(f\"Evaluating {N} scenarios...\")\n",
    "    \n",
    "    # Progress reporting variables\n",
    "    report_interval = max(1, N // 10)  # Report at 10% intervals\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Progress reporting\n",
    "        if i % report_interval == 0 or i == N-1:\n",
    "            print(f\"Processing scenario {i+1}/{N} ({(i+1)/N*100:.1f}%)\")\n",
    "        \n",
    "        scenario_data = train_data[i]\n",
    "        ego_agent_data = scenario_data[0]\n",
    "        ground_truth = ego_agent_data[Tobs:Tobs+Tpred, :2]\n",
    "        \n",
    "        # Skip if ground truth contains all zeros (padded)\n",
    "        if np.all(ground_truth == 0):\n",
    "            continue\n",
    "            \n",
    "        valid_scenarios += 1\n",
    "        \n",
    "        # Forecast future positions\n",
    "        predicted_positions = forecast_positions(\n",
    "            ego_agent_data[np.newaxis, :, :],\n",
    "            Tobs, Tpred, model, X_mean, X_std, y_mean, y_std\n",
    "        )\n",
    "        \n",
    "        # Compute MSE\n",
    "        mse = mean_squared_error(ground_truth, predicted_positions[0])\n",
    "        mse_list.append(mse)\n",
    "        \n",
    "        # Occasional MSE reporting\n",
    "        if i % report_interval == 0:\n",
    "            print(f\"  Current scenario MSE: {mse:.4f}\")\n",
    "    \n",
    "    # Final results\n",
    "    if mse_list:\n",
    "        overall_mse = np.mean(mse_list)\n",
    "        print(f\"Evaluation complete: {valid_scenarios} valid scenarios\")\n",
    "        print(f\"Mean Squared Error (MSE): {overall_mse:.4f}\")\n",
    "        print(f\"Min MSE: {np.min(mse_list):.4f}, Max MSE: {np.max(mse_list):.4f}\")\n",
    "        return overall_mse\n",
    "    else:\n",
    "        print(\"No valid scenarios for evaluation.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ae1b88910d7e8bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T01:12:28.986816Z",
     "start_time": "2025-05-03T01:04:00.357291Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 10000 scenarios...\n",
      "Processing scenario 1/10000 (0.0%)\n",
      "  Current scenario MSE: 2.5592\n",
      "Processing scenario 1001/10000 (10.0%)\n",
      "  Current scenario MSE: 6.0317\n",
      "Processing scenario 2001/10000 (20.0%)\n",
      "  Current scenario MSE: 0.1976\n",
      "Processing scenario 3001/10000 (30.0%)\n",
      "  Current scenario MSE: 0.6533\n",
      "Processing scenario 4001/10000 (40.0%)\n",
      "  Current scenario MSE: 0.0505\n",
      "Processing scenario 5001/10000 (50.0%)\n",
      "  Current scenario MSE: 9.2404\n",
      "Processing scenario 6001/10000 (60.0%)\n",
      "  Current scenario MSE: 65.1291\n",
      "Processing scenario 7001/10000 (70.0%)\n",
      "  Current scenario MSE: 10.1526\n",
      "Processing scenario 8001/10000 (80.0%)\n",
      "  Current scenario MSE: 4.5517\n",
      "Processing scenario 9001/10000 (90.0%)\n",
      "  Current scenario MSE: 0.2270\n",
      "Processing scenario 10000/10000 (100.0%)\n",
      "Evaluation complete: 10000 valid scenarios\n",
      "Mean Squared Error (MSE): 8.5850\n",
      "Min MSE: 0.0034, Max MSE: 201.9208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.584998066779487"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on training data\n",
    "evaluate_mse(train_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbc4fc43197afaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T06:16:59.708670Z",
     "start_time": "2025-05-03T06:15:13.300547Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'lstm_submission.csv' saved with shape (126000, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_submission(data, output_csv, Tobs=50, Tpred=60):\n",
    "    \"\"\"\n",
    "    Applies forecasting and generates a submission CSV with format:\n",
    "    index,x,y where index is auto-generated and matches submission key.\n",
    "    \n",
    "    Args:\n",
    "        data (np.ndarray): Test data of shape (num_scenarios, 50, 50, 6).\n",
    "        output_csv (str): Output CSV file path.\n",
    "        Tobs (int): Observed time steps (default 50).\n",
    "        Tpred (int): Prediction time steps (default 60).\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        scenario_data = data[i]            # Shape: (50, 50, 6)\n",
    "        \n",
    "        # Step 1: Standardize the scene data\n",
    "        standardized_scenario, min_values = standardize_data_dimensions(scenario_data)\n",
    "        \n",
    "        # Extract ego agent data from standardized scenario\n",
    "        ego_agent_data = standardized_scenario[0]  # Shape: (50, 6)\n",
    "\n",
    "        # Step 2: Predict future positions for the ego agent using standardized data\n",
    "        predicted_positions = forecast_positions(\n",
    "            ego_agent_data[np.newaxis, :, :], Tobs, Tpred, model, X_mean, X_std, y_mean, y_std\n",
    "        )  # Shape: (1, 60, 2)\n",
    "\n",
    "        # Step 3: Denormalize the predictions to restore original coordinate system\n",
    "        # Create a dummy array with the same structure as the standardized data for denormalization\n",
    "        # We only need to denormalize the x,y positions (first 2 columns)\n",
    "        dummy_predictions = np.zeros((1, Tpred, 6))  # Shape: (1, 60, 6)\n",
    "        dummy_predictions[0, :, :2] = predicted_positions[0]  # Insert predicted x,y positions\n",
    "        \n",
    "        # Denormalize the predictions\n",
    "        denormalized_predictions = denormalize_predictions(dummy_predictions, min_values)\n",
    "        \n",
    "        # Extract only the x,y positions from denormalized predictions\n",
    "        final_positions = denormalized_predictions[0, :, :2]  # Shape: (60, 2)\n",
    "\n",
    "        # Append 60 predictions (x, y) for this scenario\n",
    "        predictions.extend(final_positions)  # Shape: (60, 2)\n",
    "\n",
    "    # Create DataFrame without explicit ID\n",
    "    submission_df = pd.DataFrame(predictions, columns=[\"x\", \"y\"])\n",
    "    submission_df.index.name = 'index'  # Match Kaggle format\n",
    "\n",
    "    # Save CSV with index\n",
    "    submission_df.to_csv(output_csv)\n",
    "    print(f\"Submission file '{output_csv}' saved with shape {submission_df.shape}\")\n",
    "\n",
    "# Generate submission with standardization\n",
    "generate_submission(test_data, 'lstm_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6d7a17d8677e1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
