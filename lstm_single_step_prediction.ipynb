{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:39:48.351326Z",
     "start_time": "2025-05-28T04:39:46.230812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape (10000, 50, 110, 6)\n",
      "test_data's shape (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import numpy as np\n",
    "train_file = np.load('data/train.npz')\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape\", train_data.shape)\n",
    "test_file = np.load('data/test_input.npz')\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, RepeatVector, TimeDistributed, Dropout"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:39:48.430898Z",
     "start_time": "2025-05-28T04:39:48.371917Z"
    }
   },
   "id": "db97d754762b390b",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def standardize_data_dimensions(scenario_data):\n",
    "    \"\"\"\n",
    "    Standardize position data by centering a single scenario at the origin.\n",
    "    \n",
    "    :param scenario_data: numpy array of shape (50, 110, 6)\n",
    "                         where dimensions are [position_x, position_y, velocity_x, velocity_y, heading, object_type]\n",
    "    :returns: tuple of (standardized_data, min_values)\n",
    "             - standardized_data: same shape as input with centered positions\n",
    "             - min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    \"\"\"\n",
    "    # Copy the data to avoid modifying the original\n",
    "    standardized_data = scenario_data.copy()\n",
    "    \n",
    "    # Extract position data (first 2 dimensions)\n",
    "    positions = scenario_data[:, :, :2]  # Shape: (50, 110, 2)\n",
    "    \n",
    "    # Create mask for non-zero positions (to ignore padding)\n",
    "    # We consider a position valid if it's not (0,0) or if the object_type is not 0\n",
    "    object_types = scenario_data[:, :, 5]  # Shape: (50, 110)\n",
    "    valid_mask = (positions[:, :, 0] != 0) | (positions[:, :, 1] != 0) | (object_types != 0)\n",
    "    \n",
    "    # Find min values across all valid positions in this scenario\n",
    "    if np.any(valid_mask):\n",
    "        valid_positions = positions[valid_mask]  # Shape: (num_valid_points, 2)\n",
    "        min_x = np.min(valid_positions[:, 0])\n",
    "        min_y = np.min(valid_positions[:, 1])\n",
    "    else:\n",
    "        # If no valid positions found, use 0 as min values\n",
    "        min_x = 0\n",
    "        min_y = 0\n",
    "    \n",
    "    # Store min values\n",
    "    min_values = np.array([min_x, min_y])\n",
    "    \n",
    "    # Standardize positions by subtracting min values\n",
    "    # Only modify non-zero positions to preserve padding\n",
    "    for agent_idx in range(scenario_data.shape[0]):\n",
    "        for time_idx in range(scenario_data.shape[1]):\n",
    "            if valid_mask[agent_idx, time_idx]:\n",
    "                standardized_data[agent_idx, time_idx, 0] -= min_x  # position_x\n",
    "                standardized_data[agent_idx, time_idx, 1] -= min_y  # position_y\n",
    "    \n",
    "    return standardized_data, min_values\n",
    "\n",
    "\n",
    "def denormalize_predictions(predictions, min_values):\n",
    "    \"\"\"\n",
    "    Helper function to add back the min values to predicted positions.\n",
    "    \n",
    "    :param predictions: predicted data with standardized positions, shape (50, 110, 6) or similar\n",
    "    :param min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    :returns: predictions with original coordinate system restored\n",
    "    \"\"\"\n",
    "    denormalized = predictions.copy()\n",
    "    \n",
    "    # Add back the min values to restore original coordinate system\n",
    "    # Assuming predictions have position_x and position_y as first two dimensions\n",
    "    denormalized[:, :, 0] += min_values[0]  # position_x\n",
    "    denormalized[:, :, 1] += min_values[1]  # position_y\n",
    "    \n",
    "    return denormalized"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T05:26:20.322700Z",
     "start_time": "2025-05-28T05:26:20.319327Z"
    }
   },
   "id": "608ceed4f8ac038d",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "def standardize_single_scene(scene_data):\n",
    "    \"\"\"\n",
    "    Wrapper function to standardize a single scene and return both standardized data and min values.\n",
    "    This function will be called in parallel.\n",
    "    \"\"\"\n",
    "    standardized_scene, min_vals = standardize_data_dimensions(scene_data)\n",
    "    return standardized_scene, min_vals\n",
    "\n",
    "def parallel_standardize_training_data(train_data, n_jobs=-1, verbose=True):\n",
    "    \"\"\"\n",
    "    Parallelize the standardization of training data across all scenes.\n",
    "    \n",
    "    :param train_data: numpy array of shape (10000, 50, 110, 6)\n",
    "    :param n_jobs: number of parallel jobs (-1 uses all available cores)\n",
    "    :param verbose: whether to show progress bar\n",
    "    :returns: tuple of (standardized_data, min_values_array)\n",
    "    \"\"\"\n",
    "    print(f\"Standardizing {train_data.shape[0]} scenes using {multiprocessing.cpu_count() if n_jobs == -1 else n_jobs} cores...\")\n",
    "    \n",
    "    # Use joblib to parallelize the processing\n",
    "    if verbose:\n",
    "        # With progress bar\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(standardize_single_scene)(train_data[i]) \n",
    "            for i in tqdm(range(train_data.shape[0]), desc=\"Processing scenes\")\n",
    "        )\n",
    "    else:\n",
    "        # Without progress bar\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(standardize_single_scene)(train_data[i]) \n",
    "            for i in range(train_data.shape[0])\n",
    "        )\n",
    "    \n",
    "    # Unpack results\n",
    "    standardized_scenes, min_values_list = zip(*results)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    standardized_data = np.array(standardized_scenes)\n",
    "    min_values_array = np.array(min_values_list)\n",
    "    \n",
    "    print(f\"Standardization complete!\")\n",
    "    print(f\"Standardized data shape: {standardized_data.shape}\")\n",
    "    print(f\"Min values shape: {min_values_array.shape}\")\n",
    "    \n",
    "    return standardized_data, min_values_array"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T05:26:31.711457Z",
     "start_time": "2025-05-28T05:26:31.673587Z"
    }
   },
   "id": "504b76013f59f796",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing 10000 scenes using 8 cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing scenes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:11<00:00, 898.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardization complete!\n",
      "Standardized data shape: (10000, 50, 110, 6)\n",
      "Min values shape: (10000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(10000, 50, 110, 6)"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_train_data, min_values = parallel_standardize_training_data(\n",
    "    train_data, \n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=True\n",
    ")\n",
    "standardized_train_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T05:26:47.695795Z",
     "start_time": "2025-05-28T05:26:33.156061Z"
    }
   },
   "id": "bd9c62ee33aa23fb",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(model, filepath='lstm_single_step.pkl', \n",
    "               X_mean=None, X_std=None, y_mean=None, y_std=None):\n",
    "    \"\"\"Save model architecture, weights, and normalization parameters to a pickle file\"\"\"\n",
    "    model_json = model.to_json()\n",
    "    model_weights = model.get_weights()\n",
    "    data = {\n",
    "        'model_json': model_json,\n",
    "        'model_weights': model_weights,\n",
    "        'X_mean': X_mean,\n",
    "        'X_std': X_std,\n",
    "        'y_mean': y_mean,\n",
    "        'y_std': y_std,\n",
    "    }\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Model and normalization parameters saved to {filepath}\")\n",
    "\n",
    "\n",
    "def load_model(filepath='lstm_single_step.pkl'):\n",
    "    \"\"\"Load model and normalization parameters from a pickle file\"\"\"\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    # Reconstruct model\n",
    "    model = tf.keras.models.model_from_json(data['model_json'])\n",
    "    model.set_weights(data['model_weights'])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Return model and normalization parameters\n",
    "    return model, data['X_mean'], data['X_std'], data['y_mean'], data['y_std']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:39:52.509504Z",
     "start_time": "2025-05-28T04:39:52.476980Z"
    }
   },
   "id": "e3d667b335d4a0a",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input, LSTM, Dense, Dropout, TimeDistributed, Attention, Concatenate,\n",
    "    RepeatVector\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def old_model(\n",
    "    input_dim, output_dim, timesteps_in, timesteps_out,\n",
    "    lstm_units=64, num_layers=1, loss_fn='mse', lr=0.001\n",
    "):\n",
    "    # --- Input and Learnable Feature Weighting ---\n",
    "    encoder_inputs = Input(shape=(timesteps_in, input_dim))  # shape: (batch, Tobs, 6)\n",
    "    weighted_inputs = TimeDistributed(Dense(input_dim, activation=None))(encoder_inputs)\n",
    "\n",
    "    # --- Encoder ---\n",
    "    x = weighted_inputs\n",
    "    for _ in range(num_layers):\n",
    "        x = LSTM(lstm_units, return_sequences=True)(x)\n",
    "    encoder_outputs = x  # shape: (batch, Tobs, lstm_units)\n",
    "\n",
    "    # --- Decoder ---\n",
    "    decoder_input = RepeatVector(timesteps_out)(encoder_outputs[:, -1, :])\n",
    "    decoder_outputs = decoder_input\n",
    "    for _ in range(num_layers):\n",
    "        decoder_outputs = LSTM(lstm_units, return_sequences=True)(decoder_outputs)\n",
    "\n",
    "    # --- Attention ---\n",
    "    # attention = Attention()([decoder_outputs, encoder_outputs])\n",
    "    # x = Concatenate()([decoder_outputs, attention])\n",
    "\n",
    "    # --- Dense Layers ---\n",
    "    x = TimeDistributed(Dense(128, activation='relu'))(x)\n",
    "    x = TimeDistributed(Dense(64, activation='relu'))(x)\n",
    "    outputs = TimeDistributed(Dense(output_dim))(x)\n",
    "\n",
    "    model = Model(encoder_inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr, clipnorm=.5), loss=loss_fn, metrics=['mae'])\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:39:54.817522Z",
     "start_time": "2025-05-28T04:39:54.801549Z"
    }
   },
   "id": "d7f20fc814e583a3",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:39:55.746165Z",
     "start_time": "2025-05-28T04:39:55.702963Z"
    }
   },
   "id": "21f1db9fa58aef3",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_single_step_model(input_dim, timesteps_in, lstm_units=256, num_layers=1, loss_fn='mse', lr=0.001):\n",
    "    \"\"\"\n",
    "    Simplified model for single-step prediction.\n",
    "    Input: (batch, timesteps, features)\n",
    "    Output: (batch, 2) - single delta prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input\n",
    "    inputs = Input(shape=(timesteps_in, input_dim))\n",
    "    \n",
    "    # LSTM layers\n",
    "    x = inputs\n",
    "    for i in range(num_layers):\n",
    "        return_sequences = (i < num_layers - 1)  # Return sequences for all but last layer\n",
    "        x = LSTM(lstm_units, return_sequences=return_sequences, dropout=0.1)(x)\n",
    "    \n",
    "    # Dense layers for final prediction\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    outputs = Dense(2)(x)  # Predict single delta (x, y)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss=loss_fn, metrics=['mae'])\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:39:57.517696Z",
     "start_time": "2025-05-28T04:39:57.498185Z"
    }
   },
   "id": "932c0ab6efa77756",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.src.callbacks import LearningRateScheduler, EarlyStopping, Callback\n",
    "from keras.src.optimizers import Adam\n",
    "from keras import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class DynamicReduceLROnPlateau(Callback):\n",
    "    def __init__(self, factor=0.5, patience=3, min_lr=1e-6, verbose=1):\n",
    "        super().__init__()\n",
    "        self.factor = factor\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.verbose = verbose\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        current_val_loss = logs.get(\"val_loss\")\n",
    "\n",
    "        if current_val_loss is None:\n",
    "            return  # can't do anything if val_loss isn't available\n",
    "\n",
    "        if current_val_loss < self.best_val_loss - 1e-4:  # a small delta\n",
    "            self.best_val_loss = current_val_loss\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                old_lr = float(self.model.optimizer.learning_rate.numpy())\n",
    "                if old_lr > self.min_lr:\n",
    "                    new_lr = max(old_lr * self.factor, self.min_lr)\n",
    "                    self.model.optimizer.learning_rate.assign(new_lr)\n",
    "                    if self.verbose:\n",
    "                        print(f\"\\nEpoch {epoch+1}: val_loss did not improve. Reducing LR from {old_lr:.6f} to {new_lr:.6f}\")\n",
    "                    self.wait = 0  # reset after LR reduction\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:39:58.479828Z",
     "start_time": "2025-05-28T04:39:58.458275Z"
    }
   },
   "id": "4d68034c165292c5",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LRThresholdCallback(Callback):\n",
    "    def __init__(self, threshold=9e-5):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "        self.should_stop = False\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = float(self.model.optimizer.learning_rate.numpy())\n",
    "        if lr < self.threshold:\n",
    "            print(f\"\\nLearning rate {lr:.6f} < threshold {self.threshold}, moving to Phase 2.\")\n",
    "            self.model.stop_training = True\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:39:59.542959Z",
     "start_time": "2025-05-28T04:39:59.509814Z"
    }
   },
   "id": "3d4199e38cacc23e",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class GradientMonitoringCallback(Callback):\n",
    "    def __init__(self, clip_min=1e-4, clip_max=1e2, monitor_frequency=3):\n",
    "        \"\"\"\n",
    "        Monitor gradient norms during training\n",
    "        \n",
    "        Args:\n",
    "            clip_min: Minimum threshold for gradient norms\n",
    "            clip_max: Maximum threshold for gradient norms  \n",
    "            monitor_frequency: How often to check gradients (every N batches)\n",
    "        \"\"\"\n",
    "        print(f\"üîß GradientMonitoringCallback initialized with clip_min={clip_min}, clip_max={clip_max}, monitor_freq={monitor_frequency}\")\n",
    "        self.clip_min = clip_min\n",
    "        self.clip_max = clip_max\n",
    "        self.monitor_frequency = monitor_frequency\n",
    "        self.batch_count = 0\n",
    "        self.total_calls = 0\n",
    "        self.gradient_checks = 0\n",
    "        self.fallback_calls = 0\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        print(\"üöÄ GradientMonitoringCallback: Training started!\")\n",
    "        self.batch_count = 0\n",
    "        self.total_calls = 0\n",
    "        self.gradient_checks = 0\n",
    "        self.fallback_calls = 0\n",
    "        \n",
    "    # def on_epoch_begin(self, epoch, logs=None):\n",
    "    #     print(f\"üìç GradientMonitoringCallback: Starting epoch {epoch + 1}\")\n",
    "        \n",
    "    # def on_train_batch_begin(self, batch, logs=None):\n",
    "    #     # Just to prove we're being called\n",
    "    #     if batch % 50 == 0:  # Print every 50 batches to avoid spam\n",
    "    #         print(f\"‚ö° GradientMonitoringCallback: Batch {batch} starting\")\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.batch_count += 1\n",
    "        self.total_calls += 1\n",
    "        \n",
    "        # Print every time to show we're being called\n",
    "        # if batch % 50 == 0:  # Print every 50 batches\n",
    "            # print(f\"üìä GradientMonitoringCallback: Batch {batch} ended (total calls: {self.total_calls})\")\n",
    "        \n",
    "        # Only monitor every N batches to avoid performance overhead\n",
    "        if self.batch_count % self.monitor_frequency != 0:\n",
    "            return\n",
    "            \n",
    "        # print(f\"üîç GradientMonitoringCallback: Checking gradients at batch {batch} (check #{self.gradient_checks + 1})\")\n",
    "        \n",
    "        # Get gradients from the optimizer's current state\n",
    "        try:\n",
    "            # Access the model's optimizer to get gradient information\n",
    "            optimizer = self.model.optimizer\n",
    "            print(f\"   üìã Optimizer type: {type(optimizer).__name__}\")\n",
    "            \n",
    "            # Get trainable variables\n",
    "            trainable_vars = self.model.trainable_variables\n",
    "            print(f\"   üìà Number of trainable variables: {len(trainable_vars)}\")\n",
    "            \n",
    "            if hasattr(optimizer, 'get_gradients'):\n",
    "                print(\"   ‚úÖ Optimizer has get_gradients method\")\n",
    "                # For some optimizers, we can access gradients directly\n",
    "                grads = optimizer.get_gradients(self.model.total_loss, trainable_vars)\n",
    "                print(f\"   üìä Retrieved {len([g for g in grads if g is not None])} gradients\")\n",
    "            else:\n",
    "                print(\"   ‚ùå Optimizer doesn't have get_gradients, using variable norms\")\n",
    "                # Alternative approach: check the current variable states\n",
    "                grad_norms = []\n",
    "                for i, var in enumerate(trainable_vars):\n",
    "                    if var is not None:\n",
    "                        var_norm = tf.norm(var)\n",
    "                        grad_norms.append(var_norm)\n",
    "                        if i < 3:  # Print first 3 for debugging\n",
    "                            print(f\"      Variable {i} norm: {float(var_norm.numpy()):.2e}\")\n",
    "                \n",
    "                self._check_norms(grad_norms, \"Variable\")\n",
    "                self.gradient_checks += 1\n",
    "                return\n",
    "                \n",
    "            # Compute gradient norms\n",
    "            grad_norms = []\n",
    "            for i, grad in enumerate(grads):\n",
    "                if grad is not None:\n",
    "                    grad_norm = tf.norm(grad)\n",
    "                    grad_norms.append(grad_norm)\n",
    "                    if i < 3:  # Print first 3 for debugging\n",
    "                        print(f\"      Gradient {i} norm: {float(grad_norm.numpy()):.2e}\")\n",
    "                    \n",
    "            print(f\"   ‚úÖ Computed {len(grad_norms)} gradient norms\")\n",
    "            self._check_norms(grad_norms, \"Gradient\")\n",
    "            self.gradient_checks += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Exception in gradient monitoring: {str(e)}\")\n",
    "            self.fallback_calls += 1\n",
    "            # Fallback: just monitor the loss for signs of instability\n",
    "            print('   üîÑ Fallback: monitoring loss only')\n",
    "            if logs:\n",
    "                loss_value = logs.get('loss', 0)\n",
    "                print(f\"   üìâ Current loss: {loss_value:.2e}\")\n",
    "                if np.isnan(loss_value) or np.isinf(loss_value):\n",
    "                    print(f\"   ‚ö†Ô∏è  WARNING: Loss became {loss_value} at batch {batch}\")\n",
    "                elif loss_value > 1e6:\n",
    "                    print(f\"   ‚ö†Ô∏è  WARNING: Very large loss {loss_value:.2e} at batch {batch}\")\n",
    "    \n",
    "    def _check_norms(self, norms, norm_type=\"Gradient\"):\n",
    "        \"\"\"Check if norms are within acceptable range\"\"\"\n",
    "        print(f\"   üî¨ Checking {len(norms)} {norm_type.lower()} norms...\")\n",
    "        warnings = 0\n",
    "        \n",
    "        for idx, norm in enumerate(norms):\n",
    "            try:\n",
    "                norm_value = float(norm.numpy()) if hasattr(norm, 'numpy') else float(norm)\n",
    "                \n",
    "                if norm_value > self.clip_max:\n",
    "                    print(f\"   ‚ö†Ô∏è  WARNING: {norm_type} norm {norm_value:.2e} is too large (layer {idx})\")\n",
    "                    warnings += 1\n",
    "                elif norm_value < self.clip_min:\n",
    "                    print(f\"   ‚ö†Ô∏è  WARNING: {norm_type} norm {norm_value:.2e} is too small (layer {idx})\")\n",
    "                    warnings += 1\n",
    "                elif np.isnan(norm_value) or np.isinf(norm_value):\n",
    "                    print(f\"   ‚ö†Ô∏è  WARNING: {norm_type} norm is {norm_value} (layer {idx})\")\n",
    "                    warnings += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Cannot convert norm to float for layer {idx}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        if warnings == 0:\n",
    "            print(f\"   ‚úÖ All {norm_type.lower()} norms are within acceptable range\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  Found {warnings} norm warnings\")\n",
    "    \n",
    "    # def on_epoch_end(self, epoch, logs=None):\n",
    "    #     \"\"\"Print summary at end of each epoch\"\"\"\n",
    "    #     print(f\"üìà GradientMonitoringCallback: Epoch {epoch + 1} completed\")\n",
    "    #     print(f\"   üìä Total batch calls: {self.total_calls}\")\n",
    "    #     print(f\"   üîç Gradient checks performed: {self.gradient_checks}\")\n",
    "    #     print(f\"   üîÑ Fallback calls: {self.fallback_calls}\")\n",
    "    #     \n",
    "    #     if logs:\n",
    "    #         loss = logs.get('loss', 0)\n",
    "    #         val_loss = logs.get('val_loss', 0)\n",
    "    #         print(f\"   üìâ Final epoch loss: {loss:.2e}\")\n",
    "    #         if val_loss:\n",
    "    #             print(f\"   üìâ Final epoch val_loss: {val_loss:.2e}\")\n",
    "    #         \n",
    "    #         if np.isnan(loss) or np.isinf(loss):\n",
    "    #             print(f\"   ‚ö†Ô∏è  WARNING: Training loss became unstable: {loss}\")\n",
    "    #         if val_loss and (np.isnan(val_loss) or np.isinf(val_loss)):\n",
    "    #             print(f\"   ‚ö†Ô∏è  WARNING: Validation loss became unstable: {val_loss}\")\n",
    "        \n",
    "    def on_train_end(self, logs=None):\n",
    "        print(\"üèÅ GradientMonitoringCallback: Training completed!\")\n",
    "        print(f\"   üìä Final stats - Total calls: {self.total_calls}, Gradient checks: {self.gradient_checks}, Fallbacks: {self.fallback_calls}\")\n",
    "        \n",
    "        if self.total_calls == 0:\n",
    "            print(\"   ‚ùå ERROR: Callback was never called! Check if it's properly added to callbacks list.\")\n",
    "        elif self.gradient_checks == 0 and self.fallback_calls == 0:\n",
    "            print(\"   ‚ö†Ô∏è  WARNING: No gradient monitoring was performed. Check monitor_frequency setting.\")\n",
    "        else:\n",
    "            print(\"   ‚úÖ Gradient monitoring completed successfully!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:39:59.934032Z",
     "start_time": "2025-05-28T04:39:59.917492Z"
    }
   },
   "id": "8fc55c9e1f03b71e",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class SaveBestModelCallback(Callback):\n",
    "    def __init__(self, save_path='lstm_single_step.pkl', monitor='val_loss',\n",
    "                 X_mean=None, X_std=None, y_mean=None, y_std=None):\n",
    "        super().__init__()\n",
    "        self.best = float('inf')\n",
    "        self.monitor = monitor\n",
    "        self.save_path = save_path\n",
    "        self.X_mean = X_mean\n",
    "        self.X_std = X_std\n",
    "        self.y_mean = y_mean\n",
    "        self.y_std = y_std\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is not None and current < self.best:\n",
    "            self.best = current\n",
    "            print(f\"\\nNew best {self.monitor}: {current:.6f}. Saving model...\")\n",
    "            save_model(self.model, self.save_path, \n",
    "                       self.X_mean, self.X_std, self.y_mean, self.y_std)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:40:00.619908Z",
     "start_time": "2025-05-28T04:40:00.606102Z"
    }
   },
   "id": "2ef8679e5c2bcf5b",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def exponential_decay_schedule(epoch, lr):\n",
    "    decay_rate = 0.5\n",
    "    decay_steps = 10\n",
    "    if epoch % decay_steps == 0 and epoch:\n",
    "        print('Learning rate update:', lr * decay_rate)\n",
    "        return lr * decay_rate\n",
    "    return lr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:40:01.282743Z",
     "start_time": "2025-05-28T04:40:01.258575Z"
    }
   },
   "id": "64bac463d13fa013",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(train_data, batch_size=32, validation_split=0.2, Tobs=50, epochs=50, epochs2=10, lr1=0.001, lr2=0.00001):\n",
    "    n_scenarios, n_agents, T, D = train_data.shape  # Expecting (10000, 50, 110, 6)\n",
    "    assert D == 6, \"Expected 6 features per timestep (position, velocity, heading, object_type).\"\n",
    "\n",
    "    X_train_raw, y_train_deltas = [], []\n",
    "    \n",
    "    \n",
    "    pruned_fully_padded = 0\n",
    "    pruned_invalid_positions = 0\n",
    "    pruned_too_many_zeros = 0\n",
    "    valid_samples_count = 0  # To count how many valid samples are being used\n",
    "    \n",
    "    for i in range(n_scenarios):\n",
    "        for j in range(n_agents):\n",
    "            agent_data = train_data[i, j, :, :]  # shape (110, 6)\n",
    "    \n",
    "            # Count how many timesteps are completely zero\n",
    "            num_zero_timesteps = np.sum(np.all(agent_data == 0, axis=1))\n",
    "            if num_zero_timesteps >= 0.7 * agent_data.shape[0]:\n",
    "                pruned_fully_padded += 1\n",
    "                continue  # skip mostly padded agent\n",
    "    \n",
    "            # Create sliding window samples for single-step prediction\n",
    "            for t in range(Tobs, T - 1):  # From timestep 50 to 108 (inclusive)\n",
    "                # Input: previous Tobs timesteps (e.g., timesteps 0-49, 1-50, 2-51, etc.)\n",
    "                input_window = agent_data[t-Tobs:t, :]  # shape (50, 6)\n",
    "                \n",
    "                # Target: delta from current position to next position\n",
    "                current_pos = agent_data[t, :2]      # shape (2,)\n",
    "                next_pos = agent_data[t+1, :2]       # shape (2,)\n",
    "                delta = next_pos - current_pos       # shape (2,)\n",
    "    \n",
    "                # Skip only if current or next positions are invalid, or if too many zeros in window\n",
    "                if np.all(current_pos == 0) or np.all(next_pos == 0):\n",
    "                    pruned_invalid_positions += 1\n",
    "                    continue\n",
    "                \n",
    "                # Allow some zeros in the window, but not too many (e.g., less than 80% valid)\n",
    "                valid_positions = ~np.all(input_window[:, :2] == 0, axis=1)\n",
    "                if np.sum(valid_positions) < 0.8 * Tobs:  # At least 60% of timesteps must be valid\n",
    "                    pruned_too_many_zeros += 1\n",
    "                    continue\n",
    "    \n",
    "                X_train_raw.append(input_window)     # shape (50, 6)\n",
    "                y_train_deltas.append(delta)         # shape (2,)\n",
    "                valid_samples_count += 1  # Count valid samples\n",
    "    \n",
    "    # Final print statements to summarize pruning\n",
    "    print(f\"Total mostly padded agents pruned: {pruned_fully_padded}\")\n",
    "    print(f\"Total invalid positions pruned (either current or next position was all zeros): {pruned_invalid_positions}\")\n",
    "    print(f\"Total samples pruned due to too many zeros in the window: {pruned_too_many_zeros}\")\n",
    "    print(f\"Total valid samples used for training: {valid_samples_count}\\n\")\n",
    "    \n",
    "    # Convert to numpy arrays for training\n",
    "    X_train = np.array(X_train_raw)           # shape (N, 50, 6)\n",
    "    y_train = np.array(y_train_deltas)        # shape (N, 2)\n",
    "\n",
    "    print(f\"Training on {X_train.shape[0]} valid timestep sequences.\")\n",
    "    print(f\"Input shape: {X_train.shape}, Output shape: {y_train.shape}\")\n",
    "\n",
    "    # Add debugging info\n",
    "    print(f\"Delta stats: mean={y_train.mean(axis=0)}, std={y_train.std(axis=0)}\")\n",
    "    print(f\"Delta range: min={y_train.min(axis=0)}, max={y_train.max(axis=0)}\")\n",
    "\n",
    "    # --- Normalize ---\n",
    "    X_mean = X_train.mean(axis=(0, 1), keepdims=True)  # shape: (1, 1, 6)\n",
    "    X_std = X_train.std(axis=(0, 1), keepdims=True) + 1e-8\n",
    "\n",
    "    y_mean = y_train.mean(axis=0, keepdims=True)  # shape: (1, 2)\n",
    "    y_std = y_train.std(axis=0, keepdims=True) + 1e-8\n",
    "\n",
    "    X_train = (X_train - X_mean) / X_std\n",
    "    y_train = (y_train - y_mean) / y_std\n",
    "\n",
    "    # --- Model (simplified for single-step prediction) ---\n",
    "    model = create_single_step_model(\n",
    "        input_dim=X_train.shape[-1],\n",
    "        timesteps_in=Tobs,\n",
    "        loss_fn='mse',\n",
    "        lr=lr1\n",
    "    )\n",
    "    \n",
    "    lr_scheduler_callback = LearningRateScheduler(exponential_decay_schedule, verbose=1)\n",
    "    \n",
    "    gradient_monitoring_callback = GradientMonitoringCallback(clip_min=1e-4, clip_max=1e2)\n",
    "    \n",
    "    save_best_callback = SaveBestModelCallback(\n",
    "        save_path='lstm_single_step.pkl',\n",
    "        monitor='val_loss',\n",
    "        X_mean=X_mean,\n",
    "        X_std=X_std,\n",
    "        y_mean=y_mean,\n",
    "        y_std=y_std\n",
    "    )\n",
    "\n",
    "\n",
    "    phase1_callbacks = [\n",
    "        DynamicReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-5),\n",
    "        # lr_scheduler_callback,\n",
    "        save_best_callback,\n",
    "        EarlyStopping(patience=4, restore_best_weights=True, monitor='val_loss'),\n",
    "        LRThresholdCallback(threshold=9e-8)\n",
    "    ]\n",
    "\n",
    "    print(\"\\n--- Phase 1: Training ---\")\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=phase1_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Phase 2: Fine-tuning ---\")\n",
    "    model.compile(optimizer=Adam(lr2), loss='mse', metrics=['mae'])\n",
    "    phase2_callbacks = [\n",
    "        LearningRateScheduler(exponential_decay_schedule),\n",
    "        EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss'),\n",
    "        save_best_callback,\n",
    "        LRThresholdCallback(threshold=9e-8)\n",
    "\n",
    "    ]\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs2,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=phase2_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return model, X_mean, X_std, y_mean, y_std"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:40:05.080031Z",
     "start_time": "2025-05-28T04:40:05.065887Z"
    }
   },
   "id": "523c5a1dd20df920",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def reconstruct_absolute_positions(pred_deltas, last_observed_positions):\n",
    "    \"\"\"\n",
    "    Reconstruct absolute predicted positions by adding deltas to the last observed position.\n",
    "\n",
    "    Args:\n",
    "        pred_deltas: np.ndarray of shape (N, Tpred, 2)\n",
    "        last_observed_positions: np.ndarray of shape (N, 2)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray of shape (N, Tpred, 2)\n",
    "    \"\"\"\n",
    "    return last_observed_positions[:, None, :] + np.cumsum(pred_deltas, axis=1)\n",
    "\n",
    "\n",
    "def forecast_positions(scenario_data, Tobs, Tpred, model, X_mean=None, X_std=None, y_mean=None, y_std=None):\n",
    "    \"\"\"\n",
    "    Use single-step LSTM model to forecast future deltas iteratively and reconstruct absolute positions.\n",
    "    This function only forecasts for the ego agent (agent_index=0).\n",
    "    \n",
    "    This function performs autoregressive prediction: uses the model to predict one step ahead,\n",
    "    then incorporates that prediction into the input window for the next prediction.\n",
    "\n",
    "    Args:\n",
    "        scenario_data (numpy.ndarray): Shape (agents, time_steps, dimensions)\n",
    "        Tobs (int): Number of observed time steps (window size for model input)\n",
    "        Tpred (int): Number of future time steps to predict\n",
    "        model (Model): Trained single-step LSTM model that predicts one normalized delta\n",
    "        X_mean, X_std: Normalization stats for input (optional)\n",
    "        y_mean, y_std: Normalization stats for output (optional)\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Predicted absolute positions of shape (Tpred, 2) for ego agent only\n",
    "    \"\"\"\n",
    "    agents, total_timesteps, features = scenario_data.shape\n",
    "    \n",
    "    # Only process ego agent (agent_index=0)\n",
    "    agent_idx = 0\n",
    "    agent_data = scenario_data[agent_idx, :Tobs, :].copy()  # shape (Tobs, 6)\n",
    "\n",
    "    # Skip if fully padded\n",
    "    if np.all(agent_data == 0):\n",
    "        return np.zeros((Tpred, 2))\n",
    "\n",
    "    # Initialize the sliding window with observed data\n",
    "    current_window = agent_data.copy()  # shape (Tobs, 6)\n",
    "    \n",
    "    # Store predicted deltas for ego agent\n",
    "    pred_deltas = np.zeros((Tpred, 2))\n",
    "    \n",
    "    # Iteratively predict each future timestep\n",
    "    for step in range(Tpred):\n",
    "        # Prepare input for model (current sliding window)\n",
    "        X_pred = np.expand_dims(current_window, axis=0)  # shape (1, Tobs, 6)\n",
    "        \n",
    "        # Normalize input if stats are provided\n",
    "        if X_mean is not None and X_std is not None:\n",
    "            X_pred = (X_pred - X_mean) / X_std\n",
    "\n",
    "        # Predict next delta (single step)\n",
    "        pred_delta = model.predict(X_pred, verbose=0)  # shape (1, 2)\n",
    "        \n",
    "        # Denormalize delta if stats are provided\n",
    "        if y_mean is not None and y_std is not None:\n",
    "            pred_delta = pred_delta * y_std + y_mean\n",
    "            \n",
    "        pred_deltas[step] = pred_delta[0]  # Store the predicted delta\n",
    "\n",
    "        # Calculate next absolute position\n",
    "        current_pos = current_window[-1, :2]  # Last position in window\n",
    "        next_pos = current_pos + pred_delta[0]  # Add predicted delta\n",
    "        \n",
    "        # Create next timestep features\n",
    "        # Copy other features from the last timestep (velocity, heading, object_type)\n",
    "        next_timestep = current_window[-1].copy()  # shape (6,)\n",
    "        next_timestep[:2] = next_pos  # Update position\n",
    "        \n",
    "        # Update sliding window: remove oldest, add newest\n",
    "        current_window = np.roll(current_window, -1, axis=0)  # Shift left\n",
    "        current_window[-1] = next_timestep  # Add new timestep at the end\n",
    "\n",
    "    # Reconstruct absolute positions from deltas\n",
    "    last_observed_pos = agent_data[-1, :2]  # Last observed position\n",
    "    abs_positions = reconstruct_absolute_positions(\n",
    "        pred_deltas=np.expand_dims(pred_deltas, axis=0),  # shape (1, Tpred, 2)\n",
    "        last_observed_positions=np.expand_dims(last_observed_pos, axis=0)  # shape (1, 2)\n",
    "    )[0]  # shape (Tpred, 2)\n",
    "\n",
    "    return abs_positions  # Return shape (Tpred, 2) for ego agent only"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:40:05.889207Z",
     "start_time": "2025-05-28T04:40:05.875861Z"
    }
   },
   "id": "4a1b62d4021903c",
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "source": [
    "funky prediciton"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9191b70781e7bab"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_augmented_scenario_data(scenario_data, Tobs, Tpred, verbose=False):\n",
    "    num_agents, T, D = scenario_data.shape\n",
    "    assert D == 6, \"Expected 6 dimensions per timestep\"\n",
    "\n",
    "    ego_traj = scenario_data[0]\n",
    "    ego_type = int(ego_traj[0, 5])\n",
    "    ego_vel = ego_traj[:Tobs, 2:4]\n",
    "\n",
    "    if np.any(np.all(ego_traj[:Tobs, :2] == 0, axis=1)):\n",
    "        raise ValueError(\"Ego agent does not have valid positions for all observed steps.\")\n",
    "\n",
    "    ego_speed = np.linalg.norm(ego_vel, axis=1)\n",
    "    ego_mean_speed = np.mean(ego_speed)\n",
    "    ego_speed_std = np.std(ego_speed)\n",
    "\n",
    "    X_filtered = []\n",
    "    y_filtered = []\n",
    "\n",
    "    pruned_fully_padded = 0\n",
    "    pruned_type_mismatch = 0\n",
    "    pruned_velocity_mismatch = 0\n",
    "    pruned_invalid_positions = 0\n",
    "    accepted_samples = 0\n",
    "\n",
    "    agents_passed_filters = 0\n",
    "    agents_failed_all_windows = 0\n",
    "\n",
    "    similarity_threshold = 5.0  # Adjust this based on validation (mean velocity difference per timestep)\n",
    "\n",
    "    for agent_idx in range(1, num_agents):  # skip ego\n",
    "        traj = scenario_data[agent_idx]\n",
    "\n",
    "        if np.all(traj == 0):\n",
    "            pruned_fully_padded += 1\n",
    "            continue\n",
    "\n",
    "        agent_type = int(traj[0, 5])\n",
    "        if agent_type != ego_type:\n",
    "            pruned_type_mismatch += 1\n",
    "            continue\n",
    "\n",
    "        valid_positions = ~np.all(traj[:Tobs, :2] == 0, axis=1)\n",
    "        if np.sum(valid_positions) < Tobs * 0.7:\n",
    "            pruned_invalid_positions += 1\n",
    "            continue\n",
    "\n",
    "        agent_obs_vel = traj[:Tobs, 2:4]\n",
    "\n",
    "        # Per-timestep velocity difference (Euclidean norm)\n",
    "        vel_diff_per_timestep = np.linalg.norm(ego_vel - agent_obs_vel, axis=1)  # shape (Tobs,)\n",
    "        mean_vel_diff = np.mean(vel_diff_per_timestep)\n",
    "\n",
    "        # If ego speed is basically zero (stationary), just check mean agent velocity magnitude\n",
    "        ego_mean_speed = np.mean(np.linalg.norm(ego_vel, axis=1))\n",
    "        if ego_mean_speed < 1e-5:\n",
    "            mean_vel_diff = np.mean(np.linalg.norm(agent_obs_vel, axis=1))\n",
    "\n",
    "        if mean_vel_diff > similarity_threshold:\n",
    "            pruned_velocity_mismatch += 1\n",
    "            continue\n",
    "\n",
    "        agents_passed_filters += 1\n",
    "        agent_accepted = False\n",
    "\n",
    "        for t in range(Tobs, T - 1):  # Sliding windows\n",
    "            input_window = traj[t - Tobs:t, :]  # shape (Tobs, 6)\n",
    "            current_pos = traj[t, :2]\n",
    "            next_pos = traj[t + 1, :2]\n",
    "\n",
    "            if np.all(current_pos == 0) or np.all(next_pos == 0):\n",
    "                if agent_idx == 1:\n",
    "                    print(f\"Agent {agent_idx} has invalid position at t={t}\")\n",
    "                pruned_invalid_positions += 1\n",
    "                continue\n",
    "\n",
    "            delta = next_pos - current_pos\n",
    "\n",
    "            # if np.linalg.norm(delta) < 0.1:\n",
    "            #     if agent_idx == 1:\n",
    "            #         print(f\"Agent {agent_idx} movement too small at t={t}\")\n",
    "            #     continue\n",
    "\n",
    "            valid_positions = ~np.all(input_window[:, :2] == 0, axis=1)\n",
    "            if np.sum(valid_positions) < 0.6 * Tobs:\n",
    "                if agent_idx == 1:\n",
    "                    print(f\"Agent {agent_idx} has too many invalid positions in window at t={t}\")\n",
    "                continue\n",
    "\n",
    "            X_filtered.append(input_window)\n",
    "            y_filtered.append(delta)\n",
    "            accepted_samples += 1\n",
    "            agent_accepted = True\n",
    "\n",
    "        if not agent_accepted:\n",
    "            agents_failed_all_windows += 1\n",
    "            if agent_idx == 1:\n",
    "                print(f\"Agent {agent_idx} passed filters but got no valid sliding windows\")\n",
    "                \n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Total agents: {num_agents}\")\n",
    "        print(f\"Accepted samples: {accepted_samples}\")\n",
    "        print(f\"Pruned fully padded agents: {pruned_fully_padded}\")\n",
    "        print(f\"Pruned type mismatches: {pruned_type_mismatch}\")\n",
    "        print(f\"Pruned due to velocity mismatch: {pruned_velocity_mismatch}\")\n",
    "        print(f\"Pruned invalid positions: {pruned_invalid_positions}\")\n",
    "        print(f\"Agents passed outer filters: {agents_passed_filters}\")\n",
    "        print(f\"Agents passed filters but had no valid samples: {agents_failed_all_windows}\")\n",
    "\n",
    "    if len(X_filtered) == 0:\n",
    "        print(\"Warning: No samples passed filtering. Consider relaxing similarity thresholds.\")\n",
    "        return np.empty((0, Tobs, 6)), np.empty((0, 2))\n",
    "    else:\n",
    "        print(f\"Returning {len(X_filtered)} training samples\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    X_filtered = np.array(X_filtered)  # shape (N, Tobs, 6)\n",
    "    y_filtered = np.array(y_filtered)  # shape (N, 2)\n",
    "    return X_filtered, y_filtered"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:51:56.791922Z",
     "start_time": "2025-05-28T04:51:56.783526Z"
    }
   },
   "id": "c0b2fde598692275",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def finetune_forecast_positions(scenario_data, Tobs, Tpred, model, \n",
    "                                 X_mean=None, X_std=None, y_mean=None, y_std=None, \n",
    "                                 epochs=3, lr=1e-4, max_repeats=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Fine-tune model on relevant agents from a scenario, then forecast future positions.\n",
    "\n",
    "    Args:\n",
    "        scenario_data (np.ndarray): Array (agents, time_steps, 6)\n",
    "        Tobs (int): Number of observed time steps\n",
    "        Tpred (int): Number of prediction time steps\n",
    "        model (tf.keras.Model): LSTM model to be fine-tuned\n",
    "        X_mean, X_std, y_mean, y_std: Normalization statistics (optional)\n",
    "        epochs (int): Number of fine-tuning epochs\n",
    "        lr (float): Learning rate for fine-tuning\n",
    "        max_repeats (int): Max weight (duplication count) for close agents\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Predicted positions (Tpred, 2)\n",
    "    \"\"\"\n",
    "    import copy\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "    agents, total_steps, _ = scenario_data.shape\n",
    "    assert total_steps >= Tobs + Tpred, \"Not enough time steps for observation + prediction\"\n",
    "\n",
    "    # Generate fine-tuning data \n",
    "    X_finetune, y_finetune = generate_augmented_scenario_data(scenario_data, Tobs, Tpred, verbose=verbose)\n",
    "\n",
    "    if len(X_finetune) == 0:\n",
    "        print(\"No valid agents found for fine-tuning.\")\n",
    "        return np.zeros((Tpred, 2))  # Fixed: should return (Tpred, 2) not (agents, Tpred, 2)\n",
    "\n",
    "    # Normalize input/output if stats provided\n",
    "    if X_mean is not None and X_std is not None:\n",
    "        X_finetune = (X_finetune - X_mean) / X_std\n",
    "    if y_mean is not None and y_std is not None:\n",
    "        y_finetune = (y_finetune - y_mean) / y_std\n",
    "\n",
    "    # Clone model to preserve original weights\n",
    "    model_finetune = copy.deepcopy(model)\n",
    "    model_finetune.compile(optimizer=Adam(learning_rate=lr, clipnorm=0.5), loss='mse')\n",
    "    \n",
    "    gradient_monitoring_callback = GradientMonitoringCallback(clip_min=1e-4, clip_max=1e2, monitor_frequency=1)\n",
    "    # Train on augmented samples\n",
    "    model_finetune.fit(\n",
    "        X_finetune,\n",
    "        y_finetune,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        # callbacks=[gradient_monitoring_callback]\n",
    "    )\n",
    "\n",
    "    # Predict for ego agent only (agent_index=0) using autoregressive approach\n",
    "    agent_idx = 0\n",
    "    agent_data = scenario_data[agent_idx, :Tobs, :].copy()  # shape (Tobs, 6)\n",
    "    \n",
    "    # Skip if fully padded\n",
    "    if np.all(agent_data == 0):\n",
    "        return np.zeros((Tpred, 2))\n",
    "    \n",
    "    # Initialize the sliding window with observed data (keep same variable naming as forecast_positions)\n",
    "    current_window = agent_data.copy()  # shape (Tobs, 6)\n",
    "    \n",
    "    # Store predicted deltas for ego agent\n",
    "    pred_deltas = np.zeros((Tpred, 2))\n",
    "    \n",
    "    # Iteratively predict each future timestep\n",
    "    for step in range(Tpred):\n",
    "        # Prepare input for model (current sliding window)\n",
    "        X_pred = np.expand_dims(current_window, axis=0)  # shape (1, Tobs, 6)\n",
    "        \n",
    "        # Normalize input if stats are provided\n",
    "        if X_mean is not None and X_std is not None:\n",
    "            X_pred = (X_pred - X_mean) / X_std  # Fixed: apply normalization to X_pred directly\n",
    "\n",
    "        # Predict next delta (single step)\n",
    "        pred_delta = model_finetune.predict(X_pred, verbose=0)  # shape (1, 2)\n",
    "        \n",
    "        # Denormalize delta if stats are provided\n",
    "        if y_mean is not None and y_std is not None:\n",
    "            pred_delta = pred_delta * y_std + y_mean\n",
    "            \n",
    "        pred_deltas[step] = pred_delta[0]  # Store the predicted delta\n",
    "\n",
    "        # Calculate next absolute position\n",
    "        current_pos = current_window[-1, :2]  # Last position in window\n",
    "        next_pos = current_pos + pred_delta[0]  # Add predicted delta\n",
    "        \n",
    "        # Create next timestep features\n",
    "        # Copy other features from the last timestep (velocity, heading, object_type)\n",
    "        next_timestep = current_window[-1].copy()  # shape (6,)\n",
    "        next_timestep[:2] = next_pos  # Update position\n",
    "        \n",
    "        # Update sliding window: remove oldest, add newest\n",
    "        current_window = np.roll(current_window, -1, axis=0)  # Shift left\n",
    "        current_window[-1] = next_timestep  # Add new timestep at the end\n",
    "\n",
    "    # Reconstruct absolute positions from deltas\n",
    "    last_observed_pos = agent_data[-1, :2]  # Last observed position\n",
    "    predicted_positions = reconstruct_absolute_positions(\n",
    "        pred_deltas=np.expand_dims(pred_deltas, axis=0),  # shape (1, Tpred, 2)\n",
    "        last_observed_positions=np.expand_dims(last_observed_pos, axis=0)  # shape (1, 2)\n",
    "    )[0]  # shape (Tpred, 2)\n",
    "\n",
    "    return predicted_positions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:52:26.103734Z",
     "start_time": "2025-05-28T04:52:26.078553Z"
    }
   },
   "id": "9e2cae72fd878346",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def make_gif(data_matrix1, data_matrix2, name='comparison'):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.animation as animation\n",
    "\n",
    "    cmap1 = plt.cm.get_cmap('viridis', 50)\n",
    "    cmap2 = plt.cm.get_cmap('plasma', 50)\n",
    "\n",
    "    assert data_matrix1.shape[1] == data_matrix2.shape[1], \"Both matrices must have same number of timesteps\"\n",
    "    timesteps = data_matrix1.shape[1]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "    ax1, ax2 = axes\n",
    "\n",
    "    def update(frame):\n",
    "        for ax in axes:\n",
    "            ax.clear()\n",
    "\n",
    "        for i in range(data_matrix1.shape[0]):\n",
    "            for (data_matrix, ax, cmap) in [(data_matrix1, ax1, cmap1), (data_matrix2, ax2, cmap2)]:\n",
    "                x = data_matrix[i, frame, 0]\n",
    "                y = data_matrix[i, frame, 1]\n",
    "                if x != 0 and y != 0:\n",
    "                    xs = data_matrix[i, :frame+1, 0]\n",
    "                    ys = data_matrix[i, :frame+1, 1]\n",
    "                    mask = (xs != 0) & (ys != 0)\n",
    "                    xs = xs[mask]\n",
    "                    ys = ys[mask]\n",
    "                    if len(xs) > 0 and len(ys) > 0:\n",
    "                        color = cmap(i)\n",
    "                        ax.plot(xs, ys, alpha=0.9, color=color)\n",
    "                        ax.scatter(x, y, s=80, color=color)\n",
    "\n",
    "        # Plot ego vehicle (index 0) on both\n",
    "        ax1.plot(data_matrix1[0, :frame, 0], data_matrix1[0, :frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "        ax1.scatter(data_matrix1[0, frame, 0], data_matrix1[0, frame, 1], s=80, color='tab:orange')\n",
    "        ax1.set_title('Prediction')\n",
    "\n",
    "        ax2.plot(data_matrix2[0, :frame, 0], data_matrix2[0, :frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "        ax2.scatter(data_matrix2[0, frame, 0], data_matrix2[0, frame, 1], s=80, color='tab:orange')\n",
    "        ax2.set_title('Actual')\n",
    "\n",
    "        for ax, data_matrix in zip(axes, [data_matrix1, data_matrix2]):\n",
    "            ax.set_xlim(data_matrix[:, :, 0][data_matrix[:, :, 0] != 0].min() - 10,\n",
    "                        data_matrix[:, :, 0][data_matrix[:, :, 0] != 0].max() + 10)\n",
    "            ax.set_ylim(data_matrix[:, :, 1][data_matrix[:, :, 1] != 0].min() - 10,\n",
    "                        data_matrix[:, :, 1][data_matrix[:, :, 1] != 0].max() + 10)\n",
    "            ax.legend()\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "\n",
    "        # Compute MSE over non-zero entries up to current frame\n",
    "        mask = (data_matrix2[:, :frame+1, :] != 0) & (data_matrix1[:, :frame+1, :] != 0)\n",
    "        mse = np.mean((data_matrix1[:, :frame+1, :][mask] - data_matrix2[:, :frame+1, :][mask]) ** 2)\n",
    "\n",
    "        fig.suptitle(f\"Timestep {frame} - MSE: {mse:.4f}\", fontsize=16)\n",
    "        return ax1.collections + ax1.lines + ax2.collections + ax2.lines\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, update, frames=list(range(0, timesteps, 3)), interval=100, blit=True)\n",
    "    anim.save(f'trajectory_visualization_{name}.gif', writer='pillow')\n",
    "    plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:40:09.618855Z",
     "start_time": "2025-05-28T04:40:09.613953Z"
    }
   },
   "id": "658c258cac06616e",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_mae_by_timestep(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Visualize MAE across timesteps in the prediction horizon.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): shape (N, Tpred, 2)\n",
    "        y_pred (np.ndarray): shape (N, Tpred, 2)\n",
    "    \"\"\"\n",
    "    mae_per_timestep = np.mean(np.abs(y_true - y_pred), axis=(0, 2))  # shape (Tpred,)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(mae_per_timestep, label='MAE per Timestep')\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.ylabel('MAE (meters)')\n",
    "    plt.title('Mean Absolute Error Over Prediction Horizon')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:40:10.123159Z",
     "start_time": "2025-05-28T04:40:10.111261Z"
    }
   },
   "id": "8ce3811f963721e2",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mostly padded agents pruned: 29\n",
      "Total invalid positions pruned (either current or next position was all zeros): 620\n",
      "Total samples pruned due to too many zeros in the window: 294\n",
      "Total valid samples used for training: 325\n",
      "\n",
      "Training on 325 valid timestep sequences.\n",
      "Input shape: (325, 50, 6), Output shape: (325, 2)\n",
      "Delta stats: mean=[-0.4066431  0.1212915], std=[0.5375988  0.16893138]\n",
      "Delta range: min=[-1.34505657 -0.06771419], max=[0.13693132 0.42339626]\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=3\n",
      "\n",
      "--- Phase 1: Training ---\n",
      "Epoch 1/3\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 106ms/step - loss: 0.4861 - mae: 0.5724\n",
      "Epoch 2/3\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 0.1211 - mae: 0.2462\n",
      "Epoch 3/3\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 0.1003 - mae: 0.2274\n",
      "\n",
      "--- Phase 2: Fine-tuning ---\n"
     ]
    }
   ],
   "source": [
    "# first check that the model can overfit on small data\n",
    "\n",
    "model, X_mean, X_std, y_mean, y_std  = train_model(standardized_train_data[:1], batch_size=30, validation_split=0, epochs=3, epochs2=0, lr1 = 0.001, lr2=0.00001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T05:30:19.523632Z",
     "start_time": "2025-05-28T05:29:58.920841Z"
    }
   },
   "id": "deeaeac04573c115",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 2.81061451e+03  1.83470224e+03 -2.20510684e-01 -1.01152978e-01\n",
      "   -2.73318474e-01  5.63052314e-01]]] [[[2.61184594e+03 1.43047868e+03 4.34917424e+00 2.29791309e+00\n",
      "   1.81278406e+00 1.62925693e+00]]] [[-0.01783356 -0.01111547]] [[0.43912338 0.23835741]]\n"
     ]
    }
   ],
   "source": [
    "print(X_mean, X_std, y_mean, y_std)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:42:08.182216Z",
     "start_time": "2025-05-28T04:42:08.180140Z"
    }
   },
   "id": "eaa2c8dee6f431fa",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# save_model(model, \"general_single_step.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T04:42:08.245773Z",
     "start_time": "2025-05-28T04:42:08.181707Z"
    }
   },
   "id": "1fc0733bc8bee546",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wv/j6ybhf8906j4bmnp171wtn680000gn/T/ipykernel_47068/3735350324.py:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap1 = plt.cm.get_cmap('viridis', 50)\n",
      "/var/folders/wv/j6ybhf8906j4bmnp171wtn680000gn/T/ipykernel_47068/3735350324.py:10: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap2 = plt.cm.get_cmap('plasma', 50)\n"
     ]
    }
   ],
   "source": [
    "# visualize prediction\n",
    "\n",
    "# Parameters\n",
    "Tobs = 50\n",
    "Tpred = 60\n",
    "\n",
    "data = standardized_train_data[0]\n",
    "\n",
    "# Select a test scenario (can use any valid index)\n",
    "test_scenario = data.copy()  # shape (agents, time_steps, features)\n",
    "\n",
    "\n",
    "# Forecast future positions\n",
    "predicted_positions = forecast_positions(test_scenario, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std)\n",
    "\n",
    "# Create combined matrix of past observed + predicted for ego agent (agent 0)\n",
    "ego_past = test_scenario[0, :Tobs, :2]               # shape (Tobs, 2)\n",
    "ego_future = predicted_positions                  # shape (Tpred, 2)\n",
    "ego_full = np.concatenate([ego_past, ego_future], axis=0)  # shape (Tobs + Tpred, 2)\n",
    "\n",
    "# Create updated scenario with predicted ego and original others\n",
    "updated_scenario = test_scenario.copy()\n",
    "updated_scenario[0, :Tobs+Tpred, :2] = ego_full  # Replace ego trajectory\n",
    "\n",
    "# print(updated_scenario[0])\n",
    "\n",
    "# Visualize\n",
    "make_gif(updated_scenario, data, name='lstm_single_step')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T05:30:40.834822Z",
     "start_time": "2025-05-28T05:30:19.543657Z"
    }
   },
   "id": "fedc61e344476eb0",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total agents: 50\n",
      "Accepted samples: 0\n",
      "Pruned fully padded agents: 9\n",
      "Pruned type mismatches: 3\n",
      "Pruned due to velocity mismatch: 14\n",
      "Pruned invalid positions: 23\n",
      "Agents passed outer filters: 0\n",
      "Agents passed filters but had no valid samples: 0\n",
      "Warning: No samples passed filtering. Consider relaxing similarity thresholds.\n",
      "No valid agents found for fine-tuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wv/j6ybhf8906j4bmnp171wtn680000gn/T/ipykernel_47068/3735350324.py:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap1 = plt.cm.get_cmap('viridis', 50)\n",
      "/var/folders/wv/j6ybhf8906j4bmnp171wtn680000gn/T/ipykernel_47068/3735350324.py:10: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap2 = plt.cm.get_cmap('plasma', 50)\n"
     ]
    }
   ],
   "source": [
    "# visualize fine-tunded prediction\n",
    "\n",
    "\n",
    "# Parameters\n",
    "Tobs = 50\n",
    "Tpred = 60\n",
    "\n",
    "data = standardized_train_data[3026]\n",
    "\n",
    "# Select a test scenario (can use any valid index)\n",
    "test_scenario = data.copy()  # shape (agents, time_steps, features)\n",
    "\n",
    "# Forecast future positions\n",
    "predicted_positions = finetune_forecast_positions(test_scenario, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std, verbose=True)\n",
    "\n",
    "# Create combined matrix of past observed + predicted for ego agent (agent 0)\n",
    "ego_past = test_scenario[0, :Tobs, :2]               # shape (Tobs, 2)\n",
    "ego_future = predicted_positions                # shape (Tpred, 2)\n",
    "ego_full = np.concatenate([ego_past, ego_future], axis=0)  # shape (Tobs + Tpred, 2)\n",
    "\n",
    "# Create updated scenario with predicted ego and original others\n",
    "updated_scenario = test_scenario.copy()\n",
    "updated_scenario[0, :Tobs+Tpred, :2] = ego_full  # Replace ego trajectory\n",
    "\n",
    "# print(updated_scenario[0])\n",
    "\n",
    "# Visualize\n",
    "make_gif(updated_scenario, data, name='lstm_single_step')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T05:57:36.217784Z",
     "start_time": "2025-05-28T05:57:15.990218Z"
    }
   },
   "id": "c1b534ab5b272dcf",
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mostly padded agents pruned: 6435\n",
      "Total invalid positions pruned (either current or next position was all zeros): 136529\n",
      "Total samples pruned due to too many zeros in the window: 82171\n",
      "Total valid samples used for training: 286635\n",
      "\n",
      "Training on 286635 valid timestep sequences.\n",
      "Input shape: (286635, 50, 6), Output shape: (286635, 2)\n",
      "Delta stats: mean=[-0.00636867 -0.01205707], std=[0.38757208 0.34470136]\n",
      "Delta range: min=[-2.29021505 -1.96541911], max=[2.67909112 2.18569743]\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=3\n",
      "\n",
      "--- Phase 1: Training ---\n",
      "Epoch 1/30\n",
      "\u001B[1m6689/6689\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 0.1915 - mae: 0.2412\n",
      "New best val_loss: 0.094905. Saving model...\n",
      "Model and normalization parameters saved to lstm_single_step.pkl\n",
      "\u001B[1m6689/6689\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m152s\u001B[0m 22ms/step - loss: 0.1915 - mae: 0.2412 - val_loss: 0.0949 - val_mae: 0.2336\n",
      "Epoch 2/30\n",
      "\u001B[1m6689/6689\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m124s\u001B[0m 18ms/step - loss: 0.2382 - mae: 0.2846 - val_loss: 0.6088 - val_mae: 0.5822\n",
      "Epoch 3/30\n",
      "\u001B[1m6689/6689\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m128s\u001B[0m 19ms/step - loss: 2.2744 - mae: 0.9011 - val_loss: 0.2631 - val_mae: 0.4283\n",
      "Epoch 4/30\n",
      "\u001B[1m6689/6689\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 2.9130 - mae: 0.7941\n",
      "Epoch 4: val_loss did not improve. Reducing LR from 0.001000 to 0.000500\n",
      "\u001B[1m6689/6689\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m127s\u001B[0m 19ms/step - loss: 2.9195 - mae: 0.7944 - val_loss: 1102.3843 - val_mae: 22.2039\n",
      "Epoch 5/30\n",
      "\u001B[1m6689/6689\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m126s\u001B[0m 19ms/step - loss: 1092.1617 - mae: 21.5449 - val_loss: 749.0377 - val_mae: 12.7654\n",
      "\n",
      "--- Phase 2: Fine-tuning ---\n",
      "Epoch 1/15\n",
      "\u001B[1m6689/6689\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 0.1669 - mae: 0.2116\n",
      "New best val_loss: 0.052823. Saving model...\n",
      "Model and normalization parameters saved to lstm_single_step.pkl\n",
      "\u001B[1m6689/6689\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m129s\u001B[0m 19ms/step - loss: 0.1669 - mae: 0.2116 - val_loss: 0.0528 - val_mae: 0.1307 - learning_rate: 1.0000e-05\n",
      "Epoch 2/15\n",
      "\u001B[1m6687/6689\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m‚îÅ\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 0.1594 - mae: 0.2036\n",
      "New best val_loss: 0.051987. Saving model...\n",
      "Model and normalization parameters saved to lstm_single_step.pkl\n",
      "\u001B[1m6689/6689\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m123s\u001B[0m 18ms/step - loss: 0.1594 - mae: 0.2036 - val_loss: 0.0520 - val_mae: 0.1272 - learning_rate: 1.0000e-05\n",
      "Epoch 3/15\n",
      "\u001B[1m6689/6689\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m123s\u001B[0m 18ms/step - loss: 0.1551 - mae: 0.1995 - val_loss: 0.0579 - val_mae: 0.1396 - learning_rate: 1.0000e-05\n",
      "Epoch 4/15\n",
      "\u001B[1m6689/6689\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m125s\u001B[0m 19ms/step - loss: 0.1542 - mae: 0.1984 - val_loss: 0.0576 - val_mae: 0.1345 - learning_rate: 1.0000e-05\n",
      "Epoch 5/15\n",
      "\u001B[1m6689/6689\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m124s\u001B[0m 19ms/step - loss: 0.1550 - mae: 0.1969 - val_loss: 0.0613 - val_mae: 0.1380 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "shuffled_train_data = standardized_train_data.copy()\n",
    "np.random.shuffle(shuffled_train_data)  # shuffles in-place along axis 0 (scenarios)\n",
    "\n",
    "model, X_mean, X_std, y_mean, y_std  = train_model(shuffled_train_data[:300], batch_size=30, validation_split=0.3, epochs=30, epochs2=15, lr1 = 0.001, lr2=0.00001)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T05:54:51.032976Z",
     "start_time": "2025-05-28T05:33:04.680674Z"
    }
   },
   "id": "3338be4ed075b368",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_mse(train_data, model, forecast_fn, Tobs=50, Tpred=60, \n",
    "                 X_mean=None, X_std=None, y_mean=None, y_std=None):\n",
    "    \"\"\"\n",
    "    Evaluate MSE of a forecast function on ego agent across scenarios,\n",
    "    and print the worst 5 scenarios by MSE.\n",
    "\n",
    "    Args:\n",
    "        train_data (np.ndarray): Shape (N, agents, timesteps, features)\n",
    "        model (tf.keras.Model): Trained single-step model\n",
    "        forecast_fn (callable): Function to call for forecasting. Must match:\n",
    "            (scenario_data, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std) -> np.ndarray\n",
    "        Tobs (int): Number of observed steps\n",
    "        Tpred (int): Number of predicted steps\n",
    "        X_mean, X_std, y_mean, y_std (optional): Normalization statistics\n",
    "\n",
    "    Returns:\n",
    "        float: Mean squared error across valid scenarios\n",
    "    \"\"\"\n",
    "    N = train_data.shape[0]\n",
    "    mse_list = []\n",
    "    valid_scenarios = 0\n",
    "    scenario_indices = []\n",
    "    \n",
    "    print(f\"Evaluating {N} scenarios...\")\n",
    "    report_interval = max(1, N // 10)\n",
    "\n",
    "    for i in range(N):\n",
    "        if i % report_interval == 0 or i == N - 1:\n",
    "            print(f\"Processing scenario {i+1}/{N} ({(i+1)/N*100:.1f}%)\")\n",
    "        \n",
    "        scenario_data = train_data[i]  # shape (agents, timesteps, 6)\n",
    "        ego_agent_data = scenario_data[0]  # shape (timesteps, 6)\n",
    "        ground_truth = ego_agent_data[Tobs:Tobs + Tpred, :2]\n",
    "\n",
    "        if np.all(ground_truth == 0):\n",
    "            continue\n",
    "\n",
    "        valid_scenarios += 1\n",
    "\n",
    "        predicted_positions = forecast_fn(\n",
    "            scenario_data, \n",
    "            Tobs, Tpred, model,\n",
    "            X_mean=X_mean, X_std=X_std, y_mean=y_mean, y_std=y_std\n",
    "        )\n",
    "\n",
    "        mse = mean_squared_error(ground_truth, predicted_positions)\n",
    "        mse_list.append(mse)\n",
    "        scenario_indices.append(i)\n",
    "\n",
    "        if i % report_interval == 0:\n",
    "            print(f\"  Current scenario {i} MSE: {mse:.4f}\")\n",
    "\n",
    "    if mse_list:\n",
    "        overall_mse = np.mean(mse_list)\n",
    "        print(f\"\\nEvaluation complete: {valid_scenarios} valid scenarios\")\n",
    "        print(f\"Mean Squared Error (MSE): {overall_mse:.4f}\")\n",
    "        print(f\"Min MSE: {np.min(mse_list):.4f}, Max MSE: {np.max(mse_list):.4f}\")\n",
    "\n",
    "        # Find worst 5 scenarios\n",
    "        worst_indices = np.argsort(mse_list)[-5:][::-1]  # indices of top 5 MSEs, descending\n",
    "        print(\"\\nWorst 5 scenarios by MSE:\")\n",
    "        for rank, idx in enumerate(worst_indices, 1):\n",
    "            scenario_id = scenario_indices[idx]\n",
    "            print(f\"  {rank}. Scenario {scenario_id} - MSE: {mse_list[idx]:.4f}\")\n",
    "\n",
    "        return overall_mse\n",
    "    else:\n",
    "        print(\"No valid scenarios for evaluation.\")\n",
    "        return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T05:54:51.056829Z",
     "start_time": "2025-05-28T05:54:51.050675Z"
    }
   },
   "id": "94a6d7a17d8677e1",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 30 scenarios...\n",
      "Processing scenario 1/30 (3.3%)\n",
      "Returning 118 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 117ms/step - loss: 0.4161 - mae: 0.6020\n",
      "Epoch 2/3\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 0.1907 - mae: 0.4005\n",
      "Epoch 3/3\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 0.0921 - mae: 0.2620\n",
      "  Current scenario 0 MSE: 17.0161\n",
      "Returning 173 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 55ms/step - loss: 1.5647 - mae: 1.1829\n",
      "Epoch 2/3\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 0.7946 - mae: 0.8108\n",
      "Epoch 3/3\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 0.3406 - mae: 0.5127\n",
      "Returning 1066 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - loss: 0.2055 - mae: 0.3521\n",
      "Epoch 2/3\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 18ms/step - loss: 0.0473 - mae: 0.1616\n",
      "Epoch 3/3\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 18ms/step - loss: 0.0370 - mae: 0.1416\n",
      "Processing scenario 4/30 (13.3%)\n",
      "Returning 275 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 43ms/step - loss: 1.3836 - mae: 1.0142\n",
      "Epoch 2/3\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 0.3736 - mae: 0.5273\n",
      "Epoch 3/3\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 0.1397 - mae: 0.2561\n",
      "  Current scenario 3 MSE: 51.8188\n",
      "Returning 413 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 39ms/step - loss: 0.7994 - mae: 0.7818\n",
      "Epoch 2/3\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 0.2520 - mae: 0.3468\n",
      "Epoch 3/3\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 0.1337 - mae: 0.2736\n",
      "Returning 1316 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m42/42\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 21ms/step - loss: 0.1695 - mae: 0.3145\n",
      "Epoch 2/3\n",
      "\u001B[1m42/42\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step - loss: 0.0387 - mae: 0.1498\n",
      "Epoch 3/3\n",
      "\u001B[1m42/42\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step - loss: 0.0224 - mae: 0.1120\n",
      "Processing scenario 7/30 (23.3%)\n",
      "Returning 945 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m30/30\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - loss: 0.1412 - mae: 0.2933\n",
      "Epoch 2/3\n",
      "\u001B[1m30/30\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 18ms/step - loss: 0.0424 - mae: 0.1556\n",
      "Epoch 3/3\n",
      "\u001B[1m30/30\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step - loss: 0.0325 - mae: 0.1352\n",
      "  Current scenario 6 MSE: 16.4934\n",
      "Returning 92 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 86ms/step - loss: 0.8255 - mae: 0.6470\n",
      "Epoch 2/3\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 0.3304 - mae: 0.4301\n",
      "Epoch 3/3\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 0.2132 - mae: 0.3318\n",
      "Returning 241 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.5058 - mae: 0.5860\n",
      "Epoch 2/3\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 0.2329 - mae: 0.3174\n",
      "Epoch 3/3\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 0.2749 - mae: 0.2826\n",
      "Processing scenario 10/30 (33.3%)\n",
      "Returning 59 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 280ms/step - loss: 0.6286 - mae: 0.6426\n",
      "Epoch 2/3\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 0.3669 - mae: 0.4849\n",
      "Epoch 3/3\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 0.7167 - mae: 0.5121\n",
      "  Current scenario 9 MSE: 232.7945\n",
      "Returning 358 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 27ms/step - loss: 0.1533 - mae: 0.3120\n",
      "Epoch 2/3\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 0.0497 - mae: 0.1694\n",
      "Epoch 3/3\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 0.0472 - mae: 0.1690\n",
      "Returning 649 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m21/21\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 26ms/step - loss: 0.2446 - mae: 0.3392\n",
      "Epoch 2/3\n",
      "\u001B[1m21/21\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 0.0623 - mae: 0.1873\n",
      "Epoch 3/3\n",
      "\u001B[1m21/21\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 0.0444 - mae: 0.1568\n",
      "Processing scenario 13/30 (43.3%)\n",
      "Returning 927 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - loss: 0.2518 - mae: 0.4004\n",
      "Epoch 2/3\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 0.0480 - mae: 0.1707\n",
      "Epoch 3/3\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 19ms/step - loss: 0.0371 - mae: 0.1471\n",
      "  Current scenario 12 MSE: 4.0483\n",
      "Returning 84 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 82ms/step - loss: 0.4372 - mae: 0.5325\n",
      "Epoch 2/3\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 0.2188 - mae: 0.3656\n",
      "Epoch 3/3\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 0.5190 - mae: 0.3186\n",
      "Returning 398 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 28ms/step - loss: 0.3298 - mae: 0.4933\n",
      "Epoch 2/3\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 0.0964 - mae: 0.2552\n",
      "Epoch 3/3\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 0.0427 - mae: 0.1665\n",
      "Processing scenario 16/30 (53.3%)\n",
      "Returning 59 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 122ms/step - loss: 0.7182 - mae: 0.6528\n",
      "Epoch 2/3\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 0.5826 - mae: 0.5744\n",
      "Epoch 3/3\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 0.5035 - mae: 0.5556\n",
      "  Current scenario 15 MSE: 1237.8628\n",
      "Returning 1585 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 19ms/step - loss: 0.1325 - mae: 0.2763\n",
      "Epoch 2/3\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - loss: 0.0456 - mae: 0.1612\n",
      "Epoch 3/3\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step - loss: 0.0364 - mae: 0.1413\n",
      "Returning 59 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 114ms/step - loss: 1.5254 - mae: 1.1192\n",
      "Epoch 2/3\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 1.0476 - mae: 0.8989\n",
      "Epoch 3/3\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 1.0135 - mae: 0.8595\n",
      "Processing scenario 19/30 (63.3%)\n",
      "Returning 223 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 0.7907 - mae: 0.6809\n",
      "Epoch 2/3\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 0.2495 - mae: 0.3807\n",
      "Epoch 3/3\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 0.2294 - mae: 0.3196\n",
      "  Current scenario 18 MSE: 20.3064\n",
      "Returning 628 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m20/20\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - loss: 0.5615 - mae: 0.6038\n",
      "Epoch 2/3\n",
      "\u001B[1m20/20\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 0.1236 - mae: 0.2489\n",
      "Epoch 3/3\n",
      "\u001B[1m20/20\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 0.1009 - mae: 0.1975\n",
      "Returning 118 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 61ms/step - loss: 0.9923 - mae: 0.6962\n",
      "Epoch 2/3\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 0.7833 - mae: 0.6137\n",
      "Epoch 3/3\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 0.4252 - mae: 0.4697\n",
      "Processing scenario 22/30 (73.3%)\n",
      "Returning 833 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - loss: 0.1949 - mae: 0.3126\n",
      "Epoch 2/3\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 0.0926 - mae: 0.2111\n",
      "Epoch 3/3\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 18ms/step - loss: 0.0807 - mae: 0.2004\n",
      "  Current scenario 21 MSE: 57.5075\n",
      "Returning 652 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m21/21\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 25ms/step - loss: 0.4708 - mae: 0.4953\n",
      "Epoch 2/3\n",
      "\u001B[1m21/21\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 0.1951 - mae: 0.2957\n",
      "Epoch 3/3\n",
      "\u001B[1m21/21\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 0.1267 - mae: 0.2557\n",
      "Returning 569 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 25ms/step - loss: 0.1970 - mae: 0.3395\n",
      "Epoch 2/3\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 0.0527 - mae: 0.1777\n",
      "Epoch 3/3\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 0.0428 - mae: 0.1617\n",
      "Processing scenario 25/30 (83.3%)\n",
      "Returning 1284 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m41/41\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - loss: 0.1026 - mae: 0.2474\n",
      "Epoch 2/3\n",
      "\u001B[1m41/41\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 16ms/step - loss: 0.0373 - mae: 0.1473\n",
      "Epoch 3/3\n",
      "\u001B[1m41/41\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 16ms/step - loss: 0.0247 - mae: 0.1229\n",
      "  Current scenario 24 MSE: 19.5301\n",
      "Returning 169 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 39ms/step - loss: 0.6816 - mae: 0.5983\n",
      "Epoch 2/3\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 0.2530 - mae: 0.3719\n",
      "Epoch 3/3\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 0.2139 - mae: 0.3231\n",
      "Warning: No samples passed filtering. Consider relaxing similarity thresholds.\n",
      "No valid agents found for fine-tuning.\n",
      "Processing scenario 28/30 (93.3%)\n",
      "Returning 1422 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m45/45\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - loss: 0.1573 - mae: 0.3024\n",
      "Epoch 2/3\n",
      "\u001B[1m45/45\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step - loss: 0.0422 - mae: 0.1586\n",
      "Epoch 3/3\n",
      "\u001B[1m45/45\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 18ms/step - loss: 0.0299 - mae: 0.1327\n",
      "  Current scenario 27 MSE: 0.5029\n",
      "Returning 20 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2s/step - loss: 0.1435 - mae: 0.3389\n",
      "Epoch 2/3\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step - loss: 0.1328 - mae: 0.3012\n",
      "Epoch 3/3\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0981 - mae: 0.2711\n",
      "Processing scenario 30/30 (100.0%)\n",
      "Returning 384 training samples\n",
      "üîß GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=1\n",
      "Epoch 1/3\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 17ms/step - loss: 0.3223 - mae: 0.4122\n",
      "Epoch 2/3\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 0.1991 - mae: 0.3252\n",
      "Epoch 3/3\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 0.1315 - mae: 0.2681\n",
      "\n",
      "Evaluation complete: 30 valid scenarios\n",
      "Mean Squared Error (MSE): 541.9482\n",
      "Min MSE: 0.5029, Max MSE: 13179.7245\n",
      "\n",
      "Worst 5 scenarios by MSE:\n",
      "  1. Scenario 26 - MSE: 13179.7245\n",
      "  2. Scenario 15 - MSE: 1237.8628\n",
      "  3. Scenario 17 - MSE: 547.4882\n",
      "  4. Scenario 9 - MSE: 232.7945\n",
      "  5. Scenario 7 - MSE: 153.2202\n"
     ]
    },
    {
     "data": {
      "text/plain": "541.9481730767242"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on training data\n",
    "evaluate_mse(standardized_train_data[3000:3030], model, forecast_fn=finetune_forecast_positions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T05:56:54.816691Z",
     "start_time": "2025-05-28T05:54:51.054504Z"
    }
   },
   "id": "76a45de5cfb6e914",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_submission(data, output_csv, model, forecast_fn, \n",
    "                        Tobs=50, Tpred=60,\n",
    "                        X_mean=None, X_std=None, y_mean=None, y_std=None):\n",
    "    \"\"\"\n",
    "    Generates a submission CSV file with predicted (x, y) positions for the ego agent.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): Test data of shape (num_scenarios, agents, timesteps, features).\n",
    "        output_csv (str): Output CSV file path.\n",
    "        model (tf.keras.Model): Trained prediction model.\n",
    "        forecast_fn (callable): Forecast function with signature:\n",
    "            (scenario_data, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std) -> np.ndarray\n",
    "        Tobs (int): Number of observed time steps.\n",
    "        Tpred (int): Number of predicted time steps.\n",
    "        X_mean, X_std, y_mean, y_std (optional): Normalization statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    print(f\"Generating predictions for {data.shape[0]} scenarios...\")\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        scenario_data = data[i]            # Shape: (agents, timesteps, 6)\n",
    "        ego_agent_data = scenario_data[0]  # Shape: (timesteps, 6)\n",
    "\n",
    "        predicted_positions = forecast_fn(\n",
    "            ego_agent_data[np.newaxis, :, :], Tobs, Tpred, model,\n",
    "            X_mean=X_mean, X_std=X_std, y_mean=y_mean, y_std=y_std\n",
    "        )  # Shape: (1, Tpred, 2)\n",
    "\n",
    "        predictions.extend(predicted_positions[0])  # Append shape: (Tpred, 2)\n",
    "\n",
    "    submission_df = pd.DataFrame(predictions, columns=[\"x\", \"y\"])\n",
    "    submission_df.index.name = 'index'  # Match required format\n",
    "    submission_df.to_csv(output_csv)\n",
    "\n",
    "    print(f\"Submission file '{output_csv}' saved with shape {submission_df.shape}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2557ca9bf552c0b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "generate_submission(\n",
    "    data=test_data,\n",
    "    output_csv='lstm_submission.csv',\n",
    "    model=model,\n",
    "    forecast_fn=forecast_positions,  # or finetune_forecast_positions\n",
    "    Tobs=50,\n",
    "    Tpred=60,\n",
    "    X_mean=X_mean,\n",
    "    X_std=X_std,\n",
    "    y_mean=y_mean,\n",
    "    y_std=y_std\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4f8d7605d54296d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
