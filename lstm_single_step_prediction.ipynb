{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-26T08:30:55.907241Z",
     "start_time": "2025-05-26T08:30:54.211596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape (10000, 50, 110, 6)\n",
      "test_data's shape (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import numpy as np\n",
    "train_file = np.load('data/train.npz')\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape\", train_data.shape)\n",
    "test_file = np.load('data/test_input.npz')\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehul/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, RepeatVector, TimeDistributed, Dropout"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T08:31:04.426616Z",
     "start_time": "2025-05-26T08:30:55.908668Z"
    }
   },
   "id": "db97d754762b390b",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(model, filepath='lstm_single_step.pkl'):\n",
    "    \"\"\"Save model and scaler together in a pickle file\"\"\"\n",
    "    model_json = model.to_json()\n",
    "    model_weights = model.get_weights()\n",
    "    data = {\n",
    "        'model_json': model_json,\n",
    "        'model_weights': model_weights,\n",
    "    }\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Model saved to {filepath}\")\n",
    "\n",
    "def load_model(filepath='lstm_single_step.pkl'):\n",
    "    \"\"\"Load model and scaler from pickle file\"\"\"\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    # Reconstruct model\n",
    "    model = tf.keras.models.model_from_json(data['model_json'])\n",
    "    model.set_weights(data['model_weights'])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T08:31:04.429Z",
     "start_time": "2025-05-26T08:31:04.408533Z"
    }
   },
   "id": "e3d667b335d4a0a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input, LSTM, Dense, Dropout, TimeDistributed, Attention, Concatenate,\n",
    "    RepeatVector\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def old_model(\n",
    "    input_dim, output_dim, timesteps_in, timesteps_out,\n",
    "    lstm_units=64, num_layers=1, loss_fn='mse', lr=0.001\n",
    "):\n",
    "    # --- Input and Learnable Feature Weighting ---\n",
    "    encoder_inputs = Input(shape=(timesteps_in, input_dim))  # shape: (batch, Tobs, 6)\n",
    "    weighted_inputs = TimeDistributed(Dense(input_dim, activation=None))(encoder_inputs)\n",
    "\n",
    "    # --- Encoder ---\n",
    "    x = weighted_inputs\n",
    "    for _ in range(num_layers):\n",
    "        x = LSTM(lstm_units, return_sequences=True)(x)\n",
    "    encoder_outputs = x  # shape: (batch, Tobs, lstm_units)\n",
    "\n",
    "    # --- Decoder ---\n",
    "    decoder_input = RepeatVector(timesteps_out)(encoder_outputs[:, -1, :])\n",
    "    decoder_outputs = decoder_input\n",
    "    for _ in range(num_layers):\n",
    "        decoder_outputs = LSTM(lstm_units, return_sequences=True)(decoder_outputs)\n",
    "\n",
    "    # --- Attention ---\n",
    "    # attention = Attention()([decoder_outputs, encoder_outputs])\n",
    "    # x = Concatenate()([decoder_outputs, attention])\n",
    "\n",
    "    # --- Dense Layers ---\n",
    "    x = TimeDistributed(Dense(128, activation='relu'))(x)\n",
    "    x = TimeDistributed(Dense(64, activation='relu'))(x)\n",
    "    outputs = TimeDistributed(Dense(output_dim))(x)\n",
    "\n",
    "    model = Model(encoder_inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr, clipnorm=.5), loss=loss_fn, metrics=['mae'])\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T18:11:27.282676Z",
     "start_time": "2025-05-26T18:11:27.240274Z"
    }
   },
   "id": "d7f20fc814e583a3",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T08:31:04.518335Z",
     "start_time": "2025-05-26T08:31:04.427300Z"
    }
   },
   "id": "21f1db9fa58aef3",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_single_step_model(input_dim, timesteps_in, lstm_units=256, num_layers=1, loss_fn='mse', lr=0.001):\n",
    "    \"\"\"\n",
    "    Simplified model for single-step prediction.\n",
    "    Input: (batch, timesteps, features)\n",
    "    Output: (batch, 2) - single delta prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input\n",
    "    inputs = Input(shape=(timesteps_in, input_dim))\n",
    "    \n",
    "    # LSTM layers\n",
    "    x = inputs\n",
    "    for i in range(num_layers):\n",
    "        return_sequences = (i < num_layers - 1)  # Return sequences for all but last layer\n",
    "        x = LSTM(lstm_units, return_sequences=return_sequences, dropout=0.1)(x)\n",
    "    \n",
    "    # Dense layers for final prediction\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    outputs = Dense(2)(x)  # Predict single delta (x, y)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss=loss_fn, metrics=['mae'])\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T18:22:11.747274Z",
     "start_time": "2025-05-26T18:22:11.718494Z"
    }
   },
   "id": "932c0ab6efa77756",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.src.callbacks import LearningRateScheduler, EarlyStopping, Callback\n",
    "from keras.src.optimizers import Adam\n",
    "from keras import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class DynamicReduceLROnPlateau(Callback):\n",
    "    def __init__(self, factor=0.5, patience=3, min_lr=1e-6, verbose=1):\n",
    "        super().__init__()\n",
    "        self.factor = factor\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.verbose = verbose\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        current_val_loss = logs.get(\"val_loss\")\n",
    "\n",
    "        if current_val_loss is None:\n",
    "            return  # can't do anything if val_loss isn't available\n",
    "\n",
    "        if current_val_loss < self.best_val_loss - 1e-4:  # a small delta\n",
    "            self.best_val_loss = current_val_loss\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                old_lr = float(self.model.optimizer.learning_rate.numpy())\n",
    "                if old_lr > self.min_lr:\n",
    "                    new_lr = max(old_lr * self.factor, self.min_lr)\n",
    "                    self.model.optimizer.learning_rate.assign(new_lr)\n",
    "                    if self.verbose:\n",
    "                        print(f\"\\nEpoch {epoch+1}: val_loss did not improve. Reducing LR from {old_lr:.6f} to {new_lr:.6f}\")\n",
    "                    self.wait = 0  # reset after LR reduction\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T18:22:20.077316Z",
     "start_time": "2025-05-26T18:22:20.040254Z"
    }
   },
   "id": "4d68034c165292c5",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LRThresholdCallback(Callback):\n",
    "    def __init__(self, threshold=9e-5):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "        self.should_stop = False\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = float(self.model.optimizer.learning_rate.numpy())\n",
    "        if lr < self.threshold:\n",
    "            print(f\"\\nLearning rate {lr:.6f} < threshold {self.threshold}, moving to Phase 2.\")\n",
    "            self.model.stop_training = True\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T18:22:23.147289Z",
     "start_time": "2025-05-26T18:22:23.126073Z"
    }
   },
   "id": "3d4199e38cacc23e",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class GradientMonitoringCallback(Callback):\n",
    "    def __init__(self, clip_min=1e-4, clip_max=1e2, monitor_frequency=3):\n",
    "        \"\"\"\n",
    "        Monitor gradient norms during training\n",
    "        \n",
    "        Args:\n",
    "            clip_min: Minimum threshold for gradient norms\n",
    "            clip_max: Maximum threshold for gradient norms  \n",
    "            monitor_frequency: How often to check gradients (every N batches)\n",
    "        \"\"\"\n",
    "        print(f\"🔧 GradientMonitoringCallback initialized with clip_min={clip_min}, clip_max={clip_max}, monitor_freq={monitor_frequency}\")\n",
    "        self.clip_min = clip_min\n",
    "        self.clip_max = clip_max\n",
    "        self.monitor_frequency = monitor_frequency\n",
    "        self.batch_count = 0\n",
    "        self.total_calls = 0\n",
    "        self.gradient_checks = 0\n",
    "        self.fallback_calls = 0\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        print(\"🚀 GradientMonitoringCallback: Training started!\")\n",
    "        self.batch_count = 0\n",
    "        self.total_calls = 0\n",
    "        self.gradient_checks = 0\n",
    "        self.fallback_calls = 0\n",
    "        \n",
    "    # def on_epoch_begin(self, epoch, logs=None):\n",
    "    #     print(f\"📍 GradientMonitoringCallback: Starting epoch {epoch + 1}\")\n",
    "        \n",
    "    # def on_train_batch_begin(self, batch, logs=None):\n",
    "    #     # Just to prove we're being called\n",
    "    #     if batch % 50 == 0:  # Print every 50 batches to avoid spam\n",
    "    #         print(f\"⚡ GradientMonitoringCallback: Batch {batch} starting\")\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.batch_count += 1\n",
    "        self.total_calls += 1\n",
    "        \n",
    "        # Print every time to show we're being called\n",
    "        # if batch % 50 == 0:  # Print every 50 batches\n",
    "            # print(f\"📊 GradientMonitoringCallback: Batch {batch} ended (total calls: {self.total_calls})\")\n",
    "        \n",
    "        # Only monitor every N batches to avoid performance overhead\n",
    "        if self.batch_count % self.monitor_frequency != 0:\n",
    "            return\n",
    "            \n",
    "        # print(f\"🔍 GradientMonitoringCallback: Checking gradients at batch {batch} (check #{self.gradient_checks + 1})\")\n",
    "        \n",
    "        # Get gradients from the optimizer's current state\n",
    "        try:\n",
    "            # Access the model's optimizer to get gradient information\n",
    "            optimizer = self.model.optimizer\n",
    "            print(f\"   📋 Optimizer type: {type(optimizer).__name__}\")\n",
    "            \n",
    "            # Get trainable variables\n",
    "            trainable_vars = self.model.trainable_variables\n",
    "            print(f\"   📈 Number of trainable variables: {len(trainable_vars)}\")\n",
    "            \n",
    "            if hasattr(optimizer, 'get_gradients'):\n",
    "                print(\"   ✅ Optimizer has get_gradients method\")\n",
    "                # For some optimizers, we can access gradients directly\n",
    "                grads = optimizer.get_gradients(self.model.total_loss, trainable_vars)\n",
    "                print(f\"   📊 Retrieved {len([g for g in grads if g is not None])} gradients\")\n",
    "            else:\n",
    "                print(\"   ❌ Optimizer doesn't have get_gradients, using variable norms\")\n",
    "                # Alternative approach: check the current variable states\n",
    "                grad_norms = []\n",
    "                for i, var in enumerate(trainable_vars):\n",
    "                    if var is not None:\n",
    "                        var_norm = tf.norm(var)\n",
    "                        grad_norms.append(var_norm)\n",
    "                        if i < 3:  # Print first 3 for debugging\n",
    "                            print(f\"      Variable {i} norm: {float(var_norm.numpy()):.2e}\")\n",
    "                \n",
    "                self._check_norms(grad_norms, \"Variable\")\n",
    "                self.gradient_checks += 1\n",
    "                return\n",
    "                \n",
    "            # Compute gradient norms\n",
    "            grad_norms = []\n",
    "            for i, grad in enumerate(grads):\n",
    "                if grad is not None:\n",
    "                    grad_norm = tf.norm(grad)\n",
    "                    grad_norms.append(grad_norm)\n",
    "                    if i < 3:  # Print first 3 for debugging\n",
    "                        print(f\"      Gradient {i} norm: {float(grad_norm.numpy()):.2e}\")\n",
    "                    \n",
    "            print(f\"   ✅ Computed {len(grad_norms)} gradient norms\")\n",
    "            self._check_norms(grad_norms, \"Gradient\")\n",
    "            self.gradient_checks += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Exception in gradient monitoring: {str(e)}\")\n",
    "            self.fallback_calls += 1\n",
    "            # Fallback: just monitor the loss for signs of instability\n",
    "            print('   🔄 Fallback: monitoring loss only')\n",
    "            if logs:\n",
    "                loss_value = logs.get('loss', 0)\n",
    "                print(f\"   📉 Current loss: {loss_value:.2e}\")\n",
    "                if np.isnan(loss_value) or np.isinf(loss_value):\n",
    "                    print(f\"   ⚠️  WARNING: Loss became {loss_value} at batch {batch}\")\n",
    "                elif loss_value > 1e6:\n",
    "                    print(f\"   ⚠️  WARNING: Very large loss {loss_value:.2e} at batch {batch}\")\n",
    "    \n",
    "    def _check_norms(self, norms, norm_type=\"Gradient\"):\n",
    "        \"\"\"Check if norms are within acceptable range\"\"\"\n",
    "        print(f\"   🔬 Checking {len(norms)} {norm_type.lower()} norms...\")\n",
    "        warnings = 0\n",
    "        \n",
    "        for idx, norm in enumerate(norms):\n",
    "            try:\n",
    "                norm_value = float(norm.numpy()) if hasattr(norm, 'numpy') else float(norm)\n",
    "                \n",
    "                if norm_value > self.clip_max:\n",
    "                    print(f\"   ⚠️  WARNING: {norm_type} norm {norm_value:.2e} is too large (layer {idx})\")\n",
    "                    warnings += 1\n",
    "                elif norm_value < self.clip_min:\n",
    "                    print(f\"   ⚠️  WARNING: {norm_type} norm {norm_value:.2e} is too small (layer {idx})\")\n",
    "                    warnings += 1\n",
    "                elif np.isnan(norm_value) or np.isinf(norm_value):\n",
    "                    print(f\"   ⚠️  WARNING: {norm_type} norm is {norm_value} (layer {idx})\")\n",
    "                    warnings += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Cannot convert norm to float for layer {idx}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        if warnings == 0:\n",
    "            print(f\"   ✅ All {norm_type.lower()} norms are within acceptable range\")\n",
    "        else:\n",
    "            print(f\"   ⚠️  Found {warnings} norm warnings\")\n",
    "    \n",
    "    # def on_epoch_end(self, epoch, logs=None):\n",
    "    #     \"\"\"Print summary at end of each epoch\"\"\"\n",
    "    #     print(f\"📈 GradientMonitoringCallback: Epoch {epoch + 1} completed\")\n",
    "    #     print(f\"   📊 Total batch calls: {self.total_calls}\")\n",
    "    #     print(f\"   🔍 Gradient checks performed: {self.gradient_checks}\")\n",
    "    #     print(f\"   🔄 Fallback calls: {self.fallback_calls}\")\n",
    "    #     \n",
    "    #     if logs:\n",
    "    #         loss = logs.get('loss', 0)\n",
    "    #         val_loss = logs.get('val_loss', 0)\n",
    "    #         print(f\"   📉 Final epoch loss: {loss:.2e}\")\n",
    "    #         if val_loss:\n",
    "    #             print(f\"   📉 Final epoch val_loss: {val_loss:.2e}\")\n",
    "    #         \n",
    "    #         if np.isnan(loss) or np.isinf(loss):\n",
    "    #             print(f\"   ⚠️  WARNING: Training loss became unstable: {loss}\")\n",
    "    #         if val_loss and (np.isnan(val_loss) or np.isinf(val_loss)):\n",
    "    #             print(f\"   ⚠️  WARNING: Validation loss became unstable: {val_loss}\")\n",
    "        \n",
    "    def on_train_end(self, logs=None):\n",
    "        print(\"🏁 GradientMonitoringCallback: Training completed!\")\n",
    "        print(f\"   📊 Final stats - Total calls: {self.total_calls}, Gradient checks: {self.gradient_checks}, Fallbacks: {self.fallback_calls}\")\n",
    "        \n",
    "        if self.total_calls == 0:\n",
    "            print(\"   ❌ ERROR: Callback was never called! Check if it's properly added to callbacks list.\")\n",
    "        elif self.gradient_checks == 0 and self.fallback_calls == 0:\n",
    "            print(\"   ⚠️  WARNING: No gradient monitoring was performed. Check monitor_frequency setting.\")\n",
    "        else:\n",
    "            print(\"   ✅ Gradient monitoring completed successfully!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T18:22:26.604148Z",
     "start_time": "2025-05-26T18:22:26.586195Z"
    }
   },
   "id": "8fc55c9e1f03b71e",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class SaveBestModelCallback(Callback):\n",
    "    def __init__(self, save_path='best_model.keras', monitor='val_loss'):\n",
    "        super().__init__()\n",
    "        self.best = float('inf')\n",
    "        self.monitor = monitor\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is not None and current < self.best:\n",
    "            self.best = current\n",
    "            print(f\"\\nNew best {self.monitor}: {current:.6f}. Saving model...\")\n",
    "            save_model(self.model, 'lstm_single_step.pkl')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T18:22:29.978923Z",
     "start_time": "2025-05-26T18:22:29.941009Z"
    }
   },
   "id": "2ef8679e5c2bcf5b",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def exponential_decay_schedule(epoch, lr):\n",
    "    decay_rate = 0.5\n",
    "    decay_steps = 10\n",
    "    if epoch % decay_steps == 0 and epoch:\n",
    "        print('Learning rate update:', lr * decay_rate)\n",
    "        return lr * decay_rate\n",
    "    return lr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T18:22:30.787088Z",
     "start_time": "2025-05-26T18:22:30.753586Z"
    }
   },
   "id": "64bac463d13fa013",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(train_data, batch_size=32, validation_split=0.2, Tobs=50, epochs=50, epochs2=10, lr1=0.001, lr2=0.00001):\n",
    "    n_scenarios, n_agents, T, D = train_data.shape  # Expecting (10000, 50, 110, 6)\n",
    "    assert D == 6, \"Expected 6 features per timestep (position, velocity, heading, object_type).\"\n",
    "\n",
    "    X_train_raw, y_train_deltas = [], []\n",
    "    \n",
    "    \n",
    "    pruned_fully_padded = 0\n",
    "    pruned_invalid_positions = 0\n",
    "    pruned_too_many_zeros = 0\n",
    "    valid_samples_count = 0  # To count how many valid samples are being used\n",
    "    \n",
    "    for i in range(n_scenarios):\n",
    "        for j in range(n_agents):\n",
    "            agent_data = train_data[i, j, :, :]  # shape (110, 6)\n",
    "    \n",
    "            if np.all(agent_data == 0):\n",
    "                pruned_fully_padded += 1\n",
    "                continue  # skip fully padded agent\n",
    "    \n",
    "            # Create sliding window samples for single-step prediction\n",
    "            for t in range(Tobs, T - 1):  # From timestep 50 to 108 (inclusive)\n",
    "                # Input: previous Tobs timesteps (e.g., timesteps 0-49, 1-50, 2-51, etc.)\n",
    "                input_window = agent_data[t-Tobs:t, :]  # shape (50, 6)\n",
    "                \n",
    "                # Target: delta from current position to next position\n",
    "                current_pos = agent_data[t, :2]      # shape (2,)\n",
    "                next_pos = agent_data[t+1, :2]       # shape (2,)\n",
    "                delta = next_pos - current_pos       # shape (2,)\n",
    "    \n",
    "                # Skip only if current or next positions are invalid, or if too many zeros in window\n",
    "                if np.all(current_pos == 0) or np.all(next_pos == 0):\n",
    "                    pruned_invalid_positions += 1\n",
    "                    continue\n",
    "                \n",
    "                # Allow some zeros in the window, but not too many (e.g., less than 80% valid)\n",
    "                valid_positions = ~np.all(input_window[:, :2] == 0, axis=1)\n",
    "                if np.sum(valid_positions) < 0.6 * Tobs:  # At least 60% of timesteps must be valid\n",
    "                    pruned_too_many_zeros += 1\n",
    "                    continue\n",
    "    \n",
    "                X_train_raw.append(input_window)     # shape (50, 6)\n",
    "                y_train_deltas.append(delta)         # shape (2,)\n",
    "                valid_samples_count += 1  # Count valid samples\n",
    "    \n",
    "    # Final print statements to summarize pruning\n",
    "    print(f\"Total fully padded agents pruned: {pruned_fully_padded}\")\n",
    "    print(f\"Total invalid positions pruned (either current or next position was all zeros): {pruned_invalid_positions}\")\n",
    "    print(f\"Total samples pruned due to too many zeros in the window: {pruned_too_many_zeros}\")\n",
    "    print(f\"Total valid samples used for training: {valid_samples_count}\\n\")\n",
    "    \n",
    "    # Convert to numpy arrays for training\n",
    "    X_train = np.array(X_train_raw)           # shape (N, 50, 6)\n",
    "    y_train = np.array(y_train_deltas)        # shape (N, 2)\n",
    "\n",
    "    print(f\"Training on {X_train.shape[0]} valid timestep sequences.\")\n",
    "    print(f\"Input shape: {X_train.shape}, Output shape: {y_train.shape}\")\n",
    "\n",
    "    # Add debugging info\n",
    "    print(f\"Delta stats: mean={y_train.mean(axis=0)}, std={y_train.std(axis=0)}\")\n",
    "    print(f\"Delta range: min={y_train.min(axis=0)}, max={y_train.max(axis=0)}\")\n",
    "\n",
    "    # --- Normalize ---\n",
    "    X_mean = X_train.mean(axis=(0, 1), keepdims=True)  # shape: (1, 1, 6)\n",
    "    X_std = X_train.std(axis=(0, 1), keepdims=True) + 1e-8\n",
    "\n",
    "    y_mean = y_train.mean(axis=0, keepdims=True)  # shape: (1, 2)\n",
    "    y_std = y_train.std(axis=0, keepdims=True) + 1e-8\n",
    "\n",
    "    X_train = (X_train - X_mean) / X_std\n",
    "    y_train = (y_train - y_mean) / y_std\n",
    "\n",
    "    # --- Model (simplified for single-step prediction) ---\n",
    "    model = create_single_step_model(\n",
    "        input_dim=X_train.shape[-1],\n",
    "        timesteps_in=Tobs,\n",
    "        loss_fn='mse',\n",
    "        lr=lr1\n",
    "    )\n",
    "    \n",
    "    lr_scheduler_callback = LearningRateScheduler(exponential_decay_schedule, verbose=1)\n",
    "    \n",
    "    gradient_monitoring_callback = GradientMonitoringCallback(clip_min=1e-4, clip_max=1e2)\n",
    "    \n",
    "    save_best_callback = SaveBestModelCallback(save_path='lstm_single_step', monitor='val_loss')\n",
    "\n",
    "    phase1_callbacks = [\n",
    "        DynamicReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-5),\n",
    "        # lr_scheduler_callback,\n",
    "        save_best_callback,\n",
    "        EarlyStopping(patience=4, restore_best_weights=True, monitor='val_loss'),\n",
    "        LRThresholdCallback(threshold=9e-8)\n",
    "    ]\n",
    "\n",
    "    print(\"\\n--- Phase 1: Training ---\")\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=phase1_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Phase 2: Fine-tuning ---\")\n",
    "    model.compile(optimizer=Adam(lr2), loss='mse', metrics=['mae'])\n",
    "    phase2_callbacks = [\n",
    "        LearningRateScheduler(exponential_decay_schedule),\n",
    "        EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss'),\n",
    "        save_best_callback,\n",
    "        LRThresholdCallback(threshold=9e-8)\n",
    "\n",
    "    ]\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs2,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=phase2_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return model, X_mean, X_std, y_mean, y_std"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T18:23:51.151597Z",
     "start_time": "2025-05-26T18:23:51.139302Z"
    }
   },
   "id": "523c5a1dd20df920",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def reconstruct_absolute_positions(pred_deltas, last_observed_positions):\n",
    "    \"\"\"\n",
    "    Reconstruct absolute predicted positions by adding deltas to the last observed position.\n",
    "\n",
    "    Args:\n",
    "        pred_deltas: np.ndarray of shape (N, Tpred, 2)\n",
    "        last_observed_positions: np.ndarray of shape (N, 2)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray of shape (N, Tpred, 2)\n",
    "    \"\"\"\n",
    "    return last_observed_positions[:, None, :] + np.cumsum(pred_deltas, axis=1)\n",
    "\n",
    "\n",
    "def forecast_positions(scenario_data, Tobs, Tpred, model, X_mean=None, X_std=None, y_mean=None, y_std=None):\n",
    "    \"\"\"\n",
    "    Use single-step LSTM model to forecast future deltas iteratively and reconstruct absolute positions.\n",
    "    \n",
    "    This function performs autoregressive prediction: uses the model to predict one step ahead,\n",
    "    then incorporates that prediction into the input window for the next prediction.\n",
    "\n",
    "    Args:\n",
    "        scenario_data (numpy.ndarray): Shape (agents, time_steps, dimensions)\n",
    "        Tobs (int): Number of observed time steps (window size for model input)\n",
    "        Tpred (int): Number of future time steps to predict\n",
    "        model (Model): Trained single-step LSTM model that predicts one normalized delta\n",
    "        X_mean, X_std: Normalization stats for input (optional)\n",
    "        y_mean, y_std: Normalization stats for output (optional)\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Predicted absolute positions of shape (agents, Tpred, 2)\n",
    "    \"\"\"\n",
    "    agents, total_timesteps, features = scenario_data.shape\n",
    "    predicted_positions = np.zeros((agents, Tpred, 2))\n",
    "\n",
    "    for agent_idx in range(agents):\n",
    "        # Get initial observation window\n",
    "        agent_data = scenario_data[agent_idx, :Tobs, :].copy()  # shape (Tobs, 6)\n",
    "\n",
    "        # Skip if fully padded\n",
    "        if np.all(agent_data == 0):\n",
    "            continue\n",
    "\n",
    "        # Initialize the sliding window with observed data\n",
    "        current_window = agent_data.copy()  # shape (Tobs, 6)\n",
    "        \n",
    "        # Store predicted deltas for this agent\n",
    "        pred_deltas = np.zeros((Tpred, 2))\n",
    "        \n",
    "        # Iteratively predict each future timestep\n",
    "        for step in range(Tpred):\n",
    "            # Prepare input for model (current sliding window)\n",
    "            X_pred = np.expand_dims(current_window, axis=0)  # shape (1, Tobs, 6)\n",
    "            \n",
    "            # Normalize input if stats are provided\n",
    "            if X_mean is not None and X_std is not None:\n",
    "                X_pred = (X_pred - X_mean) / X_std\n",
    "\n",
    "            # Predict next delta (single step)\n",
    "            pred_delta = model.predict(X_pred, verbose=0)  # shape (1, 2)\n",
    "            \n",
    "            # Denormalize delta if stats are provided\n",
    "            if y_mean is not None and y_std is not None:\n",
    "                pred_delta = pred_delta * y_std + y_mean\n",
    "                \n",
    "            pred_deltas[step] = pred_delta[0]  # Store the predicted delta\n",
    "\n",
    "            # Calculate next absolute position\n",
    "            current_pos = current_window[-1, :2]  # Last position in window\n",
    "            next_pos = current_pos + pred_delta[0]  # Add predicted delta\n",
    "            \n",
    "            # Create next timestep features\n",
    "            # Copy other features from the last timestep (velocity, heading, object_type)\n",
    "            next_timestep = current_window[-1].copy()  # shape (6,)\n",
    "            next_timestep[:2] = next_pos  # Update position\n",
    "            \n",
    "            # Update sliding window: remove oldest, add newest\n",
    "            current_window = np.roll(current_window, -1, axis=0)  # Shift left\n",
    "            current_window[-1] = next_timestep  # Add new timestep at the end\n",
    "\n",
    "        # Reconstruct absolute positions from deltas\n",
    "        last_observed_pos = agent_data[-1, :2]  # Last observed position\n",
    "        abs_positions = reconstruct_absolute_positions(\n",
    "            pred_deltas=np.expand_dims(pred_deltas, axis=0),  # shape (1, Tpred, 2)\n",
    "            last_observed_positions=np.expand_dims(last_observed_pos, axis=0)  # shape (1, 2)\n",
    "        )[0]  # shape (Tpred, 2)\n",
    "\n",
    "        predicted_positions[agent_idx] = abs_positions\n",
    "\n",
    "    return predicted_positions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T17:58:05.402329Z",
     "start_time": "2025-05-26T17:58:05.390594Z"
    }
   },
   "id": "4a1b62d4021903c",
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "source": [
    "funky prediciton"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9191b70781e7bab"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_augmented_scenario_data(scenario_data, Tobs, Tpred, verbose=False):\n",
    "    \"\"\"\n",
    "    Filters agent trajectories to keep only those similar to ego in velocity profile and type,\n",
    "    and then generates sliding window samples for those agents.\n",
    "\n",
    "    Args:\n",
    "        scenario_data (np.ndarray): (num_agents, time_steps, 6)\n",
    "        Tobs (int): Observation window size\n",
    "        Tpred (int): Prediction horizon (should be 1 for delta-based prediction)\n",
    "        verbose (bool): Whether to print pruning stats\n",
    "\n",
    "    Returns:\n",
    "        X_filtered (np.ndarray): (N, Tobs, 6)\n",
    "        y_filtered (np.ndarray): (N, 2)\n",
    "    \"\"\"\n",
    "    num_agents, T, D = scenario_data.shape\n",
    "    assert D == 6, \"Expected 6 dimensions per timestep\"\n",
    "\n",
    "    ego_traj = scenario_data[0]\n",
    "    ego_type = int(ego_traj[0, 5])\n",
    "    ego_vel = ego_traj[:Tobs, 2:4]  # velocity_x, velocity_y\n",
    "\n",
    "    # Ego guaranteed valid positions for all Tobs steps\n",
    "    if np.any(np.all(ego_traj[:Tobs, :2] == 0, axis=1)):\n",
    "        raise ValueError(\"Ego agent does not have valid positions for all observed steps.\")\n",
    "\n",
    "    ego_flat_vel = ego_vel.flatten()  # shape (Tobs*2,)\n",
    "\n",
    "    X_filtered = []\n",
    "    y_filtered = []\n",
    "\n",
    "    pruned_fully_padded = 0\n",
    "    pruned_type_mismatch = 0\n",
    "    pruned_velocity_mismatch = 0\n",
    "    pruned_invalid_positions = 0\n",
    "    accepted_samples = 0\n",
    "\n",
    "    for agent_idx in range(1, num_agents):  # skip ego\n",
    "        traj = scenario_data[agent_idx]\n",
    "\n",
    "        if np.all(traj == 0):\n",
    "            pruned_fully_padded += 1\n",
    "            continue\n",
    "\n",
    "        agent_type = int(traj[0, 5])\n",
    "        if agent_type != ego_type:\n",
    "            pruned_type_mismatch += 1\n",
    "            continue\n",
    "\n",
    "        # Require agent to have valid positions for all Tobs steps\n",
    "        if np.any(np.all(traj[:Tobs, :2] == 0, axis=1)):\n",
    "            pruned_velocity_mismatch += 1\n",
    "            continue\n",
    "\n",
    "        agent_obs_vel = traj[:Tobs, 2:4]\n",
    "        agent_flat_vel = agent_obs_vel.flatten()\n",
    "\n",
    "        # Compute cosine similarity between velocity profiles\n",
    "        dot = np.dot(ego_flat_vel, agent_flat_vel)\n",
    "        norm = np.linalg.norm(ego_flat_vel) * np.linalg.norm(agent_flat_vel)\n",
    "        similarity = dot / norm if norm > 0 else -1\n",
    "\n",
    "        if similarity < 0.7:\n",
    "            pruned_velocity_mismatch += 1\n",
    "            continue\n",
    "\n",
    "        # Passed similarity filter: generate sliding window samples\n",
    "        for t in range(Tobs, T - Tpred):\n",
    "            input_window = traj[t - Tobs:t, :]  # shape (Tobs, 6)\n",
    "            current_pos = traj[t, :2]\n",
    "            next_pos = traj[t + Tpred, :2]\n",
    "            delta = next_pos - current_pos\n",
    "\n",
    "            # Skip if current or next position is zero (invalid)\n",
    "            if np.all(current_pos == 0) or np.all(next_pos == 0):\n",
    "                pruned_invalid_positions += 1\n",
    "                continue\n",
    "\n",
    "            X_filtered.append(input_window)\n",
    "            y_filtered.append(delta)\n",
    "            accepted_samples += 1\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Total agents: {num_agents}\")\n",
    "        print(f\"Accepted samples: {accepted_samples}\")\n",
    "        print(f\"Pruned fully padded agents: {pruned_fully_padded}\")\n",
    "        print(f\"Pruned type mismatches: {pruned_type_mismatch}\")\n",
    "        print(f\"Pruned due to velocity mismatch: {pruned_velocity_mismatch}\")\n",
    "        print(f\"Pruned invalid positions: {pruned_invalid_positions}\")\n",
    "\n",
    "    return np.array(X_filtered), np.array(y_filtered)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T17:58:10.924588Z",
     "start_time": "2025-05-26T17:58:10.890529Z"
    }
   },
   "id": "c0b2fde598692275",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def finetune_forecast_positions(scenario_data, Tobs, Tpred, model, \n",
    "                                 X_mean=None, X_std=None, y_mean=None, y_std=None, \n",
    "                                 epochs=3, lr=1e-4, max_repeats=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Fine-tune model on relevant agents from a scenario, then forecast future positions.\n",
    "\n",
    "    Args:\n",
    "        scenario_data (np.ndarray): Array (agents, time_steps, 6)\n",
    "        Tobs (int): Number of observed time steps\n",
    "        Tpred (int): Number of prediction time steps\n",
    "        model (tf.keras.Model): LSTM model to be fine-tuned\n",
    "        X_mean, X_std, y_mean, y_std: Normalization statistics (optional)\n",
    "        epochs (int): Number of fine-tuning epochs\n",
    "        lr (float): Learning rate for fine-tuning\n",
    "        max_repeats (int): Max weight (duplication count) for close agents\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Predicted positions (agents, Tpred, 2)\n",
    "    \"\"\"\n",
    "    import copy\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "    agents, total_steps, _ = scenario_data.shape\n",
    "    assert total_steps >= Tobs + Tpred, \"Not enough time steps for observation + prediction\"\n",
    "\n",
    "    # Generate fine-tuning data with importance scaling\n",
    "    X_finetune, y_finetune = generate_augmented_scenario_data(scenario_data, Tobs, Tpred, verbose=verbose)\n",
    "\n",
    "    if len(X_finetune) == 0:\n",
    "        print(\"No valid agents found for fine-tuning.\")\n",
    "        return np.zeros((agents, Tpred, 2))\n",
    "\n",
    "    # Normalize input/output if stats provided\n",
    "    if X_mean is not None and X_std is not None:\n",
    "        X_finetune = (X_finetune - X_mean) / X_std\n",
    "    if y_mean is not None and y_std is not None:\n",
    "        y_finetune = (y_finetune - y_mean) / y_std\n",
    "        \n",
    "    # print(X_finetune.shape)  # (N, 50, 6)\n",
    "    # print(y_finetune.shape)  # (N, 60, 2)\n",
    "\n",
    "    # Clone model to preserve original weights\n",
    "    model_finetune = copy.deepcopy(model)\n",
    "    model_finetune.compile(optimizer=Adam(learning_rate=lr, clipnorm=0.5), loss='mse')\n",
    "    \n",
    "    gradient_monitoring_callback = GradientMonitoringCallback(clip_min=1e-4, clip_max=1e2)\n",
    "    # Train on augmented samples\n",
    "    model_finetune.fit(\n",
    "        X_finetune,\n",
    "        y_finetune,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        # callbacks=[gradient_monitoring_callback]\n",
    "    )\n",
    "\n",
    "    # Predict for each agent in the scenario\n",
    "    predicted_positions = np.zeros((agents, Tpred, 2))\n",
    "\n",
    "    for agent_idx in range(agents):\n",
    "        agent_obs = scenario_data[agent_idx, :Tobs, :]\n",
    "\n",
    "        if np.any(np.all(agent_obs == 0, axis=1)):\n",
    "            continue\n",
    "\n",
    "        X_pred = np.expand_dims(agent_obs, axis=0)\n",
    "\n",
    "        if X_mean is not None and X_std is not None:\n",
    "            X_pred = (X_pred - X_mean) / X_std\n",
    "\n",
    "        pred_deltas = model_finetune.predict(X_pred, verbose=0)\n",
    "\n",
    "        if y_mean is not None and y_std is not None:\n",
    "            pred_deltas = pred_deltas * y_std + y_mean\n",
    "\n",
    "        last_pos = agent_obs[Tobs - 1, :2]\n",
    "        abs_positions = reconstruct_absolute_positions(\n",
    "            pred_deltas=pred_deltas,\n",
    "            last_observed_positions=np.expand_dims(last_pos, axis=0)\n",
    "        )[0]\n",
    "\n",
    "        predicted_positions[agent_idx] = abs_positions\n",
    "\n",
    "    return predicted_positions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T17:58:11.352478Z",
     "start_time": "2025-05-26T17:58:11.333889Z"
    }
   },
   "id": "9e2cae72fd878346",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def make_gif(data_matrix1, data_matrix2, name='comparison'):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.animation as animation\n",
    "\n",
    "    cmap1 = plt.cm.get_cmap('viridis', 50)\n",
    "    cmap2 = plt.cm.get_cmap('plasma', 50)\n",
    "\n",
    "    assert data_matrix1.shape[1] == data_matrix2.shape[1], \"Both matrices must have same number of timesteps\"\n",
    "    timesteps = data_matrix1.shape[1]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "    ax1, ax2 = axes\n",
    "\n",
    "    def update(frame):\n",
    "        for ax in axes:\n",
    "            ax.clear()\n",
    "\n",
    "        for i in range(data_matrix1.shape[0]):\n",
    "            for (data_matrix, ax, cmap) in [(data_matrix1, ax1, cmap1), (data_matrix2, ax2, cmap2)]:\n",
    "                x = data_matrix[i, frame, 0]\n",
    "                y = data_matrix[i, frame, 1]\n",
    "                if x != 0 and y != 0:\n",
    "                    xs = data_matrix[i, :frame+1, 0]\n",
    "                    ys = data_matrix[i, :frame+1, 1]\n",
    "                    mask = (xs != 0) & (ys != 0)\n",
    "                    xs = xs[mask]\n",
    "                    ys = ys[mask]\n",
    "                    if len(xs) > 0 and len(ys) > 0:\n",
    "                        color = cmap(i)\n",
    "                        ax.plot(xs, ys, alpha=0.9, color=color)\n",
    "                        ax.scatter(x, y, s=80, color=color)\n",
    "\n",
    "        # Plot ego vehicle (index 0) on both\n",
    "        ax1.plot(data_matrix1[0, :frame, 0], data_matrix1[0, :frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "        ax1.scatter(data_matrix1[0, frame, 0], data_matrix1[0, frame, 1], s=80, color='tab:orange')\n",
    "        ax1.set_title('Prediction')\n",
    "\n",
    "        ax2.plot(data_matrix2[0, :frame, 0], data_matrix2[0, :frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "        ax2.scatter(data_matrix2[0, frame, 0], data_matrix2[0, frame, 1], s=80, color='tab:orange')\n",
    "        ax2.set_title('Actual')\n",
    "\n",
    "        for ax, data_matrix in zip(axes, [data_matrix1, data_matrix2]):\n",
    "            ax.set_xlim(data_matrix[:, :, 0][data_matrix[:, :, 0] != 0].min() - 10,\n",
    "                        data_matrix[:, :, 0][data_matrix[:, :, 0] != 0].max() + 10)\n",
    "            ax.set_ylim(data_matrix[:, :, 1][data_matrix[:, :, 1] != 0].min() - 10,\n",
    "                        data_matrix[:, :, 1][data_matrix[:, :, 1] != 0].max() + 10)\n",
    "            ax.legend()\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "\n",
    "        # Compute MSE over non-zero entries up to current frame\n",
    "        mask = (data_matrix2[:, :frame+1, :] != 0) & (data_matrix1[:, :frame+1, :] != 0)\n",
    "        mse = np.mean((data_matrix1[:, :frame+1, :][mask] - data_matrix2[:, :frame+1, :][mask]) ** 2)\n",
    "\n",
    "        fig.suptitle(f\"Timestep {frame} - MSE: {mse:.4f}\", fontsize=16)\n",
    "        return ax1.collections + ax1.lines + ax2.collections + ax2.lines\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, update, frames=list(range(0, timesteps, 3)), interval=100, blit=True)\n",
    "    anim.save(f'trajectory_visualization_{name}.gif', writer='pillow')\n",
    "    plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T17:58:12.377242Z",
     "start_time": "2025-05-26T17:58:12.368788Z"
    }
   },
   "id": "658c258cac06616e",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_mae_by_timestep(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Visualize MAE across timesteps in the prediction horizon.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): shape (N, Tpred, 2)\n",
    "        y_pred (np.ndarray): shape (N, Tpred, 2)\n",
    "    \"\"\"\n",
    "    mae_per_timestep = np.mean(np.abs(y_true - y_pred), axis=(0, 2))  # shape (Tpred,)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(mae_per_timestep, label='MAE per Timestep')\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.ylabel('MAE (meters)')\n",
    "    plt.title('Mean Absolute Error Over Prediction Horizon')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T17:58:13.114438Z",
     "start_time": "2025-05-26T17:58:13.083952Z"
    }
   },
   "id": "8ce3811f963721e2",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total fully padded agents pruned: 370\n",
      "Total invalid positions pruned (either current or next position was all zeros): 27691\n",
      "Total samples pruned due to too many zeros in the window: 9461\n",
      "Total valid samples used for training: 29518\n",
      "\n",
      "Training on 29518 valid timestep sequences.\n",
      "Input shape: (29518, 50, 6), Output shape: (29518, 2)\n",
      "Delta stats: mean=[-0.01675608 -0.0146366 ], std=[0.43118823 0.24764302]\n",
      "Delta range: min=[-1.90392655 -1.53115254], max=[2.13883475 1.51240904]\n",
      "🔧 GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=3\n",
      "\n",
      "--- Phase 1: Training ---\n",
      "Epoch 1/100\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 0.1692 - mae: 0.2247\n",
      "New best val_loss: 0.176827. Saving model...\n",
      "Model saved to lstm_single_step.pkl\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 24ms/step - loss: 0.1692 - mae: 0.2247 - val_loss: 0.1768 - val_mae: 0.2468\n",
      "Epoch 2/100\n",
      "\u001B[1m786/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 0.2110 - mae: 0.2834\n",
      "New best val_loss: 0.162232. Saving model...\n",
      "Model saved to lstm_single_step.pkl\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 23ms/step - loss: 0.2109 - mae: 0.2833 - val_loss: 0.1622 - val_mae: 0.2413\n",
      "Epoch 3/100\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 0.1424 - mae: 0.2161\n",
      "New best val_loss: 0.122154. Saving model...\n",
      "Model saved to lstm_single_step.pkl\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 22ms/step - loss: 0.1424 - mae: 0.2161 - val_loss: 0.1222 - val_mae: 0.2342\n",
      "Epoch 4/100\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 22ms/step - loss: 0.1585 - mae: 0.2229 - val_loss: 0.1930 - val_mae: 0.3244\n",
      "Epoch 5/100\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 22ms/step - loss: 0.2072 - mae: 0.2862 - val_loss: 0.1587 - val_mae: 0.2317\n",
      "Epoch 6/100\n",
      "\u001B[1m787/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 0.1472 - mae: 0.2087\n",
      "New best val_loss: 0.093976. Saving model...\n",
      "Model saved to lstm_single_step.pkl\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 23ms/step - loss: 0.1472 - mae: 0.2086 - val_loss: 0.0940 - val_mae: 0.1789\n",
      "Epoch 7/100\n",
      "\u001B[1m787/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 0.1295 - mae: 0.1868\n",
      "New best val_loss: 0.083913. Saving model...\n",
      "Model saved to lstm_single_step.pkl\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 22ms/step - loss: 0.1295 - mae: 0.1868 - val_loss: 0.0839 - val_mae: 0.1581\n",
      "Epoch 8/100\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 22ms/step - loss: 0.1284 - mae: 0.1877 - val_loss: 0.1384 - val_mae: 0.2156\n",
      "Epoch 9/100\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 23ms/step - loss: 0.1661 - mae: 0.2355 - val_loss: 0.1279 - val_mae: 0.2066\n",
      "Epoch 10/100\n",
      "\u001B[1m786/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 0.2189 - mae: 0.2793\n",
      "Epoch 10: val_loss did not improve. Reducing LR from 0.001000 to 0.000500\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 22ms/step - loss: 0.2190 - mae: 0.2794 - val_loss: 0.1290 - val_mae: 0.2212\n",
      "Epoch 11/100\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 22ms/step - loss: 0.1603 - mae: 0.2287 - val_loss: 0.0918 - val_mae: 0.1735\n",
      "\n",
      "--- Phase 2: Fine-tuning ---\n",
      "Epoch 1/100\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 0.1233 - mae: 0.1690\n",
      "New best val_loss: 0.078954. Saving model...\n",
      "Model saved to lstm_single_step.pkl\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 24ms/step - loss: 0.1233 - mae: 0.1690 - val_loss: 0.0790 - val_mae: 0.1547 - learning_rate: 1.0000e-05\n",
      "Epoch 2/100\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 0.1082 - mae: 0.1560\n",
      "New best val_loss: 0.077766. Saving model...\n",
      "Model saved to lstm_single_step.pkl\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 24ms/step - loss: 0.1082 - mae: 0.1560 - val_loss: 0.0778 - val_mae: 0.1522 - learning_rate: 1.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 23ms/step - loss: 0.1111 - mae: 0.1579 - val_loss: 0.0800 - val_mae: 0.1541 - learning_rate: 1.0000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 24ms/step - loss: 0.1182 - mae: 0.1590 - val_loss: 0.0793 - val_mae: 0.1552 - learning_rate: 1.0000e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m788/788\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 24ms/step - loss: 0.1061 - mae: 0.1554 - val_loss: 0.0781 - val_mae: 0.1509 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# first check that the model can overfit on small data\n",
    "# shuffled_train_data = train_data.copy()\n",
    "# np.random.shuffle(shuffled_train_data)  # shuffles in-place along axis 0 (scenarios)\n",
    "\n",
    "model, X_mean, X_std, y_mean, y_std  = train_model(train_data[:30], batch_size=30, validation_split=0.2, epochs=100, epochs2=100, lr1 = 0.001, lr2=0.00001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T18:28:45.600034Z",
     "start_time": "2025-05-26T18:23:52.589660Z"
    }
   },
   "id": "deeaeac04573c115",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# save_model(model, \"general_single_step.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T18:28:45.602283Z",
     "start_time": "2025-05-26T18:28:45.596009Z"
    }
   },
   "id": "1fc0733bc8bee546",
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wv/j6ybhf8906j4bmnp171wtn680000gn/T/ipykernel_31200/3735350324.py:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap1 = plt.cm.get_cmap('viridis', 50)\n",
      "/var/folders/wv/j6ybhf8906j4bmnp171wtn680000gn/T/ipykernel_31200/3735350324.py:10: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap2 = plt.cm.get_cmap('plasma', 50)\n"
     ]
    }
   ],
   "source": [
    "# visualize prediction\n",
    "\n",
    "# model = load_model()\n",
    "\n",
    "# Parameters\n",
    "Tobs = 50\n",
    "Tpred = 60\n",
    "\n",
    "data = train_data[3000]\n",
    "\n",
    "# Select a test scenario (can use any valid index)\n",
    "test_scenario = data.copy()  # shape (agents, time_steps, features)\n",
    "\n",
    "# Forecast future positions\n",
    "predicted_positions = forecast_positions(test_scenario, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std)\n",
    "\n",
    "# Create combined matrix of past observed + predicted for ego agent (agent 0)\n",
    "ego_past = test_scenario[0, :Tobs, :2]               # shape (Tobs, 2)\n",
    "ego_future = predicted_positions[0]                  # shape (Tpred, 2)\n",
    "ego_full = np.concatenate([ego_past, ego_future], axis=0)  # shape (Tobs + Tpred, 2)\n",
    "\n",
    "# Create updated scenario with predicted ego and original others\n",
    "updated_scenario = test_scenario.copy()\n",
    "updated_scenario[0, :Tobs+Tpred, :2] = ego_full  # Replace ego trajectory\n",
    "\n",
    "# print(updated_scenario[0])\n",
    "\n",
    "# Visualize\n",
    "make_gif(updated_scenario, data, name='lstm_single_step')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T18:35:43.945008Z",
     "start_time": "2025-05-26T18:34:42.096184Z"
    }
   },
   "id": "fedc61e344476eb0",
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total agents: 50\n",
      "Accepted samples: 0\n",
      "Pruned fully padded agents: 3\n",
      "Pruned type mismatches: 0\n",
      "Pruned due to velocity mismatch: 45\n",
      "Pruned invalid positions: 0\n",
      "No valid agents found for fine-tuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wv/j6ybhf8906j4bmnp171wtn680000gn/T/ipykernel_31200/3735350324.py:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap1 = plt.cm.get_cmap('viridis', 50)\n",
      "/var/folders/wv/j6ybhf8906j4bmnp171wtn680000gn/T/ipykernel_31200/3735350324.py:10: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap2 = plt.cm.get_cmap('plasma', 50)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[72], line 29\u001B[0m\n\u001B[1;32m     24\u001B[0m updated_scenario[\u001B[38;5;241m0\u001B[39m, :Tobs\u001B[38;5;241m+\u001B[39mTpred, :\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m=\u001B[39m ego_full  \u001B[38;5;66;03m# Replace ego trajectory\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# print(updated_scenario[0])\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# Visualize\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m \u001B[43mmake_gif\u001B[49m\u001B[43m(\u001B[49m\u001B[43mupdated_scenario\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlstm_single_step\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[47], line 63\u001B[0m, in \u001B[0;36mmake_gif\u001B[0;34m(data_matrix1, data_matrix2, name)\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ax1\u001B[38;5;241m.\u001B[39mcollections \u001B[38;5;241m+\u001B[39m ax1\u001B[38;5;241m.\u001B[39mlines \u001B[38;5;241m+\u001B[39m ax2\u001B[38;5;241m.\u001B[39mcollections \u001B[38;5;241m+\u001B[39m ax2\u001B[38;5;241m.\u001B[39mlines\n\u001B[1;32m     62\u001B[0m anim \u001B[38;5;241m=\u001B[39m animation\u001B[38;5;241m.\u001B[39mFuncAnimation(fig, update, frames\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, timesteps, \u001B[38;5;241m3\u001B[39m)), interval\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, blit\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 63\u001B[0m \u001B[43manim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrajectory_visualization_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mname\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.gif\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwriter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpillow\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     64\u001B[0m plt\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/animation.py:1085\u001B[0m, in \u001B[0;36mAnimation.save\u001B[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001B[0m\n\u001B[1;32m   1082\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39m[a\u001B[38;5;241m.\u001B[39mnew_saved_frame_seq() \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m all_anim]):\n\u001B[1;32m   1083\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m anim, d \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(all_anim, data):\n\u001B[1;32m   1084\u001B[0m         \u001B[38;5;66;03m# TODO: See if turning off blit is really necessary\u001B[39;00m\n\u001B[0;32m-> 1085\u001B[0m         \u001B[43manim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_draw_next_frame\u001B[49m\u001B[43m(\u001B[49m\u001B[43md\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mblit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   1086\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m progress_callback \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1087\u001B[0m             progress_callback(frame_number, total_frames)\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/animation.py:1121\u001B[0m, in \u001B[0;36mAnimation._draw_next_frame\u001B[0;34m(self, framedata, blit)\u001B[0m\n\u001B[1;32m   1119\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pre_draw(framedata, blit)\n\u001B[1;32m   1120\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_draw_frame(framedata)\n\u001B[0;32m-> 1121\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post_draw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframedata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mblit\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/animation.py:1146\u001B[0m, in \u001B[0;36mAnimation._post_draw\u001B[0;34m(self, framedata, blit)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_blit_draw(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_drawn_artists)\n\u001B[1;32m   1145\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1146\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcanvas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw_idle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/backend_bases.py:1905\u001B[0m, in \u001B[0;36mFigureCanvasBase.draw_idle\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1903\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_idle_drawing:\n\u001B[1;32m   1904\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_idle_draw_cntx():\n\u001B[0;32m-> 1905\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:387\u001B[0m, in \u001B[0;36mFigureCanvasAgg.draw\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    384\u001B[0m \u001B[38;5;66;03m# Acquire a lock on the shared font cache.\u001B[39;00m\n\u001B[1;32m    385\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtoolbar\u001B[38;5;241m.\u001B[39m_wait_cursor_for_draw_cm() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtoolbar\n\u001B[1;32m    386\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m nullcontext()):\n\u001B[0;32m--> 387\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfigure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001B[39;00m\n\u001B[1;32m    389\u001B[0m     \u001B[38;5;66;03m# don't forget to call the superclass.\u001B[39;00m\n\u001B[1;32m    390\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mdraw()\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/artist.py:95\u001B[0m, in \u001B[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001B[0;34m(artist, renderer, *args, **kwargs)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(draw)\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdraw_wrapper\u001B[39m(artist, renderer, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m---> 95\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43martist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m renderer\u001B[38;5;241m.\u001B[39m_rasterizing:\n\u001B[1;32m     97\u001B[0m         renderer\u001B[38;5;241m.\u001B[39mstop_rasterizing()\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/artist.py:72\u001B[0m, in \u001B[0;36mallow_rasterization.<locals>.draw_wrapper\u001B[0;34m(artist, renderer)\u001B[0m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     70\u001B[0m         renderer\u001B[38;5;241m.\u001B[39mstart_filter()\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43martist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/figure.py:3162\u001B[0m, in \u001B[0;36mFigure.draw\u001B[0;34m(self, renderer)\u001B[0m\n\u001B[1;32m   3159\u001B[0m             \u001B[38;5;66;03m# ValueError can occur when resizing a window.\u001B[39;00m\n\u001B[1;32m   3161\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatch\u001B[38;5;241m.\u001B[39mdraw(renderer)\n\u001B[0;32m-> 3162\u001B[0m     \u001B[43mmimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_draw_list_compositing_images\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3163\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martists\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msuppressComposite\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3165\u001B[0m     renderer\u001B[38;5;241m.\u001B[39mclose_group(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfigure\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   3166\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/image.py:132\u001B[0m, in \u001B[0;36m_draw_list_compositing_images\u001B[0;34m(renderer, parent, artists, suppress_composite)\u001B[0m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m not_composite \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m has_images:\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m artists:\n\u001B[0;32m--> 132\u001B[0m         \u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;66;03m# Composite any adjacent images together\u001B[39;00m\n\u001B[1;32m    135\u001B[0m     image_group \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/artist.py:72\u001B[0m, in \u001B[0;36mallow_rasterization.<locals>.draw_wrapper\u001B[0;34m(artist, renderer)\u001B[0m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     70\u001B[0m         renderer\u001B[38;5;241m.\u001B[39mstart_filter()\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43martist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py:3137\u001B[0m, in \u001B[0;36m_AxesBase.draw\u001B[0;34m(self, renderer)\u001B[0m\n\u001B[1;32m   3134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m artists_rasterized:\n\u001B[1;32m   3135\u001B[0m     _draw_rasterized(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfigure, artists_rasterized, renderer)\n\u001B[0;32m-> 3137\u001B[0m \u001B[43mmimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_draw_list_compositing_images\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3138\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martists\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfigure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msuppressComposite\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3140\u001B[0m renderer\u001B[38;5;241m.\u001B[39mclose_group(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maxes\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   3141\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstale \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/image.py:132\u001B[0m, in \u001B[0;36m_draw_list_compositing_images\u001B[0;34m(renderer, parent, artists, suppress_composite)\u001B[0m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m not_composite \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m has_images:\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m artists:\n\u001B[0;32m--> 132\u001B[0m         \u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;66;03m# Composite any adjacent images together\u001B[39;00m\n\u001B[1;32m    135\u001B[0m     image_group \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/artist.py:72\u001B[0m, in \u001B[0;36mallow_rasterization.<locals>.draw_wrapper\u001B[0;34m(artist, renderer)\u001B[0m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     70\u001B[0m         renderer\u001B[38;5;241m.\u001B[39mstart_filter()\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43martist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/axis.py:1427\u001B[0m, in \u001B[0;36mAxis.draw\u001B[0;34m(self, renderer)\u001B[0m\n\u001B[1;32m   1424\u001B[0m tlb1, tlb2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001B[1;32m   1426\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m tick \u001B[38;5;129;01min\u001B[39;00m ticks_to_draw:\n\u001B[0;32m-> 1427\u001B[0m     \u001B[43mtick\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1429\u001B[0m \u001B[38;5;66;03m# Shift label away from axes to avoid overlapping ticklabels.\u001B[39;00m\n\u001B[1;32m   1430\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_label_position(renderer)\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/artist.py:72\u001B[0m, in \u001B[0;36mallow_rasterization.<locals>.draw_wrapper\u001B[0;34m(artist, renderer)\u001B[0m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     70\u001B[0m         renderer\u001B[38;5;241m.\u001B[39mstart_filter()\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43martist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/axis.py:277\u001B[0m, in \u001B[0;36mTick.draw\u001B[0;34m(self, renderer)\u001B[0m\n\u001B[1;32m    274\u001B[0m renderer\u001B[38;5;241m.\u001B[39mopen_group(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, gid\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_gid())\n\u001B[1;32m    275\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m artist \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgridline, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtick1line, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtick2line,\n\u001B[1;32m    276\u001B[0m                \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabel1, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabel2]:\n\u001B[0;32m--> 277\u001B[0m     \u001B[43martist\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    278\u001B[0m renderer\u001B[38;5;241m.\u001B[39mclose_group(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m    279\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstale \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/artist.py:72\u001B[0m, in \u001B[0;36mallow_rasterization.<locals>.draw_wrapper\u001B[0;34m(artist, renderer)\u001B[0m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     70\u001B[0m         renderer\u001B[38;5;241m.\u001B[39mstart_filter()\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43martist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/lines.py:751\u001B[0m, in \u001B[0;36mLine2D.draw\u001B[0;34m(self, renderer)\u001B[0m\n\u001B[1;32m    748\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    750\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_invalidy \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_invalidx:\n\u001B[0;32m--> 751\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecache\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    752\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mind_offset \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m  \u001B[38;5;66;03m# Needed for contains() method.\u001B[39;00m\n\u001B[1;32m    753\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_subslice \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes:\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/matplotlib/lines.py:683\u001B[0m, in \u001B[0;36mLine2D.recache\u001B[0;34m(self, always)\u001B[0m\n\u001B[1;32m    680\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    681\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_y\n\u001B[0;32m--> 683\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_xy \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumn_stack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbroadcast_arrays\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mfloat\u001B[39m)\n\u001B[1;32m    684\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_xy\u001B[38;5;241m.\u001B[39mT  \u001B[38;5;66;03m# views\u001B[39;00m\n\u001B[1;32m    686\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_subslice \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/numpy/lib/shape_base.py:652\u001B[0m, in \u001B[0;36mcolumn_stack\u001B[0;34m(tup)\u001B[0m\n\u001B[1;32m    650\u001B[0m         arr \u001B[38;5;241m=\u001B[39m array(arr, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, subok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, ndmin\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mT\n\u001B[1;32m    651\u001B[0m     arrays\u001B[38;5;241m.\u001B[39mappend(arr)\n\u001B[0;32m--> 652\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_nx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1800x900 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize fine-tunded prediction\n",
    "\n",
    "# model = load_model()\n",
    "\n",
    "# Parameters\n",
    "Tobs = 50\n",
    "Tpred = 60\n",
    "\n",
    "data = train_data[0]\n",
    "\n",
    "# Select a test scenario (can use any valid index)\n",
    "test_scenario = data.copy()  # shape (agents, time_steps, features)\n",
    "\n",
    "# Forecast future positions\n",
    "predicted_positions = finetune_forecast_positions(test_scenario, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std, verbose=True)\n",
    "\n",
    "# Create combined matrix of past observed + predicted for ego agent (agent 0)\n",
    "ego_past = test_scenario[0, :Tobs, :2]               # shape (Tobs, 2)\n",
    "ego_future = predicted_positions[0]                  # shape (Tpred, 2)\n",
    "ego_full = np.concatenate([ego_past, ego_future], axis=0)  # shape (Tobs + Tpred, 2)\n",
    "\n",
    "# Create updated scenario with predicted ego and original others\n",
    "updated_scenario = test_scenario.copy()\n",
    "updated_scenario[0, :Tobs+Tpred, :2] = ego_full  # Replace ego trajectory\n",
    "\n",
    "# print(updated_scenario[0])\n",
    "\n",
    "# Visualize\n",
    "make_gif(updated_scenario, data, name='lstm_single_step')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T18:18:51.051254Z",
     "start_time": "2025-05-26T18:18:44.138927Z"
    }
   },
   "id": "c1b534ab5b272dcf",
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Train the model -> to beat val of 0.0711\n",
    "model, X_mean, X_std, y_mean, y_std = train_model(train_data)\n",
    "\n",
    "# Save the model \n",
    "save_model(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-25T22:47:01.937412Z"
    }
   },
   "id": "3338be4ed075b368",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_mse(train_data, model, forecast_fn, Tobs=50, Tpred=60, \n",
    "                 X_mean=None, X_std=None, y_mean=None, y_std=None):\n",
    "    \"\"\"\n",
    "    Evaluate MSE of a forecast function on ego agent across scenarios.\n",
    "\n",
    "    Args:\n",
    "        train_data (np.ndarray): Shape (N, agents, timesteps, features)\n",
    "        model (tf.keras.Model): Trained single-step model\n",
    "        forecast_fn (callable): Function to call for forecasting. Must match:\n",
    "            (scenario_data, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std) -> np.ndarray\n",
    "        Tobs (int): Number of observed steps\n",
    "        Tpred (int): Number of predicted steps\n",
    "        X_mean, X_std, y_mean, y_std (optional): Normalization statistics\n",
    "\n",
    "    Returns:\n",
    "        float: Mean squared error across valid scenarios\n",
    "    \"\"\"\n",
    "    N = train_data.shape[0]\n",
    "    mse_list = []\n",
    "    valid_scenarios = 0\n",
    "    \n",
    "    print(f\"Evaluating {N} scenarios...\")\n",
    "    report_interval = max(1, N // 10)\n",
    "\n",
    "    for i in range(N):\n",
    "        if i % report_interval == 0 or i == N - 1:\n",
    "            print(f\"Processing scenario {i+1}/{N} ({(i+1)/N*100:.1f}%)\")\n",
    "        \n",
    "        scenario_data = train_data[i]  # shape (agents, timesteps, 6)\n",
    "        ego_agent_data = scenario_data[0]  # shape (timesteps, 6)\n",
    "        ground_truth = ego_agent_data[Tobs:Tobs + Tpred, :2]\n",
    "\n",
    "        if np.all(ground_truth == 0):\n",
    "            continue\n",
    "\n",
    "        valid_scenarios += 1\n",
    "\n",
    "        predicted_positions = forecast_fn(\n",
    "            ego_agent_data[np.newaxis, :, :],  # (1, timesteps, 6)\n",
    "            Tobs, Tpred, model,\n",
    "            X_mean=X_mean, X_std=X_std, y_mean=y_mean, y_std=y_std\n",
    "        )\n",
    "\n",
    "        mse = mean_squared_error(ground_truth, predicted_positions[0])\n",
    "        mse_list.append(mse)\n",
    "\n",
    "        if i % report_interval == 0:\n",
    "            print(f\"  Current scenario {i} MSE: {mse:.4f}\")\n",
    "\n",
    "    if mse_list:\n",
    "        overall_mse = np.mean(mse_list)\n",
    "        print(f\"\\nEvaluation complete: {valid_scenarios} valid scenarios\")\n",
    "        print(f\"Mean Squared Error (MSE): {overall_mse:.4f}\")\n",
    "        print(f\"Min MSE: {np.min(mse_list):.4f}, Max MSE: {np.max(mse_list):.4f}\")\n",
    "        return overall_mse\n",
    "    else:\n",
    "        print(\"No valid scenarios for evaluation.\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T18:30:59.758070Z",
     "start_time": "2025-05-26T18:30:59.393202Z"
    }
   },
   "id": "94a6d7a17d8677e1",
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 30 scenarios...\n",
      "Processing scenario 1/30 (3.3%)\n",
      "  Current scenario 0 MSE: 5361.8938\n",
      "Processing scenario 4/30 (13.3%)\n",
      "  Current scenario 3 MSE: 2907.5031\n",
      "Processing scenario 7/30 (23.3%)\n",
      "  Current scenario 6 MSE: 5737.7192\n",
      "Processing scenario 10/30 (33.3%)\n",
      "  Current scenario 9 MSE: 3346.7940\n",
      "Processing scenario 13/30 (43.3%)\n",
      "  Current scenario 12 MSE: 3678.9222\n",
      "Processing scenario 16/30 (53.3%)\n",
      "  Current scenario 15 MSE: 12.3063\n",
      "Processing scenario 19/30 (63.3%)\n",
      "  Current scenario 18 MSE: 1043.1046\n",
      "Processing scenario 22/30 (73.3%)\n",
      "  Current scenario 21 MSE: 4337.2805\n",
      "Processing scenario 25/30 (83.3%)\n",
      "  Current scenario 24 MSE: 3588.6713\n",
      "Processing scenario 28/30 (93.3%)\n",
      "  Current scenario 27 MSE: 3550.3187\n",
      "Processing scenario 30/30 (100.0%)\n",
      "\n",
      "Evaluation complete: 30 valid scenarios\n",
      "Mean Squared Error (MSE): 3320.9765\n",
      "Min MSE: 12.3063, Max MSE: 8035.7212\n"
     ]
    },
    {
     "data": {
      "text/plain": "3320.976507999308"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on training data\n",
    "evaluate_mse(train_data[3000:3030], model, forecast_fn=forecast_positions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T18:31:44.505134Z",
     "start_time": "2025-05-26T18:30:59.769318Z"
    }
   },
   "id": "76a45de5cfb6e914",
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_submission(data, output_csv, model, forecast_fn, \n",
    "                        Tobs=50, Tpred=60,\n",
    "                        X_mean=None, X_std=None, y_mean=None, y_std=None):\n",
    "    \"\"\"\n",
    "    Generates a submission CSV file with predicted (x, y) positions for the ego agent.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): Test data of shape (num_scenarios, agents, timesteps, features).\n",
    "        output_csv (str): Output CSV file path.\n",
    "        model (tf.keras.Model): Trained prediction model.\n",
    "        forecast_fn (callable): Forecast function with signature:\n",
    "            (scenario_data, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std) -> np.ndarray\n",
    "        Tobs (int): Number of observed time steps.\n",
    "        Tpred (int): Number of predicted time steps.\n",
    "        X_mean, X_std, y_mean, y_std (optional): Normalization statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    print(f\"Generating predictions for {data.shape[0]} scenarios...\")\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        scenario_data = data[i]            # Shape: (agents, timesteps, 6)\n",
    "        ego_agent_data = scenario_data[0]  # Shape: (timesteps, 6)\n",
    "\n",
    "        predicted_positions = forecast_fn(\n",
    "            ego_agent_data[np.newaxis, :, :], Tobs, Tpred, model,\n",
    "            X_mean=X_mean, X_std=X_std, y_mean=y_mean, y_std=y_std\n",
    "        )  # Shape: (1, Tpred, 2)\n",
    "\n",
    "        predictions.extend(predicted_positions[0])  # Append shape: (Tpred, 2)\n",
    "\n",
    "    submission_df = pd.DataFrame(predictions, columns=[\"x\", \"y\"])\n",
    "    submission_df.index.name = 'index'  # Match required format\n",
    "    submission_df.to_csv(output_csv)\n",
    "\n",
    "    print(f\"Submission file '{output_csv}' saved with shape {submission_df.shape}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2557ca9bf552c0b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "generate_submission(\n",
    "    data=test_data,\n",
    "    output_csv='lstm_submission.csv',\n",
    "    model=model,\n",
    "    forecast_fn=forecast_positions,  # or finetune_forecast_positions\n",
    "    Tobs=50,\n",
    "    Tpred=60,\n",
    "    X_mean=X_mean,\n",
    "    X_std=X_std,\n",
    "    y_mean=y_mean,\n",
    "    y_std=y_std\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4f8d7605d54296d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
