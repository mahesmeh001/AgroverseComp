{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-28T19:45:52.394040Z",
     "start_time": "2025-05-28T19:45:50.187462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape (10000, 50, 110, 6)\n",
      "test_data's shape (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import numpy as np\n",
    "train_file = np.load('data/train.npz')\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape\", train_data.shape)\n",
    "test_file = np.load('data/test_input.npz')\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehul/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, RepeatVector, TimeDistributed, Dropout"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:15.026902Z",
     "start_time": "2025-05-28T18:32:10.825953Z"
    }
   },
   "id": "db97d754762b390b",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def standardize_data_dimensions(scenario_data):\n",
    "    \"\"\"\n",
    "    Standardize position data by centering a single scenario at the origin.\n",
    "    \n",
    "    :param scenario_data: numpy array of shape (50, 110, 6)\n",
    "                         where dimensions are [position_x, position_y, velocity_x, velocity_y, heading, object_type]\n",
    "    :returns: tuple of (standardized_data, min_values)\n",
    "             - standardized_data: same shape as input with centered positions\n",
    "             - min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    \"\"\"\n",
    "    # Copy the data to avoid modifying the original\n",
    "    standardized_data = scenario_data.copy()\n",
    "    \n",
    "    # Extract position data (first 2 dimensions)\n",
    "    positions = scenario_data[:, :, :2]  # Shape: (50, 110, 2)\n",
    "    \n",
    "    # Create mask for non-zero positions (to ignore padding)\n",
    "    # We consider a position valid if it's not (0,0) or if the object_type is not 0\n",
    "    object_types = scenario_data[:, :, 5]  # Shape: (50, 110)\n",
    "    valid_mask = (positions[:, :, 0] != 0) | (positions[:, :, 1] != 0) | (object_types != 0)\n",
    "    \n",
    "    # Find min values across all valid positions in this scenario\n",
    "    if np.any(valid_mask):\n",
    "        valid_positions = positions[valid_mask]  # Shape: (num_valid_points, 2)\n",
    "        min_x = np.min(valid_positions[:, 0])\n",
    "        min_y = np.min(valid_positions[:, 1])\n",
    "    else:\n",
    "        # If no valid positions found, use 0 as min values\n",
    "        min_x = 0\n",
    "        min_y = 0\n",
    "    \n",
    "    # Store min values\n",
    "    min_values = np.array([min_x, min_y])\n",
    "    \n",
    "    # Standardize positions by subtracting min values\n",
    "    # Only modify non-zero positions to preserve padding\n",
    "    for agent_idx in range(scenario_data.shape[0]):\n",
    "        for time_idx in range(scenario_data.shape[1]):\n",
    "            if valid_mask[agent_idx, time_idx]:\n",
    "                standardized_data[agent_idx, time_idx, 0] -= min_x  # position_x\n",
    "                standardized_data[agent_idx, time_idx, 1] -= min_y  # position_y\n",
    "    \n",
    "    return standardized_data, min_values\n",
    "\n",
    "\n",
    "def denormalize_predictions(predictions, min_values):\n",
    "    \"\"\"\n",
    "    Helper function to add back the min values to predicted positions.\n",
    "    \n",
    "    :param predictions: predicted data with standardized positions, shape (50, 110, 6) or similar\n",
    "    :param min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    :returns: predictions with original coordinate system restored\n",
    "    \"\"\"\n",
    "    denormalized = predictions.copy()\n",
    "    \n",
    "    # Add back the min values to restore original coordinate system\n",
    "    # Assuming predictions have position_x and position_y as first two dimensions\n",
    "    denormalized[:, :, 0] += min_values[0]  # position_x\n",
    "    denormalized[:, :, 1] += min_values[1]  # position_y\n",
    "    \n",
    "    return denormalized"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:15.034125Z",
     "start_time": "2025-05-28T18:32:15.029498Z"
    }
   },
   "id": "608ceed4f8ac038d",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "def standardize_single_scene(scene_data):\n",
    "    \"\"\"\n",
    "    Wrapper function to standardize a single scene and return both standardized data and min values.\n",
    "    This function will be called in parallel.\n",
    "    \"\"\"\n",
    "    standardized_scene, min_vals = standardize_data_dimensions(scene_data)\n",
    "    return standardized_scene, min_vals\n",
    "\n",
    "def parallel_standardize_training_data(train_data, n_jobs=-1, verbose=True):\n",
    "    \"\"\"\n",
    "    Parallelize the standardization of training data across all scenes.\n",
    "    \n",
    "    :param train_data: numpy array of shape (10000, 50, 110, 6)\n",
    "    :param n_jobs: number of parallel jobs (-1 uses all available cores)\n",
    "    :param verbose: whether to show progress bar\n",
    "    :returns: tuple of (standardized_data, min_values_array)\n",
    "    \"\"\"\n",
    "    print(f\"Standardizing {train_data.shape[0]} scenes using {multiprocessing.cpu_count() if n_jobs == -1 else n_jobs} cores...\")\n",
    "    \n",
    "    # Use joblib to parallelize the processing\n",
    "    if verbose:\n",
    "        # With progress bar\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(standardize_single_scene)(train_data[i]) \n",
    "            for i in tqdm(range(train_data.shape[0]), desc=\"Processing scenes\")\n",
    "        )\n",
    "    else:\n",
    "        # Without progress bar\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(standardize_single_scene)(train_data[i]) \n",
    "            for i in range(train_data.shape[0])\n",
    "        )\n",
    "    \n",
    "    # Unpack results\n",
    "    standardized_scenes, min_values_list = zip(*results)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    standardized_data = np.array(standardized_scenes)\n",
    "    min_values_array = np.array(min_values_list)\n",
    "    \n",
    "    print(f\"Standardization complete!\")\n",
    "    print(f\"Standardized data shape: {standardized_data.shape}\")\n",
    "    print(f\"Min values shape: {min_values_array.shape}\")\n",
    "    \n",
    "    return standardized_data, min_values_array"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:15.042580Z",
     "start_time": "2025-05-28T18:32:15.033394Z"
    }
   },
   "id": "504b76013f59f796",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing 10000 scenes using 8 cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing scenes: 100%|██████████| 10000/10000 [00:13<00:00, 734.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardization complete!\n",
      "Standardized data shape: (10000, 50, 110, 6)\n",
      "Min values shape: (10000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(10000, 50, 110, 6)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_train_data, min_values = parallel_standardize_training_data(\n",
    "    train_data, \n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=True\n",
    ")\n",
    "standardized_train_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:40.799028Z",
     "start_time": "2025-05-28T18:32:15.039668Z"
    }
   },
   "id": "bd9c62ee33aa23fb",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(model, filepath='lstm_single_step.pkl', \n",
    "               X_mean=None, X_std=None, y_mean=None, y_std=None):\n",
    "    \"\"\"Save model architecture, weights, and normalization parameters to a pickle file\"\"\"\n",
    "    model_json = model.to_json()\n",
    "    model_weights = model.get_weights()\n",
    "    data = {\n",
    "        'model_json': model_json,\n",
    "        'model_weights': model_weights,\n",
    "        'X_mean': X_mean,\n",
    "        'X_std': X_std,\n",
    "        'y_mean': y_mean,\n",
    "        'y_std': y_std,\n",
    "    }\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Model and normalization parameters saved to {filepath}\")\n",
    "\n",
    "\n",
    "def load_model(filepath='lstm_single_step.pkl'):\n",
    "    \"\"\"Load model and normalization parameters from a pickle file\"\"\"\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    # Reconstruct model\n",
    "    model = tf.keras.models.model_from_json(data['model_json'])\n",
    "    model.set_weights(data['model_weights'])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Return model and normalization parameters\n",
    "    return model, data['X_mean'], data['X_std'], data['y_mean'], data['y_std']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:40.821368Z",
     "start_time": "2025-05-28T18:32:40.801844Z"
    }
   },
   "id": "e3d667b335d4a0a",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input, LSTM, Dense, Dropout, TimeDistributed, Attention, Concatenate,\n",
    "    RepeatVector\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def old_model(\n",
    "    input_dim, output_dim, timesteps_in, timesteps_out,\n",
    "    lstm_units=64, num_layers=1, loss_fn='mse', lr=0.001\n",
    "):\n",
    "    # --- Input and Learnable Feature Weighting ---\n",
    "    encoder_inputs = Input(shape=(timesteps_in, input_dim))  # shape: (batch, Tobs, 6)\n",
    "    weighted_inputs = TimeDistributed(Dense(input_dim, activation=None))(encoder_inputs)\n",
    "\n",
    "    # --- Encoder ---\n",
    "    x = weighted_inputs\n",
    "    for _ in range(num_layers):\n",
    "        x = LSTM(lstm_units, return_sequences=True)(x)\n",
    "    encoder_outputs = x  # shape: (batch, Tobs, lstm_units)\n",
    "\n",
    "    # --- Decoder ---\n",
    "    decoder_input = RepeatVector(timesteps_out)(encoder_outputs[:, -1, :])\n",
    "    decoder_outputs = decoder_input\n",
    "    for _ in range(num_layers):\n",
    "        decoder_outputs = LSTM(lstm_units, return_sequences=True)(decoder_outputs)\n",
    "\n",
    "    # --- Attention ---\n",
    "    # attention = Attention()([decoder_outputs, encoder_outputs])\n",
    "    # x = Concatenate()([decoder_outputs, attention])\n",
    "\n",
    "    # --- Dense Layers ---\n",
    "    x = TimeDistributed(Dense(128, activation='relu'))(x)\n",
    "    x = TimeDistributed(Dense(64, activation='relu'))(x)\n",
    "    outputs = TimeDistributed(Dense(output_dim))(x)\n",
    "\n",
    "    model = Model(encoder_inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr, clipnorm=.5), loss=loss_fn, metrics=['mae'])\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:40.914281Z",
     "start_time": "2025-05-28T18:32:40.807472Z"
    }
   },
   "id": "d7f20fc814e583a3",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:40.916274Z",
     "start_time": "2025-05-28T18:32:40.832778Z"
    }
   },
   "id": "21f1db9fa58aef3",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_single_step_model(input_dim, timesteps_in, lstm_units=256, num_layers=2, loss_fn='mse', lr=0.0001):\n",
    "    \"\"\"\n",
    "    Simplified model for single-step prediction.\n",
    "    Input: (batch, timesteps, features)\n",
    "    Output: (batch, 2) - single delta prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input\n",
    "    inputs = Input(shape=(timesteps_in, input_dim))\n",
    "    \n",
    "    # LSTM layers\n",
    "    x = inputs\n",
    "    for i in range(num_layers):\n",
    "        return_sequences = (i < num_layers - 1)  # Return sequences for all but last layer\n",
    "        x = LSTM(lstm_units, return_sequences=return_sequences, dropout=0)(x)\n",
    "    \n",
    "    # Dense layers for final prediction\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    # x = Dropout(0.1)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    outputs = Dense(2)(x)  # Predict single delta (x, y)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr, clipnorm=0.5), loss=loss_fn, metrics=['mae'])\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:40.917494Z",
     "start_time": "2025-05-28T18:32:40.837490Z"
    }
   },
   "id": "932c0ab6efa77756",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.src.callbacks import LearningRateScheduler, EarlyStopping, Callback\n",
    "from keras.src.optimizers import Adam\n",
    "from keras import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class DynamicReduceLROnPlateau(Callback):\n",
    "    def __init__(self, factor=0.1, patience=3, min_lr=1e-7, verbose=1):\n",
    "        super().__init__()\n",
    "        self.factor = factor\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.verbose = verbose\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        current_val_loss = logs.get(\"val_loss\")\n",
    "\n",
    "        if current_val_loss is None:\n",
    "            return  # can't do anything if val_loss isn't available\n",
    "\n",
    "        if current_val_loss < self.best_val_loss - 1e-4:  # a small delta\n",
    "            self.best_val_loss = current_val_loss\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                old_lr = float(self.model.optimizer.learning_rate.numpy())\n",
    "                if old_lr > self.min_lr:\n",
    "                    new_lr = max(old_lr * self.factor, self.min_lr)\n",
    "                    self.model.optimizer.learning_rate.assign(new_lr)\n",
    "                    if self.verbose:\n",
    "                        print(f\"\\nEpoch {epoch+1}: val_loss did not improve. Reducing LR from {old_lr:.6f} to {new_lr:.6f}\")\n",
    "                    self.wait = 0  # reset after LR reduction\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:40.924752Z",
     "start_time": "2025-05-28T18:32:40.848397Z"
    }
   },
   "id": "4d68034c165292c5",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LRThresholdCallback(Callback):\n",
    "    def __init__(self, threshold=9e-5):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "        self.should_stop = False\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = float(self.model.optimizer.learning_rate.numpy())\n",
    "        if lr < self.threshold:\n",
    "            print(f\"\\nLearning rate {lr:.6f} < threshold {self.threshold}, moving to Phase 2.\")\n",
    "            self.model.stop_training = True\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:40.946049Z",
     "start_time": "2025-05-28T18:32:40.852133Z"
    }
   },
   "id": "3d4199e38cacc23e",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class GradientMonitoringCallback(Callback):\n",
    "    def __init__(self, clip_min=1e-4, clip_max=1e2, monitor_frequency=3):\n",
    "        \"\"\"\n",
    "        Monitor gradient norms during training\n",
    "        \n",
    "        Args:\n",
    "            clip_min: Minimum threshold for gradient norms\n",
    "            clip_max: Maximum threshold for gradient norms  \n",
    "            monitor_frequency: How often to check gradients (every N batches)\n",
    "        \"\"\"\n",
    "        print(f\"🔧 GradientMonitoringCallback initialized with clip_min={clip_min}, clip_max={clip_max}, monitor_freq={monitor_frequency}\")\n",
    "        self.clip_min = clip_min\n",
    "        self.clip_max = clip_max\n",
    "        self.monitor_frequency = monitor_frequency\n",
    "        self.batch_count = 0\n",
    "        self.total_calls = 0\n",
    "        self.gradient_checks = 0\n",
    "        self.fallback_calls = 0\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        print(\"🚀 GradientMonitoringCallback: Training started!\")\n",
    "        self.batch_count = 0\n",
    "        self.total_calls = 0\n",
    "        self.gradient_checks = 0\n",
    "        self.fallback_calls = 0\n",
    "        \n",
    "    # def on_epoch_begin(self, epoch, logs=None):\n",
    "    #     print(f\"📍 GradientMonitoringCallback: Starting epoch {epoch + 1}\")\n",
    "        \n",
    "    # def on_train_batch_begin(self, batch, logs=None):\n",
    "    #     # Just to prove we're being called\n",
    "    #     if batch % 50 == 0:  # Print every 50 batches to avoid spam\n",
    "    #         print(f\"⚡ GradientMonitoringCallback: Batch {batch} starting\")\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.batch_count += 1\n",
    "        self.total_calls += 1\n",
    "        \n",
    "        # Print every time to show we're being called\n",
    "        # if batch % 50 == 0:  # Print every 50 batches\n",
    "            # print(f\"📊 GradientMonitoringCallback: Batch {batch} ended (total calls: {self.total_calls})\")\n",
    "        \n",
    "        # Only monitor every N batches to avoid performance overhead\n",
    "        if self.batch_count % self.monitor_frequency != 0:\n",
    "            return\n",
    "            \n",
    "        # print(f\"🔍 GradientMonitoringCallback: Checking gradients at batch {batch} (check #{self.gradient_checks + 1})\")\n",
    "        \n",
    "        # Get gradients from the optimizer's current state\n",
    "        try:\n",
    "            # Access the model's optimizer to get gradient information\n",
    "            optimizer = self.model.optimizer\n",
    "            print(f\"   📋 Optimizer type: {type(optimizer).__name__}\")\n",
    "            \n",
    "            # Get trainable variables\n",
    "            trainable_vars = self.model.trainable_variables\n",
    "            print(f\"   📈 Number of trainable variables: {len(trainable_vars)}\")\n",
    "            \n",
    "            if hasattr(optimizer, 'get_gradients'):\n",
    "                print(\"   ✅ Optimizer has get_gradients method\")\n",
    "                # For some optimizers, we can access gradients directly\n",
    "                grads = optimizer.get_gradients(self.model.total_loss, trainable_vars)\n",
    "                print(f\"   📊 Retrieved {len([g for g in grads if g is not None])} gradients\")\n",
    "            else:\n",
    "                print(\"   ❌ Optimizer doesn't have get_gradients, using variable norms\")\n",
    "                # Alternative approach: check the current variable states\n",
    "                grad_norms = []\n",
    "                for i, var in enumerate(trainable_vars):\n",
    "                    if var is not None:\n",
    "                        var_norm = tf.norm(var)\n",
    "                        grad_norms.append(var_norm)\n",
    "                        if i < 3:  # Print first 3 for debugging\n",
    "                            print(f\"      Variable {i} norm: {float(var_norm.numpy()):.2e}\")\n",
    "                \n",
    "                self._check_norms(grad_norms, \"Variable\")\n",
    "                self.gradient_checks += 1\n",
    "                return\n",
    "                \n",
    "            # Compute gradient norms\n",
    "            grad_norms = []\n",
    "            for i, grad in enumerate(grads):\n",
    "                if grad is not None:\n",
    "                    grad_norm = tf.norm(grad)\n",
    "                    grad_norms.append(grad_norm)\n",
    "                    if i < 3:  # Print first 3 for debugging\n",
    "                        print(f\"      Gradient {i} norm: {float(grad_norm.numpy()):.2e}\")\n",
    "                    \n",
    "            print(f\"   ✅ Computed {len(grad_norms)} gradient norms\")\n",
    "            self._check_norms(grad_norms, \"Gradient\")\n",
    "            self.gradient_checks += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Exception in gradient monitoring: {str(e)}\")\n",
    "            self.fallback_calls += 1\n",
    "            # Fallback: just monitor the loss for signs of instability\n",
    "            print('   🔄 Fallback: monitoring loss only')\n",
    "            if logs:\n",
    "                loss_value = logs.get('loss', 0)\n",
    "                print(f\"   📉 Current loss: {loss_value:.2e}\")\n",
    "                if np.isnan(loss_value) or np.isinf(loss_value):\n",
    "                    print(f\"   ⚠️  WARNING: Loss became {loss_value} at batch {batch}\")\n",
    "                elif loss_value > 1e6:\n",
    "                    print(f\"   ⚠️  WARNING: Very large loss {loss_value:.2e} at batch {batch}\")\n",
    "    \n",
    "    def _check_norms(self, norms, norm_type=\"Gradient\"):\n",
    "        \"\"\"Check if norms are within acceptable range\"\"\"\n",
    "        print(f\"   🔬 Checking {len(norms)} {norm_type.lower()} norms...\")\n",
    "        warnings = 0\n",
    "        \n",
    "        for idx, norm in enumerate(norms):\n",
    "            try:\n",
    "                norm_value = float(norm.numpy()) if hasattr(norm, 'numpy') else float(norm)\n",
    "                \n",
    "                if norm_value > self.clip_max:\n",
    "                    print(f\"   ⚠️  WARNING: {norm_type} norm {norm_value:.2e} is too large (layer {idx})\")\n",
    "                    warnings += 1\n",
    "                elif norm_value < self.clip_min:\n",
    "                    print(f\"   ⚠️  WARNING: {norm_type} norm {norm_value:.2e} is too small (layer {idx})\")\n",
    "                    warnings += 1\n",
    "                elif np.isnan(norm_value) or np.isinf(norm_value):\n",
    "                    print(f\"   ⚠️  WARNING: {norm_type} norm is {norm_value} (layer {idx})\")\n",
    "                    warnings += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Cannot convert norm to float for layer {idx}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        if warnings == 0:\n",
    "            print(f\"   ✅ All {norm_type.lower()} norms are within acceptable range\")\n",
    "        else:\n",
    "            print(f\"   ⚠️  Found {warnings} norm warnings\")\n",
    "    \n",
    "    # def on_epoch_end(self, epoch, logs=None):\n",
    "    #     \"\"\"Print summary at end of each epoch\"\"\"\n",
    "    #     print(f\"📈 GradientMonitoringCallback: Epoch {epoch + 1} completed\")\n",
    "    #     print(f\"   📊 Total batch calls: {self.total_calls}\")\n",
    "    #     print(f\"   🔍 Gradient checks performed: {self.gradient_checks}\")\n",
    "    #     print(f\"   🔄 Fallback calls: {self.fallback_calls}\")\n",
    "    #     \n",
    "    #     if logs:\n",
    "    #         loss = logs.get('loss', 0)\n",
    "    #         val_loss = logs.get('val_loss', 0)\n",
    "    #         print(f\"   📉 Final epoch loss: {loss:.2e}\")\n",
    "    #         if val_loss:\n",
    "    #             print(f\"   📉 Final epoch val_loss: {val_loss:.2e}\")\n",
    "    #         \n",
    "    #         if np.isnan(loss) or np.isinf(loss):\n",
    "    #             print(f\"   ⚠️  WARNING: Training loss became unstable: {loss}\")\n",
    "    #         if val_loss and (np.isnan(val_loss) or np.isinf(val_loss)):\n",
    "    #             print(f\"   ⚠️  WARNING: Validation loss became unstable: {val_loss}\")\n",
    "        \n",
    "    def on_train_end(self, logs=None):\n",
    "        print(\"🏁 GradientMonitoringCallback: Training completed!\")\n",
    "        print(f\"   📊 Final stats - Total calls: {self.total_calls}, Gradient checks: {self.gradient_checks}, Fallbacks: {self.fallback_calls}\")\n",
    "        \n",
    "        if self.total_calls == 0:\n",
    "            print(\"   ❌ ERROR: Callback was never called! Check if it's properly added to callbacks list.\")\n",
    "        elif self.gradient_checks == 0 and self.fallback_calls == 0:\n",
    "            print(\"   ⚠️  WARNING: No gradient monitoring was performed. Check monitor_frequency setting.\")\n",
    "        else:\n",
    "            print(\"   ✅ Gradient monitoring completed successfully!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:40.947252Z",
     "start_time": "2025-05-28T18:32:40.854124Z"
    }
   },
   "id": "8fc55c9e1f03b71e",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class SaveBestModelCallback(Callback):\n",
    "    def __init__(self, save_path='lstm_single_step.pkl', monitor='val_loss',\n",
    "                 X_mean=None, X_std=None, y_mean=None, y_std=None):\n",
    "        super().__init__()\n",
    "        self.best = float('inf')\n",
    "        self.monitor = monitor\n",
    "        self.save_path = save_path\n",
    "        self.X_mean = X_mean\n",
    "        self.X_std = X_std\n",
    "        self.y_mean = y_mean\n",
    "        self.y_std = y_std\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is not None and current < self.best:\n",
    "            self.best = current\n",
    "            print(f\"\\nNew best {self.monitor}: {current:.6f}. Saving model...\")\n",
    "            save_model(self.model, self.save_path, \n",
    "                       self.X_mean, self.X_std, self.y_mean, self.y_std)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:40.948074Z",
     "start_time": "2025-05-28T18:32:40.869248Z"
    }
   },
   "id": "2ef8679e5c2bcf5b",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def exponential_decay_schedule(epoch, lr):\n",
    "    decay_rate = 0.5\n",
    "    decay_steps = 5\n",
    "    if epoch % decay_steps == 0 and epoch:\n",
    "        print('Learning rate update:', lr * decay_rate)\n",
    "        return lr * decay_rate\n",
    "    return lr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:40.948832Z",
     "start_time": "2025-05-28T18:32:40.873572Z"
    }
   },
   "id": "64bac463d13fa013",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(train_data, batch_size=32, validation_split=0.2, Tobs=50, epochs=50, epochs2=10, lr1=0.0001, lr2=0.000001):\n",
    "    n_scenarios, n_agents, T, D = train_data.shape  # Expecting (10000, 50, 110, 6)\n",
    "    assert D == 6, \"Expected 6 features per timestep (position, velocity, heading, object_type).\"\n",
    "\n",
    "    X_train_raw, y_train_deltas = [], []\n",
    "    \n",
    "    \n",
    "    pruned_fully_padded = 0\n",
    "    pruned_invalid_positions = 0\n",
    "    pruned_too_many_zeros = 0\n",
    "    valid_samples_count = 0  # To count how many valid samples are being used\n",
    "    \n",
    "    for i in range(n_scenarios):\n",
    "        for j in range(5): #n_agents\n",
    "            agent_data = train_data[i, j, :, :]  # shape (110, 6)\n",
    "    \n",
    "            # Count how many timesteps are completely zero\n",
    "            num_zero_timesteps = np.sum(np.all(agent_data == 0, axis=1))\n",
    "            if num_zero_timesteps >= 0.7 * agent_data.shape[0]:\n",
    "                pruned_fully_padded += 1\n",
    "                continue  # skip mostly padded agent\n",
    "    \n",
    "            # Create sliding window samples for single-step prediction\n",
    "            for t in range(Tobs, T - 1,15):  # From timestep 50 to 108 (inclusive)\n",
    "                # Input: previous Tobs timesteps (e.g., timesteps 0-49, 1-50, 2-51, etc.)\n",
    "                input_window = agent_data[t-Tobs:t, :]  # shape (50, 6)\n",
    "                \n",
    "                # Target: delta from current position to next position\n",
    "                current_pos = agent_data[t, :2]      # shape (2,)\n",
    "                next_pos = agent_data[t+1, :2]       # shape (2,)\n",
    "                delta = next_pos - current_pos       # shape (2,)\n",
    "    \n",
    "                # Skip only if current or next positions are invalid, or if too many zeros in window\n",
    "                if np.all(current_pos == 0) or np.all(next_pos == 0):\n",
    "                    pruned_invalid_positions += 1\n",
    "                    continue\n",
    "                \n",
    "                # Allow some zeros in the window, but not too many (e.g., less than 80% valid)\n",
    "                valid_positions = ~np.all(input_window[:, :2] == 0, axis=1)\n",
    "                if np.sum(valid_positions) < 0.8 * Tobs:  # At least 60% of timesteps must be valid\n",
    "                    pruned_too_many_zeros += 1\n",
    "                    continue\n",
    "    \n",
    "                X_train_raw.append(input_window)     # shape (50, 6)\n",
    "                y_train_deltas.append(delta)         # shape (2,)\n",
    "                valid_samples_count += 1  # Count valid samples\n",
    "    \n",
    "    # Final print statements to summarize pruning\n",
    "    print(f\"Total mostly padded agents pruned: {pruned_fully_padded}\")\n",
    "    print(f\"Total invalid positions pruned (either current or next position was all zeros): {pruned_invalid_positions}\")\n",
    "    print(f\"Total samples pruned due to too many zeros in the window: {pruned_too_many_zeros}\")\n",
    "    print(f\"Total valid samples used for training: {valid_samples_count}\\n\")\n",
    "    \n",
    "    # Convert to numpy arrays for training\n",
    "    X_train = np.array(X_train_raw)           # shape (N, 50, 6)\n",
    "    y_train = np.array(y_train_deltas)        # shape (N, 2)\n",
    "\n",
    "    print(f\"Training on {X_train.shape[0]} valid timestep sequences.\")\n",
    "    print(f\"Input shape: {X_train.shape}, Output shape: {y_train.shape}\")\n",
    "\n",
    "    # Add debugging info\n",
    "    print(f\"Delta stats: mean={y_train.mean(axis=0)}, std={y_train.std(axis=0)}\")\n",
    "    print(f\"Delta range: min={y_train.min(axis=0)}, max={y_train.max(axis=0)}\")\n",
    "\n",
    "    # --- Normalize ---\n",
    "    X_mean = X_train.mean(axis=(0, 1), keepdims=True)  # shape: (1, 1, 6)\n",
    "    X_std = X_train.std(axis=(0, 1), keepdims=True) + 1e-8\n",
    "\n",
    "    y_mean = y_train.mean(axis=0, keepdims=True)  # shape: (1, 2)\n",
    "    y_std = y_train.std(axis=0, keepdims=True) + 1e-8\n",
    "\n",
    "    X_train = (X_train - X_mean) / X_std\n",
    "    y_train = (y_train - y_mean) / y_std\n",
    "\n",
    "    # --- Model (simplified for single-step prediction) ---\n",
    "    model = create_single_step_model(\n",
    "        input_dim=X_train.shape[-1],\n",
    "        timesteps_in=Tobs,\n",
    "        loss_fn='mse',\n",
    "        lr=lr1\n",
    "    )\n",
    "    \n",
    "    lr_scheduler_callback = LearningRateScheduler(exponential_decay_schedule, verbose=1)\n",
    "    \n",
    "    gradient_monitoring_callback = GradientMonitoringCallback(clip_min=1e-4, clip_max=1e2)\n",
    "    \n",
    "    save_best_callback = SaveBestModelCallback(\n",
    "        save_path='lstm_single_step.pkl',\n",
    "        monitor='val_loss',\n",
    "        X_mean=X_mean,\n",
    "        X_std=X_std,\n",
    "        y_mean=y_mean,\n",
    "        y_std=y_std\n",
    "    )\n",
    "\n",
    "\n",
    "    phase1_callbacks = [\n",
    "        DynamicReduceLROnPlateau(factor=0.1, patience=2, min_lr=1e-9),\n",
    "        # lr_scheduler_callback,\n",
    "        save_best_callback,\n",
    "        EarlyStopping(patience=6, restore_best_weights=True, monitor='val_loss'),\n",
    "        LRThresholdCallback(threshold=9e-8)\n",
    "    ]\n",
    "\n",
    "    print(\"\\n--- Phase 1: Training ---\")\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=phase1_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Phase 2: Fine-tuning ---\")\n",
    "    model.compile(optimizer=Adam(lr2, clipnorm=0.5), loss='mse', metrics=['mae'])\n",
    "    phase2_callbacks = [\n",
    "        LearningRateScheduler(exponential_decay_schedule),\n",
    "        EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss'),\n",
    "        save_best_callback,\n",
    "        LRThresholdCallback(threshold=9e-8)\n",
    "\n",
    "    ]\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs2,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=phase2_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return model, X_mean, X_std, y_mean, y_std"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:40.950845Z",
     "start_time": "2025-05-28T18:32:40.876044Z"
    }
   },
   "id": "523c5a1dd20df920",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def reconstruct_absolute_positions(pred_deltas, last_observed_positions):\n",
    "    \"\"\"\n",
    "    Reconstruct absolute predicted positions by adding deltas to the last observed position.\n",
    "\n",
    "    Args:\n",
    "        pred_deltas: np.ndarray of shape (N, Tpred, 2)\n",
    "        last_observed_positions: np.ndarray of shape (N, 2)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray of shape (N, Tpred, 2)\n",
    "    \"\"\"\n",
    "    return last_observed_positions[:, None, :] + np.cumsum(pred_deltas, axis=1)\n",
    "\n",
    "\n",
    "def forecast_positions(scenario_data, Tobs, Tpred, model, X_mean=None, X_std=None, y_mean=None, y_std=None):\n",
    "    \"\"\"\n",
    "    Use single-step LSTM model to forecast future deltas iteratively and reconstruct absolute positions.\n",
    "    This function only forecasts for the ego agent (agent_index=0).\n",
    "    \n",
    "    This function performs autoregressive prediction: uses the model to predict one step ahead,\n",
    "    then incorporates that prediction into the input window for the next prediction.\n",
    "\n",
    "    Args:\n",
    "        scenario_data (numpy.ndarray): Shape (agents, time_steps, dimensions)\n",
    "        Tobs (int): Number of observed time steps (window size for model input)\n",
    "        Tpred (int): Number of future time steps to predict\n",
    "        model (Model): Trained single-step LSTM model that predicts one normalized delta\n",
    "        X_mean, X_std: Normalization stats for input (optional)\n",
    "        y_mean, y_std: Normalization stats for output (optional)\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Predicted absolute positions of shape (Tpred, 2) for ego agent only\n",
    "    \"\"\"\n",
    "    agents, total_timesteps, features = scenario_data.shape\n",
    "    \n",
    "    # Only process ego agent (agent_index=0)\n",
    "    agent_idx = 0\n",
    "    agent_data = scenario_data[agent_idx, :Tobs, :].copy()  # shape (Tobs, 6)\n",
    "\n",
    "    # Skip if fully padded\n",
    "    if np.all(agent_data == 0):\n",
    "        return np.zeros((Tpred, 2))\n",
    "\n",
    "    # Initialize the sliding window with observed data\n",
    "    current_window = agent_data.copy()  # shape (Tobs, 6)\n",
    "    \n",
    "    # Store predicted deltas for ego agent\n",
    "    pred_deltas = np.zeros((Tpred, 2))\n",
    "    \n",
    "    # Iteratively predict each future timestep\n",
    "    for step in range(Tpred):\n",
    "        # Prepare input for model (current sliding window)\n",
    "        X_pred = np.expand_dims(current_window, axis=0)  # shape (1, Tobs, 6)\n",
    "        \n",
    "        # Normalize input if stats are provided\n",
    "        if X_mean is not None and X_std is not None:\n",
    "            X_pred = (X_pred - X_mean) / X_std\n",
    "\n",
    "        # Predict next delta (single step)\n",
    "        pred_delta = model.predict(X_pred, verbose=0)  # shape (1, 2)\n",
    "        \n",
    "        # Denormalize delta if stats are provided\n",
    "        if y_mean is not None and y_std is not None:\n",
    "            pred_delta = pred_delta * y_std + y_mean\n",
    "            \n",
    "        pred_deltas[step] = pred_delta[0]  # Store the predicted delta\n",
    "\n",
    "        # Calculate next absolute position\n",
    "        current_pos = current_window[-1, :2]  # Last position in window\n",
    "        next_pos = current_pos + pred_delta[0]  # Add predicted delta\n",
    "        \n",
    "        # Create next timestep features\n",
    "        # Copy other features from the last timestep (velocity, heading, object_type)\n",
    "        next_timestep = current_window[-1].copy()  # shape (6,)\n",
    "        next_timestep[:2] = next_pos  # Update position\n",
    "        \n",
    "        # Update sliding window: remove oldest, add newest\n",
    "        current_window = np.roll(current_window, -1, axis=0)  # Shift left\n",
    "        current_window[-1] = next_timestep  # Add new timestep at the end\n",
    "\n",
    "    # Reconstruct absolute positions from deltas\n",
    "    last_observed_pos = agent_data[-1, :2]  # Last observed position\n",
    "    abs_positions = reconstruct_absolute_positions(\n",
    "        pred_deltas=np.expand_dims(pred_deltas, axis=0),  # shape (1, Tpred, 2)\n",
    "        last_observed_positions=np.expand_dims(last_observed_pos, axis=0)  # shape (1, 2)\n",
    "    )[0]  # shape (Tpred, 2)\n",
    "\n",
    "    return abs_positions  # Return shape (Tpred, 2) for ego agent only"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:40.961165Z",
     "start_time": "2025-05-28T18:32:40.885154Z"
    }
   },
   "id": "4a1b62d4021903c",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "funky prediciton"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9191b70781e7bab"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_augmented_scenario_data(scenario_data, Tobs, Tpred, verbose=False):\n",
    "    num_agents, T, D = scenario_data.shape\n",
    "    assert D == 6, \"Expected 6 dimensions per timestep\"\n",
    "\n",
    "    ego_traj = scenario_data[0]\n",
    "    ego_type = int(ego_traj[0, 5])\n",
    "    ego_vel = ego_traj[:Tobs, 2:4]\n",
    "\n",
    "    if np.any(np.all(ego_traj[:Tobs, :2] == 0, axis=1)):\n",
    "        raise ValueError(\"Ego agent does not have valid positions for all observed steps.\")\n",
    "\n",
    "    ego_speed = np.linalg.norm(ego_vel, axis=1)\n",
    "    ego_mean_speed = np.mean(ego_speed)\n",
    "    ego_speed_std = np.std(ego_speed)\n",
    "\n",
    "    X_filtered = []\n",
    "    y_filtered = []\n",
    "\n",
    "    pruned_fully_padded = 0\n",
    "    pruned_type_mismatch = 0\n",
    "    pruned_velocity_mismatch = 0\n",
    "    pruned_invalid_positions = 0\n",
    "    accepted_samples = 0\n",
    "\n",
    "    agents_passed_filters = 0\n",
    "    agents_failed_all_windows = 0\n",
    "\n",
    "    similarity_threshold = 5.0  # Adjust this based on validation (mean velocity difference per timestep)\n",
    "\n",
    "    for agent_idx in range(1, num_agents):  # skip ego\n",
    "        traj = scenario_data[agent_idx]\n",
    "\n",
    "        if np.all(traj == 0):\n",
    "            pruned_fully_padded += 1\n",
    "            continue\n",
    "\n",
    "        agent_type = int(traj[0, 5])\n",
    "        if agent_type != ego_type:\n",
    "            pruned_type_mismatch += 1\n",
    "            continue\n",
    "\n",
    "        valid_positions = ~np.all(traj[:Tobs, :2] == 0, axis=1)\n",
    "        if np.sum(valid_positions) < Tobs * 0.7:\n",
    "            pruned_invalid_positions += 1\n",
    "            continue\n",
    "\n",
    "        agent_obs_vel = traj[:Tobs, 2:4]\n",
    "\n",
    "        # Per-timestep velocity difference (Euclidean norm)\n",
    "        vel_diff_per_timestep = np.linalg.norm(ego_vel - agent_obs_vel, axis=1)  # shape (Tobs,)\n",
    "        mean_vel_diff = np.mean(vel_diff_per_timestep)\n",
    "\n",
    "        # If ego speed is basically zero (stationary), just check mean agent velocity magnitude\n",
    "        ego_mean_speed = np.mean(np.linalg.norm(ego_vel, axis=1))\n",
    "        if ego_mean_speed < 1e-5:\n",
    "            mean_vel_diff = np.mean(np.linalg.norm(agent_obs_vel, axis=1))\n",
    "\n",
    "        if mean_vel_diff > similarity_threshold:\n",
    "            pruned_velocity_mismatch += 1\n",
    "            continue\n",
    "\n",
    "        agents_passed_filters += 1\n",
    "        agent_accepted = False\n",
    "\n",
    "        for t in range(Tobs, T - 1):  # Sliding windows\n",
    "            input_window = traj[t - Tobs:t, :]  # shape (Tobs, 6)\n",
    "            current_pos = traj[t, :2]\n",
    "            next_pos = traj[t + 1, :2]\n",
    "\n",
    "            if np.all(current_pos == 0) or np.all(next_pos == 0):\n",
    "                if agent_idx == 1:\n",
    "                    print(f\"Agent {agent_idx} has invalid position at t={t}\")\n",
    "                pruned_invalid_positions += 1\n",
    "                continue\n",
    "\n",
    "            delta = next_pos - current_pos\n",
    "\n",
    "            # if np.linalg.norm(delta) < 0.1:\n",
    "            #     if agent_idx == 1:\n",
    "            #         print(f\"Agent {agent_idx} movement too small at t={t}\")\n",
    "            #     continue\n",
    "\n",
    "            valid_positions = ~np.all(input_window[:, :2] == 0, axis=1)\n",
    "            if np.sum(valid_positions) < 0.6 * Tobs:\n",
    "                if agent_idx == 1:\n",
    "                    print(f\"Agent {agent_idx} has too many invalid positions in window at t={t}\")\n",
    "                continue\n",
    "\n",
    "            X_filtered.append(input_window)\n",
    "            y_filtered.append(delta)\n",
    "            accepted_samples += 1\n",
    "            agent_accepted = True\n",
    "\n",
    "        if not agent_accepted:\n",
    "            agents_failed_all_windows += 1\n",
    "            if agent_idx == 1:\n",
    "                print(f\"Agent {agent_idx} passed filters but got no valid sliding windows\")\n",
    "                \n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Total agents: {num_agents}\")\n",
    "        print(f\"Accepted samples: {accepted_samples}\")\n",
    "        print(f\"Pruned fully padded agents: {pruned_fully_padded}\")\n",
    "        print(f\"Pruned type mismatches: {pruned_type_mismatch}\")\n",
    "        print(f\"Pruned due to velocity mismatch: {pruned_velocity_mismatch}\")\n",
    "        print(f\"Pruned invalid positions: {pruned_invalid_positions}\")\n",
    "        print(f\"Agents passed outer filters: {agents_passed_filters}\")\n",
    "        print(f\"Agents passed filters but had no valid samples: {agents_failed_all_windows}\")\n",
    "\n",
    "    if len(X_filtered) == 0:\n",
    "        print(\"Warning: No samples passed filtering. Consider relaxing similarity thresholds.\")\n",
    "        return np.empty((0, Tobs, 6)), np.empty((0, 2))\n",
    "    else:\n",
    "        print(f\"Returning {len(X_filtered)} training samples\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    X_filtered = np.array(X_filtered)  # shape (N, Tobs, 6)\n",
    "    y_filtered = np.array(y_filtered)  # shape (N, 2)\n",
    "    return X_filtered, y_filtered"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:40.964226Z",
     "start_time": "2025-05-28T18:32:40.891904Z"
    }
   },
   "id": "c0b2fde598692275",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def finetune_forecast_positions(scenario_data, Tobs, Tpred, model, \n",
    "                                 X_mean=None, X_std=None, y_mean=None, y_std=None, \n",
    "                                 epochs=3, lr=1e-6, verbose=False):\n",
    "    \"\"\"\n",
    "    Fine-tune model on relevant agents from a scenario, then forecast future positions.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Predicted positions (Tpred, 2)\n",
    "    \"\"\"\n",
    "    import copy\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "    agents, total_steps, _ = scenario_data.shape\n",
    "    assert total_steps >= Tobs + Tpred, \"Not enough time steps for observation + prediction\"\n",
    "\n",
    "    # Generate fine-tuning data \n",
    "    X_finetune, y_finetune = generate_augmented_scenario_data(scenario_data, Tobs, Tpred, verbose=verbose)\n",
    "\n",
    "    # Clone model for potential fine-tuning\n",
    "    model_finetune = copy.deepcopy(model)\n",
    "    model_finetune.compile(optimizer=Adam(learning_rate=lr, clipnorm=0.5), loss='mse')\n",
    "\n",
    "    if len(X_finetune) > 0:\n",
    "        # Normalize input/output if stats provided\n",
    "        if X_mean is not None and X_std is not None:\n",
    "            X_finetune = (X_finetune - X_mean) / X_std\n",
    "        if y_mean is not None and y_std is not None:\n",
    "            y_finetune = (y_finetune - y_mean) / y_std\n",
    "\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            filepath='finetuned_checkpoint.weights.h5',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=True,\n",
    "            mode='min',\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        model_finetune.fit(\n",
    "            X_finetune,\n",
    "            y_finetune,\n",
    "            validation_split=0.2,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            callbacks=[checkpoint]\n",
    "        )\n",
    "\n",
    "        # Load best weights\n",
    "        model_finetune.load_weights('finetuned_checkpoint.weights.h5')\n",
    "    else:\n",
    "        print(\"No valid agents found for fine-tuning. Using original model.\")\n",
    "\n",
    "        # Use the original model instead of the fine-tuned one\n",
    "        model_finetune = model\n",
    "\n",
    "    # Predict for ego agent only (agent_index=0)\n",
    "    agent_idx = 0\n",
    "    agent_data = scenario_data[agent_idx, :Tobs, :].copy()\n",
    "\n",
    "    if np.all(agent_data == 0):\n",
    "        print('Ego agent is fully padded, returning zeros.')\n",
    "        return np.zeros((Tpred, 2))\n",
    "\n",
    "    current_window = agent_data.copy()\n",
    "    pred_deltas = np.zeros((Tpred, 2))\n",
    "\n",
    "    for step in range(Tpred):\n",
    "        X_pred = np.expand_dims(current_window, axis=0)\n",
    "\n",
    "        if X_mean is not None and X_std is not None:\n",
    "            X_pred = (X_pred - X_mean) / X_std\n",
    "\n",
    "        pred_delta = model_finetune.predict(X_pred, verbose=0)\n",
    "\n",
    "        if y_mean is not None and y_std is not None:\n",
    "            pred_delta = pred_delta * y_std + y_mean\n",
    "\n",
    "        pred_deltas[step] = pred_delta[0]\n",
    "\n",
    "        current_pos = current_window[-1, :2]\n",
    "        next_pos = current_pos + pred_delta[0]\n",
    "\n",
    "        next_timestep = current_window[-1].copy()\n",
    "        next_timestep[:2] = next_pos\n",
    "\n",
    "        current_window = np.roll(current_window, -1, axis=0)\n",
    "        current_window[-1] = next_timestep\n",
    "\n",
    "    last_observed_pos = agent_data[-1, :2]\n",
    "    predicted_positions = reconstruct_absolute_positions(\n",
    "        pred_deltas=np.expand_dims(pred_deltas, axis=0),\n",
    "        last_observed_positions=np.expand_dims(last_observed_pos, axis=0)\n",
    "    )[0]\n",
    "\n",
    "    return predicted_positions\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:40.975044Z",
     "start_time": "2025-05-28T18:32:40.906827Z"
    }
   },
   "id": "9e2cae72fd878346",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def make_gif(data_matrix1, data_matrix2, name='comparison'):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.animation as animation\n",
    "\n",
    "    cmap1 = plt.cm.get_cmap('viridis', 50)\n",
    "    cmap2 = plt.cm.get_cmap('plasma', 50)\n",
    "\n",
    "    assert data_matrix1.shape[1] == data_matrix2.shape[1], \"Both matrices must have same number of timesteps\"\n",
    "    timesteps = data_matrix1.shape[1]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "    ax1, ax2 = axes\n",
    "\n",
    "    def update(frame):\n",
    "        for ax in axes:\n",
    "            ax.clear()\n",
    "\n",
    "        for i in range(data_matrix1.shape[0]):\n",
    "            for (data_matrix, ax, cmap) in [(data_matrix1, ax1, cmap1), (data_matrix2, ax2, cmap2)]:\n",
    "                x = data_matrix[i, frame, 0]\n",
    "                y = data_matrix[i, frame, 1]\n",
    "                if x != 0 and y != 0:\n",
    "                    xs = data_matrix[i, :frame+1, 0]\n",
    "                    ys = data_matrix[i, :frame+1, 1]\n",
    "                    mask = (xs != 0) & (ys != 0)\n",
    "                    xs = xs[mask]\n",
    "                    ys = ys[mask]\n",
    "                    if len(xs) > 0 and len(ys) > 0:\n",
    "                        color = cmap(i)\n",
    "                        ax.plot(xs, ys, alpha=0.9, color=color)\n",
    "                        ax.scatter(x, y, s=80, color=color)\n",
    "\n",
    "        # Plot ego vehicle (index 0) on both\n",
    "        ax1.plot(data_matrix1[0, :frame, 0], data_matrix1[0, :frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "        ax1.scatter(data_matrix1[0, frame, 0], data_matrix1[0, frame, 1], s=80, color='tab:orange')\n",
    "        ax1.set_title('Prediction')\n",
    "\n",
    "        ax2.plot(data_matrix2[0, :frame, 0], data_matrix2[0, :frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "        ax2.scatter(data_matrix2[0, frame, 0], data_matrix2[0, frame, 1], s=80, color='tab:orange')\n",
    "        ax2.set_title('Actual')\n",
    "\n",
    "        for ax, data_matrix in zip(axes, [data_matrix1, data_matrix2]):\n",
    "            ax.set_xlim(data_matrix[:, :, 0][data_matrix[:, :, 0] != 0].min() - 10,\n",
    "                        data_matrix[:, :, 0][data_matrix[:, :, 0] != 0].max() + 10)\n",
    "            ax.set_ylim(data_matrix[:, :, 1][data_matrix[:, :, 1] != 0].min() - 10,\n",
    "                        data_matrix[:, :, 1][data_matrix[:, :, 1] != 0].max() + 10)\n",
    "            ax.legend()\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "\n",
    "        # Compute MSE over non-zero entries up to current frame\n",
    "        mask = (data_matrix2[:, :frame+1, :] != 0) & (data_matrix1[:, :frame+1, :] != 0)\n",
    "        mse = np.mean((data_matrix1[:, :frame+1, :][mask] - data_matrix2[:, :frame+1, :][mask]) ** 2)\n",
    "\n",
    "        fig.suptitle(f\"Timestep {frame} - MSE: {mse:.4f}\", fontsize=16)\n",
    "        return ax1.collections + ax1.lines + ax2.collections + ax2.lines\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, update, frames=list(range(0, timesteps, 3)), interval=100, blit=True)\n",
    "    anim.save(f'trajectory_visualization_{name}.gif', writer='pillow')\n",
    "    plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:40.996929Z",
     "start_time": "2025-05-28T18:32:40.909619Z"
    }
   },
   "id": "658c258cac06616e",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_mae_by_timestep(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Visualize MAE across timesteps in the prediction horizon.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): shape (N, Tpred, 2)\n",
    "        y_pred (np.ndarray): shape (N, Tpred, 2)\n",
    "    \"\"\"\n",
    "    mae_per_timestep = np.mean(np.abs(y_true - y_pred), axis=(0, 2))  # shape (Tpred,)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(mae_per_timestep, label='MAE per Timestep')\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.ylabel('MAE (meters)')\n",
    "    plt.title('Mean Absolute Error Over Prediction Horizon')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:40.997966Z",
     "start_time": "2025-05-28T18:32:40.928765Z"
    }
   },
   "id": "8ce3811f963721e2",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mostly padded agents pruned: 0\n",
      "Total invalid positions pruned (either current or next position was all zeros): 4\n",
      "Total samples pruned due to too many zeros in the window: 2\n",
      "Total valid samples used for training: 14\n",
      "\n",
      "Training on 14 valid timestep sequences.\n",
      "Input shape: (14, 50, 6), Output shape: (14, 2)\n",
      "Delta stats: mean=[-0.64457837  0.19818896], std=[0.56999729 0.17493391]\n",
      "Delta range: min=[-1.26092664 -0.0123789 ], max=[0.04542103 0.4018996 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 11:32:41.008931: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2025-05-28 11:32:41.009821: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-05-28 11:32:41.009835: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-05-28 11:32:41.010280: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-28 11:32:41.010781: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=3\n",
      "\n",
      "--- Phase 1: Training ---\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 11:32:41.859436: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3s/step - loss: 1.2212 - mae: 1.0863\n",
      "Epoch 2/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 1.2085 - mae: 1.0805\n",
      "Epoch 3/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 1.1958 - mae: 1.0747\n",
      "Epoch 4/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.1833 - mae: 1.0690\n",
      "Epoch 5/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.1708 - mae: 1.0633\n",
      "Epoch 6/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 1.1585 - mae: 1.0576\n",
      "Epoch 7/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehul/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.1463 - mae: 1.0519\n",
      "Epoch 8/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.1342 - mae: 1.0462\n",
      "Epoch 9/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 1.1221 - mae: 1.0406\n",
      "Epoch 10/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 1.1102 - mae: 1.0349\n",
      "Epoch 11/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.0984 - mae: 1.0293\n",
      "Epoch 12/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 1.0867 - mae: 1.0237\n",
      "Epoch 13/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 1.0751 - mae: 1.0182\n",
      "Epoch 14/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step - loss: 1.0636 - mae: 1.0126\n",
      "Epoch 15/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step - loss: 1.0522 - mae: 1.0071\n",
      "Epoch 16/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 1.0409 - mae: 1.0016\n",
      "Epoch 17/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - loss: 1.0297 - mae: 0.9961\n",
      "Epoch 18/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step - loss: 1.0186 - mae: 0.9906\n",
      "Epoch 19/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 1.0076 - mae: 0.9851\n",
      "Epoch 20/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.9967 - mae: 0.9797\n",
      "Epoch 21/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.9859 - mae: 0.9743\n",
      "Epoch 22/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.9751 - mae: 0.9689\n",
      "Epoch 23/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.9645 - mae: 0.9635\n",
      "Epoch 24/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.9539 - mae: 0.9580\n",
      "Epoch 25/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.9433 - mae: 0.9526\n",
      "Epoch 26/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.9328 - mae: 0.9472\n",
      "Epoch 27/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.9223 - mae: 0.9418\n",
      "Epoch 28/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.9119 - mae: 0.9363\n",
      "Epoch 29/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.9015 - mae: 0.9308\n",
      "Epoch 30/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.8911 - mae: 0.9253\n",
      "Epoch 31/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.8808 - mae: 0.9198\n",
      "Epoch 32/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.8705 - mae: 0.9143\n",
      "Epoch 33/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.8602 - mae: 0.9088\n",
      "Epoch 34/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.8500 - mae: 0.9032\n",
      "Epoch 35/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.8398 - mae: 0.8977\n",
      "Epoch 36/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.8297 - mae: 0.8921\n",
      "Epoch 37/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.8196 - mae: 0.8866\n",
      "Epoch 38/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.8095 - mae: 0.8810\n",
      "Epoch 39/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.7995 - mae: 0.8754\n",
      "Epoch 40/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.7895 - mae: 0.8698\n",
      "Epoch 41/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.7795 - mae: 0.8641\n",
      "Epoch 42/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.7696 - mae: 0.8584\n",
      "Epoch 43/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.7596 - mae: 0.8527\n",
      "Epoch 44/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.7497 - mae: 0.8469\n",
      "Epoch 45/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.7397 - mae: 0.8411\n",
      "Epoch 46/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.7297 - mae: 0.8353\n",
      "Epoch 47/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.7196 - mae: 0.8293\n",
      "Epoch 48/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.7095 - mae: 0.8233\n",
      "Epoch 49/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.6995 - mae: 0.8173\n",
      "Epoch 50/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.6894 - mae: 0.8112\n",
      "Epoch 51/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.6793 - mae: 0.8050\n",
      "Epoch 52/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.6692 - mae: 0.7989\n",
      "Epoch 53/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.6592 - mae: 0.7926\n",
      "Epoch 54/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.6492 - mae: 0.7864\n",
      "Epoch 55/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.6393 - mae: 0.7802\n",
      "Epoch 56/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.6295 - mae: 0.7740\n",
      "Epoch 57/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.6197 - mae: 0.7677\n",
      "Epoch 58/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.6099 - mae: 0.7614\n",
      "Epoch 59/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.6001 - mae: 0.7551\n",
      "Epoch 60/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.5904 - mae: 0.7487\n",
      "Epoch 61/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.5807 - mae: 0.7423\n",
      "Epoch 62/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.5711 - mae: 0.7359\n",
      "Epoch 63/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.5615 - mae: 0.7294\n",
      "Epoch 64/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.5519 - mae: 0.7229\n",
      "Epoch 65/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.5424 - mae: 0.7164\n",
      "Epoch 66/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.5329 - mae: 0.7099\n",
      "Epoch 67/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.5235 - mae: 0.7033\n",
      "Epoch 68/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.5141 - mae: 0.6966\n",
      "Epoch 69/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.5047 - mae: 0.6899\n",
      "Epoch 70/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.4953 - mae: 0.6831\n",
      "Epoch 71/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.4858 - mae: 0.6763\n",
      "Epoch 72/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.4764 - mae: 0.6694\n",
      "Epoch 73/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.4670 - mae: 0.6624\n",
      "Epoch 74/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.4576 - mae: 0.6554\n",
      "Epoch 75/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.4483 - mae: 0.6482\n",
      "Epoch 76/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.4389 - mae: 0.6411\n",
      "Epoch 77/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.4296 - mae: 0.6338\n",
      "Epoch 78/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.4203 - mae: 0.6265\n",
      "Epoch 79/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.4111 - mae: 0.6191\n",
      "Epoch 80/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.4018 - mae: 0.6117\n",
      "Epoch 81/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.3927 - mae: 0.6043\n",
      "Epoch 82/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.3836 - mae: 0.5967\n",
      "Epoch 83/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.3745 - mae: 0.5891\n",
      "Epoch 84/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.3655 - mae: 0.5815\n",
      "Epoch 85/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.3565 - mae: 0.5738\n",
      "Epoch 86/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.3476 - mae: 0.5660\n",
      "Epoch 87/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.3387 - mae: 0.5582\n",
      "Epoch 88/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.3299 - mae: 0.5502\n",
      "Epoch 89/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.3211 - mae: 0.5422\n",
      "Epoch 90/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.3124 - mae: 0.5342\n",
      "Epoch 91/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.3038 - mae: 0.5261\n",
      "Epoch 92/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.2952 - mae: 0.5180\n",
      "Epoch 93/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.2867 - mae: 0.5097\n",
      "Epoch 94/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.2784 - mae: 0.5015\n",
      "Epoch 95/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.2700 - mae: 0.4931\n",
      "Epoch 96/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.2618 - mae: 0.4847\n",
      "Epoch 97/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.2537 - mae: 0.4763\n",
      "Epoch 98/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.2456 - mae: 0.4678\n",
      "Epoch 99/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.2377 - mae: 0.4592\n",
      "Epoch 100/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.2299 - mae: 0.4506\n",
      "Epoch 101/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.2222 - mae: 0.4420\n",
      "Epoch 102/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.2145 - mae: 0.4333\n",
      "Epoch 103/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.2070 - mae: 0.4245\n",
      "Epoch 104/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1995 - mae: 0.4157\n",
      "Epoch 105/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1922 - mae: 0.4068\n",
      "Epoch 106/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1850 - mae: 0.3978\n",
      "Epoch 107/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1779 - mae: 0.3888\n",
      "Epoch 108/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1709 - mae: 0.3798\n",
      "Epoch 109/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1641 - mae: 0.3710\n",
      "Epoch 110/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1574 - mae: 0.3625\n",
      "Epoch 111/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1508 - mae: 0.3539\n",
      "Epoch 112/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1444 - mae: 0.3453\n",
      "Epoch 113/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1382 - mae: 0.3367\n",
      "Epoch 114/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1320 - mae: 0.3281\n",
      "Epoch 115/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1261 - mae: 0.3194\n",
      "Epoch 116/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1203 - mae: 0.3108\n",
      "Epoch 117/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.1146 - mae: 0.3022\n",
      "Epoch 118/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.1091 - mae: 0.2936\n",
      "Epoch 119/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.1037 - mae: 0.2850\n",
      "Epoch 120/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0986 - mae: 0.2764\n",
      "Epoch 121/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0935 - mae: 0.2683\n",
      "Epoch 122/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0887 - mae: 0.2602\n",
      "Epoch 123/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0840 - mae: 0.2522\n",
      "Epoch 124/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0794 - mae: 0.2446\n",
      "Epoch 125/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.0750 - mae: 0.2372\n",
      "Epoch 126/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.0708 - mae: 0.2301\n",
      "Epoch 127/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.0667 - mae: 0.2233\n",
      "Epoch 128/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 0.0628 - mae: 0.2165\n",
      "Epoch 129/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.0591 - mae: 0.2097\n",
      "Epoch 130/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0556 - mae: 0.2029\n",
      "Epoch 131/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 0.0522 - mae: 0.1961\n",
      "Epoch 132/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step - loss: 0.0489 - mae: 0.1894\n",
      "Epoch 133/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 66ms/step - loss: 0.0459 - mae: 0.1835\n",
      "Epoch 134/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0430 - mae: 0.1778\n",
      "Epoch 135/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0402 - mae: 0.1722\n",
      "Epoch 136/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0377 - mae: 0.1666\n",
      "Epoch 137/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0352 - mae: 0.1611\n",
      "Epoch 138/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step - loss: 0.0330 - mae: 0.1557\n",
      "Epoch 139/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 73ms/step - loss: 0.0309 - mae: 0.1503\n",
      "Epoch 140/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 128ms/step - loss: 0.0289 - mae: 0.1450\n",
      "Epoch 141/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0271 - mae: 0.1398\n",
      "Epoch 142/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0253 - mae: 0.1347\n",
      "Epoch 143/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0238 - mae: 0.1297\n",
      "Epoch 144/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0223 - mae: 0.1247\n",
      "Epoch 145/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0209 - mae: 0.1199\n",
      "Epoch 146/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0197 - mae: 0.1157\n",
      "Epoch 147/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0185 - mae: 0.1118\n",
      "Epoch 148/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0174 - mae: 0.1081\n",
      "Epoch 149/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0164 - mae: 0.1046\n",
      "Epoch 150/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0155 - mae: 0.1012\n",
      "Epoch 151/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0147 - mae: 0.0978\n",
      "Epoch 152/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0139 - mae: 0.0948\n",
      "Epoch 153/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0132 - mae: 0.0919\n",
      "Epoch 154/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0126 - mae: 0.0890\n",
      "Epoch 155/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0120 - mae: 0.0862\n",
      "Epoch 156/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0114 - mae: 0.0834\n",
      "Epoch 157/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0109 - mae: 0.0807\n",
      "Epoch 158/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0104 - mae: 0.0781\n",
      "Epoch 159/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0100 - mae: 0.0756\n",
      "Epoch 160/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0096 - mae: 0.0731\n",
      "Epoch 161/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0092 - mae: 0.0709\n",
      "Epoch 162/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0089 - mae: 0.0692\n",
      "Epoch 163/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0085 - mae: 0.0678\n",
      "Epoch 164/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0082 - mae: 0.0664\n",
      "Epoch 165/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0080 - mae: 0.0651\n",
      "Epoch 166/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0077 - mae: 0.0641\n",
      "Epoch 167/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0074 - mae: 0.0635\n",
      "Epoch 168/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0072 - mae: 0.0630\n",
      "Epoch 169/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0070 - mae: 0.0625\n",
      "Epoch 170/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0068 - mae: 0.0620\n",
      "Epoch 171/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0066 - mae: 0.0614\n",
      "Epoch 172/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0065 - mae: 0.0609\n",
      "Epoch 173/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0063 - mae: 0.0603\n",
      "Epoch 174/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0061 - mae: 0.0597\n",
      "Epoch 175/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0060 - mae: 0.0592\n",
      "Epoch 176/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0059 - mae: 0.0589\n",
      "Epoch 177/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0058 - mae: 0.0588\n",
      "Epoch 178/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0056 - mae: 0.0586\n",
      "Epoch 179/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0055 - mae: 0.0585\n",
      "Epoch 180/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0054 - mae: 0.0584\n",
      "Epoch 181/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0053 - mae: 0.0582\n",
      "Epoch 182/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0053 - mae: 0.0580\n",
      "Epoch 183/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0052 - mae: 0.0578\n",
      "Epoch 184/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0051 - mae: 0.0576\n",
      "Epoch 185/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0050 - mae: 0.0574\n",
      "Epoch 186/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0050 - mae: 0.0572\n",
      "Epoch 187/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0049 - mae: 0.0570\n",
      "Epoch 188/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0048 - mae: 0.0567\n",
      "Epoch 189/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0048 - mae: 0.0565\n",
      "Epoch 190/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0047 - mae: 0.0563\n",
      "Epoch 191/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0047 - mae: 0.0561\n",
      "Epoch 192/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0046 - mae: 0.0559\n",
      "Epoch 193/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0046 - mae: 0.0557\n",
      "Epoch 194/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0045 - mae: 0.0555\n",
      "Epoch 195/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0045 - mae: 0.0554\n",
      "Epoch 196/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0045 - mae: 0.0552\n",
      "Epoch 197/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0044 - mae: 0.0550\n",
      "Epoch 198/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0044 - mae: 0.0548\n",
      "Epoch 199/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0044 - mae: 0.0546\n",
      "Epoch 200/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0043 - mae: 0.0545\n",
      "Epoch 201/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0043 - mae: 0.0543\n",
      "Epoch 202/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0043 - mae: 0.0541\n",
      "Epoch 203/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0042 - mae: 0.0539\n",
      "Epoch 204/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0042 - mae: 0.0537\n",
      "Epoch 205/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0042 - mae: 0.0535\n",
      "Epoch 206/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0041 - mae: 0.0533\n",
      "Epoch 207/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0041 - mae: 0.0531\n",
      "Epoch 208/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0041 - mae: 0.0529\n",
      "Epoch 209/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0041 - mae: 0.0527\n",
      "Epoch 210/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0040 - mae: 0.0525\n",
      "Epoch 211/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0040 - mae: 0.0523\n",
      "Epoch 212/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0040 - mae: 0.0520\n",
      "Epoch 213/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0040 - mae: 0.0518\n",
      "Epoch 214/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0039 - mae: 0.0516\n",
      "Epoch 215/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0039 - mae: 0.0514\n",
      "Epoch 216/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0039 - mae: 0.0512\n",
      "Epoch 217/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0039 - mae: 0.0510\n",
      "Epoch 218/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0038 - mae: 0.0509\n",
      "Epoch 219/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0038 - mae: 0.0507\n",
      "Epoch 220/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0038 - mae: 0.0505\n",
      "Epoch 221/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0038 - mae: 0.0504\n",
      "Epoch 222/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0038 - mae: 0.0502\n",
      "Epoch 223/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0037 - mae: 0.0501\n",
      "Epoch 224/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0037 - mae: 0.0499\n",
      "Epoch 225/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0037 - mae: 0.0498\n",
      "Epoch 226/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0037 - mae: 0.0496\n",
      "Epoch 227/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0037 - mae: 0.0495\n",
      "Epoch 228/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0036 - mae: 0.0493\n",
      "Epoch 229/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0036 - mae: 0.0492\n",
      "Epoch 230/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0036 - mae: 0.0490\n",
      "Epoch 231/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0036 - mae: 0.0489\n",
      "Epoch 232/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0036 - mae: 0.0487\n",
      "Epoch 233/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0035 - mae: 0.0486\n",
      "Epoch 234/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0035 - mae: 0.0485\n",
      "Epoch 235/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0035 - mae: 0.0483\n",
      "Epoch 236/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0035 - mae: 0.0482\n",
      "Epoch 237/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0035 - mae: 0.0480\n",
      "Epoch 238/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0035 - mae: 0.0479\n",
      "Epoch 239/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0034 - mae: 0.0478\n",
      "Epoch 240/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0034 - mae: 0.0476\n",
      "Epoch 241/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0034 - mae: 0.0475\n",
      "Epoch 242/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0034 - mae: 0.0474\n",
      "Epoch 243/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0034 - mae: 0.0472\n",
      "Epoch 244/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0033 - mae: 0.0471\n",
      "Epoch 245/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0033 - mae: 0.0470\n",
      "Epoch 246/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0033 - mae: 0.0469\n",
      "Epoch 247/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0033 - mae: 0.0467\n",
      "Epoch 248/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0033 - mae: 0.0466\n",
      "Epoch 249/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0033 - mae: 0.0465\n",
      "Epoch 250/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0033 - mae: 0.0464\n",
      "Epoch 251/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0032 - mae: 0.0462\n",
      "Epoch 252/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0032 - mae: 0.0461\n",
      "Epoch 253/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0032 - mae: 0.0460\n",
      "Epoch 254/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0032 - mae: 0.0459\n",
      "Epoch 255/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0032 - mae: 0.0457\n",
      "Epoch 256/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0032 - mae: 0.0456\n",
      "Epoch 257/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0032 - mae: 0.0455\n",
      "Epoch 258/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0031 - mae: 0.0454\n",
      "Epoch 259/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0031 - mae: 0.0453\n",
      "Epoch 260/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0031 - mae: 0.0452\n",
      "Epoch 261/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0031 - mae: 0.0451\n",
      "Epoch 262/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0031 - mae: 0.0450\n",
      "Epoch 263/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0031 - mae: 0.0449\n",
      "Epoch 264/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0031 - mae: 0.0448\n",
      "Epoch 265/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0030 - mae: 0.0447\n",
      "Epoch 266/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0030 - mae: 0.0446\n",
      "Epoch 267/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0030 - mae: 0.0445\n",
      "Epoch 268/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0030 - mae: 0.0444\n",
      "Epoch 269/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0030 - mae: 0.0443\n",
      "Epoch 270/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0030 - mae: 0.0443\n",
      "Epoch 271/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0030 - mae: 0.0442\n",
      "Epoch 272/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0030 - mae: 0.0441\n",
      "Epoch 273/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0030 - mae: 0.0440\n",
      "Epoch 274/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0029 - mae: 0.0439\n",
      "Epoch 275/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0029 - mae: 0.0438\n",
      "Epoch 276/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0029 - mae: 0.0437\n",
      "Epoch 277/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0029 - mae: 0.0436\n",
      "Epoch 278/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0029 - mae: 0.0436\n",
      "Epoch 279/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0029 - mae: 0.0435\n",
      "Epoch 280/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0029 - mae: 0.0434\n",
      "Epoch 281/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0029 - mae: 0.0433\n",
      "Epoch 282/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0029 - mae: 0.0432\n",
      "Epoch 283/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0029 - mae: 0.0431\n",
      "Epoch 284/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0028 - mae: 0.0431\n",
      "Epoch 285/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0028 - mae: 0.0430\n",
      "Epoch 286/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0028 - mae: 0.0429\n",
      "Epoch 287/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0028 - mae: 0.0428\n",
      "Epoch 288/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0028 - mae: 0.0427\n",
      "Epoch 289/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 0.0028 - mae: 0.0427\n",
      "Epoch 290/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.0028 - mae: 0.0426\n",
      "Epoch 291/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.0028 - mae: 0.0425\n",
      "Epoch 292/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.0028 - mae: 0.0424\n",
      "Epoch 293/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0028 - mae: 0.0423\n",
      "Epoch 294/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0028 - mae: 0.0423\n",
      "Epoch 295/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0028 - mae: 0.0422\n",
      "Epoch 296/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0027 - mae: 0.0421\n",
      "Epoch 297/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0027 - mae: 0.0420\n",
      "Epoch 298/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0027 - mae: 0.0420\n",
      "Epoch 299/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0027 - mae: 0.0419\n",
      "Epoch 300/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.0027 - mae: 0.0418\n",
      "Epoch 301/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step - loss: 0.0027 - mae: 0.0417\n",
      "Epoch 302/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step - loss: 0.0027 - mae: 0.0417\n",
      "Epoch 303/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0027 - mae: 0.0416\n",
      "Epoch 304/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0027 - mae: 0.0416\n",
      "Epoch 305/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0027 - mae: 0.0415\n",
      "Epoch 306/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0027 - mae: 0.0414\n",
      "Epoch 307/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0027 - mae: 0.0414\n",
      "Epoch 308/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0027 - mae: 0.0413\n",
      "Epoch 309/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0027 - mae: 0.0413\n",
      "Epoch 310/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0027 - mae: 0.0412\n",
      "Epoch 311/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0026 - mae: 0.0411\n",
      "Epoch 312/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0026 - mae: 0.0411\n",
      "Epoch 313/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0026 - mae: 0.0410\n",
      "Epoch 314/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0026 - mae: 0.0410\n",
      "Epoch 315/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0026 - mae: 0.0409\n",
      "Epoch 316/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0026 - mae: 0.0409\n",
      "Epoch 317/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0026 - mae: 0.0408\n",
      "Epoch 318/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0026 - mae: 0.0408\n",
      "Epoch 319/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0026 - mae: 0.0407\n",
      "Epoch 320/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0026 - mae: 0.0406\n",
      "Epoch 321/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0026 - mae: 0.0406\n",
      "Epoch 322/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0026 - mae: 0.0405\n",
      "Epoch 323/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0026 - mae: 0.0405\n",
      "Epoch 324/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0026 - mae: 0.0404\n",
      "Epoch 325/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0026 - mae: 0.0404\n",
      "Epoch 326/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0026 - mae: 0.0403\n",
      "Epoch 327/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0026 - mae: 0.0403\n",
      "Epoch 328/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0026 - mae: 0.0402\n",
      "Epoch 329/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0026 - mae: 0.0402\n",
      "Epoch 330/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0025 - mae: 0.0401\n",
      "Epoch 331/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0025 - mae: 0.0401\n",
      "Epoch 332/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0025 - mae: 0.0400\n",
      "Epoch 333/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0025 - mae: 0.0400\n",
      "Epoch 334/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0025 - mae: 0.0399\n",
      "Epoch 335/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0025 - mae: 0.0399\n",
      "Epoch 336/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0025 - mae: 0.0398\n",
      "Epoch 337/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0025 - mae: 0.0398\n",
      "Epoch 338/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0025 - mae: 0.0397\n",
      "Epoch 339/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0025 - mae: 0.0397\n",
      "Epoch 340/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0025 - mae: 0.0397\n",
      "Epoch 341/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0025 - mae: 0.0396\n",
      "Epoch 342/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0025 - mae: 0.0396\n",
      "Epoch 343/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0025 - mae: 0.0396\n",
      "Epoch 344/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0025 - mae: 0.0395\n",
      "Epoch 345/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0025 - mae: 0.0395\n",
      "Epoch 346/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0025 - mae: 0.0394\n",
      "Epoch 347/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0025 - mae: 0.0394\n",
      "Epoch 348/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0025 - mae: 0.0394\n",
      "Epoch 349/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0025 - mae: 0.0393\n",
      "Epoch 350/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0025 - mae: 0.0393\n",
      "Epoch 351/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0025 - mae: 0.0393\n",
      "Epoch 352/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0025 - mae: 0.0392\n",
      "Epoch 353/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0025 - mae: 0.0392\n",
      "Epoch 354/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0025 - mae: 0.0391\n",
      "Epoch 355/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0025 - mae: 0.0391\n",
      "Epoch 356/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0024 - mae: 0.0391\n",
      "Epoch 357/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0024 - mae: 0.0390\n",
      "Epoch 358/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.0024 - mae: 0.0390\n",
      "Epoch 359/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.0024 - mae: 0.0390\n",
      "Epoch 360/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0024 - mae: 0.0389\n",
      "Epoch 361/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0024 - mae: 0.0389\n",
      "Epoch 362/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0024 - mae: 0.0389\n",
      "Epoch 363/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0024 - mae: 0.0388\n",
      "Epoch 364/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0024 - mae: 0.0388\n",
      "Epoch 365/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0024 - mae: 0.0388\n",
      "Epoch 366/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0024 - mae: 0.0387\n",
      "Epoch 367/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0024 - mae: 0.0387\n",
      "Epoch 368/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0024 - mae: 0.0387\n",
      "Epoch 369/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0024 - mae: 0.0386\n",
      "Epoch 370/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.0024 - mae: 0.0386\n",
      "Epoch 371/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0024 - mae: 0.0386\n",
      "Epoch 372/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0024 - mae: 0.0386\n",
      "Epoch 373/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0024 - mae: 0.0385\n",
      "Epoch 374/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0024 - mae: 0.0385\n",
      "Epoch 375/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0024 - mae: 0.0385\n",
      "Epoch 376/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - loss: 0.0024 - mae: 0.0384\n",
      "Epoch 377/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0024 - mae: 0.0384\n",
      "Epoch 378/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0024 - mae: 0.0384\n",
      "Epoch 379/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0024 - mae: 0.0383\n",
      "Epoch 380/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0024 - mae: 0.0383\n",
      "Epoch 381/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0024 - mae: 0.0383\n",
      "Epoch 382/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0024 - mae: 0.0383\n",
      "Epoch 383/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0024 - mae: 0.0382\n",
      "Epoch 384/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0024 - mae: 0.0382\n",
      "Epoch 385/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0024 - mae: 0.0382\n",
      "Epoch 386/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0024 - mae: 0.0381\n",
      "Epoch 387/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0024 - mae: 0.0381\n",
      "Epoch 388/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0024 - mae: 0.0381\n",
      "Epoch 389/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0024 - mae: 0.0381\n",
      "Epoch 390/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0023 - mae: 0.0380\n",
      "Epoch 391/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0023 - mae: 0.0380\n",
      "Epoch 392/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0023 - mae: 0.0380\n",
      "Epoch 393/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0023 - mae: 0.0379\n",
      "Epoch 394/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0023 - mae: 0.0379\n",
      "Epoch 395/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0023 - mae: 0.0379\n",
      "Epoch 396/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0023 - mae: 0.0378\n",
      "Epoch 397/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0023 - mae: 0.0378\n",
      "Epoch 398/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0023 - mae: 0.0378\n",
      "Epoch 399/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0023 - mae: 0.0378\n",
      "Epoch 400/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0023 - mae: 0.0377\n",
      "Epoch 401/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0023 - mae: 0.0377\n",
      "Epoch 402/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.0023 - mae: 0.0377\n",
      "Epoch 403/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.0023 - mae: 0.0377\n",
      "Epoch 404/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.0023 - mae: 0.0376\n",
      "Epoch 405/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0023 - mae: 0.0376\n",
      "Epoch 406/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.0023 - mae: 0.0376\n",
      "Epoch 407/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0023 - mae: 0.0376\n",
      "Epoch 408/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.0023 - mae: 0.0375\n",
      "Epoch 409/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0023 - mae: 0.0375\n",
      "Epoch 410/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0023 - mae: 0.0375\n",
      "Epoch 411/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0023 - mae: 0.0374\n",
      "Epoch 412/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0023 - mae: 0.0374\n",
      "Epoch 413/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0023 - mae: 0.0374\n",
      "Epoch 414/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0023 - mae: 0.0374\n",
      "Epoch 415/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0023 - mae: 0.0373\n",
      "Epoch 416/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0023 - mae: 0.0373\n",
      "Epoch 417/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0023 - mae: 0.0373\n",
      "Epoch 418/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0023 - mae: 0.0373\n",
      "Epoch 419/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0023 - mae: 0.0372\n",
      "Epoch 420/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0023 - mae: 0.0372\n",
      "Epoch 421/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0023 - mae: 0.0372\n",
      "Epoch 422/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0023 - mae: 0.0372\n",
      "Epoch 423/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0023 - mae: 0.0371\n",
      "Epoch 424/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0023 - mae: 0.0371\n",
      "Epoch 425/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0023 - mae: 0.0371\n",
      "Epoch 426/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0023 - mae: 0.0371\n",
      "Epoch 427/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0023 - mae: 0.0370\n",
      "Epoch 428/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0023 - mae: 0.0370\n",
      "Epoch 429/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0023 - mae: 0.0370\n",
      "Epoch 430/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0023 - mae: 0.0370\n",
      "Epoch 431/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0023 - mae: 0.0369\n",
      "Epoch 432/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0022 - mae: 0.0369\n",
      "Epoch 433/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0022 - mae: 0.0369\n",
      "Epoch 434/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0022 - mae: 0.0369\n",
      "Epoch 435/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0022 - mae: 0.0368\n",
      "Epoch 436/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0022 - mae: 0.0368\n",
      "Epoch 437/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0022 - mae: 0.0368\n",
      "Epoch 438/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0022 - mae: 0.0368\n",
      "Epoch 439/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0022 - mae: 0.0367\n",
      "Epoch 440/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0022 - mae: 0.0367\n",
      "Epoch 441/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0022 - mae: 0.0367\n",
      "Epoch 442/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0022 - mae: 0.0367\n",
      "Epoch 443/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0022 - mae: 0.0366\n",
      "Epoch 444/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0022 - mae: 0.0366\n",
      "Epoch 445/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0022 - mae: 0.0366\n",
      "Epoch 446/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0022 - mae: 0.0366\n",
      "Epoch 447/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0022 - mae: 0.0365\n",
      "Epoch 448/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.0022 - mae: 0.0365\n",
      "Epoch 449/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0022 - mae: 0.0365\n",
      "Epoch 450/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0022 - mae: 0.0365\n",
      "Epoch 451/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.0022 - mae: 0.0364\n",
      "Epoch 452/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - loss: 0.0022 - mae: 0.0364\n",
      "Epoch 453/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step - loss: 0.0022 - mae: 0.0364\n",
      "Epoch 454/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.0022 - mae: 0.0364\n",
      "Epoch 455/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.0022 - mae: 0.0363\n",
      "Epoch 456/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step - loss: 0.0022 - mae: 0.0363\n",
      "Epoch 457/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 73ms/step - loss: 0.0022 - mae: 0.0363\n",
      "Epoch 458/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 0.0022 - mae: 0.0363\n",
      "Epoch 459/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step - loss: 0.0022 - mae: 0.0363\n",
      "Epoch 460/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 55ms/step - loss: 0.0022 - mae: 0.0362\n",
      "Epoch 461/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.0022 - mae: 0.0362\n",
      "Epoch 462/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0022 - mae: 0.0362\n",
      "Epoch 463/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0022 - mae: 0.0362\n",
      "Epoch 464/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0022 - mae: 0.0361\n",
      "Epoch 465/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0022 - mae: 0.0361\n",
      "Epoch 466/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0022 - mae: 0.0361\n",
      "Epoch 467/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0022 - mae: 0.0361\n",
      "Epoch 468/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0022 - mae: 0.0360\n",
      "Epoch 469/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0022 - mae: 0.0360\n",
      "Epoch 470/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0022 - mae: 0.0360\n",
      "Epoch 471/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0022 - mae: 0.0360\n",
      "Epoch 472/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0022 - mae: 0.0360\n",
      "Epoch 473/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0022 - mae: 0.0359\n",
      "Epoch 474/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0022 - mae: 0.0359\n",
      "Epoch 475/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0022 - mae: 0.0359\n",
      "Epoch 476/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0022 - mae: 0.0359\n",
      "Epoch 477/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0022 - mae: 0.0359\n",
      "Epoch 478/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0022 - mae: 0.0358\n",
      "Epoch 479/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0022 - mae: 0.0358\n",
      "Epoch 480/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0021 - mae: 0.0358\n",
      "Epoch 481/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0021 - mae: 0.0358\n",
      "Epoch 482/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0021 - mae: 0.0357\n",
      "Epoch 483/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0021 - mae: 0.0357\n",
      "Epoch 484/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0021 - mae: 0.0357\n",
      "Epoch 485/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0021 - mae: 0.0357\n",
      "Epoch 486/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0021 - mae: 0.0357\n",
      "Epoch 487/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0021 - mae: 0.0356\n",
      "Epoch 488/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 0.0021 - mae: 0.0356\n",
      "Epoch 489/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0021 - mae: 0.0356\n",
      "Epoch 490/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0021 - mae: 0.0356\n",
      "Epoch 491/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0021 - mae: 0.0355\n",
      "Epoch 492/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0021 - mae: 0.0355\n",
      "Epoch 493/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0021 - mae: 0.0355\n",
      "Epoch 494/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0021 - mae: 0.0355\n",
      "Epoch 495/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0021 - mae: 0.0355\n",
      "Epoch 496/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0021 - mae: 0.0354\n",
      "Epoch 497/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0021 - mae: 0.0354\n",
      "Epoch 498/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0021 - mae: 0.0354\n",
      "Epoch 499/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 0.0021 - mae: 0.0354\n",
      "Epoch 500/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 0.0021 - mae: 0.0354\n",
      "\n",
      "--- Phase 2: Fine-tuning ---\n"
     ]
    }
   ],
   "source": [
    "# first check that the model can overfit on small data\n",
    "\n",
    "model, X_mean, X_std, y_mean, y_std  = train_model(standardized_train_data[:1], batch_size=30, validation_split=0, epochs=500, epochs2=0, lr1 = 0.00001, lr2=0.00001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:33:02.602681Z",
     "start_time": "2025-05-28T18:32:40.935577Z"
    }
   },
   "id": "deeaeac04573c115",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[187.20459398 149.9500545   -6.41029163   1.95444741   2.39551873\n",
      "     0.        ]]] [[[3.87119775e+01 1.50830377e+01 5.59114706e+00 1.70699105e+00\n",
      "   1.10718219e+00 1.00000000e-08]]] [[-0.64457837  0.19818896]] [[0.5699973  0.17493392]]\n"
     ]
    }
   ],
   "source": [
    "print(X_mean, X_std, y_mean, y_std)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:33:02.604927Z",
     "start_time": "2025-05-28T18:33:02.571417Z"
    }
   },
   "id": "eaa2c8dee6f431fa",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# save_model(model, \"general_single_step.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:33:02.606094Z",
     "start_time": "2025-05-28T18:33:02.575376Z"
    }
   },
   "id": "1fc0733bc8bee546",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wv/j6ybhf8906j4bmnp171wtn680000gn/T/ipykernel_56149/3735350324.py:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap1 = plt.cm.get_cmap('viridis', 50)\n",
      "/var/folders/wv/j6ybhf8906j4bmnp171wtn680000gn/T/ipykernel_56149/3735350324.py:10: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap2 = plt.cm.get_cmap('plasma', 50)\n"
     ]
    }
   ],
   "source": [
    "# visualize prediction\n",
    "\n",
    "# Parameters\n",
    "Tobs = 50\n",
    "Tpred = 60\n",
    "\n",
    "data = standardized_train_data[3007]\n",
    "\n",
    "# Select a test scenario (can use any valid index)\n",
    "test_scenario = data.copy()  # shape (agents, time_steps, features)\n",
    "\n",
    "\n",
    "# Forecast future positions\n",
    "predicted_positions = forecast_positions(test_scenario, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std)\n",
    "\n",
    "# Create combined matrix of past observed + predicted for ego agent (agent 0)\n",
    "ego_past = test_scenario[0, :Tobs, :2]               # shape (Tobs, 2)\n",
    "ego_future = predicted_positions                  # shape (Tpred, 2)\n",
    "ego_full = np.concatenate([ego_past, ego_future], axis=0)  # shape (Tobs + Tpred, 2)\n",
    "\n",
    "# Create updated scenario with predicted ego and original others\n",
    "updated_scenario = test_scenario.copy()\n",
    "updated_scenario[0, :Tobs+Tpred, :2] = ego_full  # Replace ego trajectory\n",
    "\n",
    "# print(updated_scenario[0])\n",
    "\n",
    "# Visualize\n",
    "make_gif(updated_scenario, data, name='lstm_single_step')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:33:14.566043Z",
     "start_time": "2025-05-28T18:33:02.580174Z"
    }
   },
   "id": "fedc61e344476eb0",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total agents: 50\n",
      "Accepted samples: 0\n",
      "Pruned fully padded agents: 9\n",
      "Pruned type mismatches: 3\n",
      "Pruned due to velocity mismatch: 14\n",
      "Pruned invalid positions: 23\n",
      "Agents passed outer filters: 0\n",
      "Agents passed filters but had no valid samples: 0\n",
      "Warning: No samples passed filtering. Consider relaxing similarity thresholds.\n",
      "No valid agents found for fine-tuning. Using original model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehul/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 26 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/var/folders/wv/j6ybhf8906j4bmnp171wtn680000gn/T/ipykernel_56149/3735350324.py:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap1 = plt.cm.get_cmap('viridis', 50)\n",
      "/var/folders/wv/j6ybhf8906j4bmnp171wtn680000gn/T/ipykernel_56149/3735350324.py:10: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap2 = plt.cm.get_cmap('plasma', 50)\n"
     ]
    }
   ],
   "source": [
    "# visualize fine-tunded prediction\n",
    "\n",
    "\n",
    "# Parameters\n",
    "Tobs = 50\n",
    "Tpred = 60\n",
    "\n",
    "data = standardized_train_data[3026]\n",
    "\n",
    "# Select a test scenario (can use any valid index)\n",
    "test_scenario = data.copy()  # shape (agents, time_steps, features)\n",
    "\n",
    "# Forecast future positions\n",
    "predicted_positions = finetune_forecast_positions(test_scenario, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std, verbose=True)\n",
    "\n",
    "# Create combined matrix of past observed + predicted for ego agent (agent 0)\n",
    "ego_past = test_scenario[0, :Tobs, :2]               # shape (Tobs, 2)\n",
    "ego_future = predicted_positions                # shape (Tpred, 2)\n",
    "ego_full = np.concatenate([ego_past, ego_future], axis=0)  # shape (Tobs + Tpred, 2)\n",
    "\n",
    "# Create updated scenario with predicted ego and original others\n",
    "updated_scenario = test_scenario.copy()\n",
    "updated_scenario[0, :Tobs+Tpred, :2] = ego_full  # Replace ego trajectory\n",
    "\n",
    "# print(updated_scenario[0])\n",
    "\n",
    "# Visualize\n",
    "make_gif(updated_scenario, data, name='lstm_single_step')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:33:24.117133Z",
     "start_time": "2025-05-28T18:33:14.560529Z"
    }
   },
   "id": "c1b534ab5b272dcf",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mostly padded agents pruned: 73\n",
      "Total invalid positions pruned (either current or next position was all zeros): 1621\n",
      "Total samples pruned due to too many zeros in the window: 2056\n",
      "Total valid samples used for training: 196031\n",
      "\n",
      "Training on 196031 valid timestep sequences.\n",
      "Input shape: (196031, 50, 6), Output shape: (196031, 2)\n",
      "Delta stats: mean=[-0.00894765 -0.00328844], std=[0.48115293 0.41585955]\n",
      "Delta range: min=[-2.50389183 -3.01111659], max=[2.58443213 2.32696563]\n",
      "🔧 GradientMonitoringCallback initialized with clip_min=0.0001, clip_max=100.0, monitor_freq=3\n",
      "\n",
      "--- Phase 1: Training ---\n",
      "Epoch 1/30\n",
      "\u001B[1m 822/4575\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m1:09\u001B[0m 19ms/step - loss: 0.3693 - mae: 0.3125"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "Cell \u001B[0;32mIn[27], line 3\u001B[0m\n\u001B[1;32m      2\u001B[0m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mshuffle(shuffled_train_data)  \u001B[38;5;66;03m# shuffles in-place along axis 0 (scenarios)\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m model, X_mean, X_std, y_mean, y_std  \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshuffled_train_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr1\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.00001\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.00001\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[16], line 106\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(train_data, batch_size, validation_split, Tobs, epochs, epochs2, lr1, lr2)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m--- Phase 1: Training ---\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 106\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    107\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    108\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    109\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_split\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    111\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mphase1_callbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    112\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[1;32m    113\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m--- Phase 2: Fine-tuning ---\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    370\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m--> 371\u001B[0m logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    372\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(step, logs)\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001B[0m, in \u001B[0;36mTensorFlowTrainer._make_function.<locals>.function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[1;32m    217\u001B[0m     iterator, (tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mIterator, tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mDistributedIterator)\n\u001B[1;32m    218\u001B[0m ):\n\u001B[0;32m--> 219\u001B[0m     opt_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmulti_step_on_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    220\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m opt_outputs\u001B[38;5;241m.\u001B[39mhas_value():\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 878\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1324\u001B[0m     args,\n\u001B[1;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1326\u001B[0m     executing_eagerly)\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1500\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1499\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1500\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1501\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1503\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1504\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1505\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1506\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1507\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2144\u001B[0m, in \u001B[0;36mInteractiveShell.showtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2143\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2144\u001B[0m         stb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mInteractiveTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2145\u001B[0m \u001B[43m            \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtb_offset\u001B[49m\n\u001B[1;32m   2146\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2148\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/IPython/core/ultratb.py:1435\u001B[0m, in \u001B[0;36mAutoFormattedTB.structured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1434\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtb \u001B[38;5;241m=\u001B[39m etb\n\u001B[0;32m-> 1435\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mFormattedTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1436\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\n\u001B[1;32m   1437\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/IPython/core/ultratb.py:1326\u001B[0m, in \u001B[0;36mFormattedTB.structured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose_modes:\n\u001B[1;32m   1325\u001B[0m     \u001B[38;5;66;03m# Verbose modes need a full traceback\u001B[39;00m\n\u001B[0;32m-> 1326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVerboseTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1327\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\n\u001B[1;32m   1328\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1329\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMinimal\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/IPython/core/ultratb.py:1173\u001B[0m, in \u001B[0;36mVerboseTB.structured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1172\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1173\u001B[0m formatted_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_exception_as_a_whole\u001B[49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1174\u001B[0m \u001B[43m                                                       \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1176\u001B[0m colors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mColors  \u001B[38;5;66;03m# just a shorthand + quicker name lookup\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/IPython/core/ultratb.py:1063\u001B[0m, in \u001B[0;36mVerboseTB.format_exception_as_a_whole\u001B[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m   1061\u001B[0m head \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_header(\u001B[38;5;28mstr\u001B[39m(etype), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlong_header)\n\u001B[1;32m   1062\u001B[0m records \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m-> 1063\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_records\u001B[49m\u001B[43m(\u001B[49m\u001B[43metb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m etb \u001B[38;5;28;01melse\u001B[39;00m []\n\u001B[1;32m   1064\u001B[0m )\n\u001B[1;32m   1066\u001B[0m frames \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/IPython/core/ultratb.py:1131\u001B[0m, in \u001B[0;36mVerboseTB.get_records\u001B[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m   1130\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1131\u001B[0m     mod \u001B[38;5;241m=\u001B[39m \u001B[43minspect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtb_frame\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1132\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mod \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/inspect.py:738\u001B[0m, in \u001B[0;36mgetmodule\u001B[0;34m(object, _filename)\u001B[0m\n\u001B[1;32m    737\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 738\u001B[0m     file \u001B[38;5;241m=\u001B[39m \u001B[43mgetabsfile\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mobject\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_filename\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    739\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/inspect.py:721\u001B[0m, in \u001B[0;36mgetabsfile\u001B[0;34m(object, _filename)\u001B[0m\n\u001B[1;32m    720\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _filename \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 721\u001B[0m     _filename \u001B[38;5;241m=\u001B[39m \u001B[43mgetsourcefile\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mobject\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mor\u001B[39;00m getfile(\u001B[38;5;28mobject\u001B[39m)\n\u001B[1;32m    722\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mnormcase(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mabspath(_filename))\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/inspect.py:709\u001B[0m, in \u001B[0;36mgetsourcefile\u001B[0;34m(object)\u001B[0m\n\u001B[1;32m    708\u001B[0m \u001B[38;5;66;03m# only return a non-existent filename if the module has a PEP 302 loader\u001B[39;00m\n\u001B[0;32m--> 709\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[43mgetmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mobject\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__loader__\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    710\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m filename\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/inspect.py:745\u001B[0m, in \u001B[0;36mgetmodule\u001B[0;34m(object, _filename)\u001B[0m\n\u001B[1;32m    743\u001B[0m \u001B[38;5;66;03m# Update the filename to module name cache and check yet again\u001B[39;00m\n\u001B[1;32m    744\u001B[0m \u001B[38;5;66;03m# Copy sys.modules in order to cope with changes while iterating\u001B[39;00m\n\u001B[0;32m--> 745\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m modname, module \u001B[38;5;129;01min\u001B[39;00m \u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodules\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    746\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ismodule(module) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(module, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__file__\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2165\u001B[0m, in \u001B[0;36mInteractiveShell.showtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2162\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_showtraceback(etype, value, stb)\n\u001B[1;32m   2164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m-> 2165\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_exception_only\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, file\u001B[38;5;241m=\u001B[39msys\u001B[38;5;241m.\u001B[39mstderr)\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2088\u001B[0m, in \u001B[0;36mInteractiveShell.get_exception_only\u001B[0;34m(self, exc_tuple)\u001B[0m\n\u001B[1;32m   2083\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2084\u001B[0m \u001B[38;5;124;03mReturn as a string (ending with a newline) the exception that\u001B[39;00m\n\u001B[1;32m   2085\u001B[0m \u001B[38;5;124;03mjust occurred, without any traceback.\u001B[39;00m\n\u001B[1;32m   2086\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2087\u001B[0m etype, value, tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_exc_info(exc_tuple)\n\u001B[0;32m-> 2088\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[43mtraceback\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_exception_only\u001B[49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2089\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(msg)\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/traceback.py:140\u001B[0m, in \u001B[0;36mformat_exception_only\u001B[0;34m(etype, value)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mformat_exception_only\u001B[39m(etype, value):\n\u001B[1;32m    125\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Format the exception part of a traceback.\u001B[39;00m\n\u001B[1;32m    126\u001B[0m \n\u001B[1;32m    127\u001B[0m \u001B[38;5;124;03m    The arguments are the exception type and value such as given by\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    138\u001B[0m \n\u001B[1;32m    139\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(\u001B[43mTracebackException\u001B[49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mformat_exception_only())\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/exceptiongroup/_formatting.py:179\u001B[0m, in \u001B[0;36mPatchedTracebackException.__init__\u001B[0;34m(self, exc_type, exc_value, exc_traceback, limit, lookup_lines, capture_locals, compact, _seen)\u001B[0m\n\u001B[1;32m    172\u001B[0m     need_context \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    174\u001B[0m     e\n\u001B[1;32m    175\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m e\u001B[38;5;241m.\u001B[39m__context__ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    176\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m need_context\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mid\u001B[39m(e\u001B[38;5;241m.\u001B[39m__context__) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m _seen\n\u001B[1;32m    178\u001B[0m ):\n\u001B[0;32m--> 179\u001B[0m     context \u001B[38;5;241m=\u001B[39m \u001B[43mPatchedTracebackException\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__context__\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43me\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__context__\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m        \u001B[49m\u001B[43me\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__context__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__traceback__\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlimit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlookup_lines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlookup_lines\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapture_locals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapture_locals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_seen\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_seen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    189\u001B[0m     context \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/UCSD Classes/Deep Learning/AgroverseComp/.venv/lib/python3.9/site-packages/exceptiongroup/_formatting.py:96\u001B[0m, in \u001B[0;36mPatchedTracebackException.__init__\u001B[0;34m(self, exc_type, exc_value, exc_traceback, limit, lookup_lines, capture_locals, compact, _seen)\u001B[0m\n\u001B[1;32m     93\u001B[0m     _seen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[1;32m     94\u001B[0m _seen\u001B[38;5;241m.\u001B[39madd(\u001B[38;5;28mid\u001B[39m(exc_value))\n\u001B[0;32m---> 96\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstack \u001B[38;5;241m=\u001B[39m \u001B[43mtraceback\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mStackSummary\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     97\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraceback\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwalk_tb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexc_traceback\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     98\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlimit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     99\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlookup_lines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlookup_lines\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    100\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcapture_locals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapture_locals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    101\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexc_type \u001B[38;5;241m=\u001B[39m exc_type\n\u001B[1;32m    103\u001B[0m \u001B[38;5;66;03m# Capture now to permit freeing resources: only complication is in the\u001B[39;00m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;66;03m# unofficial API _format_final_exc_line\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/traceback.py:366\u001B[0m, in \u001B[0;36mStackSummary.extract\u001B[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001B[0m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m lookup_lines:\n\u001B[1;32m    365\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m result:\n\u001B[0;32m--> 366\u001B[0m         \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mline\u001B[49m\n\u001B[1;32m    367\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/traceback.py:288\u001B[0m, in \u001B[0;36mFrameSummary.line\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mline\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_line \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_line \u001B[38;5;241m=\u001B[39m \u001B[43mlinecache\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetline\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlineno\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[1;32m    289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_line\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/linecache.py:30\u001B[0m, in \u001B[0;36mgetline\u001B[0;34m(filename, lineno, module_globals)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mgetline\u001B[39m(filename, lineno, module_globals\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m     27\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get a line for a Python source file from the cache.\u001B[39;00m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;124;03m    Update the cache if it doesn't contain an entry for this file already.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 30\u001B[0m     lines \u001B[38;5;241m=\u001B[39m \u001B[43mgetlines\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule_globals\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m lineno \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(lines):\n\u001B[1;32m     32\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m lines[lineno \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/linecache.py:54\u001B[0m, in \u001B[0;36mgetlines\u001B[0;34m(filename, module_globals)\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mod \u001B[38;5;129;01min\u001B[39;00m mods:\n\u001B[0;32m---> 54\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m__file__\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m \u001B[38;5;241m==\u001B[39m filename:\n\u001B[1;32m     55\u001B[0m         module_globals \u001B[38;5;241m=\u001B[39m mod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m\n\u001B[1;32m     56\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "shuffled_train_data = standardized_train_data.copy()\n",
    "np.random.shuffle(shuffled_train_data)  # shuffles in-place along axis 0 (scenarios)\n",
    "model, X_mean, X_std, y_mean, y_std  = train_model(shuffled_train_data[:], batch_size=30, validation_split=0.3, epochs=30, epochs2=15, lr1 = 0.00001, lr2=0.00001)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:33:51.649213Z",
     "start_time": "2025-05-28T18:33:24.115293Z"
    }
   },
   "id": "3338be4ed075b368",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_mse(data, model, forecast_fn, Tobs=50, Tpred=60, \n",
    "                 X_mean=None, X_std=None, y_mean=None, y_std=None):\n",
    "    \"\"\"\n",
    "    Evaluate MSE of a forecast function on ego agent across scenarios,\n",
    "    and print the worst 5 scenarios by MSE.\n",
    "\n",
    "    Args:\n",
    "        train_data (np.ndarray): Shape (N, agents, timesteps, features)\n",
    "        model (tf.keras.Model): Trained single-step model\n",
    "        forecast_fn (callable): Function to call for forecasting. Must match:\n",
    "            (scenario_data, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std) -> np.ndarray\n",
    "        Tobs (int): Number of observed steps\n",
    "        Tpred (int): Number of predicted steps\n",
    "        X_mean, X_std, y_mean, y_std (optional): Normalization statistics\n",
    "\n",
    "    Returns:\n",
    "        float: Mean squared error across valid scenarios\n",
    "    \"\"\"\n",
    "    N = data.shape[0]\n",
    "    mse_list = []\n",
    "    valid_scenarios = 0\n",
    "    scenario_indices = []\n",
    "    \n",
    "    print(f\"Evaluating {N} scenarios...\")\n",
    "    # report_interval = max(1, N // 10)\n",
    "    report_interval=1\n",
    "    for i in range(N):\n",
    "        if i % report_interval == 0 or i == N - 1:\n",
    "            print(f\"Processing scenario {i+1}/{N} ({(i+1)/N*100:.1f}%)\")\n",
    "        \n",
    "        scenario_data = data[i]  # shape (agents, timesteps, 6)\n",
    "        ego_agent_data = scenario_data[0]  # shape (timesteps, 6)\n",
    "        ground_truth = ego_agent_data[Tobs:Tobs + Tpred, :2]\n",
    "\n",
    "        if np.all(ground_truth == 0):\n",
    "            continue\n",
    "\n",
    "        valid_scenarios += 1\n",
    "\n",
    "        predicted_positions = forecast_fn(\n",
    "            scenario_data, \n",
    "            Tobs, Tpred, model,\n",
    "            X_mean=X_mean, X_std=X_std, y_mean=y_mean, y_std=y_std\n",
    "        )\n",
    "\n",
    "        mse = mean_squared_error(ground_truth, predicted_positions)\n",
    "        mse_list.append(mse)\n",
    "        scenario_indices.append(i)\n",
    "\n",
    "        if i % report_interval == 0:\n",
    "            print(f\"  Current scenario {i} MSE: {mse:.4f}\")\n",
    "\n",
    "    if mse_list:\n",
    "        overall_mse = np.mean(mse_list)\n",
    "        print(f\"\\nEvaluation complete: {valid_scenarios} valid scenarios\")\n",
    "        print(f\"Mean Squared Error (MSE): {overall_mse:.4f}\")\n",
    "        print(f\"Min MSE: {np.min(mse_list):.4f}, Max MSE: {np.max(mse_list):.4f}\")\n",
    "\n",
    "        # Find worst 5 scenarios\n",
    "        worst_indices = np.argsort(mse_list)[-5:][::-1]  # indices of top 5 MSEs, descending\n",
    "        print(\"\\nWorst 5 scenarios by MSE:\")\n",
    "        for rank, idx in enumerate(worst_indices, 1):\n",
    "            scenario_id = scenario_indices[idx]\n",
    "            print(f\"  {rank}. Scenario {scenario_id} - MSE: {mse_list[idx]:.4f}\")\n",
    "\n",
    "        return overall_mse\n",
    "    else:\n",
    "        print(\"No valid scenarios for evaluation.\")\n",
    "        return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-28T18:33:51.648510Z"
    }
   },
   "id": "94a6d7a17d8677e1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate on training data\n",
    "evaluate_mse(standardized_train_data[3000:3030], model, forecast_fn=forecast_positions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:33:51.651453Z",
     "start_time": "2025-05-28T18:33:51.649823Z"
    }
   },
   "id": "37d911e07608a229",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate on training data\n",
    "evaluate_mse(standardized_train_data[3000:3030], model, forecast_fn=finetune_forecast_positions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-28T18:33:51.650701Z"
    }
   },
   "id": "76a45de5cfb6e914",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_submission(data, output_csv, model, forecast_fn, \n",
    "                        Tobs=50, Tpred=60,\n",
    "                        X_mean=None, X_std=None, y_mean=None, y_std=None):\n",
    "    \"\"\"\n",
    "    Generates a submission CSV file with predicted (x, y) positions for the ego agent.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): Test data of shape (num_scenarios, agents, timesteps, features).\n",
    "        output_csv (str): Output CSV file path.\n",
    "        model (tf.keras.Model): Trained prediction model.\n",
    "        forecast_fn (callable): Forecast function with signature:\n",
    "            (scenario_data, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std) -> np.ndarray\n",
    "        Tobs (int): Number of observed time steps.\n",
    "        Tpred (int): Number of predicted time steps.\n",
    "        X_mean, X_std, y_mean, y_std (optional): Normalization statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    print(f\"Generating predictions for {data.shape[0]} scenarios...\")\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        scenario_data = data[i]            # Shape: (agents, timesteps, 6)\n",
    "        ego_agent_data = scenario_data[0]  # Shape: (timesteps, 6)\n",
    "\n",
    "        predicted_positions = forecast_fn(\n",
    "            ego_agent_data[np.newaxis, :, :], Tobs, Tpred, model,\n",
    "            X_mean=X_mean, X_std=X_std, y_mean=y_mean, y_std=y_std\n",
    "        )  # Shape: (1, Tpred, 2)\n",
    "\n",
    "        predictions.extend(predicted_positions[0])  # Append shape: (Tpred, 2)\n",
    "\n",
    "    submission_df = pd.DataFrame(predictions, columns=[\"x\", \"y\"])\n",
    "    submission_df.index.name = 'index'  # Match required format\n",
    "    submission_df.to_csv(output_csv)\n",
    "\n",
    "    print(f\"Submission file '{output_csv}' saved with shape {submission_df.shape}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-28T18:33:51.651195Z"
    }
   },
   "id": "c2557ca9bf552c0b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "generate_submission(\n",
    "    data=test_data,\n",
    "    output_csv='lstm_submission.csv',\n",
    "    model=model,\n",
    "    forecast_fn=forecast_positions,  # or finetune_forecast_positions\n",
    "    Tobs=50,\n",
    "    Tpred=60,\n",
    "    X_mean=X_mean,\n",
    "    X_std=X_std,\n",
    "    y_mean=y_mean,\n",
    "    y_std=y_std\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T18:33:51.655641Z",
     "start_time": "2025-05-28T18:33:51.651747Z"
    }
   },
   "id": "d4f8d7605d54296d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
