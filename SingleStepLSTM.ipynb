{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9885a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:59:33.423576Z",
     "start_time": "2025-05-30T19:59:32.069696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape (10000, 50, 110, 6)\n",
      "test_data's shape (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import numpy as np\n",
    "train_file = np.load('argoverse_data/train.npz')\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape\", train_data.shape)\n",
    "test_file = np.load('argoverse_data/test_input.npz')\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c708e385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:59:34.294156Z",
     "start_time": "2025-05-30T19:59:34.066491Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Optional\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def rotate_trajectory(trajectory: np.ndarray, angle: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Rotate trajectory by given angle around the origin.\n",
    "    Updates position, velocity, and heading.\n",
    "    \n",
    "    Args:\n",
    "        trajectory: Shape (timesteps, 6) where columns are [pos_x, pos_y, vel_x, vel_y, heading, obj_type]\n",
    "        angle: Rotation angle in radians\n",
    "        \n",
    "    Returns:\n",
    "        Rotated trajectory of same shape\n",
    "    \"\"\"\n",
    "    if trajectory.shape[-1] < 6:\n",
    "        raise ValueError(\"Trajectory must have 6 features\")\n",
    "        \n",
    "    cos_a, sin_a = np.cos(angle), np.sin(angle)\n",
    "    rotation_matrix = np.array([[cos_a, -sin_a],\n",
    "                               [sin_a, cos_a]])\n",
    "    \n",
    "    rotated_trajectory = trajectory.copy()\n",
    "    \n",
    "    # Rotate positions (columns 0, 1)\n",
    "    pos_xy = trajectory[:, :2]  # position_x, position_y\n",
    "    rotated_pos = pos_xy @ rotation_matrix.T\n",
    "    rotated_trajectory[:, :2] = rotated_pos\n",
    "    \n",
    "    # Rotate velocities (columns 2, 3)\n",
    "    vel_xy = trajectory[:, 2:4]  # velocity_x, velocity_y\n",
    "    rotated_vel = vel_xy @ rotation_matrix.T\n",
    "    rotated_trajectory[:, 2:4] = rotated_vel\n",
    "    \n",
    "    # Update heading (column 4)\n",
    "    rotated_trajectory[:, 4] = trajectory[:, 4] + angle\n",
    "    \n",
    "    # Keep object_type unchanged (column 5)\n",
    "    \n",
    "    return rotated_trajectory\n",
    "\n",
    "def translate_trajectory(trajectory: np.ndarray, dx: float, dy: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Translate trajectory by given offsets.\n",
    "    Only affects position coordinates.\n",
    "    \n",
    "    Args:\n",
    "        trajectory: Shape (timesteps, 6)\n",
    "        dx: Translation in x direction\n",
    "        dy: Translation in y direction\n",
    "        \n",
    "    Returns:\n",
    "        Translated trajectory of same shape\n",
    "    \"\"\"\n",
    "    if trajectory.shape[-1] < 6:\n",
    "        raise ValueError(\"Trajectory must have 6 features\")\n",
    "        \n",
    "    translated_trajectory = trajectory.copy()\n",
    "    translated_trajectory[:, 0] += dx  # position_x\n",
    "    translated_trajectory[:, 1] += dy  # position_y\n",
    "    \n",
    "    return translated_trajectory\n",
    "\n",
    "def flip_horizontal(trajectory: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Flip trajectory horizontally (mirror across y-axis).\n",
    "    Updates position, velocity, and heading.\n",
    "    \"\"\"\n",
    "    if trajectory.shape[-1] < 6:\n",
    "        raise ValueError(\"Trajectory must have 6 features\")\n",
    "        \n",
    "    flipped = trajectory.copy()\n",
    "    flipped[:, 0] = -flipped[:, 0]  # Negate position_x\n",
    "    flipped[:, 2] = -flipped[:, 2]  # Negate velocity_x\n",
    "    flipped[:, 4] = np.pi - flipped[:, 4]  # Mirror heading across y-axis\n",
    "    \n",
    "    return flipped\n",
    "\n",
    "def flip_vertical(trajectory: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Flip trajectory vertically (mirror across x-axis).\n",
    "    Updates position, velocity, and heading.\n",
    "    \"\"\"\n",
    "    if trajectory.shape[-1] < 6:\n",
    "        raise ValueError(\"Trajectory must have 6 features\")\n",
    "        \n",
    "    flipped = trajectory.copy()\n",
    "    flipped[:, 1] = -flipped[:, 1]  # Negate position_y\n",
    "    flipped[:, 3] = -flipped[:, 3]  # Negate velocity_y\n",
    "    flipped[:, 4] = -flipped[:, 4]  # Mirror heading across x-axis\n",
    "    \n",
    "    return flipped\n",
    "\n",
    "def augment_single_sample(sample: np.ndarray, \n",
    "                         rotation_range: float = np.pi/4,\n",
    "                         translation_range: float = 5.0,\n",
    "                         flip_prob: float = 0.5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply random augmentations to a single sample.\n",
    "    \n",
    "    Args:\n",
    "        sample: Shape (agents, timesteps, 6) for single scene\n",
    "        rotation_range: Maximum rotation angle in radians\n",
    "        translation_range: Maximum translation distance\n",
    "        flip_prob: Probability of applying flips\n",
    "        \n",
    "    Returns:\n",
    "        Augmented sample of same shape\n",
    "    \"\"\"\n",
    "    if len(sample.shape) != 3 or sample.shape[2] != 6:\n",
    "        raise ValueError(f\"Expected shape (agents, timesteps, 6), got {sample.shape}\")\n",
    "    \n",
    "    augmented = sample.copy()\n",
    "    \n",
    "    # Random rotation, translation parameters (same for all agents in scene)\n",
    "    angle = np.random.uniform(-rotation_range, rotation_range)\n",
    "    dx = np.random.uniform(-translation_range, translation_range)\n",
    "    dy = np.random.uniform(-translation_range, translation_range)\n",
    "    \n",
    "    # Random flip decisions (same for all agents in scene)\n",
    "    do_horizontal_flip = np.random.random() < flip_prob\n",
    "    do_vertical_flip = np.random.random() < flip_prob\n",
    "    \n",
    "    for agent_idx in range(sample.shape[0]):\n",
    "        trajectory = sample[agent_idx, :, :]  # Shape (timesteps, 6)\n",
    "        \n",
    "        # Skip if trajectory is all zeros (padding/inactive agent)\n",
    "        if np.all(trajectory[:, :2] == 0):  # Check if positions are all zero\n",
    "            continue\n",
    "            \n",
    "        # Apply transformations\n",
    "        trajectory = rotate_trajectory(trajectory, angle)\n",
    "        trajectory = translate_trajectory(trajectory, dx, dy)\n",
    "        \n",
    "        if do_horizontal_flip:\n",
    "            trajectory = flip_horizontal(trajectory)\n",
    "        \n",
    "        if do_vertical_flip:\n",
    "            trajectory = flip_vertical(trajectory)\n",
    "            \n",
    "        augmented[agent_idx, :, :] = trajectory\n",
    "    \n",
    "    return augmented\n",
    "\n",
    "def augment_batch_worker(batch_data: np.ndarray,\n",
    "                        rotation_range: float,\n",
    "                        translation_range: float,\n",
    "                        flip_prob: float) -> np.ndarray:\n",
    "    \"\"\"Process a batch of samples for parallel augmentation.\"\"\"\n",
    "    return np.array([augment_single_sample(sample,\n",
    "                                          rotation_range,\n",
    "                                          translation_range,\n",
    "                                          flip_prob)\n",
    "                     for sample in batch_data])\n",
    "\n",
    "def augment_dataset(data: np.ndarray, \n",
    "                   num_augmentations: int = 5,\n",
    "                   rotation_range: float = np.pi/4,\n",
    "                   translation_range: float = 5.0,\n",
    "                   flip_prob: float = 0.5,\n",
    "                   return_original: bool = True,\n",
    "                   n_jobs: Optional[int] = None,\n",
    "                   batch_size: Optional[int] = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Augment entire dataset.\n",
    "    \n",
    "    Args:\n",
    "        data: Shape (scenes, agents, timesteps, 6) dataset\n",
    "        num_augmentations: Number of augmented versions per sample\n",
    "        rotation_range: Maximum rotation angle in radians\n",
    "        translation_range: Maximum translation distance\n",
    "        flip_prob: Probability of applying flips\n",
    "        return_original: Whether to include original data in output\n",
    "        n_jobs: Number of parallel jobs\n",
    "        batch_size: Size of batches for parallel processing\n",
    "        \n",
    "    Returns:\n",
    "        Augmented dataset with shape (scenes*(1+num_augmentations), agents, timesteps, 6)\n",
    "    \"\"\"\n",
    "    if len(data.shape) != 4 or data.shape[3] != 6:\n",
    "        raise ValueError(f\"Expected shape (scenes, agents, timesteps, 6), got {data.shape}\")\n",
    "    \n",
    "    original_size = data.shape[0]\n",
    "    augmented_samples = []\n",
    "    \n",
    "    if return_original:\n",
    "        augmented_samples.append(data)\n",
    "\n",
    "    if n_jobs is None:\n",
    "        n_jobs = min(os.cpu_count(), 8)\n",
    "    elif n_jobs == -1:\n",
    "        n_jobs = os.cpu_count()\n",
    "\n",
    "    if batch_size is None:\n",
    "        batch_size = max(1, original_size // n_jobs)\n",
    "\n",
    "    print(f\"Using {n_jobs} jobs with batch size {batch_size}\")\n",
    "    \n",
    "    for aug_idx in tqdm(range(num_augmentations), desc=\"Augmentations\"):\n",
    "        batches = [data[i:i + batch_size] for i in range(0, original_size, batch_size)]\n",
    "\n",
    "        augmented_batches = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(augment_batch_worker)(\n",
    "                batch,\n",
    "                rotation_range,\n",
    "                translation_range,\n",
    "                flip_prob\n",
    "            ) for batch in tqdm(batches, desc=f\"Processing aug {aug_idx + 1}\", leave=False)\n",
    "        )\n",
    "\n",
    "        augmented_batch = np.concatenate(augmented_batches, axis=0)\n",
    "        augmented_samples.append(augmented_batch)\n",
    "\n",
    "    return np.concatenate(augmented_samples, axis=0)\n",
    "\n",
    "def visualize_augmentations(original_sample: np.ndarray, \n",
    "                           num_examples: int = 4,\n",
    "                           agent_idx: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    Visualize original and augmented trajectories for comparison.\n",
    "    \n",
    "    Args:\n",
    "        original_sample: Single sample of shape (agents, timesteps, 6)\n",
    "        num_examples: Number of augmented examples to show\n",
    "        agent_idx: Which agent's trajectory to visualize\n",
    "    \"\"\"\n",
    "    if len(original_sample.shape) != 3 or original_sample.shape[2] != 6:\n",
    "        raise ValueError(f\"Expected shape (agents, timesteps, 6), got {original_sample.shape}\")\n",
    "    \n",
    "    if agent_idx >= original_sample.shape[0]:\n",
    "        raise ValueError(f\"agent_idx {agent_idx} >= number of agents {original_sample.shape[0]}\")\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_examples + 1, figsize=(15, 3))\n",
    "    \n",
    "    # Extract original trajectory (position_x, position_y)\n",
    "    orig_traj = original_sample[agent_idx, :, :2]  # Shape (timesteps, 2)\n",
    "    \n",
    "    # Plot original\n",
    "    axes[0].plot(orig_traj[:, 0], orig_traj[:, 1], 'b-o', markersize=3)\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].grid(True)\n",
    "    axes[0].axis('equal')\n",
    "    \n",
    "    # Plot augmented versions\n",
    "    for i in range(num_examples):\n",
    "        aug_sample = augment_single_sample(original_sample)\n",
    "        aug_traj = aug_sample[agent_idx, :, :2]  # Shape (timesteps, 2)\n",
    "        \n",
    "        axes[i + 1].plot(aug_traj[:, 0], aug_traj[:, 1], 'r-o', markersize=3)\n",
    "        axes[i + 1].set_title(f'Augmented {i + 1}')\n",
    "        axes[i + 1].grid(True)\n",
    "        axes[i + 1].axis('equal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92d2b355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_augmentations(train_data[0], agent_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "614217f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:59:34.405790Z",
     "start_time": "2025-05-30T19:59:34.403969Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def standardize_data_dimensions(scenario_data):\n",
    "    \"\"\"\n",
    "    Standardize position data by centering a single scenario at the origin.\n",
    "    \n",
    "    :param scenario_data: numpy array of shape (50, 110, 6)\n",
    "                         where dimensions are [position_x, position_y, velocity_x, velocity_y, heading, object_type]\n",
    "    :returns: tuple of (standardized_data, min_values)\n",
    "             - standardized_data: same shape as input with centered positions\n",
    "             - min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    \"\"\"\n",
    "    # Copy the data to avoid modifying the original\n",
    "    standardized_data = scenario_data.copy()\n",
    "    \n",
    "    # Extract position data (first 2 dimensions)\n",
    "    positions = scenario_data[:, :, :2]  # Shape: (50, 110, 2)\n",
    "    \n",
    "    # Create mask for non-zero positions (to ignore padding)\n",
    "    # We consider a position valid if it's not (0,0) or if the object_type is not 0\n",
    "    object_types = scenario_data[:, :, 5]  # Shape: (50, 110)\n",
    "    valid_mask = (positions[:, :, 0] != 0) | (positions[:, :, 1] != 0) | (object_types != 0)\n",
    "    \n",
    "    # Find min values across all valid positions in this scenario\n",
    "    if np.any(valid_mask):\n",
    "        valid_positions = positions[valid_mask]  # Shape: (num_valid_points, 2)\n",
    "        min_x = np.min(valid_positions[:, 0])\n",
    "        min_y = np.min(valid_positions[:, 1])\n",
    "    else:\n",
    "        # If no valid positions found, use 0 as min values\n",
    "        min_x = 0\n",
    "        min_y = 0\n",
    "    \n",
    "    # Store min values\n",
    "    min_values = np.array([min_x, min_y])\n",
    "    \n",
    "    # Standardize positions by subtracting min values\n",
    "    # Only modify non-zero positions to preserve padding\n",
    "    for agent_idx in range(scenario_data.shape[0]):\n",
    "        for time_idx in range(scenario_data.shape[1]):\n",
    "            if valid_mask[agent_idx, time_idx]:\n",
    "                standardized_data[agent_idx, time_idx, 0] -= min_x  # position_x\n",
    "                standardized_data[agent_idx, time_idx, 1] -= min_y  # position_y\n",
    "    \n",
    "    return standardized_data, min_values\n",
    "\n",
    "\n",
    "def denormalize_predictions(predictions, min_values):\n",
    "    \"\"\"\n",
    "    Helper function to add back the min values to predicted positions.\n",
    "    \n",
    "    :param predictions: predicted data with standardized positions, shape (50, 110, 6) or similar\n",
    "    :param min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    :returns: predictions with original coordinate system restored\n",
    "    \"\"\"\n",
    "    denormalized = predictions.copy()\n",
    "    \n",
    "    # Add back the min values to restore original coordinate system\n",
    "    # Assuming predictions have position_x and position_y as first two dimensions\n",
    "    denormalized[:, :, 0] += min_values[0]  # position_x\n",
    "    denormalized[:, :, 1] += min_values[1]  # position_y\n",
    "    \n",
    "    return denormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f93de194",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:59:34.405790Z",
     "start_time": "2025-05-30T19:59:34.403969Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def standardize_data_dimensions(scenario_data):\n",
    "    \"\"\"\n",
    "    Standardize position data by centering a single scenario at the origin.\n",
    "    \n",
    "    :param scenario_data: numpy array of shape (50, 110, 6)\n",
    "                         where dimensions are [position_x, position_y, velocity_x, velocity_y, heading, object_type]\n",
    "    :returns: tuple of (standardized_data, min_values)\n",
    "             - standardized_data: same shape as input with centered positions\n",
    "             - min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    \"\"\"\n",
    "    # Copy the data to avoid modifying the original\n",
    "    standardized_data = scenario_data.copy()\n",
    "    \n",
    "    # Extract position data (first 2 dimensions)\n",
    "    positions = scenario_data[:, :, :2]  # Shape: (50, 110, 2)\n",
    "    \n",
    "    # Create mask for non-zero positions (to ignore padding)\n",
    "    # We consider a position valid if it's not (0,0) or if the object_type is not 0\n",
    "    object_types = scenario_data[:, :, 5]  # Shape: (50, 110)\n",
    "    valid_mask = (positions[:, :, 0] != 0) | (positions[:, :, 1] != 0) | (object_types != 0)\n",
    "    \n",
    "    # Find min values across all valid positions in this scenario\n",
    "    if np.any(valid_mask):\n",
    "        valid_positions = positions[valid_mask]  # Shape: (num_valid_points, 2)\n",
    "        min_x = np.min(valid_positions[:, 0])\n",
    "        min_y = np.min(valid_positions[:, 1])\n",
    "    else:\n",
    "        # If no valid positions found, use 0 as min values\n",
    "        min_x = 0\n",
    "        min_y = 0\n",
    "    \n",
    "    # Store min values\n",
    "    min_values = np.array([min_x, min_y])\n",
    "    \n",
    "    # Standardize positions by subtracting min values\n",
    "    # Only modify non-zero positions to preserve padding\n",
    "    for agent_idx in range(scenario_data.shape[0]):\n",
    "        for time_idx in range(scenario_data.shape[1]):\n",
    "            if valid_mask[agent_idx, time_idx]:\n",
    "                standardized_data[agent_idx, time_idx, 0] -= min_x  # position_x\n",
    "                standardized_data[agent_idx, time_idx, 1] -= min_y  # position_y\n",
    "    \n",
    "    return standardized_data, min_values\n",
    "\n",
    "\n",
    "def denormalize_predictions(predictions, min_values):\n",
    "    \"\"\"\n",
    "    Helper function to add back the min values to predicted positions.\n",
    "    \n",
    "    :param predictions: predicted data with standardized positions, shape (50, 110, 6) or similar\n",
    "    :param min_values: array of shape (2,) containing [min_x, min_y] for this scenario\n",
    "    :returns: predictions with original coordinate system restored\n",
    "    \"\"\"\n",
    "    denormalized = predictions.copy()\n",
    "    \n",
    "    # Add back the min values to restore original coordinate system\n",
    "    # Assuming predictions have position_x and position_y as first two dimensions\n",
    "    denormalized[:, :, 0] += min_values[0]  # position_x\n",
    "    denormalized[:, :, 1] += min_values[1]  # position_y\n",
    "    \n",
    "    return denormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba31f6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:59:35.013159Z",
     "start_time": "2025-05-30T19:59:34.999388Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "def standardize_single_scene(scene_data):\n",
    "    \"\"\"\n",
    "    Wrapper function to standardize a single scene and return both standardized data and min values.\n",
    "    This function will be called in parallel.\n",
    "    \"\"\"\n",
    "    standardized_scene, min_vals = standardize_data_dimensions(scene_data)\n",
    "    return standardized_scene, min_vals\n",
    "\n",
    "def parallel_standardize_training_data(train_data, n_jobs=-1, verbose=True):\n",
    "    \"\"\"\n",
    "    Parallelize the standardization of training data across all scenes.\n",
    "    \n",
    "    :param train_data: numpy array of shape (10000, 50, 110, 6)\n",
    "    :param n_jobs: number of parallel jobs (-1 uses all available cores)\n",
    "    :param verbose: whether to show progress bar\n",
    "    :returns: tuple of (standardized_data, min_values_array)\n",
    "    \"\"\"\n",
    "    print(f\"Standardizing {train_data.shape[0]} scenes using {multiprocessing.cpu_count() if n_jobs == -1 else n_jobs} cores...\")\n",
    "    \n",
    "    # Use joblib to parallelize the processing\n",
    "    if verbose:\n",
    "        # With progress bar\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(standardize_single_scene)(train_data[i]) \n",
    "            for i in tqdm(range(train_data.shape[0]), desc=\"Processing scenes\")\n",
    "        )\n",
    "    else:\n",
    "        # Without progress bar\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(standardize_single_scene)(train_data[i]) \n",
    "            for i in range(train_data.shape[0])\n",
    "        )\n",
    "    \n",
    "    # Unpack results\n",
    "    standardized_scenes, min_values_list = zip(*results)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    standardized_data = np.array(standardized_scenes)\n",
    "    min_values_array = np.array(min_values_list)\n",
    "    \n",
    "    print(f\"Standardization complete!\")\n",
    "    print(f\"Standardized data shape: {standardized_data.shape}\")\n",
    "    print(f\"Min values shape: {min_values_array.shape}\")\n",
    "    \n",
    "    return standardized_data, min_values_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c024cd93",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# full agents are too much data; only want 5 agents worth\n",
    "train_data = train_data[:, :5, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5136d75",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-30T19:59:35.583428Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data not found. Running augmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting chunk 1/5...\n",
      "Using 128 jobs with batch size 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmentations:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Processing aug 1:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  20%|        | 1/5 [00:05<00:22,  5.58s/it]\u001b[A\n",
      "\n",
      "Processing aug 2:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  40%|      | 2/5 [00:06<00:08,  2.68s/it]\u001b[A\n",
      "\n",
      "Processing aug 3:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  60%|    | 3/5 [00:06<00:03,  1.72s/it]\u001b[A\n",
      "\n",
      "Processing aug 4:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  80%|  | 4/5 [00:07<00:01,  1.26s/it]\u001b[A\n",
      "\n",
      "Processing aug 5:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations: 100%|| 5/5 [00:07<00:00,  1.59s/it]\u001b[A\n",
      "Processing chunks:  20%|        | 1/5 [00:08<00:32,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting chunk 2/5...\n",
      "Using 128 jobs with batch size 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmentations:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Processing aug 1:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  20%|        | 1/5 [00:00<00:02,  1.39it/s]\u001b[A\n",
      "\n",
      "Processing aug 2:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  40%|      | 2/5 [00:01<00:02,  1.40it/s]\u001b[A\n",
      "\n",
      "Processing aug 3:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  60%|    | 3/5 [00:02<00:01,  1.44it/s]\u001b[A\n",
      "\n",
      "Processing aug 4:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  80%|  | 4/5 [00:02<00:00,  1.56it/s]\u001b[A\n",
      "\n",
      "Processing aug 5:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations: 100%|| 5/5 [00:03<00:00,  1.55it/s]\u001b[A\n",
      "Processing chunks:  40%|      | 2/5 [00:11<00:15,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting chunk 3/5...\n",
      "Using 128 jobs with batch size 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmentations:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Processing aug 1:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  20%|        | 1/5 [00:00<00:02,  1.59it/s]\u001b[A\n",
      "\n",
      "Processing aug 2:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  40%|      | 2/5 [00:01<00:01,  1.68it/s]\u001b[A\n",
      "\n",
      "Processing aug 3:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  60%|    | 3/5 [00:01<00:01,  1.71it/s]\u001b[A\n",
      "\n",
      "Processing aug 4:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  80%|  | 4/5 [00:02<00:00,  1.66it/s]\u001b[A\n",
      "\n",
      "Processing aug 5:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations: 100%|| 5/5 [00:03<00:00,  1.60it/s]\u001b[A\n",
      "Processing chunks:  60%|    | 3/5 [00:14<00:08,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting chunk 4/5...\n",
      "Using 128 jobs with batch size 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmentations:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Processing aug 1:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  20%|        | 1/5 [00:00<00:02,  1.61it/s]\u001b[A\n",
      "\n",
      "Processing aug 2:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  40%|      | 2/5 [00:01<00:02,  1.42it/s]\u001b[A\n",
      "\n",
      "Processing aug 3:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  60%|    | 3/5 [00:02<00:01,  1.43it/s]\u001b[A\n",
      "\n",
      "Processing aug 4:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  80%|  | 4/5 [00:02<00:00,  1.46it/s]\u001b[A\n",
      "\n",
      "Processing aug 5:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations: 100%|| 5/5 [00:03<00:00,  1.45it/s]\u001b[A\n",
      "Processing chunks:  80%|  | 4/5 [00:18<00:04,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting chunk 5/5...\n",
      "Using 128 jobs with batch size 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmentations:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Processing aug 1:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  20%|        | 1/5 [00:00<00:02,  1.48it/s]\u001b[A\n",
      "\n",
      "Processing aug 2:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  40%|      | 2/5 [00:01<00:02,  1.45it/s]\u001b[A\n",
      "\n",
      "Processing aug 3:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  60%|    | 3/5 [00:02<00:01,  1.48it/s]\u001b[A\n",
      "\n",
      "Processing aug 4:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations:  80%|  | 4/5 [00:02<00:00,  1.53it/s]\u001b[A\n",
      "\n",
      "Processing aug 5:   0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A\n",
      "Augmentations: 100%|| 5/5 [00:03<00:00,  1.52it/s]\u001b[A\n",
      "Processing chunks: 100%|| 5/5 [00:21<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation done. Preparing to dump to pickle...\n",
      "Original shape: (10000, 5, 110, 6)\n",
      "Augmented shape: (60000, 5, 110, 6)\n"
     ]
    }
   ],
   "source": [
    "# Main execution code\n",
    "augmented_pkl_path = Path(\"augmented_train.pkl\")\n",
    "\n",
    "# Check if the file exists\n",
    "if augmented_pkl_path.exists():\n",
    "    print(\"Loading augmented data from pickle file...\")\n",
    "    with open(augmented_pkl_path, \"rb\") as f:\n",
    "        augmented_train = pickle.load(f)\n",
    "else:\n",
    "    print(\"Augmented data not found. Running augmentation...\")\n",
    "    # Split into 5 chunks\n",
    "    num_chunks = 5\n",
    "    chunk_size = len(train_data) // num_chunks\n",
    "    chunks = [train_data[i * chunk_size: (i + 1) * chunk_size] for i in range(num_chunks - 1)]\n",
    "    chunks.append(train_data[(num_chunks - 1) * chunk_size:])  # last chunk\n",
    "    \n",
    "    augmented_chunks = []\n",
    "    for i, chunk in enumerate(tqdm(chunks, desc=\"Processing chunks\")):\n",
    "        print(f\"Augmenting chunk {i+1}/{num_chunks}...\")\n",
    "        augmented_chunk = augment_dataset(\n",
    "            chunk, \n",
    "            num_augmentations=5,\n",
    "            n_jobs=-1,\n",
    "            batch_size=25\n",
    "        )\n",
    "        augmented_chunks.append(augmented_chunk)\n",
    "        \n",
    "        # Force cleanup\n",
    "        del augmented_chunk\n",
    "        del chunk\n",
    "        gc.collect()\n",
    "    \n",
    "    # Concatenate all augmented chunks\n",
    "    augmented_train = np.concatenate(augmented_chunks, axis=0)\n",
    "    print(\"Augmentation done. Preparing to dump to pickle...\")\n",
    "    \n",
    "    # Uncomment to save to pickle\n",
    "    # with open(augmented_pkl_path, \"wb\") as f:\n",
    "    #     pickle.dump(augmented_train, f)\n",
    "    # print(\"Dumped to pickle.\")\n",
    "\n",
    "print(f\"Original shape: {train_data.shape}\")\n",
    "print(f\"Augmented shape: {augmented_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dce1544",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:41:35.979602Z",
     "start_time": "2025-05-30T19:41:35.938072Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing 60000 scenes using 128 cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing scenes: 100%|| 60000/60000 [00:25<00:00, 2308.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardization complete!\n",
      "Standardized data shape: (60000, 5, 110, 6)\n",
      "Min values shape: (60000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 5, 110, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_train_data, min_values = parallel_standardize_training_data(\n",
    "    augmented_train, \n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=True\n",
    ")\n",
    "standardized_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "504ea3f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T17:40:42.779341Z",
     "start_time": "2025-05-02T17:40:37.771284Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 23:08:10.116811: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749769690.144965     724 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749769690.153770     724 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-12 23:08:10.182142: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, RepeatVector, TimeDistributed, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4575fed9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T17:40:42.786049Z",
     "start_time": "2025-05-02T17:40:42.783787Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def angle_change_loss(y_pred):\n",
    "    \"\"\"\n",
    "    Penalize large changes in direction between consecutive deltas.\n",
    "\n",
    "    Args:\n",
    "        y_pred: Tensor of shape (batch_size, Tpred, 2)\n",
    "\n",
    "    Returns:\n",
    "        Scalar loss penalizing angle differences\n",
    "    \"\"\"\n",
    "    # Normalize deltas to unit vectors\n",
    "    delta_unit = tf.math.l2_normalize(y_pred, axis=-1)  # shape: (B, T, 2)\n",
    "\n",
    "    # Compute cosine similarity between consecutive deltas\n",
    "    dot_products = tf.reduce_sum(delta_unit[:, 1:, :] * delta_unit[:, :-1, :], axis=-1)  # shape: (B, T-1)\n",
    "\n",
    "    # Clamp for numerical stability (to avoid NaNs in arccos)\n",
    "    dot_products = tf.clip_by_value(dot_products, -1.0, 1.0)\n",
    "\n",
    "    # Compute angle in radians between -1 and 1 (cos)\n",
    "    angle_diff = tf.acos(dot_products)  # shape: (B, T-1)\n",
    "\n",
    "    # Mean angle difference per sequence\n",
    "    return tf.reduce_mean(angle_diff)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    # Check if there are NaN values in y_true or y_pred\n",
    "    nan_check = tf.reduce_any(tf.math.is_nan(y_true)) | tf.reduce_any(tf.math.is_nan(y_pred))\n",
    "\n",
    "    # Use tf.cond to perform the check\n",
    "    def return_nan_loss():\n",
    "        return tf.constant(float('nan'))\n",
    "\n",
    "    def calculate_loss():\n",
    "        mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "        angle_loss = angle_change_loss(y_pred)\n",
    "        return mse_loss + 0.5 * angle_loss\n",
    "\n",
    "    return tf.cond(nan_check, return_nan_loss, calculate_loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01d59fe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T18:15:51.012605Z",
     "start_time": "2025-05-02T18:15:51.003936Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def create_lstm_encoder_decoder(\n",
    "    input_dim=3,\n",
    "    output_dim=2,\n",
    "    timesteps_in=10,\n",
    "    lstm_units=256,\n",
    "    num_layers=2,\n",
    "    loss_fn='mse',\n",
    "    lr=0.001\n",
    "):\n",
    "    inputs = Input(shape=(timesteps_in, input_dim))  # (10, 3)\n",
    "\n",
    "    x = inputs\n",
    "    for _ in range(num_layers - 1):\n",
    "        x = LSTM(lstm_units, return_sequences=True)(x)\n",
    "    x = LSTM(lstm_units)(x)  # final layer returns last hidden state\n",
    "\n",
    "    outputs = Dense(64, activation='relu')(x)\n",
    "    outputs = Dense(output_dim)(outputs)  # output_dim = 2 (delta_x, delta_y)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss=loss_fn, metrics=['mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7558da9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T19:20:44.861403Z",
     "start_time": "2025-05-02T19:20:44.758718Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.src.callbacks import LearningRateScheduler, EarlyStopping, Callback, ModelCheckpoint\n",
    "from keras.src.optimizers import Adam\n",
    "from keras import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def exponential_decay_schedule(epoch, lr):\n",
    "    decay_rate = 0.9\n",
    "    decay_steps = 5\n",
    "    if epoch % decay_steps == 0 and epoch:\n",
    "        print('Learning rate update:', lr * decay_rate)\n",
    "        return lr * decay_rate\n",
    "    return lr\n",
    "\n",
    "\n",
    "# Custom callback to monitor LR and stop training\n",
    "class LRThresholdCallback(Callback):\n",
    "    def __init__(self, threshold=9e-5):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "        self.should_stop = False\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = float(self.model.optimizer.learning_rate.numpy())\n",
    "        if lr < self.threshold:\n",
    "            print(f\"\\nLearning rate {lr:.6f} < threshold {self.threshold}, moving to Phase 2.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "def train_model(train_data, batch_size=32, validation_split=0.2, Tobs=50, Tpred=60):\n",
    "    n_scenarios = train_data.shape[0]\n",
    "\n",
    "    X_processed = []\n",
    "    y_processed = []\n",
    "    \n",
    "    for i in range(n_scenarios):\n",
    "        ego_data = train_data[i, 0, :, :]  # shape (110, 6)\n",
    "    \n",
    "        if np.all(ego_data == 0) or ego_data.shape[0] < 110:\n",
    "            continue\n",
    "    \n",
    "        # Compute deltas of position only (x, y)\n",
    "        deltas = np.diff(ego_data[:, :2], axis=0)  # shape (109, 2)\n",
    "    \n",
    "        # Object type (assumed constant)\n",
    "        obj_type = ego_data[0, 5]\n",
    "    \n",
    "        # Create sliding windows: 10 steps of X, 1 step of y\n",
    "        for t in range(0, 99):  # max index is 98 to access t+10\n",
    "            delta_window = deltas[t : t + 10]      # shape (10, 2)\n",
    "            delta_target = deltas[t + 10]          # shape (2,)\n",
    "    \n",
    "            # Add object type as a 3rd feature\n",
    "            obj_column = np.full((10, 1), obj_type, dtype=np.float32)  # shape (10, 1)\n",
    "            X_seq = np.concatenate([delta_window, obj_column], axis=1)  # shape (10, 3)\n",
    "    \n",
    "            X_processed.append(X_seq)\n",
    "            y_processed.append(delta_target)\n",
    "    \n",
    "    # Convert to arrays\n",
    "    X_processed = np.array(X_processed)  # shape (N, 10, 3)\n",
    "    y_processed = np.array(y_processed)  # shape (N, 2)\n",
    "    \n",
    "    print(f\"X_processed shape: {X_processed.shape}  # Expected: (N, 10, 3)\")\n",
    "    print(f\"y_processed shape: {y_processed.shape}  # Expected: (N, 2)\")\n",
    "    \n",
    "    X_deltas = X_processed[:, :, :2]\n",
    "\n",
    "    # Compute global mean and std over all delta_x and delta_y\n",
    "    X_mean = X_deltas.mean(axis=(0, 1), keepdims=True)  # shape (1, 1, 2)\n",
    "    X_std = X_deltas.std(axis=(0, 1), keepdims=True) + 1e-8  # add epsilon to avoid div by zero\n",
    "    \n",
    "    # Normalize X deltas\n",
    "    X_deltas_norm = (X_deltas - X_mean) / X_std\n",
    "    \n",
    "    # Concatenate back the object type (unchanged)\n",
    "    object_types = X_processed[:, :, 2:]  # shape (N, 10, 1)\n",
    "    X_train = np.concatenate([X_deltas_norm, object_types], axis=-1)  # shape (N, 10, 3)\n",
    "    \n",
    "    # Normalize y (delta target)\n",
    "    y_mean = y_processed.mean(axis=0, keepdims=True)  # shape (1, 2)\n",
    "    y_std = y_processed.std(axis=0, keepdims=True) + 1e-8\n",
    "    y_train = (y_processed - y_mean) / y_std  # shape (N, 2)\n",
    "    \n",
    "    # --- Output Shapes ---\n",
    "    print(f\"X_normalized shape: {X_train.shape}  # (N, 10, 3)\")\n",
    "    print(f\"y_normalized shape: {y_train.shape}  # (N, 2)\")\n",
    "\n",
    "    model = create_lstm_encoder_decoder()\n",
    "\n",
    "    phase1_callbacks = [\n",
    "        LearningRateScheduler(exponential_decay_schedule),\n",
    "        EarlyStopping(patience=4, restore_best_weights=True, monitor='val_loss'),\n",
    "        LRThresholdCallback(threshold=9e-5)\n",
    "    ]\n",
    "\n",
    "    print(\"\\n--- Phase 1: Training ---\")\n",
    "    checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\")\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=[phase1_callbacks, checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Phase 2: Fine-tuning ---\")\n",
    "    # model.compile(optimizer=Adam(1e-4), loss='mse', metrics=['mae'])\n",
    "    # phase2_callbacks = [\n",
    "    #     LearningRateScheduler(exponential_decay_schedule),\n",
    "    #     EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss')\n",
    "    # ]\n",
    "    # model.fit(\n",
    "    #     X_train, y_train,\n",
    "    #     epochs=10,\n",
    "    #     batch_size=batch_size,\n",
    "    #     validation_split=validation_split,\n",
    "    #     callbacks=phase2_callbacks,\n",
    "    #     verbose=1\n",
    "    # )\n",
    "\n",
    "    # Return model and normalization parameters\n",
    "    return model, X_mean, X_std, y_mean, y_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05d03f52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T19:20:47.293888Z",
     "start_time": "2025-05-02T19:20:47.285992Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(model, filepath='lstm_1.pkl'):\n",
    "    \"\"\"Save model and scaler together in a pickle file\"\"\"\n",
    "    model_json = model.to_json()\n",
    "    model_weights = model.get_weights()\n",
    "    data = {\n",
    "        'model_json': model_json,\n",
    "        'model_weights': model_weights,\n",
    "    }\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Model saved to {filepath}\")\n",
    "\n",
    "def load_model(filepath='lstm_1.pkl'):\n",
    "    \"\"\"Load model and scaler from pickle file\"\"\"\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    # Reconstruct model\n",
    "    model = tf.keras.models.model_from_json(data['model_json'])\n",
    "    model.set_weights(data['model_weights'])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1bc4b4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T18:42:28.285866Z",
     "start_time": "2025-05-02T18:41:59.875150Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_processed shape: (1980, 10, 3)  # Expected: (N, 10, 3)\n",
      "y_processed shape: (1980, 2)  # Expected: (N, 2)\n",
      "X_normalized shape: (1980, 10, 3)  # (N, 10, 3)\n",
      "y_normalized shape: (1980, 2)  # (N, 2)\n",
      "\n",
      "--- Phase 1: Training ---\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 17:20:32.531123: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/99 [============================>.] - ETA: 0s - loss: 0.0479 - mae: 0.1123WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "99/99 [==============================] - 3s 5ms/step - loss: 0.0476 - mae: 0.1119 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "12/99 [==>...........................] - ETA: 0s - loss: 0.0134 - mae: 0.0752"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# first check that the model can overfit on small data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model, X_mean, X_std, y_mean, y_std  \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 98\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(train_data, batch_size, validation_split, Tobs, Tpred)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Phase 1: Training ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mphase1_callbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    105\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Phase 2: Fine-tuning ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# model.compile(optimizer=Adam(1e-4), loss='mse', metrics=['mae'])\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# phase2_callbacks = [\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m#     LearningRateScheduler(exponential_decay_schedule),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m \n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Return model and normalization parameters\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# first check that the model can overfit on small data\n",
    "model, X_mean, X_std, y_mean, y_std  = train_model(train_data[:20], batch_size=20, validation_split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a51c06da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T18:42:54.682368Z",
     "start_time": "2025-05-02T18:42:54.675886Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_mae_by_timestep(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Visualize MAE across timesteps in the prediction horizon.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): shape (N, Tpred, 2)\n",
    "        y_pred (np.ndarray): shape (N, Tpred, 2)\n",
    "    \"\"\"\n",
    "    mae_per_timestep = np.mean(np.abs(y_true - y_pred), axis=(0, 2))  # shape (Tpred,)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(mae_per_timestep, label='MAE per Timestep')\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.ylabel('MAE (meters)')\n",
    "    plt.title('Mean Absolute Error Over Prediction Horizon')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "978306dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T18:42:55.168565Z",
     "start_time": "2025-05-02T18:42:55.165875Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def forecast_positions(scenario_data, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std):\n",
    "    \"\"\"\n",
    "    Use normalized LSTM model to forecast future deltas and reconstruct absolute positions.\n",
    "\n",
    "    Args:\n",
    "        scenario_data (numpy.ndarray): (agents, time_steps, 6)\n",
    "        Tobs (int): Number of observed steps (e.g. 50)\n",
    "        Tpred (int): Number of steps to forecast (e.g. 60)\n",
    "        model (Model): Trained LSTM model\n",
    "        X_mean, X_std: Normalization stats for deltas (input)\n",
    "        y_mean, y_std: Normalization stats for delta target (output)\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Predicted absolute positions (agents, Tpred, 2)\n",
    "    \"\"\"\n",
    "    agents, _, _ = scenario_data.shape\n",
    "    predicted_positions = np.zeros((agents, Tpred, 2))\n",
    "\n",
    "    for agent_idx in range(agents):\n",
    "        agent_data = scenario_data[agent_idx, :Tobs, :]  # shape (Tobs, 6)\n",
    "\n",
    "        if np.all(agent_data == 0):\n",
    "            continue\n",
    "\n",
    "        # Extract last 11 positions to get 10 deltas\n",
    "        if Tobs < 11:\n",
    "            continue  # not enough for 10 deltas\n",
    "\n",
    "        positions = agent_data[:Tobs, :2]\n",
    "        deltas = np.diff(positions[-11:], axis=0)  # (10, 2)\n",
    "\n",
    "        obj_type = agent_data[0, 5]  # scalar\n",
    "        obj_column = np.full((10, 1), obj_type, dtype=np.float32)\n",
    "\n",
    "        X_window = np.concatenate([deltas, obj_column], axis=1)  # shape (10, 3)\n",
    "\n",
    "        future_positions = []\n",
    "        current_pos = positions[-1]  # last observed position\n",
    "\n",
    "        for _ in range(Tpred):\n",
    "            # Normalize input\n",
    "            X_deltas_norm = (X_window[:, :2] - X_mean.squeeze()) / X_std.squeeze()  # (10, 2)\n",
    "            obj_column = X_window[:, 2:]  # (10, 1)\n",
    "            X_input = np.concatenate([X_deltas_norm, obj_column], axis=1)  # (10, 3)\n",
    "            X_input = np.expand_dims(X_input, axis=0)  # (1, 10, 3)\n",
    "\n",
    "\n",
    "            # Predict normalized delta\n",
    "            pred_delta_norm = model.predict(X_input, verbose=0)[0]  # (2,)\n",
    "            pred_delta = pred_delta_norm * y_std + y_mean  # denormalize\n",
    "\n",
    "            # Update current position\n",
    "            current_pos = current_pos.flatten()  # or use current_pos = current_pos.reshape(-1)\n",
    "            future_positions.append(current_pos.copy())\n",
    "\n",
    "\n",
    "            # Update sliding window with new delta\n",
    "            pred_delta = (pred_delta_norm * y_std + y_mean).squeeze()  # shape (2,)\n",
    "            new_row = np.concatenate([pred_delta, [obj_type]])  # shape (3,)\n",
    "            X_window = np.vstack([X_window[1:], new_row])  # keep last 10 steps\n",
    "\n",
    "        predicted_positions[agent_idx] = np.array(future_positions)\n",
    "\n",
    "    return predicted_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59698794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T18:42:56.727430Z",
     "start_time": "2025-05-02T18:42:56.726626Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def make_gif(data_matrix1, data_matrix2, name='comparison'):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.animation as animation\n",
    "\n",
    "    cmap1 = plt.cm.get_cmap('viridis', 50)\n",
    "    cmap2 = plt.cm.get_cmap('plasma', 50)\n",
    "\n",
    "    assert data_matrix1.shape[1] == data_matrix2.shape[1], \"Both matrices must have same number of timesteps\"\n",
    "    timesteps = data_matrix1.shape[1]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "    ax1, ax2 = axes\n",
    "\n",
    "    def update(frame):\n",
    "        for ax in axes:\n",
    "            ax.clear()\n",
    "\n",
    "        for i in range(data_matrix1.shape[0]):\n",
    "            for (data_matrix, ax, cmap) in [(data_matrix1, ax1, cmap1), (data_matrix2, ax2, cmap2)]:\n",
    "                x = data_matrix[i, frame, 0]\n",
    "                y = data_matrix[i, frame, 1]\n",
    "                if x != 0 and y != 0:\n",
    "                    xs = data_matrix[i, :frame+1, 0]\n",
    "                    ys = data_matrix[i, :frame+1, 1]\n",
    "                    mask = (xs != 0) & (ys != 0)\n",
    "                    xs = xs[mask]\n",
    "                    ys = ys[mask]\n",
    "                    if len(xs) > 0 and len(ys) > 0:\n",
    "                        color = cmap(i)\n",
    "                        ax.plot(xs, ys, alpha=0.9, color=color)\n",
    "                        ax.scatter(x, y, s=80, color=color)\n",
    "\n",
    "        # Plot ego vehicle (index 0) on both\n",
    "        ax1.plot(data_matrix1[0, :frame, 0], data_matrix1[0, :frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "        ax1.scatter(data_matrix1[0, frame, 0], data_matrix1[0, frame, 1], s=80, color='tab:orange')\n",
    "        ax1.set_title('Prediction')\n",
    "\n",
    "        ax2.plot(data_matrix2[0, :frame, 0], data_matrix2[0, :frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "        ax2.scatter(data_matrix2[0, frame, 0], data_matrix2[0, frame, 1], s=80, color='tab:orange')\n",
    "        ax2.set_title('Actual')\n",
    "\n",
    "        for ax, data_matrix in zip(axes, [data_matrix1, data_matrix2]):\n",
    "            ax.set_xlim(data_matrix[:, :, 0][data_matrix[:, :, 0] != 0].min() - 10,\n",
    "                        data_matrix[:, :, 0][data_matrix[:, :, 0] != 0].max() + 10)\n",
    "            ax.set_ylim(data_matrix[:, :, 1][data_matrix[:, :, 1] != 0].min() - 10,\n",
    "                        data_matrix[:, :, 1][data_matrix[:, :, 1] != 0].max() + 10)\n",
    "            ax.legend()\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "\n",
    "        # Compute MSE over non-zero entries up to current frame\n",
    "        mask = (data_matrix2[:, :frame+1, :] != 0) & (data_matrix1[:, :frame+1, :] != 0)\n",
    "        mse = np.mean((data_matrix1[:, :frame+1, :][mask] - data_matrix2[:, :frame+1, :][mask]) ** 2)\n",
    "\n",
    "        fig.suptitle(f\"Timestep {frame} - MSE: {mse:.4f}\", fontsize=16)\n",
    "        return ax1.collections + ax1.lines + ax2.collections + ax2.lines\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, update, frames=list(range(0, timesteps, 3)), interval=100, blit=True)\n",
    "    anim.save(f'trajectory_visualization_{name}.gif', writer='pillow')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3908f5da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T01:00:46.798817Z",
     "start_time": "2025-05-03T01:00:35.906297Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m test_scenario \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# shape (agents, time_steps, features)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Forecast future positions\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m predicted_positions \u001b[38;5;241m=\u001b[39m forecast_positions(test_scenario, Tobs, Tpred, \u001b[43mmodel\u001b[49m, X_mean, X_std, y_mean, y_std)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Create combined matrix of past observed + predicted for ego agent (agent 0)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m ego_past \u001b[38;5;241m=\u001b[39m test_scenario[\u001b[38;5;241m0\u001b[39m, :Tobs, :\u001b[38;5;241m2\u001b[39m]               \u001b[38;5;66;03m# shape (Tobs, 2)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# visualize prediction\n",
    "\n",
    "# model = load_model()\n",
    "\n",
    "# Parameters\n",
    "Tobs = 50\n",
    "Tpred = 60\n",
    "\n",
    "data = train_data[5000]\n",
    "\n",
    "# Select a test scenario (can use any valid index)\n",
    "test_scenario = data.copy()  # shape (agents, time_steps, features)\n",
    "\n",
    "# Forecast future positions\n",
    "predicted_positions = forecast_positions(test_scenario, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std)\n",
    "\n",
    "# Create combined matrix of past observed + predicted for ego agent (agent 0)\n",
    "ego_past = test_scenario[0, :Tobs, :2]               # shape (Tobs, 2)\n",
    "ego_future = predicted_positions[0]                  # shape (Tpred, 2)\n",
    "ego_full = np.concatenate([ego_past, ego_future], axis=0)  # shape (Tobs + Tpred, 2)\n",
    "\n",
    "# Create updated scenario with predicted ego and original others\n",
    "updated_scenario = test_scenario.copy()\n",
    "updated_scenario[0, :Tobs+Tpred, :2] = ego_full  # Replace ego trajectory\n",
    "\n",
    "# Visualize\n",
    "make_gif(updated_scenario, data, name='lstm1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d252d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T22:42:07.483287Z",
     "start_time": "2025-05-02T19:20:54.021001Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_processed shape: (5940000, 10, 3)  # Expected: (N, 10, 3)\n",
      "y_processed shape: (5940000, 2)  # Expected: (N, 2)\n",
      "X_normalized shape: (5940000, 10, 3)  # (N, 10, 3)\n",
      "y_normalized shape: (5940000, 2)  # (N, 2)\n",
      "\n",
      "--- Phase 1: Training ---\n",
      "Epoch 1/50\n",
      "148500/148500 [==============================] - 746s 5ms/step - loss: 2.4501e-04 - mae: 0.0073 - val_loss: 5.1869e-05 - val_mae: 0.0031 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "    28/148500 [..............................] - ETA: 9:40 - loss: 8.2041e-05 - mae: 0.0049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148500/148500 [==============================] - 594s 4ms/step - loss: 7.8802e-05 - mae: 0.0047 - val_loss: 5.6333e-05 - val_mae: 0.0039 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "148500/148500 [==============================] - 618s 4ms/step - loss: 6.8898e-05 - mae: 0.0042 - val_loss: 4.7555e-05 - val_mae: 0.0033 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "148500/148500 [==============================] - 587s 4ms/step - loss: 6.4168e-05 - mae: 0.0040 - val_loss: 6.1671e-05 - val_mae: 0.0045 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "148500/148500 [==============================] - 628s 4ms/step - loss: 6.1111e-05 - mae: 0.0038 - val_loss: 4.8792e-05 - val_mae: 0.0033 - lr: 0.0010\n",
      "Learning rate update: 0.0009000000427477062\n",
      "Epoch 6/50\n",
      "148500/148500 [==============================] - 718s 5ms/step - loss: 5.6700e-05 - mae: 0.0035 - val_loss: 4.2053e-05 - val_mae: 0.0028 - lr: 9.0000e-04\n",
      "Epoch 7/50\n",
      "148500/148500 [==============================] - 590s 4ms/step - loss: 5.5290e-05 - mae: 0.0035 - val_loss: 4.1424e-05 - val_mae: 0.0029 - lr: 9.0000e-04\n",
      "Epoch 8/50\n",
      "148500/148500 [==============================] - 611s 4ms/step - loss: 5.4284e-05 - mae: 0.0034 - val_loss: 5.6365e-05 - val_mae: 0.0040 - lr: 9.0000e-04\n",
      "Epoch 9/50\n",
      "148500/148500 [==============================] - 533s 4ms/step - loss: 5.3153e-05 - mae: 0.0033 - val_loss: 4.7472e-05 - val_mae: 0.0032 - lr: 9.0000e-04\n",
      "Epoch 10/50\n",
      "148500/148500 [==============================] - 511s 3ms/step - loss: 5.2091e-05 - mae: 0.0033 - val_loss: 4.0499e-05 - val_mae: 0.0029 - lr: 9.0000e-04\n",
      "Learning rate update: 0.0008100000384729356\n",
      "Epoch 11/50\n",
      "148500/148500 [==============================] - 509s 3ms/step - loss: 4.9598e-05 - mae: 0.0031 - val_loss: 3.7551e-05 - val_mae: 0.0022 - lr: 8.1000e-04\n",
      "Epoch 12/50\n",
      "148500/148500 [==============================] - 555s 4ms/step - loss: 4.9023e-05 - mae: 0.0031 - val_loss: 4.6536e-05 - val_mae: 0.0030 - lr: 8.1000e-04\n",
      "Epoch 13/50\n",
      "148500/148500 [==============================] - 753s 5ms/step - loss: 4.8133e-05 - mae: 0.0030 - val_loss: 3.3895e-05 - val_mae: 0.0022 - lr: 8.1000e-04\n",
      "Epoch 14/50\n",
      "148500/148500 [==============================] - 667s 4ms/step - loss: 4.7439e-05 - mae: 0.0030 - val_loss: 3.3624e-05 - val_mae: 0.0021 - lr: 8.1000e-04\n",
      "Epoch 15/50\n",
      "148500/148500 [==============================] - 741s 5ms/step - loss: 4.6859e-05 - mae: 0.0029 - val_loss: 3.4348e-05 - val_mae: 0.0024 - lr: 8.1000e-04\n",
      "Learning rate update: 0.0007290000503417104\n",
      "Epoch 16/50\n",
      "148500/148500 [==============================] - 761s 5ms/step - loss: 4.4917e-05 - mae: 0.0028 - val_loss: 4.3547e-05 - val_mae: 0.0034 - lr: 7.2900e-04\n",
      "Epoch 17/50\n",
      "148500/148500 [==============================] - 696s 5ms/step - loss: 4.4497e-05 - mae: 0.0027 - val_loss: 3.2351e-05 - val_mae: 0.0020 - lr: 7.2900e-04\n",
      "Epoch 18/50\n",
      "148500/148500 [==============================] - 535s 4ms/step - loss: 4.4217e-05 - mae: 0.0027 - val_loss: 3.2411e-05 - val_mae: 0.0020 - lr: 7.2900e-04\n",
      "Epoch 19/50\n",
      "148500/148500 [==============================] - 593s 4ms/step - loss: 4.3931e-05 - mae: 0.0027 - val_loss: 4.6072e-05 - val_mae: 0.0034 - lr: 7.2900e-04\n",
      "Epoch 20/50\n",
      "148500/148500 [==============================] - 609s 4ms/step - loss: 4.3659e-05 - mae: 0.0027 - val_loss: 4.1256e-05 - val_mae: 0.0032 - lr: 7.2900e-04\n",
      "Learning rate update: 0.0006561000715009868\n",
      "Epoch 21/50\n",
      "148500/148500 [==============================] - 551s 4ms/step - loss: 4.2469e-05 - mae: 0.0026 - val_loss: 6.2156e-05 - val_mae: 0.0044 - lr: 6.5610e-04\n",
      "\n",
      "--- Phase 2: Fine-tuning ---\n",
      "Model saved to lstm_1.pkl\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model, X_mean, X_std, y_mean, y_std = train_model(standardized_train_data)\n",
    "\n",
    "# Save the model \n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6054870a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T01:01:38.098690Z",
     "start_time": "2025-05-03T01:01:38.097196Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def evaluate_mse(train_data, model, Tobs=50, Tpred=60):\n",
    "    \"\"\"\n",
    "    Computes LSTM prediction for ego agent and evaluates MSE with progress reporting.\n",
    "    \"\"\"\n",
    "    N = train_data.shape[0]\n",
    "    mse_list = []\n",
    "    valid_scenarios = 0\n",
    "    \n",
    "    print(f\"Evaluating {N} scenarios...\")\n",
    "    \n",
    "    # Progress reporting variables\n",
    "    report_interval = max(1, N // 10)  # Report at 10% intervals\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Progress reporting\n",
    "        if i % report_interval == 0 or i == N-1:\n",
    "            print(f\"Processing scenario {i+1}/{N} ({(i+1)/N*100:.1f}%)\")\n",
    "        \n",
    "        scenario_data = train_data[i]\n",
    "        ego_agent_data = scenario_data[0]\n",
    "        ground_truth = ego_agent_data[Tobs:Tobs+Tpred, :2]\n",
    "        \n",
    "        # Skip if ground truth contains all zeros (padded)\n",
    "        if np.all(ground_truth == 0):\n",
    "            continue\n",
    "            \n",
    "        valid_scenarios += 1\n",
    "        \n",
    "        # Forecast future positions\n",
    "        predicted_positions = forecast_positions(\n",
    "            ego_agent_data[np.newaxis, :, :],\n",
    "            Tobs, Tpred, model, X_mean, X_std, y_mean, y_std\n",
    "        )\n",
    "        \n",
    "        # Compute MSE\n",
    "        mse = mean_squared_error(ground_truth, predicted_positions[0])\n",
    "        mse_list.append(mse)\n",
    "        \n",
    "        # Occasional MSE reporting\n",
    "        if i % report_interval == 0:\n",
    "            print(f\"  Current scenario MSE: {mse:.4f}\")\n",
    "    \n",
    "    # Final results\n",
    "    if mse_list:\n",
    "        overall_mse = np.mean(mse_list)\n",
    "        print(f\"Evaluation complete: {valid_scenarios} valid scenarios\")\n",
    "        print(f\"Mean Squared Error (MSE): {overall_mse:.4f}\")\n",
    "        print(f\"Min MSE: {np.min(mse_list):.4f}, Max MSE: {np.max(mse_list):.4f}\")\n",
    "        return overall_mse\n",
    "    else:\n",
    "        print(\"No valid scenarios for evaluation.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c394951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T01:12:28.986816Z",
     "start_time": "2025-05-03T01:04:00.357291Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 2066 scenarios...\n",
      "Processing scenario 1/2066 (0.0%)\n",
      "  Current scenario MSE: 60.5652\n",
      "Processing scenario 207/2066 (10.0%)\n",
      "  Current scenario MSE: 3.6637\n",
      "Processing scenario 413/2066 (20.0%)\n",
      "  Current scenario MSE: 232.1906\n",
      "Processing scenario 619/2066 (30.0%)\n",
      "  Current scenario MSE: 292.2623\n",
      "Processing scenario 825/2066 (39.9%)\n",
      "  Current scenario MSE: 0.1040\n",
      "Processing scenario 1031/2066 (49.9%)\n",
      "  Current scenario MSE: 126.7362\n",
      "Processing scenario 1237/2066 (59.9%)\n",
      "  Current scenario MSE: 350.7167\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate on training data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mevaluate_mse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstandardized_train_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3234\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5300\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 33\u001b[0m, in \u001b[0;36mevaluate_mse\u001b[0;34m(train_data, model, Tobs, Tpred)\u001b[0m\n\u001b[1;32m     30\u001b[0m valid_scenarios \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Forecast future positions\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m predicted_positions \u001b[38;5;241m=\u001b[39m \u001b[43mforecast_positions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mego_agent_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_std\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Compute MSE\u001b[39;00m\n\u001b[1;32m     39\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(ground_truth, predicted_positions[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[20], line 49\u001b[0m, in \u001b[0;36mforecast_positions\u001b[0;34m(scenario_data, Tobs, Tpred, model, X_mean, X_std, y_mean, y_std)\u001b[0m\n\u001b[1;32m     45\u001b[0m X_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(X_input, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# (1, 10, 3)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Predict normalized delta\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m pred_delta_norm \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (2,)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m pred_delta \u001b[38;5;241m=\u001b[39m pred_delta_norm \u001b[38;5;241m*\u001b[39m y_std \u001b[38;5;241m+\u001b[39m y_mean  \u001b[38;5;66;03m# denormalize\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Update current position\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py:2620\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2611\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   2612\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2614\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2617\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2618\u001b[0m         )\n\u001b[0;32m-> 2620\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2623\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2624\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2628\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2630\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2631\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2633\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1688\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1292\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[1;32m   1291\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1292\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:355\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m    353\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mflat_map(slice_batch_indices)\n\u001b[0;32m--> 355\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshuffle_batch\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:388\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.slice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice_inputs\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices_dataset, inputs):\n\u001b[1;32m    373\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Slice inputs into a Dataset of batches.\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    Given a Dataset of batch indices and the unsliced inputs,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m      A Dataset of input batches matching the batch indices.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    387\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mzip(\n\u001b[0;32m--> 388\u001b[0m         (indices_dataset, \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    389\u001b[0m     )\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrab_batch\u001b[39m(i, data):\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    393\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m d: tf\u001b[38;5;241m.\u001b[39mgather(d, i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), data\n\u001b[1;32m    394\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:1349\u001b[0m, in \u001b[0;36mDatasetV2.repeat\u001b[0;34m(self, count, name)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> repeat_op ->\u001b[39;00m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access,redefined-outer-name\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m repeat_op\n\u001b[0;32m-> 1349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepeat_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_repeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/ops/repeat_op.py:25\u001b[0m, in \u001b[0;36m_repeat\u001b[0;34m(input_dataset, count, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repeat\u001b[39m(input_dataset, count, name):  \u001b[38;5;66;03m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_RepeatDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/ops/repeat_op.py:40\u001b[0m, in \u001b[0;36m_RepeatDataset.__init__\u001b[0;34m(self, input_dataset, count, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m     38\u001b[0m       count, dtype\u001b[38;5;241m=\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mint64, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m---> 40\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_common_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/ops/gen_dataset_ops.py:6286\u001b[0m, in \u001b[0;36mrepeat_dataset\u001b[0;34m(input_dataset, count, output_types, output_shapes, metadata, name)\u001b[0m\n\u001b[1;32m   6284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   6285\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6286\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRepeatDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   6290\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate on training data\n",
    "evaluate_mse(standardized_train_data[4300:5300], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c67b4ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T06:16:59.708670Z",
     "start_time": "2025-05-03T06:15:13.300547Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_submission(data, output_csv, Tobs=50, Tpred=60):\n",
    "    \"\"\"\n",
    "    Applies forecasting and generates a submission CSV with format:\n",
    "    index,x,y where index is auto-generated and matches submission key.\n",
    "    \n",
    "    Args:\n",
    "        data (np.ndarray): Test data of shape (num_scenarios, 50, 50, 6).\n",
    "        output_csv (str): Output CSV file path.\n",
    "        Tobs (int): Observed time steps (default 50).\n",
    "        Tpred (int): Prediction time steps (default 60).\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        scenario_data = data[i]            # Shape: (50, 50, 6)\n",
    "        \n",
    "        # Step 1: Standardize the scene data\n",
    "        standardized_scenario, min_values = standardize_data_dimensions(scenario_data)\n",
    "        \n",
    "        # Extract ego agent data from standardized scenario\n",
    "        ego_agent_data = standardized_scenario[0]  # Shape: (50, 6)\n",
    "\n",
    "        # Step 2: Predict future positions for the ego agent using standardized data\n",
    "        predicted_positions = forecast_positions(\n",
    "            ego_agent_data[np.newaxis, :, :], Tobs, Tpred, model, X_mean, X_std, y_mean, y_std\n",
    "        )  # Shape: (1, 60, 2)\n",
    "\n",
    "        # Step 3: Denormalize the predictions to restore original coordinate system\n",
    "        # Create a dummy array with the same structure as the standardized data for denormalization\n",
    "        # We only need to denormalize the x,y positions (first 2 columns)\n",
    "        dummy_predictions = np.zeros((1, Tpred, 6))  # Shape: (1, 60, 6)\n",
    "        dummy_predictions[0, :, :2] = predicted_positions[0]  # Insert predicted x,y positions\n",
    "        \n",
    "        # Denormalize the predictions\n",
    "        denormalized_predictions = denormalize_predictions(dummy_predictions, min_values)\n",
    "        \n",
    "        # Extract only the x,y positions from denormalized predictions\n",
    "        final_positions = denormalized_predictions[0, :, :2]  # Shape: (60, 2)\n",
    "\n",
    "        # Append 60 predictions (x, y) for this scenario\n",
    "        predictions.extend(final_positions)  # Shape: (60, 2)\n",
    "\n",
    "    # Create DataFrame without explicit ID\n",
    "    submission_df = pd.DataFrame(predictions, columns=[\"x\", \"y\"])\n",
    "    submission_df.index.name = 'index'  # Match Kaggle format\n",
    "\n",
    "    # Save CSV with index\n",
    "    submission_df.to_csv(output_csv)\n",
    "    print(f\"Submission file '{output_csv}' saved with shape {submission_df.shape}\")\n",
    "\n",
    "# Generate submission with standardization\n",
    "generate_submission(test_data, 'lstm_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb89c0f4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
